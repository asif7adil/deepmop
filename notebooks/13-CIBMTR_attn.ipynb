{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69da942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b20d8a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob, os\n",
    "\n",
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pyprojroot import here\n",
    "\n",
    "# Add the project root to sys.path\n",
    "sys.path.append(str(here()))\n",
    "\n",
    "from hspc.config import get_config\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53860844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "plt.style.use('default')\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "863c5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6af76f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dc61ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60d62b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn import TabPFNClassifier as tbp\n",
    "import shapiq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d420c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f4cf313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df_raw = pd.read_sas(here() / config.data / 'external' / 'cibmtr' / 'cibmtr.sas7bdat', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1055c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "coll_yr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "twodaycoll",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wbc0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "plt0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hgb0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skeletal0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxmtc0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wbc5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "plt5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hgb5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bld_vol5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wbc6pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "plt6pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hgb6pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bld_vol6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skeletal2d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxmtc2d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skeletal1w",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxmtc1w",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skeletal1m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxmtc1m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skeletal6m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxmtc6m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skeletal1y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxmtc1y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p1_mnc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p1_cd34",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p2_mnc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p2_cd34",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_wt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_bmi_grp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gcsf_dse1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gcsf_dsettl",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxmtc1_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxskeletal1_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absneut0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absmnc0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absneut5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absmnc5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absneut6pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absmnc6pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "abscd34_5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "abscd34_6pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wbc0_5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "plt0_5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absmnc0_5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ttl_cd34",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ttl_mnc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bld_vol_ttl",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bld_vol_ttl_grp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxmtc1_5_24",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxmtc1_5_34",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxmtc1_6_24",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxmtc1_6_34",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxmtc2d_24",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxmtc2d_34",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxmtc1m_24",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxmtc1m_34",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxmtc6m_24",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxmtc6m_34",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxskeletal1_5_24",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxskeletal1_5_34",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxskeletal1_6_24",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "maxskeletal1_6_34",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bld_vol5_grp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bld_vol6_grp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dsex",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "drace",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "coll_age_gp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hosp5n",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hypo_cad5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hypo_cad5_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "clined5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "clined5_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pseudoid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pseudoctr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RqstgtcollectedDay1",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2f3579bd-269b-49f8-966d-d395fec57647",
       "rows": [
        [
         "0",
         "2008.0",
         "0.0",
         "3.8",
         "159.0",
         "15.5",
         "0.0",
         "0.0",
         "13.0",
         "136.0",
         "14.4",
         "18.0",
         null,
         null,
         null,
         null,
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "58.8",
         "317.0",
         null,
         null,
         "93.0",
         "4.0",
         "10.32",
         "51.61",
         "1.0",
         "2.0",
         "2.24",
         "1.56",
         "10.79",
         "2.21",
         null,
         null,
         "11.7",
         null,
         "9.2",
         "-23.0",
         "0.65",
         "317.0",
         "58.8",
         "18.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "7.0",
         "4.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "93409976.0",
         "10366760.0",
         "-9.0"
        ],
        [
         "1",
         "2015.0",
         "0.0",
         "5.5",
         "218.0",
         "13.2",
         "0.0",
         "0.0",
         "31.2",
         "232.0",
         "12.2",
         "21.5",
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         null,
         null,
         "57.71",
         "930.0",
         null,
         null,
         "79.0",
         "3.0",
         "11.39",
         "56.96",
         "1.0",
         "1.0",
         "3.0",
         "2.49",
         "26.36",
         "4.8",
         null,
         null,
         "70.2",
         null,
         "25.7",
         "14.0",
         "2.32",
         "930.0",
         "57.71",
         "21.5",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "2.0",
         "1.0",
         "4.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "93370093.0",
         "10366776.0",
         "0.0"
        ],
        [
         "2",
         "2007.0",
         "0.0",
         "6.1",
         "175.0",
         "15.0",
         "0.0",
         "0.0",
         "31.5",
         "181.0",
         "14.9",
         "24.0",
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "72.8",
         "459.0",
         null,
         null,
         "124.0",
         "4.0",
         "9.68",
         "48.39",
         "1.0",
         "1.0",
         "3.23",
         "2.87",
         "26.46",
         "5.04",
         null,
         null,
         "22.05",
         null,
         "25.4",
         "6.0",
         "2.17",
         "459.0",
         "72.8",
         "24.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "7.0",
         "4.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "93323774.0",
         "10366760.0",
         "-9.0"
        ],
        [
         "3",
         "2011.0",
         "0.0",
         "8.0",
         "280.0",
         "15.4",
         "1.0",
         "0.0",
         "68.4",
         "230.0",
         "15.9",
         "24.0",
         null,
         null,
         null,
         null,
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         null,
         null,
         "108.67",
         "1023.8",
         null,
         null,
         "84.0",
         "3.0",
         "10.71",
         "53.57",
         "1.0",
         "1.0",
         "5.04",
         "2.96",
         "60.19",
         "8.21",
         null,
         null,
         "87.55",
         null,
         "60.400000000000006",
         "-50.0",
         "5.25",
         "1023.8",
         "108.67",
         "24.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "4.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "93344918.0",
         "10366785.0",
         "-9.0"
        ],
        [
         "4",
         "2008.0",
         "0.0",
         "8.1",
         "351.0",
         "13.2",
         "0.0",
         "0.0",
         "34.0",
         "278.0",
         "11.7",
         "24.0",
         null,
         null,
         null,
         null,
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "87.1",
         "1053.0",
         null,
         null,
         "94.0",
         "4.0",
         "10.21",
         "45.96",
         "1.0",
         "1.0",
         "4.94",
         "3.16",
         "26.18",
         "7.82",
         null,
         null,
         "51.0",
         null,
         "25.9",
         "-73.0",
         "4.66",
         "1053.0",
         "87.1",
         "24.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "2.0",
         "7.0",
         "4.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "93355053.0",
         "10366760.0",
         "-9.0"
        ],
        [
         "5",
         "2010.0",
         "0.0",
         "4.2",
         "299.0",
         "16.1",
         "0.0",
         "0.0",
         "54.9",
         "222.0",
         "14.3",
         "22.0",
         null,
         null,
         null,
         null,
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "64.97",
         "640.5",
         null,
         null,
         "95.0",
         "3.0",
         "10.11",
         "50.53",
         "1.0",
         "2.0",
         "2.18",
         "2.02",
         "47.21",
         "7.69",
         null,
         null,
         "76.86",
         null,
         "50.699999999999996",
         "-77.0",
         "5.67",
         "640.5",
         "64.97",
         "22.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "7.0",
         "4.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "93562560.0",
         "10366758.0",
         "0.0"
        ],
        [
         "6",
         "2010.0",
         "0.0",
         "7.1",
         "256.0",
         "16.2",
         "0.0",
         "0.0",
         "42.4",
         "199.0",
         "14.6",
         "24.0",
         null,
         null,
         null,
         null,
         "1.0",
         "0.0",
         "0.0",
         "2.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         null,
         null,
         "77.37",
         "1465.5",
         null,
         null,
         "87.09",
         "3.0",
         "10.33",
         "51.67",
         "0.0",
         "1.0",
         "4.54",
         "2.56",
         "36.04",
         "6.36",
         null,
         null,
         "106.0",
         null,
         "35.3",
         "-57.0",
         "3.8",
         "1465.5",
         "77.37",
         "24.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "3.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "93568857.0",
         "10366758.0",
         "-9.0"
        ],
        [
         "7",
         "2006.0",
         "0.0",
         "5.4",
         "244.0",
         "12.9",
         "1.0",
         "1.0",
         "29.2",
         "267.0",
         "12.1",
         "24.0",
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         null,
         null,
         "0.0",
         "2.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "73.3",
         "619.0",
         null,
         null,
         "54.0",
         "2.0",
         "11.11",
         "55.56",
         "2.0",
         "2.0",
         "3.35",
         "2.05",
         "23.07",
         "6.13",
         null,
         null,
         "37.96",
         null,
         "23.799999999999997",
         "23.0",
         "4.08",
         "619.0",
         "73.3",
         "24.0",
         "3.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "2.0",
         "1.0",
         "3.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "93571163.0",
         "10366760.0",
         "-9.0"
        ],
        [
         "8",
         "2006.0",
         "0.0",
         "5.5",
         "188.0",
         "15.7",
         "0.0",
         "0.0",
         "38.7",
         "212.0",
         "15.2",
         "22.0",
         null,
         null,
         null,
         null,
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "46.4",
         "920.0",
         null,
         null,
         "97.0",
         "3.0",
         "9.9",
         "49.48",
         "1.0",
         "1.0",
         "3.41",
         "2.09",
         "30.19",
         "8.51",
         null,
         null,
         "46.44",
         null,
         "33.2",
         "24.0",
         "6.42",
         "920.0",
         "46.4",
         "22.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "4.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "93580161.0",
         "10366760.0",
         "-9.0"
        ],
        [
         "9",
         "2011.0",
         "0.0",
         "5.8",
         "247.0",
         "13.9",
         "0.0",
         "1.0",
         "25.8",
         "182.0",
         "13.7",
         "20.0",
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "43.04",
         "758.0",
         null,
         null,
         "91.63",
         "4.0",
         "10.48",
         "52.39",
         "1.0",
         "2.0",
         "3.71",
         "2.09",
         "21.98",
         "3.82",
         null,
         null,
         "67.08",
         null,
         "20.0",
         "-65.0",
         "1.73",
         "758.0",
         "43.04",
         "20.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "2.0",
         "1.0",
         "4.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "93525333.0",
         "10366846.0",
         "0.0"
        ],
        [
         "10",
         "2013.0",
         "0.0",
         "10.3",
         "425.0",
         "12.5",
         "0.0",
         "0.0",
         "43.4",
         "244.0",
         "11.7",
         "18.2",
         null,
         null,
         null,
         null,
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "56.04",
         "655.5",
         null,
         null,
         "66.0",
         "2.0",
         "11.82",
         "59.09",
         "1.0",
         "1.0",
         "7.27",
         "3.03",
         "40.8",
         "2.6",
         null,
         null,
         "81.16",
         null,
         "33.099999999999994",
         "-181.0",
         "-0.42",
         "655.5",
         "56.04",
         "18.2",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "2.0",
         "1.0",
         "4.0",
         "0.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "93529830.0",
         "10366800.0",
         "0.0"
        ],
        [
         "11",
         "2014.0",
         "0.0",
         "5.3",
         "188.0",
         "15.4",
         "0.0",
         "0.0",
         "33.9",
         "135.0",
         "15.7",
         "24.0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         null,
         null,
         "59.99",
         "323.1",
         null,
         null,
         "105.23",
         "4.0",
         "10.26",
         "51.31",
         "1.0",
         "1.0",
         "3.13",
         "2.17",
         "27.46",
         "6.44",
         null,
         null,
         "88.14",
         null,
         "28.599999999999998",
         "-53.0",
         "4.27",
         "323.1",
         "59.99",
         "24.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "99.0",
         "99.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "7.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "93530273.0",
         "10366758.0",
         "1.0"
        ],
        [
         "12",
         "2009.0",
         "0.0",
         "6.6",
         "192.0",
         "14.2",
         "1.0",
         "0.0",
         "41.4",
         "168.0",
         "14.7",
         "24.0",
         null,
         null,
         null,
         null,
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "0.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "0.0",
         "53.5",
         "977.3",
         null,
         null,
         "119.75",
         "4.0",
         "9.02",
         "45.09",
         "2.0",
         "2.0",
         "4.09",
         "2.51",
         "33.53",
         "7.87",
         null,
         null,
         "82.8",
         null,
         "34.8",
         "-24.0",
         "5.36",
         "977.3",
         "53.5",
         "24.0",
         "3.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "4.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "93538145.0",
         "10366611.0",
         "0.0"
        ],
        [
         "13",
         "2008.0",
         "0.0",
         "7.1",
         "233.0",
         "14.5",
         "0.0",
         "0.0",
         "40.2",
         "178.0",
         "14.4",
         "12.0",
         null,
         null,
         null,
         null,
         "1.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "38.0",
         "399.5",
         null,
         null,
         "120.9",
         "4.0",
         "8.93",
         "44.67",
         "3.0",
         "2.0",
         "4.19",
         "2.84",
         "32.96",
         "7.24",
         null,
         null,
         "52.26",
         null,
         "33.1",
         "-55.0",
         "4.4",
         "399.5",
         "38.0",
         "12.0",
         "2.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "2.0",
         "99.0",
         "1.0",
         "1.0",
         "4.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "93538145.0",
         "10366611.0",
         "-9.0"
        ],
        [
         "14",
         "2008.0",
         "0.0",
         "5.6",
         "238.0",
         "17.0",
         "0.0",
         "0.0",
         "35.5",
         "207.0",
         "15.7",
         "20.0",
         null,
         null,
         null,
         null,
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "40.2",
         "952.0",
         null,
         null,
         "103.63",
         "4.0",
         "10.42",
         "52.11",
         "0.0",
         "2.0",
         "3.26",
         "2.34",
         "30.0",
         "5.5",
         null,
         null,
         "97.63",
         null,
         "29.9",
         "-31.0",
         "3.17",
         "952.0",
         "40.2",
         "20.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "4.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "93544412.0",
         "10366776.0",
         "-9.0"
        ],
        [
         "15",
         "2009.0",
         "0.0",
         "5.6",
         "204.0",
         "14.0",
         "0.0",
         "0.0",
         "25.3",
         "131.0",
         "13.5",
         "18.2",
         null,
         null,
         null,
         null,
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "58.79",
         "455.8",
         null,
         null,
         "79.0",
         "2.0",
         "11.39",
         "56.96",
         "0.0",
         "1.0",
         "3.75",
         "1.85",
         "23.68",
         "1.62",
         null,
         null,
         "35.42",
         null,
         "19.700000000000003",
         "-73.0",
         "-0.23",
         "455.8",
         "58.79",
         "18.2",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "93469126.0",
         "10366846.0",
         "-9.0"
        ],
        [
         "16",
         "2013.0",
         "0.0",
         "5.5",
         "173.0",
         "14.2",
         "0.0",
         "0.0",
         "28.0",
         "189.0",
         "14.1",
         "19.5",
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "40.96",
         "684.2",
         null,
         null,
         "87.0",
         "4.0",
         "10.34",
         "51.72",
         "1.0",
         "1.0",
         "4.03",
         "1.47",
         "24.81",
         "3.19",
         null,
         null,
         "103.6",
         null,
         "22.5",
         "16.0",
         "1.72",
         "684.2",
         "40.96",
         "19.5",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "4.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "93677034.0",
         "10366966.0",
         "0.0"
        ],
        [
         "17",
         "2007.0",
         "0.0",
         "10.8",
         "398.0",
         "15.3",
         "0.0",
         "0.0",
         "62.5",
         "316.0",
         "14.4",
         "18.0",
         null,
         null,
         null,
         null,
         "2.0",
         "2.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "66.5",
         "627.3",
         null,
         null,
         "85.0",
         "4.0",
         "10.59",
         "52.94",
         "1.0",
         "2.0",
         "7.48",
         "3.3",
         "46.88",
         "15.63",
         null,
         null,
         "93.75",
         null,
         "51.7",
         "-82.0",
         "12.32",
         "627.3",
         "66.5",
         "18.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "2.0",
         "1.0",
         "4.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "93629310.0",
         "10366613.0",
         "-9.0"
        ],
        [
         "18",
         "2007.0",
         "0.0",
         "5.6",
         "191.0",
         "17.1",
         "0.0",
         "0.0",
         "61.0",
         "176.0",
         "15.9",
         "24.0",
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "85.2",
         "433.3",
         null,
         null,
         "77.27",
         "3.0",
         "10.09",
         "50.47",
         "1.0",
         "2.0",
         "3.98",
         "1.62",
         "55.51",
         "5.49",
         null,
         null,
         "73.2",
         null,
         "55.4",
         "-15.0",
         "3.87",
         "433.3",
         "85.2",
         "24.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "3.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "93650522.0",
         "10366924.0",
         "-9.0"
        ],
        [
         "19",
         "2016.0",
         "0.0",
         "6.2",
         "198.0",
         "15.2",
         "0.0",
         "0.0",
         "52.6",
         "223.0",
         "13.4",
         "24.0",
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         null,
         null,
         "66.25",
         "916.5",
         null,
         null,
         "112.49",
         "4.0",
         "10.67",
         "53.34",
         "0.0",
         "0.0",
         "3.97",
         "2.17",
         "44.39",
         "8.21",
         null,
         null,
         "42.08",
         null,
         "46.4",
         "25.0",
         "6.04",
         "916.5",
         "66.25",
         "24.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "4.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "93609903.0",
         "10366846.0",
         "-9.0"
        ],
        [
         "20",
         "2010.0",
         "0.0",
         "8.2",
         "343.0",
         "14.0",
         "0.0",
         "0.0",
         "33.8",
         "328.0",
         "13.6",
         "12.0",
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "40.16",
         "1280.4",
         null,
         null,
         "68.0",
         "2.0",
         "11.47",
         "57.35",
         "2.0",
         "1.0",
         "5.17",
         "2.87",
         "23.32",
         "10.48",
         null,
         null,
         "270.4",
         null,
         "25.599999999999998",
         "-15.0",
         "7.61",
         "1280.4",
         "40.16",
         "12.0",
         "2.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2.0",
         "99.0",
         "1.0",
         "1.0",
         "4.0",
         "0.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "93611587.0",
         "10366727.0",
         "0.0"
        ],
        [
         "21",
         "2010.0",
         "0.0",
         "8.6",
         "201.0",
         "16.0",
         "0.0",
         "0.0",
         "42.2",
         "200.0",
         "13.0",
         "20.7",
         null,
         null,
         null,
         null,
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         null,
         null,
         "32.72",
         "910.4",
         null,
         null,
         "88.0",
         "4.0",
         "10.23",
         "51.14",
         "1.0",
         "2.0",
         "6.71",
         "1.89",
         "27.85",
         "14.35",
         null,
         null,
         "88.62",
         null,
         "33.6",
         "-1.0",
         "12.46",
         "910.4",
         "32.72",
         "20.7",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "4.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "93612785.0",
         "10366753.0",
         "0.0"
        ],
        [
         "22",
         "2014.0",
         "0.0",
         "6.1",
         "207.0",
         "13.0",
         "0.0",
         "0.0",
         "46.6",
         "216.0",
         "13.1",
         "11.3",
         null,
         null,
         null,
         null,
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "39.12",
         "729.0",
         null,
         null,
         "88.0",
         "4.0",
         "10.23",
         "51.14",
         "1.0",
         "2.0",
         "3.89",
         "2.21",
         "43.34",
         "3.26",
         null,
         null,
         "116.5",
         null,
         "40.5",
         "9.0",
         "1.05",
         "729.0",
         "39.12",
         "11.3",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "99.0",
         "1.0",
         "1.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "93828609.0",
         "10366760.0",
         "-9.0"
        ],
        [
         "23",
         "2010.0",
         "0.0",
         "7.8",
         "247.0",
         "14.6",
         "0.0",
         "0.0",
         "43.8",
         "211.0",
         "13.2",
         "18.0",
         null,
         null,
         null,
         null,
         "1.0",
         "1.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "47.29",
         "611.5",
         null,
         null,
         "81.0",
         "2.0",
         "11.11",
         "55.56",
         "1.0",
         "2.0",
         "4.24",
         "3.51",
         "35.78",
         "8.02",
         null,
         null,
         "122.64",
         null,
         "36.0",
         "-36.0",
         "4.51",
         "611.5",
         "47.29",
         "18.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "93770923.0",
         "10366728.0",
         "-9.0"
        ],
        [
         "24",
         "2009.0",
         "0.0",
         "5.3",
         "196.0",
         "14.6",
         "0.0",
         "0.0",
         "28.5",
         "185.0",
         "13.3",
         "24.0",
         null,
         null,
         null,
         null,
         "1.0",
         "2.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "44.4",
         "424.6",
         null,
         null,
         "75.45",
         "2.0",
         "10.34",
         "51.69",
         "1.0",
         "2.0",
         "3.13",
         "2.17",
         "24.51",
         "3.99",
         null,
         null,
         "62.7",
         null,
         "23.2",
         "-11.0",
         "1.82",
         "424.6",
         "44.4",
         "24.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "3.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "93722512.0",
         "10366728.0",
         "-9.0"
        ],
        [
         "25",
         "2011.0",
         "0.0",
         "7.8",
         "287.0",
         "13.8",
         "0.0",
         "3.0",
         "32.1",
         "275.0",
         "12.8",
         "24.0",
         null,
         null,
         null,
         null,
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "70.9",
         "223.0",
         null,
         null,
         "87.0",
         "3.0",
         "10.34",
         "51.72",
         "1.0",
         "1.0",
         "4.98",
         "2.82",
         "24.72",
         "8.35",
         null,
         null,
         "19.26",
         null,
         "24.3",
         "-12.0",
         "5.52",
         "223.0",
         "70.9",
         "24.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "2.0",
         "1.0",
         "4.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "93961139.0",
         "10366612.0",
         "-9.0"
        ],
        [
         "26",
         "2010.0",
         "0.0",
         "6.0",
         "232.0",
         "13.9",
         "0.0",
         "0.0",
         "43.8",
         "239.0",
         "13.7",
         "24.0",
         null,
         null,
         null,
         null,
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         null,
         null,
         "60.97",
         "469.3",
         null,
         null,
         "64.41",
         "2.0",
         "12.11",
         "60.55",
         "1.0",
         "2.0",
         "4.44",
         "1.56",
         "37.23",
         "6.57",
         null,
         null,
         "52.56",
         null,
         "37.8",
         "7.0",
         "5.01",
         "469.3",
         "60.97",
         "24.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "2.0",
         "1.0",
         "3.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "93902962.0",
         "10366924.0",
         "0.0"
        ],
        [
         "27",
         "2011.0",
         "0.0",
         "6.7",
         "252.0",
         "13.3",
         "0.0",
         "0.0",
         "23.4",
         "205.0",
         "13.1",
         "12.0",
         null,
         null,
         null,
         null,
         "1.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "36.28",
         "343.7",
         null,
         null,
         "74.84",
         "4.0",
         "10.42",
         "52.11",
         "1.0",
         "1.0",
         "4.22",
         "2.41",
         "18.25",
         "5.15",
         null,
         null,
         "46.8",
         null,
         "16.7",
         "-47.0",
         "2.74",
         "343.7",
         "36.28",
         "12.0",
         "2.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2.0",
         "99.0",
         "2.0",
         "1.0",
         "3.0",
         "0.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "93912879.0",
         "10366611.0",
         "-9.0"
        ],
        [
         "28",
         "2013.0",
         "0.0",
         "4.9",
         "197.0",
         "13.5",
         "0.0",
         "0.0",
         "22.1",
         "195.0",
         "14.0",
         "18.0",
         null,
         null,
         null,
         null,
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         null,
         null,
         null,
         null,
         null,
         null,
         "44.59",
         "325.0",
         null,
         null,
         "63.5",
         "2.0",
         "12.28",
         "61.41",
         "1.0",
         "2.0",
         "2.93",
         "1.97",
         "18.79",
         "3.32",
         null,
         null,
         "37.57",
         null,
         "17.200000000000003",
         "-2.0",
         "1.35",
         "325.0",
         "44.59",
         "18.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "99.0",
         "99.0",
         "99.0",
         "99.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "2.0",
         "1.0",
         "3.0",
         "0.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "93912879.0",
         "10366765.0",
         "-9.0"
        ],
        [
         "29",
         "2007.0",
         "0.0",
         "7.5",
         "191.0",
         "16.7",
         "0.0",
         "0.0",
         "47.5",
         "189.0",
         "15.2",
         "24.0",
         null,
         null,
         null,
         null,
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "40.2",
         "608.7",
         null,
         null,
         "93.63",
         "3.0",
         "10.25",
         "51.27",
         "1.0",
         "2.0",
         "5.92",
         "1.5",
         "43.23",
         "3.66",
         null,
         null,
         "61.75",
         null,
         "40.0",
         "-2.0",
         "2.16",
         "608.7",
         "40.2",
         "24.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "2.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "93855245.0",
         "10366970.0",
         "-9.0"
        ],
        [
         "30",
         "2010.0",
         "0.0",
         "6.3",
         "251.0",
         "13.7",
         "0.0",
         "0.0",
         "46.5",
         "214.0",
         "12.2",
         "16.0",
         null,
         null,
         null,
         null,
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2.0",
         "0.0",
         "0.0",
         "0.0",
         "28.69",
         "808.4",
         null,
         null,
         "87.0",
         "4.0",
         "10.34",
         "46.9",
         "2.0",
         "3.0",
         "3.53",
         "2.77",
         "36.74",
         "9.77",
         null,
         null,
         "102.3",
         null,
         "40.2",
         "-37.0",
         "6.99",
         "808.4",
         "28.69",
         "16.0",
         "2.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "2.0",
         "99.0",
         "2.0",
         "1.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "94086404.0",
         "10366753.0",
         "0.0"
        ],
        [
         "31",
         "2006.0",
         "0.0",
         "5.9",
         "286.0",
         "16.3",
         "0.0",
         "0.0",
         "54.9",
         "235.0",
         "16.4",
         "24.0",
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         null,
         null,
         "46.4",
         "1223.4",
         null,
         null,
         "75.0",
         "3.0",
         "10.4",
         "52.0",
         "1.0",
         "2.0",
         "4.08",
         "1.82",
         "47.87",
         "6.97",
         null,
         null,
         "878.4",
         null,
         "49.0",
         "-51.0",
         "5.16",
         "1223.4",
         "46.4",
         "24.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "4.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "94101687.0",
         "10366728.0",
         "-9.0"
        ],
        [
         "32",
         "2013.0",
         "0.0",
         "6.7",
         "271.0",
         "13.6",
         "0.0",
         "0.0",
         "47.9",
         "206.0",
         "13.6",
         "22.0",
         null,
         null,
         null,
         null,
         "2.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "55.31",
         "449.6",
         null,
         null,
         "66.0",
         "2.0",
         "11.82",
         "59.09",
         "1.0",
         "1.0",
         "3.73",
         "2.97",
         "37.12",
         "10.78",
         null,
         null,
         "57.48",
         null,
         "41.199999999999996",
         "-65.0",
         "7.81",
         "449.6",
         "55.31",
         "22.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "2.0",
         "1.0",
         "4.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "94056760.0",
         "10366767.0",
         "-9.0"
        ],
        [
         "33",
         "2007.0",
         "0.0",
         "7.5",
         "318.0",
         "14.5",
         "1.0",
         "0.0",
         "42.6",
         "249.0",
         "13.5",
         "24.0",
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         null,
         null,
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "71.4",
         "574.4",
         null,
         null,
         "96.0",
         "3.0",
         "10.0",
         "50.0",
         "0.0",
         "1.0",
         "5.28",
         "2.23",
         "35.36",
         "7.24",
         null,
         null,
         "85.2",
         null,
         "35.1",
         "-69.0",
         "5.01",
         "574.4",
         "71.4",
         "24.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "4.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "93987175.0",
         "10366767.0",
         "-9.0"
        ],
        [
         "34",
         "2016.0",
         "0.0",
         "5.7",
         "217.0",
         "14.1",
         "0.0",
         "0.0",
         "50.7",
         "225.0",
         "14.5",
         "20.7",
         null,
         null,
         null,
         null,
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         null,
         null,
         "38.84",
         "659.2",
         null,
         null,
         "90.27",
         "4.0",
         "9.97",
         "49.85",
         "3.0",
         "3.0",
         "3.31",
         "2.39",
         "44.51",
         "6.19",
         null,
         null,
         "106.47",
         null,
         "45.0",
         "8.0",
         "3.79",
         "659.2",
         "38.84",
         "20.7",
         "3.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "3.0",
         "99.0",
         "2.0",
         "2.0",
         "4.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "93993202.0",
         "10366940.0",
         "0.0"
        ],
        [
         "35",
         "2007.0",
         "0.0",
         "5.4",
         "273.0",
         "15.1",
         "0.0",
         "0.0",
         "28.9",
         "177.0",
         "14.0",
         "18.0",
         null,
         null,
         null,
         null,
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "37.2",
         "754.0",
         null,
         null,
         "105.9",
         "4.0",
         "10.2",
         "50.99",
         "1.0",
         "2.0",
         "3.62",
         "1.78",
         "26.01",
         "2.89",
         null,
         null,
         "112.71",
         null,
         "23.5",
         "-96.0",
         "1.11",
         "754.0",
         "37.2",
         "18.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "7.0",
         "2.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "93994677.0",
         "10366740.0",
         "-9.0"
        ],
        [
         "36",
         "2012.0",
         "0.0",
         "7.6",
         "275.0",
         "16.2",
         "0.0",
         "0.0",
         "34.4",
         "262.0",
         "15.6",
         "24.0",
         null,
         null,
         null,
         null,
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         null,
         null,
         "0.0",
         "0.0",
         "47.23",
         "565.0",
         null,
         null,
         "69.4",
         "2.0",
         "11.24",
         "56.2",
         "1.0",
         "1.0",
         "6.22",
         "1.38",
         "27.52",
         "6.88",
         null,
         null,
         "72.24",
         null,
         "26.799999999999997",
         "-13.0",
         "5.5",
         "565.0",
         "47.23",
         "24.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "99.0",
         "99.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "4.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "94177942.0",
         "10366964.0",
         "-9.0"
        ],
        [
         "37",
         "2007.0",
         "0.0",
         "8.4",
         "208.0",
         "13.0",
         "0.0",
         "0.0",
         "38.4",
         "223.0",
         "13.0",
         "22.0",
         null,
         null,
         null,
         null,
         "1.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "43.7",
         "119.8",
         null,
         null,
         "54.54",
         "2.0",
         "11.0",
         "55.01",
         "1.0",
         "1.0",
         "6.47",
         "1.93",
         "31.87",
         "6.14",
         null,
         null,
         "15.36",
         null,
         "30.0",
         "15.0",
         "4.21",
         "119.8",
         "43.7",
         "22.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "2.0",
         "1.0",
         "2.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "94191277.0",
         "10366924.0",
         "-9.0"
        ],
        [
         "38",
         "2007.0",
         "0.0",
         "4.3",
         "383.0",
         "13.5",
         "0.0",
         "0.0",
         "41.5",
         "336.0",
         "12.6",
         "18.0",
         null,
         null,
         null,
         null,
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         null,
         null,
         "30.7",
         "399.0",
         null,
         null,
         "69.09",
         "3.0",
         "11.29",
         "56.45",
         "1.0",
         "2.0",
         "2.55",
         "1.75",
         "34.94",
         "6.52",
         null,
         null,
         "83.0",
         null,
         "37.2",
         "-47.0",
         "4.77",
         "399.0",
         "30.7",
         "18.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "2.0",
         "1.0",
         "4.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "94203152.0",
         "10366776.0",
         "-9.0"
        ],
        [
         "39",
         "2007.0",
         "0.0",
         "7.2",
         "204.0",
         "14.4",
         "1.0",
         "1.0",
         "74.5",
         "218.0",
         "14.8",
         "12.0",
         null,
         null,
         null,
         null,
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "31.9",
         "802.0",
         null,
         null,
         "75.0",
         "3.0",
         "10.4",
         "52.0",
         "3.0",
         "2.0",
         "4.82",
         "2.38",
         "65.41",
         "9.01",
         null,
         null,
         "298.0",
         null,
         "67.3",
         "14.0",
         "6.64",
         "802.0",
         "31.9",
         "12.0",
         "2.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "2.0",
         "99.0",
         "1.0",
         "1.0",
         "4.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "94115557.0",
         "10366728.0",
         "-9.0"
        ],
        [
         "40",
         "2007.0",
         "0.0",
         "10.1",
         "359.0",
         "14.4",
         "1.0",
         "0.0",
         "29.0",
         "306.0",
         "12.5",
         "24.0",
         null,
         null,
         null,
         null,
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "121.0",
         "965.0",
         null,
         null,
         "82.0",
         "4.0",
         "10.98",
         "54.88",
         "3.0",
         "2.0",
         "6.46",
         "3.64",
         "19.72",
         "9.28",
         null,
         null,
         "26.1",
         null,
         "18.9",
         "-53.0",
         "5.64",
         "965.0",
         "121.0",
         "24.0",
         "3.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "2.0",
         "1.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "94120876.0",
         "10366760.0",
         "-9.0"
        ],
        [
         "41",
         "2010.0",
         "0.0",
         "4.8",
         "183.0",
         "15.4",
         "0.0",
         "0.0",
         "29.9",
         "182.0",
         "15.4",
         "24.0",
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "57.67",
         "1064.0",
         null,
         null,
         "97.0",
         "4.0",
         "11.13",
         "55.67",
         "0.0",
         "1.0",
         "3.41",
         "1.39",
         "24.82",
         "5.08",
         null,
         null,
         "110.63",
         null,
         "25.099999999999998",
         "-1.0",
         "3.69",
         "1064.0",
         "57.67",
         "24.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "94121628.0",
         "10366760.0",
         "0.0"
        ],
        [
         "42",
         "2009.0",
         "0.0",
         "4.6",
         "186.0",
         "16.5",
         "0.0",
         "0.0",
         "20.0",
         "180.0",
         "16.8",
         "24.0",
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "57.85",
         "663.8",
         null,
         null,
         "80.74",
         "2.0",
         "11.15",
         "55.73",
         "0.0",
         "1.0",
         "3.12",
         "1.48",
         "16.2",
         "3.8",
         null,
         null,
         "49.0",
         null,
         "15.4",
         "-6.0",
         "2.32",
         "663.8",
         "57.85",
         "24.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "2.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "94131849.0",
         "10366775.0",
         "0.0"
        ],
        [
         "43",
         "2006.0",
         "0.0",
         "4.9",
         "206.0",
         "15.2",
         "0.0",
         "0.0",
         "34.0",
         "186.0",
         "15.2",
         "24.0",
         null,
         null,
         null,
         null,
         "2.0",
         "1.0",
         "1.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "64.9",
         "832.0",
         null,
         null,
         "107.0",
         "4.0",
         "10.09",
         "48.79",
         "2.0",
         "2.0",
         "2.97",
         "1.92",
         "28.9",
         "4.76",
         null,
         null,
         "102.0",
         null,
         "29.1",
         "-20.0",
         "2.84",
         "832.0",
         "64.9",
         "24.0",
         "3.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "94344490.0",
         "10366613.0",
         "-9.0"
        ],
        [
         "44",
         "2008.0",
         "0.0",
         "5.3",
         "262.0",
         "15.3",
         "0.0",
         "0.0",
         "34.6",
         "243.0",
         "14.9",
         "24.0",
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "90.8",
         "754.5",
         null,
         null,
         "96.36",
         "3.0",
         null,
         null,
         null,
         null,
         "3.02",
         "2.28",
         "29.76",
         "4.84",
         null,
         null,
         "76.12",
         null,
         "29.3",
         "-19.0",
         "2.57",
         "754.5",
         "90.8",
         "24.0",
         "3.0",
         "99.0",
         "99.0",
         "99.0",
         "99.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "99.0",
         "99.0",
         "99.0",
         "99.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "94348239.0",
         "10366924.0",
         "-9.0"
        ],
        [
         "45",
         "2009.0",
         "0.0",
         "5.6",
         "173.0",
         "16.4",
         "0.0",
         "0.0",
         "46.3",
         "142.0",
         "14.9",
         "24.0",
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "31.9",
         "926.0",
         null,
         null,
         "79.0",
         "2.0",
         "11.39",
         "56.96",
         "1.0",
         "1.0",
         "3.86",
         "1.74",
         "41.81",
         "4.49",
         null,
         null,
         "64.82",
         null,
         "40.699999999999996",
         "-31.0",
         "2.75",
         "926.0",
         "31.9",
         "24.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "2.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "94311317.0",
         "10366776.0",
         "-9.0"
        ],
        [
         "46",
         "2012.0",
         "0.0",
         "5.0",
         "259.0",
         "11.9",
         "1.0",
         "1.0",
         "46.7",
         "232.0",
         "12.5",
         "17.4",
         null,
         null,
         null,
         null,
         "1.0",
         "2.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2.0",
         "0.0",
         "55.46",
         "621.0",
         null,
         null,
         "60.0",
         "2.0",
         "10.0",
         "50.0",
         "1.0",
         "1.0",
         "3.0",
         "1.99",
         "40.07",
         "6.63",
         null,
         null,
         "77.06",
         null,
         "41.7",
         "-27.0",
         "4.64",
         "621.0",
         "55.46",
         "17.4",
         "2.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2.0",
         "99.0",
         "2.0",
         "1.0",
         "3.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "94316721.0",
         "10366776.0",
         "0.0"
        ],
        [
         "47",
         "2011.0",
         "0.0",
         "4.9",
         "199.0",
         "13.7",
         "0.0",
         "0.0",
         "28.5",
         "205.0",
         "13.0",
         "24.0",
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "33.58",
         "290.2",
         null,
         null,
         "99.0",
         "4.0",
         "10.91",
         "54.55",
         "1.0",
         "2.0",
         "2.7",
         "2.21",
         "25.37",
         "3.14",
         null,
         null,
         "35.91",
         null,
         "23.6",
         "6.0",
         "0.93",
         "290.2",
         "33.58",
         "24.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "7.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "94276724.0",
         "10366732.0",
         "-9.0"
        ],
        [
         "48",
         "2011.0",
         "0.0",
         "6.5",
         "166.0",
         "15.7",
         "0.0",
         "0.0",
         "39.9",
         "187.0",
         "15.0",
         "24.8",
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         null,
         null,
         "0.0",
         "0.0",
         null,
         null,
         "1.0",
         "0.0",
         "63.04",
         "310.0",
         null,
         null,
         "102.51",
         "4.0",
         "10.54",
         "52.68",
         "0.0",
         "1.0",
         "4.63",
         "1.87",
         "33.08",
         "6.82",
         null,
         null,
         "35.91",
         null,
         "33.4",
         "21.0",
         "4.95",
         "310.0",
         "63.04",
         "24.8",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "99.0",
         "99.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "7.0",
         "4.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "94301982.0",
         "10366774.0",
         "1.0"
        ],
        [
         "49",
         "2013.0",
         "0.0",
         "6.2",
         "178.0",
         "15.3",
         "1.0",
         "0.0",
         "36.6",
         "141.0",
         "14.3",
         "21.2",
         null,
         null,
         null,
         null,
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         null,
         null,
         "0.0",
         "0.0",
         "41.91",
         "1021.8",
         null,
         null,
         "105.69",
         "4.0",
         "10.22",
         "51.09",
         "1.0",
         "2.0",
         "3.7",
         "2.5",
         "31.26",
         "5.34",
         null,
         null,
         "157.38",
         null,
         "30.400000000000002",
         "-37.0",
         "2.84",
         "1021.8",
         "41.91",
         "21.2",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "99.0",
         "99.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "3.0",
         "99.0",
         "1.0",
         "1.0",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "94303078.0",
         "10366846.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 77,
        "rows": 22348
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coll_yr</th>\n",
       "      <th>twodaycoll</th>\n",
       "      <th>wbc0</th>\n",
       "      <th>plt0</th>\n",
       "      <th>hgb0</th>\n",
       "      <th>skeletal0</th>\n",
       "      <th>maxmtc0</th>\n",
       "      <th>wbc5pre</th>\n",
       "      <th>plt5pre</th>\n",
       "      <th>hgb5pre</th>\n",
       "      <th>...</th>\n",
       "      <th>drace</th>\n",
       "      <th>coll_age_gp</th>\n",
       "      <th>hosp5n</th>\n",
       "      <th>hypo_cad5</th>\n",
       "      <th>hypo_cad5_6</th>\n",
       "      <th>clined5</th>\n",
       "      <th>clined5_6</th>\n",
       "      <th>pseudoid</th>\n",
       "      <th>pseudoctr</th>\n",
       "      <th>RqstgtcollectedDay1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>159.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93409976.0</td>\n",
       "      <td>10366760.0</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>218.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>232.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93370093.0</td>\n",
       "      <td>10366776.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>175.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>181.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93323774.0</td>\n",
       "      <td>10366760.0</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.4</td>\n",
       "      <td>230.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93344918.0</td>\n",
       "      <td>10366785.0</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>351.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93355053.0</td>\n",
       "      <td>10366760.0</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22343</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>361.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>350.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27583677.0</td>\n",
       "      <td>10366763.0</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22344</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34469796.0</td>\n",
       "      <td>10366763.0</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22345</th>\n",
       "      <td>2007.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>327.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26517063.0</td>\n",
       "      <td>10366965.0</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22346</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>398.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.9</td>\n",
       "      <td>409.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>122124260.0</td>\n",
       "      <td>10366817.0</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22347</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.9</td>\n",
       "      <td>413.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49480485.0</td>\n",
       "      <td>10366763.0</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22348 rows  77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       coll_yr  twodaycoll  wbc0   plt0  hgb0  skeletal0  maxmtc0  wbc5pre  \\\n",
       "0       2008.0         0.0   3.8  159.0  15.5        0.0      0.0     13.0   \n",
       "1       2015.0         0.0   5.5  218.0  13.2        0.0      0.0     31.2   \n",
       "2       2007.0         0.0   6.1  175.0  15.0        0.0      0.0     31.5   \n",
       "3       2011.0         0.0   8.0  280.0  15.4        1.0      0.0     68.4   \n",
       "4       2008.0         0.0   8.1  351.0  13.2        0.0      0.0     34.0   \n",
       "...        ...         ...   ...    ...   ...        ...      ...      ...   \n",
       "22343   2013.0         1.0   5.2  361.0   8.7        0.0      0.0     25.5   \n",
       "22344   2015.0         1.0   5.7  296.0  15.6        0.0      0.0     35.0   \n",
       "22345   2007.0         1.0   6.0  335.0  14.0        0.0      0.0     18.3   \n",
       "22346   2008.0         1.0  10.6  398.0   9.6        0.0      0.0     69.9   \n",
       "22347   2013.0         1.0  10.0  434.0  15.0        0.0      0.0     60.9   \n",
       "\n",
       "       plt5pre  hgb5pre  ...  drace  coll_age_gp  hosp5n  hypo_cad5  \\\n",
       "0        136.0     14.4  ...    7.0          4.0     0.0        0.0   \n",
       "1        232.0     12.2  ...    1.0          4.0     0.0        1.0   \n",
       "2        181.0     14.9  ...    7.0          4.0     0.0        0.0   \n",
       "3        230.0     15.9  ...    1.0          4.0     0.0        1.0   \n",
       "4        278.0     11.7  ...    7.0          4.0     0.0        0.0   \n",
       "...        ...      ...  ...    ...          ...     ...        ...   \n",
       "22343    350.0      9.3  ...    4.0          2.0     0.0        0.0   \n",
       "22344    323.0     15.0  ...    1.0          3.0     0.0        0.0   \n",
       "22345    327.0     12.9  ...    1.0          1.0     0.0        1.0   \n",
       "22346    409.0     10.0  ...    1.0          3.0     0.0        0.0   \n",
       "22347    413.0     14.6  ...    1.0          1.0     0.0        0.0   \n",
       "\n",
       "       hypo_cad5_6  clined5  clined5_6     pseudoid   pseudoctr  \\\n",
       "0              0.0      0.0        0.0   93409976.0  10366760.0   \n",
       "1              1.0      0.0        0.0   93370093.0  10366776.0   \n",
       "2              0.0      0.0        0.0   93323774.0  10366760.0   \n",
       "3              1.0      0.0        0.0   93344918.0  10366785.0   \n",
       "4              0.0      0.0        0.0   93355053.0  10366760.0   \n",
       "...            ...      ...        ...          ...         ...   \n",
       "22343          0.0      0.0        0.0   27583677.0  10366763.0   \n",
       "22344          0.0      0.0        0.0   34469796.0  10366763.0   \n",
       "22345          1.0      0.0        0.0   26517063.0  10366965.0   \n",
       "22346          0.0      0.0        1.0  122124260.0  10366817.0   \n",
       "22347          0.0      0.0        0.0   49480485.0  10366763.0   \n",
       "\n",
       "       RqstgtcollectedDay1  \n",
       "0                     -9.0  \n",
       "1                      0.0  \n",
       "2                     -9.0  \n",
       "3                     -9.0  \n",
       "4                     -9.0  \n",
       "...                    ...  \n",
       "22343                 -9.0  \n",
       "22344                 -9.0  \n",
       "22345                 -9.0  \n",
       "22346                 -9.0  \n",
       "22347                 -9.0  \n",
       "\n",
       "[22348 rows x 77 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4710b649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pseudoid is not unique, dropping duplicates\n",
      "Number of duplicates: 447\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check whether pseudoid is unique\n",
    "if df_raw['pseudoid'].is_unique:\n",
    "    print(\"pseudoid is unique\")\n",
    "else:\n",
    "    print(\"pseudoid is not unique, dropping duplicates\")\n",
    "    # print the number of duplicates\n",
    "    print(f\"Number of duplicates: {df_raw['pseudoid'].duplicated().sum()}\")\n",
    "    df_raw = df_raw.drop_duplicates(subset='pseudoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d75ef2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [ 'pseudoid', # unique identifier\n",
    "                'twodaycoll', # collection day\n",
    "                'dsex', # donor sex\n",
    "                'coll_age_gp', # collection age group\n",
    "                'd_wt', # donor weight\n",
    "                'd_bmi_grp', # donor BMI group\n",
    "                'wbc0', # white blood cell count at baseline\n",
    "                'plt0', # platelet count at baseline\n",
    "                'hgb0', # hemoglobin at baseline\n",
    "                'absneut0', # absolute neutrophil count at baseline\n",
    "                'absmnc0', # absolute monocyte count at baseline\n",
    "                'wbc5pre', # white blood cell count at 5 day\n",
    "                'absneut5pre', # absolute neutrophil count at 5 day\n",
    "                'absmnc5pre', # absolute monocyte count at 5 day\n",
    "                'abscd34_5pre', # absolute CD34 count at 5 day\n",
    "                'plt5pre',  # platelet count at 5 day\n",
    "                'hgb5pre', # hemoglobin at 5 day\n",
    "                # 'wbc6pre', # white blood cell count at 6 day\n",
    "                # 'absneut6pre', # absolute neutrophil count at 6 day\n",
    "                # 'absmnc6pre', # absolute monocyte count at 6 day\n",
    "                # 'abscd34_6pre', # absolute CD34 count at 6 day\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a93595a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pseudoid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "twodaycoll",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dsex",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "coll_age_gp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_wt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_bmi_grp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wbc0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "plt0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hgb0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absneut0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absmnc0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wbc5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absneut5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absmnc5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "abscd34_5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "plt5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hgb5pre",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "cdbbfc05-15e4-4d84-bf97-bf17d59cc6a1",
       "rows": [
        [
         "0",
         "93409976.0",
         "0.0",
         "1.0",
         "4.0",
         "93.0",
         "4.0",
         "3.8",
         "159.0",
         "15.5",
         "2.24",
         "1.56",
         "13.0",
         "10.79",
         "2.21",
         "11.7",
         "136.0",
         "14.4"
        ],
        [
         "1",
         "93370093.0",
         "0.0",
         "2.0",
         "4.0",
         "79.0",
         "3.0",
         "5.5",
         "218.0",
         "13.2",
         "3.0",
         "2.49",
         "31.2",
         "26.36",
         "4.8",
         "70.2",
         "232.0",
         "12.2"
        ],
        [
         "2",
         "93323774.0",
         "0.0",
         "1.0",
         "4.0",
         "124.0",
         "4.0",
         "6.1",
         "175.0",
         "15.0",
         "3.23",
         "2.87",
         "31.5",
         "26.46",
         "5.04",
         "22.05",
         "181.0",
         "14.9"
        ],
        [
         "3",
         "93344918.0",
         "0.0",
         "1.0",
         "4.0",
         "84.0",
         "3.0",
         "8.0",
         "280.0",
         "15.4",
         "5.04",
         "2.96",
         "68.4",
         "60.19",
         "8.21",
         "87.55",
         "230.0",
         "15.9"
        ],
        [
         "4",
         "93355053.0",
         "0.0",
         "2.0",
         "4.0",
         "94.0",
         "4.0",
         "8.1",
         "351.0",
         "13.2",
         "4.94",
         "3.16",
         "34.0",
         "26.18",
         "7.82",
         "51.0",
         "278.0",
         "11.7"
        ],
        [
         "5",
         "93562560.0",
         "0.0",
         "1.0",
         "4.0",
         "95.0",
         "3.0",
         "4.2",
         "299.0",
         "16.1",
         "2.18",
         "2.02",
         "54.9",
         "47.21",
         "7.69",
         "76.86",
         "222.0",
         "14.3"
        ],
        [
         "6",
         "93568857.0",
         "0.0",
         "1.0",
         "3.0",
         "87.09",
         "3.0",
         "7.1",
         "256.0",
         "16.2",
         "4.54",
         "2.56",
         "42.4",
         "36.04",
         "6.36",
         "106.0",
         "199.0",
         "14.6"
        ],
        [
         "7",
         "93571163.0",
         "0.0",
         "2.0",
         "3.0",
         "54.0",
         "2.0",
         "5.4",
         "244.0",
         "12.9",
         "3.35",
         "2.05",
         "29.2",
         "23.07",
         "6.13",
         "37.96",
         "267.0",
         "12.1"
        ],
        [
         "8",
         "93580161.0",
         "0.0",
         "1.0",
         "4.0",
         "97.0",
         "3.0",
         "5.5",
         "188.0",
         "15.7",
         "3.41",
         "2.09",
         "38.7",
         "30.19",
         "8.51",
         "46.44",
         "212.0",
         "15.2"
        ],
        [
         "9",
         "93525333.0",
         "0.0",
         "2.0",
         "4.0",
         "91.63",
         "4.0",
         "5.8",
         "247.0",
         "13.9",
         "3.71",
         "2.09",
         "25.8",
         "21.98",
         "3.82",
         "67.08",
         "182.0",
         "13.7"
        ],
        [
         "10",
         "93529830.0",
         "0.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "10.3",
         "425.0",
         "12.5",
         "7.27",
         "3.03",
         "43.4",
         "40.8",
         "2.6",
         "81.16",
         "244.0",
         "11.7"
        ],
        [
         "11",
         "93530273.0",
         "0.0",
         "1.0",
         "3.0",
         "105.23",
         "4.0",
         "5.3",
         "188.0",
         "15.4",
         "3.13",
         "2.17",
         "33.9",
         "27.46",
         "6.44",
         "88.14",
         "135.0",
         "15.7"
        ],
        [
         "12",
         "93538145.0",
         "0.0",
         "1.0",
         "4.0",
         "119.75",
         "4.0",
         "6.6",
         "192.0",
         "14.2",
         "4.09",
         "2.51",
         "41.4",
         "33.53",
         "7.87",
         "82.8",
         "168.0",
         "14.7"
        ],
        [
         "14",
         "93544412.0",
         "0.0",
         "1.0",
         "4.0",
         "103.63",
         "4.0",
         "5.6",
         "238.0",
         "17.0",
         "3.26",
         "2.34",
         "35.5",
         "30.0",
         "5.5",
         "97.63",
         "207.0",
         "15.7"
        ],
        [
         "15",
         "93469126.0",
         "0.0",
         "1.0",
         "3.0",
         "79.0",
         "2.0",
         "5.6",
         "204.0",
         "14.0",
         "3.75",
         "1.85",
         "25.3",
         "23.68",
         "1.62",
         "35.42",
         "131.0",
         "13.5"
        ],
        [
         "16",
         "93677034.0",
         "0.0",
         "1.0",
         "4.0",
         "87.0",
         "4.0",
         "5.5",
         "173.0",
         "14.2",
         "4.03",
         "1.47",
         "28.0",
         "24.81",
         "3.19",
         "103.6",
         "189.0",
         "14.1"
        ],
        [
         "17",
         "93629310.0",
         "0.0",
         "2.0",
         "4.0",
         "85.0",
         "4.0",
         "10.8",
         "398.0",
         "15.3",
         "7.48",
         "3.3",
         "62.5",
         "46.88",
         "15.63",
         "93.75",
         "316.0",
         "14.4"
        ],
        [
         "18",
         "93650522.0",
         "0.0",
         "1.0",
         "3.0",
         "77.27",
         "3.0",
         "5.6",
         "191.0",
         "17.1",
         "3.98",
         "1.62",
         "61.0",
         "55.51",
         "5.49",
         "73.2",
         "176.0",
         "15.9"
        ],
        [
         "19",
         "93609903.0",
         "0.0",
         "1.0",
         "4.0",
         "112.49",
         "4.0",
         "6.2",
         "198.0",
         "15.2",
         "3.97",
         "2.17",
         "52.6",
         "44.39",
         "8.21",
         "42.08",
         "223.0",
         "13.4"
        ],
        [
         "20",
         "93611587.0",
         "0.0",
         "1.0",
         "4.0",
         "68.0",
         "2.0",
         "8.2",
         "343.0",
         "14.0",
         "5.17",
         "2.87",
         "33.8",
         "23.32",
         "10.48",
         "270.4",
         "328.0",
         "13.6"
        ],
        [
         "21",
         "93612785.0",
         "0.0",
         "1.0",
         "4.0",
         "88.0",
         "4.0",
         "8.6",
         "201.0",
         "16.0",
         "6.71",
         "1.89",
         "42.2",
         "27.85",
         "14.35",
         "88.62",
         "200.0",
         "13.0"
        ],
        [
         "22",
         "93828609.0",
         "0.0",
         "1.0",
         "3.0",
         "88.0",
         "4.0",
         "6.1",
         "207.0",
         "13.0",
         "3.89",
         "2.21",
         "46.6",
         "43.34",
         "3.26",
         "116.5",
         "216.0",
         "13.1"
        ],
        [
         "23",
         "93770923.0",
         "0.0",
         "1.0",
         "3.0",
         "81.0",
         "2.0",
         "7.8",
         "247.0",
         "14.6",
         "4.24",
         "3.51",
         "43.8",
         "35.78",
         "8.02",
         "122.64",
         "211.0",
         "13.2"
        ],
        [
         "24",
         "93722512.0",
         "0.0",
         "1.0",
         "3.0",
         "75.45",
         "2.0",
         "5.3",
         "196.0",
         "14.6",
         "3.13",
         "2.17",
         "28.5",
         "24.51",
         "3.99",
         "62.7",
         "185.0",
         "13.3"
        ],
        [
         "25",
         "93961139.0",
         "0.0",
         "2.0",
         "4.0",
         "87.0",
         "3.0",
         "7.8",
         "287.0",
         "13.8",
         "4.98",
         "2.82",
         "32.1",
         "24.72",
         "8.35",
         "19.26",
         "275.0",
         "12.8"
        ],
        [
         "26",
         "93902962.0",
         "0.0",
         "2.0",
         "3.0",
         "64.41",
         "2.0",
         "6.0",
         "232.0",
         "13.9",
         "4.44",
         "1.56",
         "43.8",
         "37.23",
         "6.57",
         "52.56",
         "239.0",
         "13.7"
        ],
        [
         "27",
         "93912879.0",
         "0.0",
         "2.0",
         "3.0",
         "74.84",
         "4.0",
         "6.7",
         "252.0",
         "13.3",
         "4.22",
         "2.41",
         "23.4",
         "18.25",
         "5.15",
         "46.8",
         "205.0",
         "13.1"
        ],
        [
         "29",
         "93855245.0",
         "0.0",
         "1.0",
         "2.0",
         "93.63",
         "3.0",
         "7.5",
         "191.0",
         "16.7",
         "5.92",
         "1.5",
         "47.5",
         "43.23",
         "3.66",
         "61.75",
         "189.0",
         "15.2"
        ],
        [
         "30",
         "94086404.0",
         "0.0",
         "2.0",
         "3.0",
         "87.0",
         "4.0",
         "6.3",
         "251.0",
         "13.7",
         "3.53",
         "2.77",
         "46.5",
         "36.74",
         "9.77",
         "102.3",
         "214.0",
         "12.2"
        ],
        [
         "31",
         "94101687.0",
         "0.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "5.9",
         "286.0",
         "16.3",
         "4.08",
         "1.82",
         "54.9",
         "47.87",
         "6.97",
         "878.4",
         "235.0",
         "16.4"
        ],
        [
         "32",
         "94056760.0",
         "0.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "6.7",
         "271.0",
         "13.6",
         "3.73",
         "2.97",
         "47.9",
         "37.12",
         "10.78",
         "57.48",
         "206.0",
         "13.6"
        ],
        [
         "33",
         "93987175.0",
         "0.0",
         "1.0",
         "4.0",
         "96.0",
         "3.0",
         "7.5",
         "318.0",
         "14.5",
         "5.28",
         "2.23",
         "42.6",
         "35.36",
         "7.24",
         "85.2",
         "249.0",
         "13.5"
        ],
        [
         "34",
         "93993202.0",
         "0.0",
         "2.0",
         "4.0",
         "90.27",
         "4.0",
         "5.7",
         "217.0",
         "14.1",
         "3.31",
         "2.39",
         "50.7",
         "44.51",
         "6.19",
         "106.47",
         "225.0",
         "14.5"
        ],
        [
         "35",
         "93994677.0",
         "0.0",
         "1.0",
         "2.0",
         "105.9",
         "4.0",
         "5.4",
         "273.0",
         "15.1",
         "3.62",
         "1.78",
         "28.9",
         "26.01",
         "2.89",
         "112.71",
         "177.0",
         "14.0"
        ],
        [
         "36",
         "94177942.0",
         "0.0",
         "1.0",
         "4.0",
         "69.4",
         "2.0",
         "7.6",
         "275.0",
         "16.2",
         "6.22",
         "1.38",
         "34.4",
         "27.52",
         "6.88",
         "72.24",
         "262.0",
         "15.6"
        ],
        [
         "37",
         "94191277.0",
         "0.0",
         "2.0",
         "2.0",
         "54.54",
         "2.0",
         "8.4",
         "208.0",
         "13.0",
         "6.47",
         "1.93",
         "38.4",
         "31.87",
         "6.14",
         "15.36",
         "223.0",
         "13.0"
        ],
        [
         "38",
         "94203152.0",
         "0.0",
         "2.0",
         "4.0",
         "69.09",
         "3.0",
         "4.3",
         "383.0",
         "13.5",
         "2.55",
         "1.75",
         "41.5",
         "34.94",
         "6.52",
         "83.0",
         "336.0",
         "12.6"
        ],
        [
         "39",
         "94115557.0",
         "0.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "7.2",
         "204.0",
         "14.4",
         "4.82",
         "2.38",
         "74.5",
         "65.41",
         "9.01",
         "298.0",
         "218.0",
         "14.8"
        ],
        [
         "40",
         "94120876.0",
         "0.0",
         "2.0",
         "3.0",
         "82.0",
         "4.0",
         "10.1",
         "359.0",
         "14.4",
         "6.46",
         "3.64",
         "29.0",
         "19.72",
         "9.28",
         "26.1",
         "306.0",
         "12.5"
        ],
        [
         "41",
         "94121628.0",
         "0.0",
         "1.0",
         "3.0",
         "97.0",
         "4.0",
         "4.8",
         "183.0",
         "15.4",
         "3.41",
         "1.39",
         "29.9",
         "24.82",
         "5.08",
         "110.63",
         "182.0",
         "15.4"
        ],
        [
         "42",
         "94131849.0",
         "0.0",
         "1.0",
         "2.0",
         "80.74",
         "2.0",
         "4.6",
         "186.0",
         "16.5",
         "3.12",
         "1.48",
         "20.0",
         "16.2",
         "3.8",
         "49.0",
         "180.0",
         "16.8"
        ],
        [
         "43",
         "94344490.0",
         "0.0",
         "1.0",
         "3.0",
         "107.0",
         "4.0",
         "4.9",
         "206.0",
         "15.2",
         "2.97",
         "1.92",
         "34.0",
         "28.9",
         "4.76",
         "102.0",
         "186.0",
         "15.2"
        ],
        [
         "44",
         "94348239.0",
         "0.0",
         "1.0",
         "3.0",
         "96.36",
         "3.0",
         "5.3",
         "262.0",
         "15.3",
         "3.02",
         "2.28",
         "34.6",
         "29.76",
         "4.84",
         "76.12",
         "243.0",
         "14.9"
        ],
        [
         "45",
         "94311317.0",
         "0.0",
         "1.0",
         "2.0",
         "79.0",
         "2.0",
         "5.6",
         "173.0",
         "16.4",
         "3.86",
         "1.74",
         "46.3",
         "41.81",
         "4.49",
         "64.82",
         "142.0",
         "14.9"
        ],
        [
         "46",
         "94316721.0",
         "0.0",
         "2.0",
         "3.0",
         "60.0",
         "2.0",
         "5.0",
         "259.0",
         "11.9",
         "3.0",
         "1.99",
         "46.7",
         "40.07",
         "6.63",
         "77.06",
         "232.0",
         "12.5"
        ],
        [
         "47",
         "94276724.0",
         "0.0",
         "1.0",
         "3.0",
         "99.0",
         "4.0",
         "4.9",
         "199.0",
         "13.7",
         "2.7",
         "2.21",
         "28.5",
         "25.37",
         "3.14",
         "35.91",
         "205.0",
         "13.0"
        ],
        [
         "48",
         "94301982.0",
         "0.0",
         "1.0",
         "4.0",
         "102.51",
         "4.0",
         "6.5",
         "166.0",
         "15.7",
         "4.63",
         "1.87",
         "39.9",
         "33.08",
         "6.82",
         "35.91",
         "187.0",
         "15.0"
        ],
        [
         "49",
         "94303078.0",
         "0.0",
         "1.0",
         "3.0",
         "105.69",
         "4.0",
         "6.2",
         "178.0",
         "15.3",
         "3.7",
         "2.5",
         "36.6",
         "31.26",
         "5.34",
         "157.38",
         "141.0",
         "14.3"
        ],
        [
         "50",
         "94247403.0",
         "0.0",
         "2.0",
         "4.0",
         "55.0",
         "2.0",
         "6.4",
         "224.0",
         "13.7",
         "4.03",
         "2.36",
         "32.3",
         "29.55",
         "2.75",
         "129.2",
         "202.0",
         "12.5"
        ],
        [
         "51",
         "92348789.0",
         "0.0",
         "1.0",
         "4.0",
         "104.0",
         "4.0",
         "10.1",
         "197.0",
         "16.3",
         "6.27",
         "3.8",
         "41.3",
         "35.11",
         "7.43",
         "49.56",
         "177.0",
         "15.3"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 21901
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudoid</th>\n",
       "      <th>twodaycoll</th>\n",
       "      <th>dsex</th>\n",
       "      <th>coll_age_gp</th>\n",
       "      <th>d_wt</th>\n",
       "      <th>d_bmi_grp</th>\n",
       "      <th>wbc0</th>\n",
       "      <th>plt0</th>\n",
       "      <th>hgb0</th>\n",
       "      <th>absneut0</th>\n",
       "      <th>absmnc0</th>\n",
       "      <th>wbc5pre</th>\n",
       "      <th>absneut5pre</th>\n",
       "      <th>absmnc5pre</th>\n",
       "      <th>abscd34_5pre</th>\n",
       "      <th>plt5pre</th>\n",
       "      <th>hgb5pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93409976.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>159.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.56</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.79</td>\n",
       "      <td>2.21</td>\n",
       "      <td>11.70</td>\n",
       "      <td>136.0</td>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93370093.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>218.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.49</td>\n",
       "      <td>31.2</td>\n",
       "      <td>26.36</td>\n",
       "      <td>4.80</td>\n",
       "      <td>70.20</td>\n",
       "      <td>232.0</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93323774.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>175.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.87</td>\n",
       "      <td>31.5</td>\n",
       "      <td>26.46</td>\n",
       "      <td>5.04</td>\n",
       "      <td>22.05</td>\n",
       "      <td>181.0</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93344918.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>5.04</td>\n",
       "      <td>2.96</td>\n",
       "      <td>68.4</td>\n",
       "      <td>60.19</td>\n",
       "      <td>8.21</td>\n",
       "      <td>87.55</td>\n",
       "      <td>230.0</td>\n",
       "      <td>15.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93355053.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>351.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3.16</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.18</td>\n",
       "      <td>7.82</td>\n",
       "      <td>51.00</td>\n",
       "      <td>278.0</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22343</th>\n",
       "      <td>27583677.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>63.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>361.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2.91</td>\n",
       "      <td>2.29</td>\n",
       "      <td>25.5</td>\n",
       "      <td>20.15</td>\n",
       "      <td>5.36</td>\n",
       "      <td>38.25</td>\n",
       "      <td>350.0</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22344</th>\n",
       "      <td>34469796.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>3.53</td>\n",
       "      <td>2.11</td>\n",
       "      <td>35.0</td>\n",
       "      <td>27.65</td>\n",
       "      <td>7.00</td>\n",
       "      <td>59.50</td>\n",
       "      <td>323.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22345</th>\n",
       "      <td>26517063.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.60</td>\n",
       "      <td>18.3</td>\n",
       "      <td>12.81</td>\n",
       "      <td>5.49</td>\n",
       "      <td>49.41</td>\n",
       "      <td>327.0</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22346</th>\n",
       "      <td>122124260.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>96.81</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>398.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>7.84</td>\n",
       "      <td>2.76</td>\n",
       "      <td>69.9</td>\n",
       "      <td>58.72</td>\n",
       "      <td>11.18</td>\n",
       "      <td>174.75</td>\n",
       "      <td>409.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22347</th>\n",
       "      <td>49480485.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.10</td>\n",
       "      <td>3.90</td>\n",
       "      <td>60.9</td>\n",
       "      <td>51.16</td>\n",
       "      <td>9.74</td>\n",
       "      <td>127.89</td>\n",
       "      <td>413.0</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21901 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pseudoid  twodaycoll  dsex  coll_age_gp    d_wt  d_bmi_grp  wbc0  \\\n",
       "0       93409976.0         0.0   1.0          4.0   93.00        4.0   3.8   \n",
       "1       93370093.0         0.0   2.0          4.0   79.00        3.0   5.5   \n",
       "2       93323774.0         0.0   1.0          4.0  124.00        4.0   6.1   \n",
       "3       93344918.0         0.0   1.0          4.0   84.00        3.0   8.0   \n",
       "4       93355053.0         0.0   2.0          4.0   94.00        4.0   8.1   \n",
       "...            ...         ...   ...          ...     ...        ...   ...   \n",
       "22343   27583677.0         1.0   2.0          2.0   63.00        3.0   5.2   \n",
       "22344   34469796.0         1.0   1.0          3.0   70.00        2.0   5.7   \n",
       "22345   26517063.0         1.0   2.0          1.0   77.00        3.0   6.0   \n",
       "22346  122124260.0         1.0   2.0          3.0   96.81        4.0  10.6   \n",
       "22347   49480485.0         1.0   1.0          1.0  119.00        4.0  10.0   \n",
       "\n",
       "        plt0  hgb0  absneut0  absmnc0  wbc5pre  absneut5pre  absmnc5pre  \\\n",
       "0      159.0  15.5      2.24     1.56     13.0        10.79        2.21   \n",
       "1      218.0  13.2      3.00     2.49     31.2        26.36        4.80   \n",
       "2      175.0  15.0      3.23     2.87     31.5        26.46        5.04   \n",
       "3      280.0  15.4      5.04     2.96     68.4        60.19        8.21   \n",
       "4      351.0  13.2      4.94     3.16     34.0        26.18        7.82   \n",
       "...      ...   ...       ...      ...      ...          ...         ...   \n",
       "22343  361.0   8.7      2.91     2.29     25.5        20.15        5.36   \n",
       "22344  296.0  15.6      3.53     2.11     35.0        27.65        7.00   \n",
       "22345  335.0  14.0      3.40     2.60     18.3        12.81        5.49   \n",
       "22346  398.0   9.6      7.84     2.76     69.9        58.72       11.18   \n",
       "22347  434.0  15.0      6.10     3.90     60.9        51.16        9.74   \n",
       "\n",
       "       abscd34_5pre  plt5pre  hgb5pre  \n",
       "0             11.70    136.0     14.4  \n",
       "1             70.20    232.0     12.2  \n",
       "2             22.05    181.0     14.9  \n",
       "3             87.55    230.0     15.9  \n",
       "4             51.00    278.0     11.7  \n",
       "...             ...      ...      ...  \n",
       "22343         38.25    350.0      9.3  \n",
       "22344         59.50    323.0     15.0  \n",
       "22345         49.41    327.0     12.9  \n",
       "22346        174.75    409.0     10.0  \n",
       "22347        127.89    413.0     14.6  \n",
       "\n",
       "[21901 rows x 17 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only the columns of interest\n",
    "df = df_raw[cols_to_keep].copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9151c830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pseudoid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "twodaycoll",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dsex",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "coll_age_gp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_wt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_bmi_grp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wbc0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "plt0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hgb0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absneut0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absmnc0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wbc5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absneut5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absmnc5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "abscd34_5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "plt5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hgb5pre",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "27916436-7952-45a7-88b6-6e1063f40a59",
       "rows": [
        [
         "87",
         "95468317.0",
         "0.0",
         "2.0",
         "4.0",
         "65.0",
         "2.0",
         "4.2",
         "276.0",
         "13.8",
         "1.98",
         null,
         "23.5",
         "19.04",
         "4.47",
         "33.37",
         "225.0",
         "11.7"
        ],
        [
         "127",
         "94426132.0",
         "0.0",
         "2.0",
         "3.0",
         "117.94",
         "4.0",
         "5.9",
         "231.0",
         "12.9",
         "3.12",
         "2.78",
         "33.8",
         "28.39",
         "5.41",
         null,
         "203.0",
         "12.6"
        ],
        [
         "128",
         "94434419.0",
         "0.0",
         "2.0",
         "4.0",
         "72.58",
         "3.0",
         "7.1",
         "315.0",
         "13.3",
         "4.63",
         "2.47",
         "63.8",
         "56.14",
         null,
         "192.68",
         "384.0",
         "12.9"
        ],
        [
         "136",
         "94637814.0",
         "0.0",
         "1.0",
         "2.0",
         "130.0",
         "4.0",
         "6.1",
         "200.0",
         "15.5",
         "4.33",
         "1.83",
         "18.5",
         "12.95",
         "5.55",
         null,
         "190.0",
         "14.4"
        ],
        [
         "187",
         "98375675.0",
         "0.0",
         "1.0",
         "3.0",
         "60.9",
         "2.0",
         "5.3",
         "171.0",
         "13.6",
         "2.76",
         "2.54",
         "31.0",
         "24.8",
         "6.2",
         null,
         "159.0",
         "12.7"
        ],
        [
         "209",
         "96942161.0",
         "0.0",
         "2.0",
         "3.0",
         "102.51",
         "4.0",
         "9.2",
         "206.0",
         "12.8",
         "6.06",
         "3.14",
         "50.7",
         "44.82",
         "5.88",
         null,
         "227.0",
         "12.0"
        ],
        [
         "233",
         "100089516.0",
         "0.0",
         "1.0",
         "2.0",
         "71.0",
         "2.0",
         "6.9",
         "225.0",
         "16.4",
         "4.06",
         "2.8",
         "54.6",
         null,
         null,
         "54.6",
         "199.0",
         "15.0"
        ],
        [
         "273",
         "99328881.0",
         "0.0",
         "1.0",
         "2.0",
         "94.8",
         "4.0",
         "6.8",
         "236.0",
         "15.2",
         "4.68",
         "2.12",
         "39.9",
         "33.48",
         "6.42",
         null,
         "204.0",
         "14.4"
        ],
        [
         "282",
         "99272287.0",
         "0.0",
         "1.0",
         "2.0",
         "86.0",
         "3.0",
         "4.1",
         "166.0",
         "14.8",
         "2.35",
         "1.75",
         "29.3",
         "21.98",
         "7.33",
         null,
         "154.0",
         "15.9"
        ],
        [
         "304",
         "99574942.0",
         "0.0",
         "1.0",
         "3.0",
         "113.85",
         "4.0",
         "4.7",
         "236.0",
         "16.7",
         "2.6",
         "2.1",
         "43.5",
         "40.89",
         null,
         "191.4",
         "227.0",
         "16.5"
        ],
        [
         "357",
         "85584525.0",
         "0.0",
         "2.0",
         "3.0",
         "76.0",
         "3.0",
         "4.7",
         "303.0",
         "14.0",
         "2.9",
         "1.8",
         "32.4",
         "26.57",
         "6.16",
         "55.08",
         "264.0",
         null
        ],
        [
         "393",
         "85850839.0",
         "0.0",
         "1.0",
         "3.0",
         "77.27",
         "3.0",
         "4.7",
         "255.0",
         "14.9",
         "2.98",
         "1.71",
         "46.3",
         "39.36",
         "6.95",
         null,
         "268.0",
         "15.4"
        ],
        [
         "476",
         "84209950.0",
         "0.0",
         "1.0",
         "4.0",
         "94.0",
         "4.0",
         "4.7",
         "197.0",
         "14.0",
         "2.59",
         "2.12",
         "36.6",
         "33.09",
         null,
         "102.48",
         "167.0",
         "13.8"
        ],
        [
         "491",
         "84517361.0",
         "0.0",
         "1.0",
         "2.0",
         "83.0",
         "2.0",
         "6.9",
         "266.0",
         "15.0",
         "3.51",
         "3.39",
         "37.9",
         "32.67",
         "5.23",
         null,
         "213.0",
         "14.1"
        ],
        [
         "511",
         "84913184.0",
         "0.0",
         "1.0",
         "3.0",
         "77.11",
         "3.0",
         "7.7",
         "287.0",
         "14.2",
         "4.91",
         "2.79",
         "50.6",
         "48.58",
         null,
         "131.56",
         "259.0",
         "13.9"
        ],
        [
         "526",
         "87067797.0",
         "1.0",
         "1.0",
         "2.0",
         "58.0",
         "2.0",
         "6.6",
         "180.0",
         "13.5",
         "4.62",
         "1.98",
         "59.2",
         "50.97",
         "8.23",
         null,
         "186.0",
         "13.1"
        ],
        [
         "531",
         "87291894.0",
         "0.0",
         "1.0",
         "4.0",
         "88.0",
         "3.0",
         "8.4",
         "158.0",
         "15.8",
         "6.8",
         "1.6",
         "27.7",
         "21.88",
         "5.82",
         "63.71",
         null,
         "15.8"
        ],
        [
         "560",
         "87512640.0",
         "0.0",
         "1.0",
         "3.0",
         "99.34",
         "4.0",
         "7.1",
         "208.0",
         "16.1",
         "4.97",
         null,
         "39.5",
         "31.6",
         "5.93",
         "71.1",
         "221.0",
         "16.8"
        ],
        [
         "569",
         "87612546.0",
         "0.0",
         "1.0",
         "3.0",
         "89.0",
         "3.0",
         "5.0",
         "220.0",
         "13.3",
         "2.98",
         "2.02",
         "28.4",
         "24.45",
         "3.98",
         null,
         "167.0",
         "13.0"
        ],
        [
         "586",
         "87907943.0",
         "0.0",
         "2.0",
         "4.0",
         "107.0",
         "4.0",
         "8.9",
         "301.0",
         "14.5",
         "5.79",
         null,
         "39.8",
         "29.85",
         "9.95",
         "66.07",
         "256.0",
         "13.3"
        ],
        [
         "645",
         "86609121.0",
         "0.0",
         "2.0",
         "3.0",
         "80.9",
         "3.0",
         "9.1",
         "427.0",
         "13.1",
         "6.18",
         "2.92",
         "60.3",
         null,
         null,
         "108.54",
         "358.0",
         "11.8"
        ],
        [
         "647",
         "86632174.0",
         "0.0",
         "1.0",
         "3.0",
         "90.0",
         "3.0",
         "4.9",
         "180.0",
         "15.2",
         "3.0",
         "1.9",
         "29.5",
         "24.49",
         "5.02",
         null,
         "177.0",
         "15.1"
        ],
        [
         "663",
         "86877810.0",
         "0.0",
         "2.0",
         "2.0",
         "75.0",
         "3.0",
         "6.2",
         "173.0",
         "14.2",
         "4.03",
         "2.17",
         "25.3",
         "18.98",
         "6.33",
         null,
         "162.0",
         "13.9"
        ],
        [
         "664",
         "86900294.0",
         "0.0",
         "2.0",
         "3.0",
         "85.0",
         "4.0",
         "6.8",
         "299.0",
         "12.8",
         "4.28",
         "2.52",
         "41.2",
         "35.02",
         "6.18",
         null,
         "258.0",
         "13.0"
        ],
        [
         "684",
         "86930772.0",
         "0.0",
         "2.0",
         "3.0",
         "68.04",
         "2.0",
         "7.1",
         "347.0",
         "14.5",
         "4.27",
         null,
         "24.9",
         "21.66",
         "3.24",
         "27.39",
         "191.0",
         "11.8"
        ],
        [
         "729",
         "89882166.0",
         "0.0",
         "2.0",
         "4.0",
         "62.72",
         "2.0",
         "4.0",
         "236.0",
         "14.8",
         "2.76",
         "1.24",
         "31.3",
         "25.98",
         "5.32",
         null,
         "213.0",
         "14.5"
        ],
        [
         "756",
         "88445338.0",
         "0.0",
         "2.0",
         "3.0",
         "66.0",
         "2.0",
         "9.1",
         "291.0",
         "14.0",
         "5.37",
         "3.73",
         "71.7",
         "65.25",
         null,
         "114.72",
         "321.0",
         "13.9"
        ],
        [
         "782",
         "88704171.0",
         "0.0",
         "1.0",
         "2.0",
         "127.0",
         "4.0",
         "4.5",
         "164.0",
         "14.2",
         "2.66",
         "1.85",
         "19.3",
         "14.86",
         "4.44",
         null,
         "136.0",
         "14.3"
        ],
        [
         "804",
         "88660148.0",
         "0.0",
         "1.0",
         "2.0",
         "80.0",
         "2.0",
         "4.8",
         "194.0",
         "13.5",
         "3.06",
         null,
         "27.5",
         "23.93",
         "3.58",
         "19.25",
         "225.0",
         "14.4"
        ],
        [
         "866",
         "91249714.0",
         "0.0",
         "2.0",
         "4.0",
         "86.0",
         "4.0",
         "7.5",
         "305.0",
         "13.3",
         "4.88",
         null,
         "16.5",
         "13.04",
         "3.47",
         "36.96",
         "268.0",
         "12.3"
        ],
        [
         "872",
         "91422263.0",
         "0.0",
         "2.0",
         "4.0",
         "52.0",
         "1.0",
         "8.1",
         "322.0",
         "13.8",
         "6.12",
         "1.98",
         "38.7",
         "30.96",
         "5.81",
         null,
         "310.0",
         "13.4"
        ],
        [
         "910",
         "91810199.0",
         "0.0",
         "1.0",
         "4.0",
         "66.81",
         "2.0",
         "6.2",
         "246.0",
         "13.9",
         "4.1",
         "2.1",
         "29.5",
         "23.6",
         "5.9",
         null,
         "215.0",
         "14.8"
        ],
        [
         "939",
         "90295622.0",
         "0.0",
         "1.0",
         "3.0",
         "88.45",
         "3.0",
         "4.7",
         "266.0",
         "14.1",
         "2.82",
         "1.88",
         "41.2",
         "32.96",
         "8.24",
         "48.2",
         null,
         "14.0"
        ],
        [
         "945",
         "90424221.0",
         "0.0",
         "2.0",
         "2.0",
         "55.0",
         "2.0",
         "5.3",
         "218.0",
         "12.4",
         "3.46",
         "1.73",
         "39.3",
         "35.53",
         "3.26",
         null,
         "229.0",
         "13.3"
        ],
        [
         "986",
         "90896568.0",
         "0.0",
         "2.0",
         "3.0",
         "96.0",
         "4.0",
         "7.8",
         "286.0",
         "13.6",
         "5.38",
         "2.42",
         "28.7",
         "24.11",
         "4.59",
         null,
         "217.0",
         "13.7"
        ],
        [
         "1024",
         "76707070.0",
         "0.0",
         "1.0",
         "2.0",
         "84.54",
         "3.0",
         "8.5",
         "275.0",
         "15.2",
         "5.7",
         "2.81",
         "53.7",
         "47.26",
         null,
         "118.14",
         "196.0",
         "15.8"
        ],
        [
         "1157",
         "79110334.0",
         "0.0",
         "2.0",
         "3.0",
         "72.27",
         "4.0",
         "4.8",
         "275.0",
         "13.5",
         "2.12",
         "2.68",
         "71.4",
         "55.69",
         "15.71",
         null,
         "363.0",
         "13.5"
        ],
        [
         "1212",
         "79300495.0",
         "0.0",
         "1.0",
         "2.0",
         "87.27",
         "3.0",
         "5.5",
         "201.0",
         "15.0",
         "2.93",
         "2.57",
         "37.4",
         "32.13",
         "5.27",
         null,
         "183.0",
         "14.3"
        ],
        [
         "1231",
         "77705220.0",
         "0.0",
         "1.0",
         "2.0",
         "119.0",
         "4.0",
         "7.3",
         "229.0",
         "14.2",
         "4.85",
         "2.45",
         "50.6",
         null,
         null,
         "131.56",
         "173.0",
         "13.2"
        ],
        [
         "1249",
         "77911022.0",
         "0.0",
         "2.0",
         "2.0",
         "100.0",
         "4.0",
         "8.6",
         "239.0",
         "15.5",
         "5.07",
         "3.53",
         "45.2",
         "33.45",
         "11.75",
         null,
         "242.0",
         "14.0"
        ],
        [
         "1264",
         "78169998.0",
         "0.0",
         "1.0",
         "3.0",
         "91.17",
         "4.0",
         "5.5",
         "282.0",
         "15.7",
         "3.37",
         null,
         "24.8",
         "18.6",
         "6.2",
         "84.32",
         "291.0",
         "15.0"
        ],
        [
         "1265",
         "78174743.0",
         "0.0",
         "2.0",
         "3.0",
         "70.31",
         "2.0",
         "8.2",
         "216.0",
         "13.6",
         "6.05",
         null,
         "32.4",
         "28.29",
         "3.5",
         "22.68",
         "202.0",
         "13.0"
        ],
        [
         "1284",
         "78510625.0",
         "0.0",
         "1.0",
         "4.0",
         "70.45",
         "2.0",
         "6.7",
         "233.0",
         "14.8",
         "4.03",
         "2.67",
         "39.3",
         "30.81",
         "8.21",
         null,
         "212.0",
         "14.4"
        ],
        [
         "1296",
         "78615216.0",
         "0.0",
         "1.0",
         "3.0",
         "83.0",
         "2.0",
         "7.9",
         "254.0",
         "14.0",
         "5.14",
         "2.84",
         "39.0",
         "31.98",
         "6.63",
         "5.46",
         "199.0",
         null
        ],
        [
         "1297",
         "78590287.0",
         "0.0",
         "1.0",
         "3.0",
         "108.63",
         "4.0",
         "7.6",
         "234.0",
         "15.6",
         "4.72",
         "2.88",
         "51.6",
         "42.31",
         "9.29",
         null,
         "210.0",
         "14.7"
        ],
        [
         "1403",
         "80315234.0",
         "0.0",
         "2.0",
         "2.0",
         "70.31",
         "3.0",
         "5.7",
         "197.0",
         "12.9",
         "4.16",
         "1.54",
         "60.7",
         null,
         "13.23",
         "83.16",
         "297.0",
         "13.3"
        ],
        [
         "1412",
         "80415709.0",
         "0.0",
         "2.0",
         "2.0",
         "53.18",
         "2.0",
         "4.7",
         "250.0",
         "13.3",
         "3.06",
         "1.65",
         "28.3",
         "25.5",
         "2.8",
         null,
         "239.0",
         "13.5"
        ],
        [
         "1419",
         "80528131.0",
         "0.0",
         "2.0",
         "4.0",
         "82.27",
         "4.0",
         "8.9",
         "414.0",
         "14.5",
         "6.32",
         "2.58",
         "58.5",
         "46.22",
         "12.29",
         null,
         "313.0",
         "13.8"
        ],
        [
         "1422",
         "80534419.0",
         "0.0",
         "1.0",
         "2.0",
         "90.9",
         "3.0",
         "7.2",
         "227.0",
         null,
         "4.44",
         "2.76",
         "21.7",
         "18.12",
         "3.58",
         "21.7",
         "169.0",
         "15.8"
        ],
        [
         "1587",
         "82354832.0",
         "0.0",
         "1.0",
         "3.0",
         "87.0",
         "3.0",
         "5.0",
         "251.0",
         "14.9",
         "2.84",
         "2.16",
         "39.6",
         "34.02",
         "5.58",
         null,
         "249.0",
         "14.5"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 660
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudoid</th>\n",
       "      <th>twodaycoll</th>\n",
       "      <th>dsex</th>\n",
       "      <th>coll_age_gp</th>\n",
       "      <th>d_wt</th>\n",
       "      <th>d_bmi_grp</th>\n",
       "      <th>wbc0</th>\n",
       "      <th>plt0</th>\n",
       "      <th>hgb0</th>\n",
       "      <th>absneut0</th>\n",
       "      <th>absmnc0</th>\n",
       "      <th>wbc5pre</th>\n",
       "      <th>absneut5pre</th>\n",
       "      <th>absmnc5pre</th>\n",
       "      <th>abscd34_5pre</th>\n",
       "      <th>plt5pre</th>\n",
       "      <th>hgb5pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>95468317.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>276.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.50</td>\n",
       "      <td>19.04</td>\n",
       "      <td>4.47</td>\n",
       "      <td>33.37</td>\n",
       "      <td>225.0</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>94426132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>117.94</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>231.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.78</td>\n",
       "      <td>33.80</td>\n",
       "      <td>28.39</td>\n",
       "      <td>5.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>203.0</td>\n",
       "      <td>12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>94434419.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>72.58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>315.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>4.63</td>\n",
       "      <td>2.47</td>\n",
       "      <td>63.80</td>\n",
       "      <td>56.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.68</td>\n",
       "      <td>384.0</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>94637814.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.83</td>\n",
       "      <td>18.50</td>\n",
       "      <td>12.95</td>\n",
       "      <td>5.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.0</td>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>98375675.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.90</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>171.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.54</td>\n",
       "      <td>31.00</td>\n",
       "      <td>24.80</td>\n",
       "      <td>6.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159.0</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22296</th>\n",
       "      <td>75264929.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>123.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>303.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>5.41</td>\n",
       "      <td>2.29</td>\n",
       "      <td>45.28</td>\n",
       "      <td>39.39</td>\n",
       "      <td>5.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314.0</td>\n",
       "      <td>14.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22304</th>\n",
       "      <td>17779274.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.54</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>320.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>4.41</td>\n",
       "      <td>2.79</td>\n",
       "      <td>58.70</td>\n",
       "      <td>49.90</td>\n",
       "      <td>8.81</td>\n",
       "      <td>123.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22327</th>\n",
       "      <td>110044738.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.54</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>338.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>6.28</td>\n",
       "      <td>2.12</td>\n",
       "      <td>48.90</td>\n",
       "      <td>44.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.34</td>\n",
       "      <td>385.0</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22331</th>\n",
       "      <td>71277921.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.93</td>\n",
       "      <td>4.07</td>\n",
       "      <td>29.40</td>\n",
       "      <td>24.70</td>\n",
       "      <td>4.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335.0</td>\n",
       "      <td>15.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22337</th>\n",
       "      <td>120183621.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>376.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.55</td>\n",
       "      <td>1.85</td>\n",
       "      <td>56.80</td>\n",
       "      <td>49.42</td>\n",
       "      <td>7.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>370.0</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pseudoid  twodaycoll  dsex  coll_age_gp    d_wt  d_bmi_grp  wbc0  \\\n",
       "87      95468317.0         0.0   2.0          4.0   65.00        2.0   4.2   \n",
       "127     94426132.0         0.0   2.0          3.0  117.94        4.0   5.9   \n",
       "128     94434419.0         0.0   2.0          4.0   72.58        3.0   7.1   \n",
       "136     94637814.0         0.0   1.0          2.0  130.00        4.0   6.1   \n",
       "187     98375675.0         0.0   1.0          3.0   60.90        2.0   5.3   \n",
       "...            ...         ...   ...          ...     ...        ...   ...   \n",
       "22296   75264929.0         1.0   1.0          2.0  123.00        4.0   7.7   \n",
       "22304   17779274.0         1.0   2.0          1.0  104.54        4.0   7.2   \n",
       "22327  110044738.0         1.0   2.0          1.0   79.54        3.0   8.4   \n",
       "22331   71277921.0         1.0   1.0          2.0   90.00        4.0  11.0   \n",
       "22337  120183621.0         1.0   2.0          4.0  100.00        4.0   7.4   \n",
       "\n",
       "        plt0  hgb0  absneut0  absmnc0  wbc5pre  absneut5pre  absmnc5pre  \\\n",
       "87     276.0  13.8      1.98      NaN    23.50        19.04        4.47   \n",
       "127    231.0  12.9      3.12     2.78    33.80        28.39        5.41   \n",
       "128    315.0  13.3      4.63     2.47    63.80        56.14         NaN   \n",
       "136    200.0  15.5      4.33     1.83    18.50        12.95        5.55   \n",
       "187    171.0  13.6      2.76     2.54    31.00        24.80        6.20   \n",
       "...      ...   ...       ...      ...      ...          ...         ...   \n",
       "22296  303.0  14.7      5.41     2.29    45.28        39.39        5.89   \n",
       "22304  320.0  13.1      4.41     2.79    58.70        49.90        8.81   \n",
       "22327  338.0  12.6      6.28     2.12    48.90        44.99         NaN   \n",
       "22331  384.0  15.0      6.93     4.07    29.40        24.70        4.70   \n",
       "22337  376.0  14.0      5.55     1.85    56.80        49.42        7.38   \n",
       "\n",
       "       abscd34_5pre  plt5pre  hgb5pre  \n",
       "87            33.37    225.0     11.7  \n",
       "127             NaN    203.0     12.6  \n",
       "128          192.68    384.0     12.9  \n",
       "136             NaN    190.0     14.4  \n",
       "187             NaN    159.0     12.7  \n",
       "...             ...      ...      ...  \n",
       "22296           NaN    314.0     14.7  \n",
       "22304        123.27      NaN     13.4  \n",
       "22327         29.34    385.0     13.2  \n",
       "22331           NaN    335.0     15.1  \n",
       "22337           NaN    370.0     14.5  \n",
       "\n",
       "[660 rows x 17 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the rows with any missing values\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a839ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pseudoid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "twodaycoll",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dsex",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "coll_age_gp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_wt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_bmi_grp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wbc0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "plt0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hgb0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absneut0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absmnc0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wbc5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absneut5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absmnc5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "abscd34_5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "plt5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hgb5pre",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f8fff1f8-d818-431e-95cf-af4d4f6b8eb3",
       "rows": [
        [
         "1567",
         "82024176.0",
         "0.0",
         "2.0",
         "3.0",
         "59.09",
         "99.0",
         "4.8",
         "275.0",
         "13.4",
         "3.17",
         "1.63",
         "52.4",
         "45.06",
         "7.34",
         "110.04",
         "291.0",
         "12.8"
        ],
        [
         "7220",
         "106452445.0",
         "0.0",
         "1.0",
         "3.0",
         "114.0",
         "99.0",
         "5.5",
         "234.0",
         "15.1",
         "3.47",
         "2.04",
         "28.6",
         "23.74",
         "4.86",
         "85.8",
         "215.0",
         "15.2"
        ],
        [
         "7656",
         "108559250.0",
         "0.0",
         "1.0",
         "1.0",
         "71.67",
         "99.0",
         "5.0",
         "258.0",
         "15.6",
         "3.01",
         "1.99",
         "46.3",
         "37.5",
         "8.8",
         "74.08",
         "256.0",
         "14.9"
        ],
        [
         "11264",
         "23717608.0",
         "0.0",
         "1.0",
         "4.0",
         "69.0",
         "99.0",
         "5.9",
         "207.0",
         "13.4",
         "3.95",
         "2.01",
         "52.2",
         "45.94",
         "6.26",
         "73.08",
         "218.0",
         "13.4"
        ],
        [
         "11325",
         "23893387.0",
         "0.0",
         "1.0",
         "1.0",
         "95.26",
         "99.0",
         "5.6",
         "231.0",
         "16.5",
         "3.81",
         "1.79",
         "35.7",
         "20.53",
         "15.17",
         "135.66",
         "194.0",
         "15.6"
        ],
        [
         "11491",
         "10267066.0",
         "0.0",
         "1.0",
         "4.0",
         "128.37",
         "99.0",
         "9.1",
         "239.0",
         "15.0",
         "6.1",
         "3.0",
         "46.5",
         "39.99",
         "6.51",
         "93.0",
         "272.0",
         "14.9"
        ],
        [
         "14820",
         "60495856.0",
         "0.0",
         "2.0",
         "2.0",
         "75.3",
         "99.0",
         "9.6",
         "279.0",
         "13.8",
         "6.68",
         "2.89",
         "48.1",
         "41.85",
         "6.73",
         "86.58",
         "217.0",
         "13.2"
        ],
        [
         "16688",
         "48332933.0",
         "0.0",
         "2.0",
         "3.0",
         "67.0",
         "99.0",
         "8.2",
         "204.0",
         "13.6",
         "5.11",
         "3.05",
         "51.2",
         "45.67",
         "4.86",
         "76.8",
         "179.0",
         "13.4"
        ],
        [
         "17700",
         "39493302.0",
         "0.0",
         "2.0",
         "1.0",
         "92.99",
         "99.0",
         "11.6",
         "430.0",
         "12.6",
         "8.71",
         "2.89",
         "60.6",
         "48.48",
         "12.12",
         "145.44",
         "419.0",
         "12.1"
        ],
        [
         "19781",
         "452658074.0",
         "0.0",
         "2.0",
         "4.0",
         "80.74",
         "99.0",
         "6.0",
         "252.0",
         "13.8",
         "3.65",
         "2.33",
         "46.0",
         "40.43",
         "5.57",
         "23.0",
         "184.0",
         "14.3"
        ],
        [
         "21026",
         "114387202.0",
         "1.0",
         "2.0",
         "2.0",
         "87.0",
         "99.0",
         "4.3",
         "224.0",
         "13.4",
         "2.54",
         "1.76",
         "43.3",
         "37.24",
         "6.06",
         "524.8",
         "235.0",
         "14.3"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 11
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudoid</th>\n",
       "      <th>twodaycoll</th>\n",
       "      <th>dsex</th>\n",
       "      <th>coll_age_gp</th>\n",
       "      <th>d_wt</th>\n",
       "      <th>d_bmi_grp</th>\n",
       "      <th>wbc0</th>\n",
       "      <th>plt0</th>\n",
       "      <th>hgb0</th>\n",
       "      <th>absneut0</th>\n",
       "      <th>absmnc0</th>\n",
       "      <th>wbc5pre</th>\n",
       "      <th>absneut5pre</th>\n",
       "      <th>absmnc5pre</th>\n",
       "      <th>abscd34_5pre</th>\n",
       "      <th>plt5pre</th>\n",
       "      <th>hgb5pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>82024176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>59.09</td>\n",
       "      <td>99.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>275.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1.63</td>\n",
       "      <td>52.4</td>\n",
       "      <td>45.06</td>\n",
       "      <td>7.34</td>\n",
       "      <td>110.04</td>\n",
       "      <td>291.0</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7220</th>\n",
       "      <td>106452445.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>114.00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>234.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.04</td>\n",
       "      <td>28.6</td>\n",
       "      <td>23.74</td>\n",
       "      <td>4.86</td>\n",
       "      <td>85.80</td>\n",
       "      <td>215.0</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656</th>\n",
       "      <td>108559250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.67</td>\n",
       "      <td>99.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1.99</td>\n",
       "      <td>46.3</td>\n",
       "      <td>37.50</td>\n",
       "      <td>8.80</td>\n",
       "      <td>74.08</td>\n",
       "      <td>256.0</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11264</th>\n",
       "      <td>23717608.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>69.00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>207.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>3.95</td>\n",
       "      <td>2.01</td>\n",
       "      <td>52.2</td>\n",
       "      <td>45.94</td>\n",
       "      <td>6.26</td>\n",
       "      <td>73.08</td>\n",
       "      <td>218.0</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11325</th>\n",
       "      <td>23893387.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.26</td>\n",
       "      <td>99.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>231.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1.79</td>\n",
       "      <td>35.7</td>\n",
       "      <td>20.53</td>\n",
       "      <td>15.17</td>\n",
       "      <td>135.66</td>\n",
       "      <td>194.0</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11491</th>\n",
       "      <td>10267066.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.37</td>\n",
       "      <td>99.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>239.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.10</td>\n",
       "      <td>3.00</td>\n",
       "      <td>46.5</td>\n",
       "      <td>39.99</td>\n",
       "      <td>6.51</td>\n",
       "      <td>93.00</td>\n",
       "      <td>272.0</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14820</th>\n",
       "      <td>60495856.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75.30</td>\n",
       "      <td>99.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>279.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>6.68</td>\n",
       "      <td>2.89</td>\n",
       "      <td>48.1</td>\n",
       "      <td>41.85</td>\n",
       "      <td>6.73</td>\n",
       "      <td>86.58</td>\n",
       "      <td>217.0</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16688</th>\n",
       "      <td>48332933.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>67.00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>204.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>5.11</td>\n",
       "      <td>3.05</td>\n",
       "      <td>51.2</td>\n",
       "      <td>45.67</td>\n",
       "      <td>4.86</td>\n",
       "      <td>76.80</td>\n",
       "      <td>179.0</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17700</th>\n",
       "      <td>39493302.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.99</td>\n",
       "      <td>99.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>430.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>8.71</td>\n",
       "      <td>2.89</td>\n",
       "      <td>60.6</td>\n",
       "      <td>48.48</td>\n",
       "      <td>12.12</td>\n",
       "      <td>145.44</td>\n",
       "      <td>419.0</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19781</th>\n",
       "      <td>452658074.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80.74</td>\n",
       "      <td>99.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2.33</td>\n",
       "      <td>46.0</td>\n",
       "      <td>40.43</td>\n",
       "      <td>5.57</td>\n",
       "      <td>23.00</td>\n",
       "      <td>184.0</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21026</th>\n",
       "      <td>114387202.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>87.00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>224.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2.54</td>\n",
       "      <td>1.76</td>\n",
       "      <td>43.3</td>\n",
       "      <td>37.24</td>\n",
       "      <td>6.06</td>\n",
       "      <td>524.80</td>\n",
       "      <td>235.0</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pseudoid  twodaycoll  dsex  coll_age_gp    d_wt  d_bmi_grp  wbc0  \\\n",
       "1567    82024176.0         0.0   2.0          3.0   59.09       99.0   4.8   \n",
       "7220   106452445.0         0.0   1.0          3.0  114.00       99.0   5.5   \n",
       "7656   108559250.0         0.0   1.0          1.0   71.67       99.0   5.0   \n",
       "11264   23717608.0         0.0   1.0          4.0   69.00       99.0   5.9   \n",
       "11325   23893387.0         0.0   1.0          1.0   95.26       99.0   5.6   \n",
       "11491   10267066.0         0.0   1.0          4.0  128.37       99.0   9.1   \n",
       "14820   60495856.0         0.0   2.0          2.0   75.30       99.0   9.6   \n",
       "16688   48332933.0         0.0   2.0          3.0   67.00       99.0   8.2   \n",
       "17700   39493302.0         0.0   2.0          1.0   92.99       99.0  11.6   \n",
       "19781  452658074.0         0.0   2.0          4.0   80.74       99.0   6.0   \n",
       "21026  114387202.0         1.0   2.0          2.0   87.00       99.0   4.3   \n",
       "\n",
       "        plt0  hgb0  absneut0  absmnc0  wbc5pre  absneut5pre  absmnc5pre  \\\n",
       "1567   275.0  13.4      3.17     1.63     52.4        45.06        7.34   \n",
       "7220   234.0  15.1      3.47     2.04     28.6        23.74        4.86   \n",
       "7656   258.0  15.6      3.01     1.99     46.3        37.50        8.80   \n",
       "11264  207.0  13.4      3.95     2.01     52.2        45.94        6.26   \n",
       "11325  231.0  16.5      3.81     1.79     35.7        20.53       15.17   \n",
       "11491  239.0  15.0      6.10     3.00     46.5        39.99        6.51   \n",
       "14820  279.0  13.8      6.68     2.89     48.1        41.85        6.73   \n",
       "16688  204.0  13.6      5.11     3.05     51.2        45.67        4.86   \n",
       "17700  430.0  12.6      8.71     2.89     60.6        48.48       12.12   \n",
       "19781  252.0  13.8      3.65     2.33     46.0        40.43        5.57   \n",
       "21026  224.0  13.4      2.54     1.76     43.3        37.24        6.06   \n",
       "\n",
       "       abscd34_5pre  plt5pre  hgb5pre  \n",
       "1567         110.04    291.0     12.8  \n",
       "7220          85.80    215.0     15.2  \n",
       "7656          74.08    256.0     14.9  \n",
       "11264         73.08    218.0     13.4  \n",
       "11325        135.66    194.0     15.6  \n",
       "11491         93.00    272.0     14.9  \n",
       "14820         86.58    217.0     13.2  \n",
       "16688         76.80    179.0     13.4  \n",
       "17700        145.44    419.0     12.1  \n",
       "19781         23.00    184.0     14.3  \n",
       "21026        524.80    235.0     14.3  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the rows where d_bmi_grp == 99\n",
    "df[df['d_bmi_grp'] == 99]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbf86b0",
   "metadata": {},
   "source": [
    "#### Defining the Good and poor Mobilizers in full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70a7c5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count\n",
      "1    18576\n",
      "0     3325\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# add Count column, if abscd34_5pre is > 40 million, then Count is 1, else 0\n",
    "df['Count'] = np.where(df['abscd34_5pre'] > 40, 1, 0) # 1 for good and 0 for poor mobilizer\n",
    "# check the distribution of Count\n",
    "print(df['Count'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2772f21a",
   "metadata": {},
   "source": [
    "##### Removing the data with \"Twodaycoll\" as 1\n",
    "We're removing the data of the donors who underwent collection over two days and keep only those who underwent collection on a single day. This is done to ensure that the mobilization data is consistent and comparable across all donors without any discrepancies or biases that might arise from multi-day collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c49ec9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pseudoid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "twodaycoll",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dsex",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "coll_age_gp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_wt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_bmi_grp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wbc0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "plt0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hgb0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absneut0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absmnc0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wbc5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absneut5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absmnc5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "abscd34_5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "plt5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hgb5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "42ae3256-2420-47df-9bdd-31e836b17555",
       "rows": [
        [
         "0",
         "93409976.0",
         "0.0",
         "1.0",
         "4.0",
         "93.0",
         "4.0",
         "3.8",
         "159.0",
         "15.5",
         "2.24",
         "1.56",
         "13.0",
         "10.79",
         "2.21",
         "11.7",
         "136.0",
         "14.4",
         "0"
        ],
        [
         "1",
         "93370093.0",
         "0.0",
         "2.0",
         "4.0",
         "79.0",
         "3.0",
         "5.5",
         "218.0",
         "13.2",
         "3.0",
         "2.49",
         "31.2",
         "26.36",
         "4.8",
         "70.2",
         "232.0",
         "12.2",
         "1"
        ],
        [
         "2",
         "93323774.0",
         "0.0",
         "1.0",
         "4.0",
         "124.0",
         "4.0",
         "6.1",
         "175.0",
         "15.0",
         "3.23",
         "2.87",
         "31.5",
         "26.46",
         "5.04",
         "22.05",
         "181.0",
         "14.9",
         "0"
        ],
        [
         "3",
         "93344918.0",
         "0.0",
         "1.0",
         "4.0",
         "84.0",
         "3.0",
         "8.0",
         "280.0",
         "15.4",
         "5.04",
         "2.96",
         "68.4",
         "60.19",
         "8.21",
         "87.55",
         "230.0",
         "15.9",
         "1"
        ],
        [
         "4",
         "93355053.0",
         "0.0",
         "2.0",
         "4.0",
         "94.0",
         "4.0",
         "8.1",
         "351.0",
         "13.2",
         "4.94",
         "3.16",
         "34.0",
         "26.18",
         "7.82",
         "51.0",
         "278.0",
         "11.7",
         "1"
        ],
        [
         "5",
         "93562560.0",
         "0.0",
         "1.0",
         "4.0",
         "95.0",
         "3.0",
         "4.2",
         "299.0",
         "16.1",
         "2.18",
         "2.02",
         "54.9",
         "47.21",
         "7.69",
         "76.86",
         "222.0",
         "14.3",
         "1"
        ],
        [
         "6",
         "93568857.0",
         "0.0",
         "1.0",
         "3.0",
         "87.09",
         "3.0",
         "7.1",
         "256.0",
         "16.2",
         "4.54",
         "2.56",
         "42.4",
         "36.04",
         "6.36",
         "106.0",
         "199.0",
         "14.6",
         "1"
        ],
        [
         "7",
         "93571163.0",
         "0.0",
         "2.0",
         "3.0",
         "54.0",
         "2.0",
         "5.4",
         "244.0",
         "12.9",
         "3.35",
         "2.05",
         "29.2",
         "23.07",
         "6.13",
         "37.96",
         "267.0",
         "12.1",
         "0"
        ],
        [
         "8",
         "93580161.0",
         "0.0",
         "1.0",
         "4.0",
         "97.0",
         "3.0",
         "5.5",
         "188.0",
         "15.7",
         "3.41",
         "2.09",
         "38.7",
         "30.19",
         "8.51",
         "46.44",
         "212.0",
         "15.2",
         "1"
        ],
        [
         "9",
         "93525333.0",
         "0.0",
         "2.0",
         "4.0",
         "91.63",
         "4.0",
         "5.8",
         "247.0",
         "13.9",
         "3.71",
         "2.09",
         "25.8",
         "21.98",
         "3.82",
         "67.08",
         "182.0",
         "13.7",
         "1"
        ],
        [
         "10",
         "93529830.0",
         "0.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "10.3",
         "425.0",
         "12.5",
         "7.27",
         "3.03",
         "43.4",
         "40.8",
         "2.6",
         "81.16",
         "244.0",
         "11.7",
         "1"
        ],
        [
         "11",
         "93530273.0",
         "0.0",
         "1.0",
         "3.0",
         "105.23",
         "4.0",
         "5.3",
         "188.0",
         "15.4",
         "3.13",
         "2.17",
         "33.9",
         "27.46",
         "6.44",
         "88.14",
         "135.0",
         "15.7",
         "1"
        ],
        [
         "12",
         "93538145.0",
         "0.0",
         "1.0",
         "4.0",
         "119.75",
         "4.0",
         "6.6",
         "192.0",
         "14.2",
         "4.09",
         "2.51",
         "41.4",
         "33.53",
         "7.87",
         "82.8",
         "168.0",
         "14.7",
         "1"
        ],
        [
         "14",
         "93544412.0",
         "0.0",
         "1.0",
         "4.0",
         "103.63",
         "4.0",
         "5.6",
         "238.0",
         "17.0",
         "3.26",
         "2.34",
         "35.5",
         "30.0",
         "5.5",
         "97.63",
         "207.0",
         "15.7",
         "1"
        ],
        [
         "15",
         "93469126.0",
         "0.0",
         "1.0",
         "3.0",
         "79.0",
         "2.0",
         "5.6",
         "204.0",
         "14.0",
         "3.75",
         "1.85",
         "25.3",
         "23.68",
         "1.62",
         "35.42",
         "131.0",
         "13.5",
         "0"
        ],
        [
         "16",
         "93677034.0",
         "0.0",
         "1.0",
         "4.0",
         "87.0",
         "4.0",
         "5.5",
         "173.0",
         "14.2",
         "4.03",
         "1.47",
         "28.0",
         "24.81",
         "3.19",
         "103.6",
         "189.0",
         "14.1",
         "1"
        ],
        [
         "17",
         "93629310.0",
         "0.0",
         "2.0",
         "4.0",
         "85.0",
         "4.0",
         "10.8",
         "398.0",
         "15.3",
         "7.48",
         "3.3",
         "62.5",
         "46.88",
         "15.63",
         "93.75",
         "316.0",
         "14.4",
         "1"
        ],
        [
         "18",
         "93650522.0",
         "0.0",
         "1.0",
         "3.0",
         "77.27",
         "3.0",
         "5.6",
         "191.0",
         "17.1",
         "3.98",
         "1.62",
         "61.0",
         "55.51",
         "5.49",
         "73.2",
         "176.0",
         "15.9",
         "1"
        ],
        [
         "19",
         "93609903.0",
         "0.0",
         "1.0",
         "4.0",
         "112.49",
         "4.0",
         "6.2",
         "198.0",
         "15.2",
         "3.97",
         "2.17",
         "52.6",
         "44.39",
         "8.21",
         "42.08",
         "223.0",
         "13.4",
         "1"
        ],
        [
         "20",
         "93611587.0",
         "0.0",
         "1.0",
         "4.0",
         "68.0",
         "2.0",
         "8.2",
         "343.0",
         "14.0",
         "5.17",
         "2.87",
         "33.8",
         "23.32",
         "10.48",
         "270.4",
         "328.0",
         "13.6",
         "1"
        ],
        [
         "21",
         "93612785.0",
         "0.0",
         "1.0",
         "4.0",
         "88.0",
         "4.0",
         "8.6",
         "201.0",
         "16.0",
         "6.71",
         "1.89",
         "42.2",
         "27.85",
         "14.35",
         "88.62",
         "200.0",
         "13.0",
         "1"
        ],
        [
         "22",
         "93828609.0",
         "0.0",
         "1.0",
         "3.0",
         "88.0",
         "4.0",
         "6.1",
         "207.0",
         "13.0",
         "3.89",
         "2.21",
         "46.6",
         "43.34",
         "3.26",
         "116.5",
         "216.0",
         "13.1",
         "1"
        ],
        [
         "23",
         "93770923.0",
         "0.0",
         "1.0",
         "3.0",
         "81.0",
         "2.0",
         "7.8",
         "247.0",
         "14.6",
         "4.24",
         "3.51",
         "43.8",
         "35.78",
         "8.02",
         "122.64",
         "211.0",
         "13.2",
         "1"
        ],
        [
         "24",
         "93722512.0",
         "0.0",
         "1.0",
         "3.0",
         "75.45",
         "2.0",
         "5.3",
         "196.0",
         "14.6",
         "3.13",
         "2.17",
         "28.5",
         "24.51",
         "3.99",
         "62.7",
         "185.0",
         "13.3",
         "1"
        ],
        [
         "25",
         "93961139.0",
         "0.0",
         "2.0",
         "4.0",
         "87.0",
         "3.0",
         "7.8",
         "287.0",
         "13.8",
         "4.98",
         "2.82",
         "32.1",
         "24.72",
         "8.35",
         "19.26",
         "275.0",
         "12.8",
         "0"
        ],
        [
         "26",
         "93902962.0",
         "0.0",
         "2.0",
         "3.0",
         "64.41",
         "2.0",
         "6.0",
         "232.0",
         "13.9",
         "4.44",
         "1.56",
         "43.8",
         "37.23",
         "6.57",
         "52.56",
         "239.0",
         "13.7",
         "1"
        ],
        [
         "27",
         "93912879.0",
         "0.0",
         "2.0",
         "3.0",
         "74.84",
         "4.0",
         "6.7",
         "252.0",
         "13.3",
         "4.22",
         "2.41",
         "23.4",
         "18.25",
         "5.15",
         "46.8",
         "205.0",
         "13.1",
         "1"
        ],
        [
         "29",
         "93855245.0",
         "0.0",
         "1.0",
         "2.0",
         "93.63",
         "3.0",
         "7.5",
         "191.0",
         "16.7",
         "5.92",
         "1.5",
         "47.5",
         "43.23",
         "3.66",
         "61.75",
         "189.0",
         "15.2",
         "1"
        ],
        [
         "30",
         "94086404.0",
         "0.0",
         "2.0",
         "3.0",
         "87.0",
         "4.0",
         "6.3",
         "251.0",
         "13.7",
         "3.53",
         "2.77",
         "46.5",
         "36.74",
         "9.77",
         "102.3",
         "214.0",
         "12.2",
         "1"
        ],
        [
         "31",
         "94101687.0",
         "0.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "5.9",
         "286.0",
         "16.3",
         "4.08",
         "1.82",
         "54.9",
         "47.87",
         "6.97",
         "878.4",
         "235.0",
         "16.4",
         "1"
        ],
        [
         "32",
         "94056760.0",
         "0.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "6.7",
         "271.0",
         "13.6",
         "3.73",
         "2.97",
         "47.9",
         "37.12",
         "10.78",
         "57.48",
         "206.0",
         "13.6",
         "1"
        ],
        [
         "33",
         "93987175.0",
         "0.0",
         "1.0",
         "4.0",
         "96.0",
         "3.0",
         "7.5",
         "318.0",
         "14.5",
         "5.28",
         "2.23",
         "42.6",
         "35.36",
         "7.24",
         "85.2",
         "249.0",
         "13.5",
         "1"
        ],
        [
         "34",
         "93993202.0",
         "0.0",
         "2.0",
         "4.0",
         "90.27",
         "4.0",
         "5.7",
         "217.0",
         "14.1",
         "3.31",
         "2.39",
         "50.7",
         "44.51",
         "6.19",
         "106.47",
         "225.0",
         "14.5",
         "1"
        ],
        [
         "35",
         "93994677.0",
         "0.0",
         "1.0",
         "2.0",
         "105.9",
         "4.0",
         "5.4",
         "273.0",
         "15.1",
         "3.62",
         "1.78",
         "28.9",
         "26.01",
         "2.89",
         "112.71",
         "177.0",
         "14.0",
         "1"
        ],
        [
         "36",
         "94177942.0",
         "0.0",
         "1.0",
         "4.0",
         "69.4",
         "2.0",
         "7.6",
         "275.0",
         "16.2",
         "6.22",
         "1.38",
         "34.4",
         "27.52",
         "6.88",
         "72.24",
         "262.0",
         "15.6",
         "1"
        ],
        [
         "37",
         "94191277.0",
         "0.0",
         "2.0",
         "2.0",
         "54.54",
         "2.0",
         "8.4",
         "208.0",
         "13.0",
         "6.47",
         "1.93",
         "38.4",
         "31.87",
         "6.14",
         "15.36",
         "223.0",
         "13.0",
         "0"
        ],
        [
         "38",
         "94203152.0",
         "0.0",
         "2.0",
         "4.0",
         "69.09",
         "3.0",
         "4.3",
         "383.0",
         "13.5",
         "2.55",
         "1.75",
         "41.5",
         "34.94",
         "6.52",
         "83.0",
         "336.0",
         "12.6",
         "1"
        ],
        [
         "39",
         "94115557.0",
         "0.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "7.2",
         "204.0",
         "14.4",
         "4.82",
         "2.38",
         "74.5",
         "65.41",
         "9.01",
         "298.0",
         "218.0",
         "14.8",
         "1"
        ],
        [
         "40",
         "94120876.0",
         "0.0",
         "2.0",
         "3.0",
         "82.0",
         "4.0",
         "10.1",
         "359.0",
         "14.4",
         "6.46",
         "3.64",
         "29.0",
         "19.72",
         "9.28",
         "26.1",
         "306.0",
         "12.5",
         "0"
        ],
        [
         "41",
         "94121628.0",
         "0.0",
         "1.0",
         "3.0",
         "97.0",
         "4.0",
         "4.8",
         "183.0",
         "15.4",
         "3.41",
         "1.39",
         "29.9",
         "24.82",
         "5.08",
         "110.63",
         "182.0",
         "15.4",
         "1"
        ],
        [
         "42",
         "94131849.0",
         "0.0",
         "1.0",
         "2.0",
         "80.74",
         "2.0",
         "4.6",
         "186.0",
         "16.5",
         "3.12",
         "1.48",
         "20.0",
         "16.2",
         "3.8",
         "49.0",
         "180.0",
         "16.8",
         "1"
        ],
        [
         "43",
         "94344490.0",
         "0.0",
         "1.0",
         "3.0",
         "107.0",
         "4.0",
         "4.9",
         "206.0",
         "15.2",
         "2.97",
         "1.92",
         "34.0",
         "28.9",
         "4.76",
         "102.0",
         "186.0",
         "15.2",
         "1"
        ],
        [
         "44",
         "94348239.0",
         "0.0",
         "1.0",
         "3.0",
         "96.36",
         "3.0",
         "5.3",
         "262.0",
         "15.3",
         "3.02",
         "2.28",
         "34.6",
         "29.76",
         "4.84",
         "76.12",
         "243.0",
         "14.9",
         "1"
        ],
        [
         "45",
         "94311317.0",
         "0.0",
         "1.0",
         "2.0",
         "79.0",
         "2.0",
         "5.6",
         "173.0",
         "16.4",
         "3.86",
         "1.74",
         "46.3",
         "41.81",
         "4.49",
         "64.82",
         "142.0",
         "14.9",
         "1"
        ],
        [
         "46",
         "94316721.0",
         "0.0",
         "2.0",
         "3.0",
         "60.0",
         "2.0",
         "5.0",
         "259.0",
         "11.9",
         "3.0",
         "1.99",
         "46.7",
         "40.07",
         "6.63",
         "77.06",
         "232.0",
         "12.5",
         "1"
        ],
        [
         "47",
         "94276724.0",
         "0.0",
         "1.0",
         "3.0",
         "99.0",
         "4.0",
         "4.9",
         "199.0",
         "13.7",
         "2.7",
         "2.21",
         "28.5",
         "25.37",
         "3.14",
         "35.91",
         "205.0",
         "13.0",
         "0"
        ],
        [
         "48",
         "94301982.0",
         "0.0",
         "1.0",
         "4.0",
         "102.51",
         "4.0",
         "6.5",
         "166.0",
         "15.7",
         "4.63",
         "1.87",
         "39.9",
         "33.08",
         "6.82",
         "35.91",
         "187.0",
         "15.0",
         "0"
        ],
        [
         "49",
         "94303078.0",
         "0.0",
         "1.0",
         "3.0",
         "105.69",
         "4.0",
         "6.2",
         "178.0",
         "15.3",
         "3.7",
         "2.5",
         "36.6",
         "31.26",
         "5.34",
         "157.38",
         "141.0",
         "14.3",
         "1"
        ],
        [
         "50",
         "94247403.0",
         "0.0",
         "2.0",
         "4.0",
         "55.0",
         "2.0",
         "6.4",
         "224.0",
         "13.7",
         "4.03",
         "2.36",
         "32.3",
         "29.55",
         "2.75",
         "129.2",
         "202.0",
         "12.5",
         "1"
        ],
        [
         "51",
         "92348789.0",
         "0.0",
         "1.0",
         "4.0",
         "104.0",
         "4.0",
         "10.1",
         "197.0",
         "16.3",
         "6.27",
         "3.8",
         "41.3",
         "35.11",
         "7.43",
         "49.56",
         "177.0",
         "15.3",
         "1"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 19617
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudoid</th>\n",
       "      <th>twodaycoll</th>\n",
       "      <th>dsex</th>\n",
       "      <th>coll_age_gp</th>\n",
       "      <th>d_wt</th>\n",
       "      <th>d_bmi_grp</th>\n",
       "      <th>wbc0</th>\n",
       "      <th>plt0</th>\n",
       "      <th>hgb0</th>\n",
       "      <th>absneut0</th>\n",
       "      <th>absmnc0</th>\n",
       "      <th>wbc5pre</th>\n",
       "      <th>absneut5pre</th>\n",
       "      <th>absmnc5pre</th>\n",
       "      <th>abscd34_5pre</th>\n",
       "      <th>plt5pre</th>\n",
       "      <th>hgb5pre</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93409976.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>159.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.56</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.79</td>\n",
       "      <td>2.21</td>\n",
       "      <td>11.70</td>\n",
       "      <td>136.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93370093.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>218.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.49</td>\n",
       "      <td>31.2</td>\n",
       "      <td>26.36</td>\n",
       "      <td>4.80</td>\n",
       "      <td>70.20</td>\n",
       "      <td>232.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93323774.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>175.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.87</td>\n",
       "      <td>31.5</td>\n",
       "      <td>26.46</td>\n",
       "      <td>5.04</td>\n",
       "      <td>22.05</td>\n",
       "      <td>181.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93344918.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>5.04</td>\n",
       "      <td>2.96</td>\n",
       "      <td>68.4</td>\n",
       "      <td>60.19</td>\n",
       "      <td>8.21</td>\n",
       "      <td>87.55</td>\n",
       "      <td>230.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93355053.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>351.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3.16</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.18</td>\n",
       "      <td>7.82</td>\n",
       "      <td>51.00</td>\n",
       "      <td>278.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005</th>\n",
       "      <td>440943238.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>322.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>3.97</td>\n",
       "      <td>2.23</td>\n",
       "      <td>52.5</td>\n",
       "      <td>44.63</td>\n",
       "      <td>7.88</td>\n",
       "      <td>126.00</td>\n",
       "      <td>296.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006</th>\n",
       "      <td>440944836.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.93</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>173.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>2.52</td>\n",
       "      <td>2.08</td>\n",
       "      <td>35.9</td>\n",
       "      <td>31.41</td>\n",
       "      <td>4.49</td>\n",
       "      <td>61.03</td>\n",
       "      <td>191.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20007</th>\n",
       "      <td>440949006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>295.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3.54</td>\n",
       "      <td>2.56</td>\n",
       "      <td>38.9</td>\n",
       "      <td>31.51</td>\n",
       "      <td>7.39</td>\n",
       "      <td>237.29</td>\n",
       "      <td>270.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20008</th>\n",
       "      <td>440956226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>211.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.19</td>\n",
       "      <td>28.1</td>\n",
       "      <td>22.06</td>\n",
       "      <td>6.04</td>\n",
       "      <td>70.25</td>\n",
       "      <td>195.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20009</th>\n",
       "      <td>441127927.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>363.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>5.92</td>\n",
       "      <td>2.69</td>\n",
       "      <td>52.6</td>\n",
       "      <td>46.29</td>\n",
       "      <td>6.31</td>\n",
       "      <td>120.98</td>\n",
       "      <td>294.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19617 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pseudoid  twodaycoll  dsex  coll_age_gp    d_wt  d_bmi_grp  wbc0  \\\n",
       "0       93409976.0         0.0   1.0          4.0   93.00        4.0   3.8   \n",
       "1       93370093.0         0.0   2.0          4.0   79.00        3.0   5.5   \n",
       "2       93323774.0         0.0   1.0          4.0  124.00        4.0   6.1   \n",
       "3       93344918.0         0.0   1.0          4.0   84.00        3.0   8.0   \n",
       "4       93355053.0         0.0   2.0          4.0   94.00        4.0   8.1   \n",
       "...            ...         ...   ...          ...     ...        ...   ...   \n",
       "20005  440943238.0         0.0   1.0          1.0   97.52        3.0   6.2   \n",
       "20006  440944836.0         0.0   1.0          1.0   78.93        2.0   4.6   \n",
       "20007  440949006.0         0.0   2.0          1.0   72.58        3.0   6.1   \n",
       "20008  440956226.0         0.0   1.0          1.0   71.67        3.0   3.8   \n",
       "20009  441127927.0         0.0   2.0          1.0   93.44        3.0   8.7   \n",
       "\n",
       "        plt0  hgb0  absneut0  absmnc0  wbc5pre  absneut5pre  absmnc5pre  \\\n",
       "0      159.0  15.5      2.24     1.56     13.0        10.79        2.21   \n",
       "1      218.0  13.2      3.00     2.49     31.2        26.36        4.80   \n",
       "2      175.0  15.0      3.23     2.87     31.5        26.46        5.04   \n",
       "3      280.0  15.4      5.04     2.96     68.4        60.19        8.21   \n",
       "4      351.0  13.2      4.94     3.16     34.0        26.18        7.82   \n",
       "...      ...   ...       ...      ...      ...          ...         ...   \n",
       "20005  322.0  15.3      3.97     2.23     52.5        44.63        7.88   \n",
       "20006  173.0  14.7      2.52     2.08     35.9        31.41        4.49   \n",
       "20007  295.0  13.3      3.54     2.56     38.9        31.51        7.39   \n",
       "20008  211.0  14.8      1.61     2.19     28.1        22.06        6.04   \n",
       "20009  363.0  12.6      5.92     2.69     52.6        46.29        6.31   \n",
       "\n",
       "       abscd34_5pre  plt5pre  hgb5pre  Count  \n",
       "0             11.70    136.0     14.4      0  \n",
       "1             70.20    232.0     12.2      1  \n",
       "2             22.05    181.0     14.9      0  \n",
       "3             87.55    230.0     15.9      1  \n",
       "4             51.00    278.0     11.7      1  \n",
       "...             ...      ...      ...    ...  \n",
       "20005        126.00    296.0     14.2      1  \n",
       "20006         61.03    191.0     14.8      1  \n",
       "20007        237.29    270.0     13.6      1  \n",
       "20008         70.25    195.0     14.7      1  \n",
       "20009        120.98    294.0     12.2      1  \n",
       "\n",
       "[19617 rows x 18 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rows with twodaycoll == 1\n",
    "df = df[df['twodaycoll'] != 1].copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "210b0b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count\n",
      "1    17004\n",
      "0     2613\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check the distribution of Count\n",
    "print(df['Count'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61b746b",
   "metadata": {},
   "source": [
    "### Defining Pre-G-CSF dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ae1334a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pseudoid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "twodaycoll",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dsex",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "coll_age_gp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_wt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_bmi_grp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wbc0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "plt0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hgb0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absneut0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absmnc0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "abscd34_5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "00600621-c839-44d3-9179-a5bb77c3a396",
       "rows": [
        [
         "0",
         "93409976.0",
         "0.0",
         "1.0",
         "4.0",
         "93.0",
         "4.0",
         "3.8",
         "159.0",
         "15.5",
         "2.24",
         "1.56",
         "11.7",
         "0"
        ],
        [
         "1",
         "93370093.0",
         "0.0",
         "2.0",
         "4.0",
         "79.0",
         "3.0",
         "5.5",
         "218.0",
         "13.2",
         "3.0",
         "2.49",
         "70.2",
         "1"
        ],
        [
         "2",
         "93323774.0",
         "0.0",
         "1.0",
         "4.0",
         "124.0",
         "4.0",
         "6.1",
         "175.0",
         "15.0",
         "3.23",
         "2.87",
         "22.05",
         "0"
        ],
        [
         "3",
         "93344918.0",
         "0.0",
         "1.0",
         "4.0",
         "84.0",
         "3.0",
         "8.0",
         "280.0",
         "15.4",
         "5.04",
         "2.96",
         "87.55",
         "1"
        ],
        [
         "4",
         "93355053.0",
         "0.0",
         "2.0",
         "4.0",
         "94.0",
         "4.0",
         "8.1",
         "351.0",
         "13.2",
         "4.94",
         "3.16",
         "51.0",
         "1"
        ],
        [
         "5",
         "93562560.0",
         "0.0",
         "1.0",
         "4.0",
         "95.0",
         "3.0",
         "4.2",
         "299.0",
         "16.1",
         "2.18",
         "2.02",
         "76.86",
         "1"
        ],
        [
         "6",
         "93568857.0",
         "0.0",
         "1.0",
         "3.0",
         "87.09",
         "3.0",
         "7.1",
         "256.0",
         "16.2",
         "4.54",
         "2.56",
         "106.0",
         "1"
        ],
        [
         "7",
         "93571163.0",
         "0.0",
         "2.0",
         "3.0",
         "54.0",
         "2.0",
         "5.4",
         "244.0",
         "12.9",
         "3.35",
         "2.05",
         "37.96",
         "0"
        ],
        [
         "8",
         "93580161.0",
         "0.0",
         "1.0",
         "4.0",
         "97.0",
         "3.0",
         "5.5",
         "188.0",
         "15.7",
         "3.41",
         "2.09",
         "46.44",
         "1"
        ],
        [
         "9",
         "93525333.0",
         "0.0",
         "2.0",
         "4.0",
         "91.63",
         "4.0",
         "5.8",
         "247.0",
         "13.9",
         "3.71",
         "2.09",
         "67.08",
         "1"
        ],
        [
         "10",
         "93529830.0",
         "0.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "10.3",
         "425.0",
         "12.5",
         "7.27",
         "3.03",
         "81.16",
         "1"
        ],
        [
         "11",
         "93530273.0",
         "0.0",
         "1.0",
         "3.0",
         "105.23",
         "4.0",
         "5.3",
         "188.0",
         "15.4",
         "3.13",
         "2.17",
         "88.14",
         "1"
        ],
        [
         "12",
         "93538145.0",
         "0.0",
         "1.0",
         "4.0",
         "119.75",
         "4.0",
         "6.6",
         "192.0",
         "14.2",
         "4.09",
         "2.51",
         "82.8",
         "1"
        ],
        [
         "14",
         "93544412.0",
         "0.0",
         "1.0",
         "4.0",
         "103.63",
         "4.0",
         "5.6",
         "238.0",
         "17.0",
         "3.26",
         "2.34",
         "97.63",
         "1"
        ],
        [
         "15",
         "93469126.0",
         "0.0",
         "1.0",
         "3.0",
         "79.0",
         "2.0",
         "5.6",
         "204.0",
         "14.0",
         "3.75",
         "1.85",
         "35.42",
         "0"
        ],
        [
         "16",
         "93677034.0",
         "0.0",
         "1.0",
         "4.0",
         "87.0",
         "4.0",
         "5.5",
         "173.0",
         "14.2",
         "4.03",
         "1.47",
         "103.6",
         "1"
        ],
        [
         "17",
         "93629310.0",
         "0.0",
         "2.0",
         "4.0",
         "85.0",
         "4.0",
         "10.8",
         "398.0",
         "15.3",
         "7.48",
         "3.3",
         "93.75",
         "1"
        ],
        [
         "18",
         "93650522.0",
         "0.0",
         "1.0",
         "3.0",
         "77.27",
         "3.0",
         "5.6",
         "191.0",
         "17.1",
         "3.98",
         "1.62",
         "73.2",
         "1"
        ],
        [
         "19",
         "93609903.0",
         "0.0",
         "1.0",
         "4.0",
         "112.49",
         "4.0",
         "6.2",
         "198.0",
         "15.2",
         "3.97",
         "2.17",
         "42.08",
         "1"
        ],
        [
         "20",
         "93611587.0",
         "0.0",
         "1.0",
         "4.0",
         "68.0",
         "2.0",
         "8.2",
         "343.0",
         "14.0",
         "5.17",
         "2.87",
         "270.4",
         "1"
        ],
        [
         "21",
         "93612785.0",
         "0.0",
         "1.0",
         "4.0",
         "88.0",
         "4.0",
         "8.6",
         "201.0",
         "16.0",
         "6.71",
         "1.89",
         "88.62",
         "1"
        ],
        [
         "22",
         "93828609.0",
         "0.0",
         "1.0",
         "3.0",
         "88.0",
         "4.0",
         "6.1",
         "207.0",
         "13.0",
         "3.89",
         "2.21",
         "116.5",
         "1"
        ],
        [
         "23",
         "93770923.0",
         "0.0",
         "1.0",
         "3.0",
         "81.0",
         "2.0",
         "7.8",
         "247.0",
         "14.6",
         "4.24",
         "3.51",
         "122.64",
         "1"
        ],
        [
         "24",
         "93722512.0",
         "0.0",
         "1.0",
         "3.0",
         "75.45",
         "2.0",
         "5.3",
         "196.0",
         "14.6",
         "3.13",
         "2.17",
         "62.7",
         "1"
        ],
        [
         "25",
         "93961139.0",
         "0.0",
         "2.0",
         "4.0",
         "87.0",
         "3.0",
         "7.8",
         "287.0",
         "13.8",
         "4.98",
         "2.82",
         "19.26",
         "0"
        ],
        [
         "26",
         "93902962.0",
         "0.0",
         "2.0",
         "3.0",
         "64.41",
         "2.0",
         "6.0",
         "232.0",
         "13.9",
         "4.44",
         "1.56",
         "52.56",
         "1"
        ],
        [
         "27",
         "93912879.0",
         "0.0",
         "2.0",
         "3.0",
         "74.84",
         "4.0",
         "6.7",
         "252.0",
         "13.3",
         "4.22",
         "2.41",
         "46.8",
         "1"
        ],
        [
         "29",
         "93855245.0",
         "0.0",
         "1.0",
         "2.0",
         "93.63",
         "3.0",
         "7.5",
         "191.0",
         "16.7",
         "5.92",
         "1.5",
         "61.75",
         "1"
        ],
        [
         "30",
         "94086404.0",
         "0.0",
         "2.0",
         "3.0",
         "87.0",
         "4.0",
         "6.3",
         "251.0",
         "13.7",
         "3.53",
         "2.77",
         "102.3",
         "1"
        ],
        [
         "31",
         "94101687.0",
         "0.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "5.9",
         "286.0",
         "16.3",
         "4.08",
         "1.82",
         "878.4",
         "1"
        ],
        [
         "32",
         "94056760.0",
         "0.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "6.7",
         "271.0",
         "13.6",
         "3.73",
         "2.97",
         "57.48",
         "1"
        ],
        [
         "33",
         "93987175.0",
         "0.0",
         "1.0",
         "4.0",
         "96.0",
         "3.0",
         "7.5",
         "318.0",
         "14.5",
         "5.28",
         "2.23",
         "85.2",
         "1"
        ],
        [
         "34",
         "93993202.0",
         "0.0",
         "2.0",
         "4.0",
         "90.27",
         "4.0",
         "5.7",
         "217.0",
         "14.1",
         "3.31",
         "2.39",
         "106.47",
         "1"
        ],
        [
         "35",
         "93994677.0",
         "0.0",
         "1.0",
         "2.0",
         "105.9",
         "4.0",
         "5.4",
         "273.0",
         "15.1",
         "3.62",
         "1.78",
         "112.71",
         "1"
        ],
        [
         "36",
         "94177942.0",
         "0.0",
         "1.0",
         "4.0",
         "69.4",
         "2.0",
         "7.6",
         "275.0",
         "16.2",
         "6.22",
         "1.38",
         "72.24",
         "1"
        ],
        [
         "37",
         "94191277.0",
         "0.0",
         "2.0",
         "2.0",
         "54.54",
         "2.0",
         "8.4",
         "208.0",
         "13.0",
         "6.47",
         "1.93",
         "15.36",
         "0"
        ],
        [
         "38",
         "94203152.0",
         "0.0",
         "2.0",
         "4.0",
         "69.09",
         "3.0",
         "4.3",
         "383.0",
         "13.5",
         "2.55",
         "1.75",
         "83.0",
         "1"
        ],
        [
         "39",
         "94115557.0",
         "0.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "7.2",
         "204.0",
         "14.4",
         "4.82",
         "2.38",
         "298.0",
         "1"
        ],
        [
         "40",
         "94120876.0",
         "0.0",
         "2.0",
         "3.0",
         "82.0",
         "4.0",
         "10.1",
         "359.0",
         "14.4",
         "6.46",
         "3.64",
         "26.1",
         "0"
        ],
        [
         "41",
         "94121628.0",
         "0.0",
         "1.0",
         "3.0",
         "97.0",
         "4.0",
         "4.8",
         "183.0",
         "15.4",
         "3.41",
         "1.39",
         "110.63",
         "1"
        ],
        [
         "42",
         "94131849.0",
         "0.0",
         "1.0",
         "2.0",
         "80.74",
         "2.0",
         "4.6",
         "186.0",
         "16.5",
         "3.12",
         "1.48",
         "49.0",
         "1"
        ],
        [
         "43",
         "94344490.0",
         "0.0",
         "1.0",
         "3.0",
         "107.0",
         "4.0",
         "4.9",
         "206.0",
         "15.2",
         "2.97",
         "1.92",
         "102.0",
         "1"
        ],
        [
         "44",
         "94348239.0",
         "0.0",
         "1.0",
         "3.0",
         "96.36",
         "3.0",
         "5.3",
         "262.0",
         "15.3",
         "3.02",
         "2.28",
         "76.12",
         "1"
        ],
        [
         "45",
         "94311317.0",
         "0.0",
         "1.0",
         "2.0",
         "79.0",
         "2.0",
         "5.6",
         "173.0",
         "16.4",
         "3.86",
         "1.74",
         "64.82",
         "1"
        ],
        [
         "46",
         "94316721.0",
         "0.0",
         "2.0",
         "3.0",
         "60.0",
         "2.0",
         "5.0",
         "259.0",
         "11.9",
         "3.0",
         "1.99",
         "77.06",
         "1"
        ],
        [
         "47",
         "94276724.0",
         "0.0",
         "1.0",
         "3.0",
         "99.0",
         "4.0",
         "4.9",
         "199.0",
         "13.7",
         "2.7",
         "2.21",
         "35.91",
         "0"
        ],
        [
         "48",
         "94301982.0",
         "0.0",
         "1.0",
         "4.0",
         "102.51",
         "4.0",
         "6.5",
         "166.0",
         "15.7",
         "4.63",
         "1.87",
         "35.91",
         "0"
        ],
        [
         "49",
         "94303078.0",
         "0.0",
         "1.0",
         "3.0",
         "105.69",
         "4.0",
         "6.2",
         "178.0",
         "15.3",
         "3.7",
         "2.5",
         "157.38",
         "1"
        ],
        [
         "50",
         "94247403.0",
         "0.0",
         "2.0",
         "4.0",
         "55.0",
         "2.0",
         "6.4",
         "224.0",
         "13.7",
         "4.03",
         "2.36",
         "129.2",
         "1"
        ],
        [
         "51",
         "92348789.0",
         "0.0",
         "1.0",
         "4.0",
         "104.0",
         "4.0",
         "10.1",
         "197.0",
         "16.3",
         "6.27",
         "3.8",
         "49.56",
         "1"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 19617
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudoid</th>\n",
       "      <th>twodaycoll</th>\n",
       "      <th>dsex</th>\n",
       "      <th>coll_age_gp</th>\n",
       "      <th>d_wt</th>\n",
       "      <th>d_bmi_grp</th>\n",
       "      <th>wbc0</th>\n",
       "      <th>plt0</th>\n",
       "      <th>hgb0</th>\n",
       "      <th>absneut0</th>\n",
       "      <th>absmnc0</th>\n",
       "      <th>abscd34_5pre</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93409976.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>159.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.56</td>\n",
       "      <td>11.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93370093.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>218.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.49</td>\n",
       "      <td>70.20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93323774.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>175.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.87</td>\n",
       "      <td>22.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93344918.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>5.04</td>\n",
       "      <td>2.96</td>\n",
       "      <td>87.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93355053.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>351.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3.16</td>\n",
       "      <td>51.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005</th>\n",
       "      <td>440943238.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>322.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>3.97</td>\n",
       "      <td>2.23</td>\n",
       "      <td>126.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006</th>\n",
       "      <td>440944836.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.93</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>173.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>2.52</td>\n",
       "      <td>2.08</td>\n",
       "      <td>61.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20007</th>\n",
       "      <td>440949006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>295.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3.54</td>\n",
       "      <td>2.56</td>\n",
       "      <td>237.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20008</th>\n",
       "      <td>440956226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>211.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.19</td>\n",
       "      <td>70.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20009</th>\n",
       "      <td>441127927.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>363.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>5.92</td>\n",
       "      <td>2.69</td>\n",
       "      <td>120.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19617 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pseudoid  twodaycoll  dsex  coll_age_gp    d_wt  d_bmi_grp  wbc0  \\\n",
       "0       93409976.0         0.0   1.0          4.0   93.00        4.0   3.8   \n",
       "1       93370093.0         0.0   2.0          4.0   79.00        3.0   5.5   \n",
       "2       93323774.0         0.0   1.0          4.0  124.00        4.0   6.1   \n",
       "3       93344918.0         0.0   1.0          4.0   84.00        3.0   8.0   \n",
       "4       93355053.0         0.0   2.0          4.0   94.00        4.0   8.1   \n",
       "...            ...         ...   ...          ...     ...        ...   ...   \n",
       "20005  440943238.0         0.0   1.0          1.0   97.52        3.0   6.2   \n",
       "20006  440944836.0         0.0   1.0          1.0   78.93        2.0   4.6   \n",
       "20007  440949006.0         0.0   2.0          1.0   72.58        3.0   6.1   \n",
       "20008  440956226.0         0.0   1.0          1.0   71.67        3.0   3.8   \n",
       "20009  441127927.0         0.0   2.0          1.0   93.44        3.0   8.7   \n",
       "\n",
       "        plt0  hgb0  absneut0  absmnc0  abscd34_5pre  Count  \n",
       "0      159.0  15.5      2.24     1.56         11.70      0  \n",
       "1      218.0  13.2      3.00     2.49         70.20      1  \n",
       "2      175.0  15.0      3.23     2.87         22.05      0  \n",
       "3      280.0  15.4      5.04     2.96         87.55      1  \n",
       "4      351.0  13.2      4.94     3.16         51.00      1  \n",
       "...      ...   ...       ...      ...           ...    ...  \n",
       "20005  322.0  15.3      3.97     2.23        126.00      1  \n",
       "20006  173.0  14.7      2.52     2.08         61.03      1  \n",
       "20007  295.0  13.3      3.54     2.56        237.29      1  \n",
       "20008  211.0  14.8      1.61     2.19         70.25      1  \n",
       "20009  363.0  12.6      5.92     2.69        120.98      1  \n",
       "\n",
       "[19617 rows x 13 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_cols = ['pseudoid', 'twodaycoll', 'dsex', 'coll_age_gp', 'd_wt', 'd_bmi_grp',\n",
    "            'wbc0', # white blood cell count at baseline\n",
    "            'plt0', # platelet count at baseline\n",
    "            'hgb0', # hemoglobin at baseline\n",
    "            'absneut0', # absolute neutrophil count at baseline\n",
    "            'absmnc0', # absolute monocyte count at baseline\n",
    "            'abscd34_5pre', # absolute CD34 count at 5 day\n",
    "            'Count'\n",
    "            ]\n",
    "# make a new dataframe with columns from baseline including the demographics\n",
    "pre_df = df[pre_cols].copy()\n",
    "pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beda6a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pseudoid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "twodaycoll",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dsex",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "coll_age_gp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_wt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_bmi_grp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wbc0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "plt0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hgb0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absneut0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absmnc0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "abscd34_5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "99c2fb41-e2e2-4e2e-803e-e7e56d97187c",
       "rows": [
        [
         "0",
         "93409976.0",
         "0.0",
         "1.0",
         "4.0",
         "93.0",
         "4.0",
         "3.8",
         "159.0",
         "15.5",
         "2.24",
         "1.56",
         "11.7",
         "0"
        ],
        [
         "1",
         "93370093.0",
         "0.0",
         "2.0",
         "4.0",
         "79.0",
         "3.0",
         "5.5",
         "218.0",
         "13.2",
         "3.0",
         "2.49",
         "70.2",
         "1"
        ],
        [
         "2",
         "93323774.0",
         "0.0",
         "1.0",
         "4.0",
         "124.0",
         "4.0",
         "6.1",
         "175.0",
         "15.0",
         "3.23",
         "2.87",
         "22.05",
         "0"
        ],
        [
         "3",
         "93344918.0",
         "0.0",
         "1.0",
         "4.0",
         "84.0",
         "3.0",
         "8.0",
         "280.0",
         "15.4",
         "5.04",
         "2.96",
         "87.55",
         "1"
        ],
        [
         "4",
         "93355053.0",
         "0.0",
         "2.0",
         "4.0",
         "94.0",
         "4.0",
         "8.1",
         "351.0",
         "13.2",
         "4.94",
         "3.16",
         "51.0",
         "1"
        ],
        [
         "5",
         "93562560.0",
         "0.0",
         "1.0",
         "4.0",
         "95.0",
         "3.0",
         "4.2",
         "299.0",
         "16.1",
         "2.18",
         "2.02",
         "76.86",
         "1"
        ],
        [
         "6",
         "93568857.0",
         "0.0",
         "1.0",
         "3.0",
         "87.09",
         "3.0",
         "7.1",
         "256.0",
         "16.2",
         "4.54",
         "2.56",
         "106.0",
         "1"
        ],
        [
         "7",
         "93571163.0",
         "0.0",
         "2.0",
         "3.0",
         "54.0",
         "2.0",
         "5.4",
         "244.0",
         "12.9",
         "3.35",
         "2.05",
         "37.96",
         "0"
        ],
        [
         "8",
         "93580161.0",
         "0.0",
         "1.0",
         "4.0",
         "97.0",
         "3.0",
         "5.5",
         "188.0",
         "15.7",
         "3.41",
         "2.09",
         "46.44",
         "1"
        ],
        [
         "9",
         "93525333.0",
         "0.0",
         "2.0",
         "4.0",
         "91.63",
         "4.0",
         "5.8",
         "247.0",
         "13.9",
         "3.71",
         "2.09",
         "67.08",
         "1"
        ],
        [
         "10",
         "93529830.0",
         "0.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "10.3",
         "425.0",
         "12.5",
         "7.27",
         "3.03",
         "81.16",
         "1"
        ],
        [
         "11",
         "93530273.0",
         "0.0",
         "1.0",
         "3.0",
         "105.23",
         "4.0",
         "5.3",
         "188.0",
         "15.4",
         "3.13",
         "2.17",
         "88.14",
         "1"
        ],
        [
         "12",
         "93538145.0",
         "0.0",
         "1.0",
         "4.0",
         "119.75",
         "4.0",
         "6.6",
         "192.0",
         "14.2",
         "4.09",
         "2.51",
         "82.8",
         "1"
        ],
        [
         "14",
         "93544412.0",
         "0.0",
         "1.0",
         "4.0",
         "103.63",
         "4.0",
         "5.6",
         "238.0",
         "17.0",
         "3.26",
         "2.34",
         "97.63",
         "1"
        ],
        [
         "15",
         "93469126.0",
         "0.0",
         "1.0",
         "3.0",
         "79.0",
         "2.0",
         "5.6",
         "204.0",
         "14.0",
         "3.75",
         "1.85",
         "35.42",
         "0"
        ],
        [
         "16",
         "93677034.0",
         "0.0",
         "1.0",
         "4.0",
         "87.0",
         "4.0",
         "5.5",
         "173.0",
         "14.2",
         "4.03",
         "1.47",
         "103.6",
         "1"
        ],
        [
         "17",
         "93629310.0",
         "0.0",
         "2.0",
         "4.0",
         "85.0",
         "4.0",
         "10.8",
         "398.0",
         "15.3",
         "7.48",
         "3.3",
         "93.75",
         "1"
        ],
        [
         "18",
         "93650522.0",
         "0.0",
         "1.0",
         "3.0",
         "77.27",
         "3.0",
         "5.6",
         "191.0",
         "17.1",
         "3.98",
         "1.62",
         "73.2",
         "1"
        ],
        [
         "19",
         "93609903.0",
         "0.0",
         "1.0",
         "4.0",
         "112.49",
         "4.0",
         "6.2",
         "198.0",
         "15.2",
         "3.97",
         "2.17",
         "42.08",
         "1"
        ],
        [
         "20",
         "93611587.0",
         "0.0",
         "1.0",
         "4.0",
         "68.0",
         "2.0",
         "8.2",
         "343.0",
         "14.0",
         "5.17",
         "2.87",
         "270.4",
         "1"
        ],
        [
         "21",
         "93612785.0",
         "0.0",
         "1.0",
         "4.0",
         "88.0",
         "4.0",
         "8.6",
         "201.0",
         "16.0",
         "6.71",
         "1.89",
         "88.62",
         "1"
        ],
        [
         "22",
         "93828609.0",
         "0.0",
         "1.0",
         "3.0",
         "88.0",
         "4.0",
         "6.1",
         "207.0",
         "13.0",
         "3.89",
         "2.21",
         "116.5",
         "1"
        ],
        [
         "23",
         "93770923.0",
         "0.0",
         "1.0",
         "3.0",
         "81.0",
         "2.0",
         "7.8",
         "247.0",
         "14.6",
         "4.24",
         "3.51",
         "122.64",
         "1"
        ],
        [
         "24",
         "93722512.0",
         "0.0",
         "1.0",
         "3.0",
         "75.45",
         "2.0",
         "5.3",
         "196.0",
         "14.6",
         "3.13",
         "2.17",
         "62.7",
         "1"
        ],
        [
         "25",
         "93961139.0",
         "0.0",
         "2.0",
         "4.0",
         "87.0",
         "3.0",
         "7.8",
         "287.0",
         "13.8",
         "4.98",
         "2.82",
         "19.26",
         "0"
        ],
        [
         "26",
         "93902962.0",
         "0.0",
         "2.0",
         "3.0",
         "64.41",
         "2.0",
         "6.0",
         "232.0",
         "13.9",
         "4.44",
         "1.56",
         "52.56",
         "1"
        ],
        [
         "27",
         "93912879.0",
         "0.0",
         "2.0",
         "3.0",
         "74.84",
         "4.0",
         "6.7",
         "252.0",
         "13.3",
         "4.22",
         "2.41",
         "46.8",
         "1"
        ],
        [
         "29",
         "93855245.0",
         "0.0",
         "1.0",
         "2.0",
         "93.63",
         "3.0",
         "7.5",
         "191.0",
         "16.7",
         "5.92",
         "1.5",
         "61.75",
         "1"
        ],
        [
         "30",
         "94086404.0",
         "0.0",
         "2.0",
         "3.0",
         "87.0",
         "4.0",
         "6.3",
         "251.0",
         "13.7",
         "3.53",
         "2.77",
         "102.3",
         "1"
        ],
        [
         "31",
         "94101687.0",
         "0.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "5.9",
         "286.0",
         "16.3",
         "4.08",
         "1.82",
         "878.4",
         "1"
        ],
        [
         "32",
         "94056760.0",
         "0.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "6.7",
         "271.0",
         "13.6",
         "3.73",
         "2.97",
         "57.48",
         "1"
        ],
        [
         "33",
         "93987175.0",
         "0.0",
         "1.0",
         "4.0",
         "96.0",
         "3.0",
         "7.5",
         "318.0",
         "14.5",
         "5.28",
         "2.23",
         "85.2",
         "1"
        ],
        [
         "34",
         "93993202.0",
         "0.0",
         "2.0",
         "4.0",
         "90.27",
         "4.0",
         "5.7",
         "217.0",
         "14.1",
         "3.31",
         "2.39",
         "106.47",
         "1"
        ],
        [
         "35",
         "93994677.0",
         "0.0",
         "1.0",
         "2.0",
         "105.9",
         "4.0",
         "5.4",
         "273.0",
         "15.1",
         "3.62",
         "1.78",
         "112.71",
         "1"
        ],
        [
         "36",
         "94177942.0",
         "0.0",
         "1.0",
         "4.0",
         "69.4",
         "2.0",
         "7.6",
         "275.0",
         "16.2",
         "6.22",
         "1.38",
         "72.24",
         "1"
        ],
        [
         "37",
         "94191277.0",
         "0.0",
         "2.0",
         "2.0",
         "54.54",
         "2.0",
         "8.4",
         "208.0",
         "13.0",
         "6.47",
         "1.93",
         "15.36",
         "0"
        ],
        [
         "38",
         "94203152.0",
         "0.0",
         "2.0",
         "4.0",
         "69.09",
         "3.0",
         "4.3",
         "383.0",
         "13.5",
         "2.55",
         "1.75",
         "83.0",
         "1"
        ],
        [
         "39",
         "94115557.0",
         "0.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "7.2",
         "204.0",
         "14.4",
         "4.82",
         "2.38",
         "298.0",
         "1"
        ],
        [
         "40",
         "94120876.0",
         "0.0",
         "2.0",
         "3.0",
         "82.0",
         "4.0",
         "10.1",
         "359.0",
         "14.4",
         "6.46",
         "3.64",
         "26.1",
         "0"
        ],
        [
         "41",
         "94121628.0",
         "0.0",
         "1.0",
         "3.0",
         "97.0",
         "4.0",
         "4.8",
         "183.0",
         "15.4",
         "3.41",
         "1.39",
         "110.63",
         "1"
        ],
        [
         "42",
         "94131849.0",
         "0.0",
         "1.0",
         "2.0",
         "80.74",
         "2.0",
         "4.6",
         "186.0",
         "16.5",
         "3.12",
         "1.48",
         "49.0",
         "1"
        ],
        [
         "43",
         "94344490.0",
         "0.0",
         "1.0",
         "3.0",
         "107.0",
         "4.0",
         "4.9",
         "206.0",
         "15.2",
         "2.97",
         "1.92",
         "102.0",
         "1"
        ],
        [
         "44",
         "94348239.0",
         "0.0",
         "1.0",
         "3.0",
         "96.36",
         "3.0",
         "5.3",
         "262.0",
         "15.3",
         "3.02",
         "2.28",
         "76.12",
         "1"
        ],
        [
         "45",
         "94311317.0",
         "0.0",
         "1.0",
         "2.0",
         "79.0",
         "2.0",
         "5.6",
         "173.0",
         "16.4",
         "3.86",
         "1.74",
         "64.82",
         "1"
        ],
        [
         "46",
         "94316721.0",
         "0.0",
         "2.0",
         "3.0",
         "60.0",
         "2.0",
         "5.0",
         "259.0",
         "11.9",
         "3.0",
         "1.99",
         "77.06",
         "1"
        ],
        [
         "47",
         "94276724.0",
         "0.0",
         "1.0",
         "3.0",
         "99.0",
         "4.0",
         "4.9",
         "199.0",
         "13.7",
         "2.7",
         "2.21",
         "35.91",
         "0"
        ],
        [
         "48",
         "94301982.0",
         "0.0",
         "1.0",
         "4.0",
         "102.51",
         "4.0",
         "6.5",
         "166.0",
         "15.7",
         "4.63",
         "1.87",
         "35.91",
         "0"
        ],
        [
         "49",
         "94303078.0",
         "0.0",
         "1.0",
         "3.0",
         "105.69",
         "4.0",
         "6.2",
         "178.0",
         "15.3",
         "3.7",
         "2.5",
         "157.38",
         "1"
        ],
        [
         "50",
         "94247403.0",
         "0.0",
         "2.0",
         "4.0",
         "55.0",
         "2.0",
         "6.4",
         "224.0",
         "13.7",
         "4.03",
         "2.36",
         "129.2",
         "1"
        ],
        [
         "51",
         "92348789.0",
         "0.0",
         "1.0",
         "4.0",
         "104.0",
         "4.0",
         "10.1",
         "197.0",
         "16.3",
         "6.27",
         "3.8",
         "49.56",
         "1"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 19217
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudoid</th>\n",
       "      <th>twodaycoll</th>\n",
       "      <th>dsex</th>\n",
       "      <th>coll_age_gp</th>\n",
       "      <th>d_wt</th>\n",
       "      <th>d_bmi_grp</th>\n",
       "      <th>wbc0</th>\n",
       "      <th>plt0</th>\n",
       "      <th>hgb0</th>\n",
       "      <th>absneut0</th>\n",
       "      <th>absmnc0</th>\n",
       "      <th>abscd34_5pre</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93409976.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>159.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.56</td>\n",
       "      <td>11.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93370093.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>218.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.49</td>\n",
       "      <td>70.20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93323774.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>175.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.87</td>\n",
       "      <td>22.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93344918.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>5.04</td>\n",
       "      <td>2.96</td>\n",
       "      <td>87.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93355053.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>351.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3.16</td>\n",
       "      <td>51.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005</th>\n",
       "      <td>440943238.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>322.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>3.97</td>\n",
       "      <td>2.23</td>\n",
       "      <td>126.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006</th>\n",
       "      <td>440944836.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.93</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>173.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>2.52</td>\n",
       "      <td>2.08</td>\n",
       "      <td>61.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20007</th>\n",
       "      <td>440949006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>295.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3.54</td>\n",
       "      <td>2.56</td>\n",
       "      <td>237.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20008</th>\n",
       "      <td>440956226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>211.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.19</td>\n",
       "      <td>70.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20009</th>\n",
       "      <td>441127927.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>363.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>5.92</td>\n",
       "      <td>2.69</td>\n",
       "      <td>120.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19217 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pseudoid  twodaycoll  dsex  coll_age_gp    d_wt  d_bmi_grp  wbc0  \\\n",
       "0       93409976.0         0.0   1.0          4.0   93.00        4.0   3.8   \n",
       "1       93370093.0         0.0   2.0          4.0   79.00        3.0   5.5   \n",
       "2       93323774.0         0.0   1.0          4.0  124.00        4.0   6.1   \n",
       "3       93344918.0         0.0   1.0          4.0   84.00        3.0   8.0   \n",
       "4       93355053.0         0.0   2.0          4.0   94.00        4.0   8.1   \n",
       "...            ...         ...   ...          ...     ...        ...   ...   \n",
       "20005  440943238.0         0.0   1.0          1.0   97.52        3.0   6.2   \n",
       "20006  440944836.0         0.0   1.0          1.0   78.93        2.0   4.6   \n",
       "20007  440949006.0         0.0   2.0          1.0   72.58        3.0   6.1   \n",
       "20008  440956226.0         0.0   1.0          1.0   71.67        3.0   3.8   \n",
       "20009  441127927.0         0.0   2.0          1.0   93.44        3.0   8.7   \n",
       "\n",
       "        plt0  hgb0  absneut0  absmnc0  abscd34_5pre  Count  \n",
       "0      159.0  15.5      2.24     1.56         11.70      0  \n",
       "1      218.0  13.2      3.00     2.49         70.20      1  \n",
       "2      175.0  15.0      3.23     2.87         22.05      0  \n",
       "3      280.0  15.4      5.04     2.96         87.55      1  \n",
       "4      351.0  13.2      4.94     3.16         51.00      1  \n",
       "...      ...   ...       ...      ...           ...    ...  \n",
       "20005  322.0  15.3      3.97     2.23        126.00      1  \n",
       "20006  173.0  14.7      2.52     2.08         61.03      1  \n",
       "20007  295.0  13.3      3.54     2.56        237.29      1  \n",
       "20008  211.0  14.8      1.61     2.19         70.25      1  \n",
       "20009  363.0  12.6      5.92     2.69        120.98      1  \n",
       "\n",
       "[19217 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop any rows with missing data\n",
    "pre_df = pre_df.dropna()\n",
    "pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6999f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pseudoid is unique in pre_df\n"
     ]
    }
   ],
   "source": [
    "if pre_df['pseudoid'].is_unique:\n",
    "    print(\"pseudoid is unique in pre_df\")\n",
    "else:\n",
    "    print(\"pseudoid is not unique in pre_df, dropping duplicates\")\n",
    "    pre_df = pre_df.drop_duplicates(subset='pseudoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db6ff633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove data with bmi == 99\n",
    "pre_df = pre_df[pre_df['d_bmi_grp'] != 99].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1f8609e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pseudoid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dsex",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "coll_age_gp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_wt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_bmi_grp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wbc0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "plt0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hgb0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absneut0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absmnc0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "abscd34_5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "63807d53-ee83-42bc-a7b0-2cad9953fc04",
       "rows": [
        [
         "0",
         "93409976.0",
         "1.0",
         "4.0",
         "93.0",
         "4.0",
         "3.8",
         "159.0",
         "15.5",
         "2.24",
         "1.56",
         "11.7",
         "0"
        ],
        [
         "1",
         "93370093.0",
         "2.0",
         "4.0",
         "79.0",
         "3.0",
         "5.5",
         "218.0",
         "13.2",
         "3.0",
         "2.49",
         "70.2",
         "1"
        ],
        [
         "2",
         "93323774.0",
         "1.0",
         "4.0",
         "124.0",
         "4.0",
         "6.1",
         "175.0",
         "15.0",
         "3.23",
         "2.87",
         "22.05",
         "0"
        ],
        [
         "3",
         "93344918.0",
         "1.0",
         "4.0",
         "84.0",
         "3.0",
         "8.0",
         "280.0",
         "15.4",
         "5.04",
         "2.96",
         "87.55",
         "1"
        ],
        [
         "4",
         "93355053.0",
         "2.0",
         "4.0",
         "94.0",
         "4.0",
         "8.1",
         "351.0",
         "13.2",
         "4.94",
         "3.16",
         "51.0",
         "1"
        ],
        [
         "5",
         "93562560.0",
         "1.0",
         "4.0",
         "95.0",
         "3.0",
         "4.2",
         "299.0",
         "16.1",
         "2.18",
         "2.02",
         "76.86",
         "1"
        ],
        [
         "6",
         "93568857.0",
         "1.0",
         "3.0",
         "87.09",
         "3.0",
         "7.1",
         "256.0",
         "16.2",
         "4.54",
         "2.56",
         "106.0",
         "1"
        ],
        [
         "7",
         "93571163.0",
         "2.0",
         "3.0",
         "54.0",
         "2.0",
         "5.4",
         "244.0",
         "12.9",
         "3.35",
         "2.05",
         "37.96",
         "0"
        ],
        [
         "8",
         "93580161.0",
         "1.0",
         "4.0",
         "97.0",
         "3.0",
         "5.5",
         "188.0",
         "15.7",
         "3.41",
         "2.09",
         "46.44",
         "1"
        ],
        [
         "9",
         "93525333.0",
         "2.0",
         "4.0",
         "91.63",
         "4.0",
         "5.8",
         "247.0",
         "13.9",
         "3.71",
         "2.09",
         "67.08",
         "1"
        ],
        [
         "10",
         "93529830.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "10.3",
         "425.0",
         "12.5",
         "7.27",
         "3.03",
         "81.16",
         "1"
        ],
        [
         "11",
         "93530273.0",
         "1.0",
         "3.0",
         "105.23",
         "4.0",
         "5.3",
         "188.0",
         "15.4",
         "3.13",
         "2.17",
         "88.14",
         "1"
        ],
        [
         "12",
         "93538145.0",
         "1.0",
         "4.0",
         "119.75",
         "4.0",
         "6.6",
         "192.0",
         "14.2",
         "4.09",
         "2.51",
         "82.8",
         "1"
        ],
        [
         "14",
         "93544412.0",
         "1.0",
         "4.0",
         "103.63",
         "4.0",
         "5.6",
         "238.0",
         "17.0",
         "3.26",
         "2.34",
         "97.63",
         "1"
        ],
        [
         "15",
         "93469126.0",
         "1.0",
         "3.0",
         "79.0",
         "2.0",
         "5.6",
         "204.0",
         "14.0",
         "3.75",
         "1.85",
         "35.42",
         "0"
        ],
        [
         "16",
         "93677034.0",
         "1.0",
         "4.0",
         "87.0",
         "4.0",
         "5.5",
         "173.0",
         "14.2",
         "4.03",
         "1.47",
         "103.6",
         "1"
        ],
        [
         "17",
         "93629310.0",
         "2.0",
         "4.0",
         "85.0",
         "4.0",
         "10.8",
         "398.0",
         "15.3",
         "7.48",
         "3.3",
         "93.75",
         "1"
        ],
        [
         "18",
         "93650522.0",
         "1.0",
         "3.0",
         "77.27",
         "3.0",
         "5.6",
         "191.0",
         "17.1",
         "3.98",
         "1.62",
         "73.2",
         "1"
        ],
        [
         "19",
         "93609903.0",
         "1.0",
         "4.0",
         "112.49",
         "4.0",
         "6.2",
         "198.0",
         "15.2",
         "3.97",
         "2.17",
         "42.08",
         "1"
        ],
        [
         "20",
         "93611587.0",
         "1.0",
         "4.0",
         "68.0",
         "2.0",
         "8.2",
         "343.0",
         "14.0",
         "5.17",
         "2.87",
         "270.4",
         "1"
        ],
        [
         "21",
         "93612785.0",
         "1.0",
         "4.0",
         "88.0",
         "4.0",
         "8.6",
         "201.0",
         "16.0",
         "6.71",
         "1.89",
         "88.62",
         "1"
        ],
        [
         "22",
         "93828609.0",
         "1.0",
         "3.0",
         "88.0",
         "4.0",
         "6.1",
         "207.0",
         "13.0",
         "3.89",
         "2.21",
         "116.5",
         "1"
        ],
        [
         "23",
         "93770923.0",
         "1.0",
         "3.0",
         "81.0",
         "2.0",
         "7.8",
         "247.0",
         "14.6",
         "4.24",
         "3.51",
         "122.64",
         "1"
        ],
        [
         "24",
         "93722512.0",
         "1.0",
         "3.0",
         "75.45",
         "2.0",
         "5.3",
         "196.0",
         "14.6",
         "3.13",
         "2.17",
         "62.7",
         "1"
        ],
        [
         "25",
         "93961139.0",
         "2.0",
         "4.0",
         "87.0",
         "3.0",
         "7.8",
         "287.0",
         "13.8",
         "4.98",
         "2.82",
         "19.26",
         "0"
        ],
        [
         "26",
         "93902962.0",
         "2.0",
         "3.0",
         "64.41",
         "2.0",
         "6.0",
         "232.0",
         "13.9",
         "4.44",
         "1.56",
         "52.56",
         "1"
        ],
        [
         "27",
         "93912879.0",
         "2.0",
         "3.0",
         "74.84",
         "4.0",
         "6.7",
         "252.0",
         "13.3",
         "4.22",
         "2.41",
         "46.8",
         "1"
        ],
        [
         "29",
         "93855245.0",
         "1.0",
         "2.0",
         "93.63",
         "3.0",
         "7.5",
         "191.0",
         "16.7",
         "5.92",
         "1.5",
         "61.75",
         "1"
        ],
        [
         "30",
         "94086404.0",
         "2.0",
         "3.0",
         "87.0",
         "4.0",
         "6.3",
         "251.0",
         "13.7",
         "3.53",
         "2.77",
         "102.3",
         "1"
        ],
        [
         "31",
         "94101687.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "5.9",
         "286.0",
         "16.3",
         "4.08",
         "1.82",
         "878.4",
         "1"
        ],
        [
         "32",
         "94056760.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "6.7",
         "271.0",
         "13.6",
         "3.73",
         "2.97",
         "57.48",
         "1"
        ],
        [
         "33",
         "93987175.0",
         "1.0",
         "4.0",
         "96.0",
         "3.0",
         "7.5",
         "318.0",
         "14.5",
         "5.28",
         "2.23",
         "85.2",
         "1"
        ],
        [
         "34",
         "93993202.0",
         "2.0",
         "4.0",
         "90.27",
         "4.0",
         "5.7",
         "217.0",
         "14.1",
         "3.31",
         "2.39",
         "106.47",
         "1"
        ],
        [
         "35",
         "93994677.0",
         "1.0",
         "2.0",
         "105.9",
         "4.0",
         "5.4",
         "273.0",
         "15.1",
         "3.62",
         "1.78",
         "112.71",
         "1"
        ],
        [
         "36",
         "94177942.0",
         "1.0",
         "4.0",
         "69.4",
         "2.0",
         "7.6",
         "275.0",
         "16.2",
         "6.22",
         "1.38",
         "72.24",
         "1"
        ],
        [
         "37",
         "94191277.0",
         "2.0",
         "2.0",
         "54.54",
         "2.0",
         "8.4",
         "208.0",
         "13.0",
         "6.47",
         "1.93",
         "15.36",
         "0"
        ],
        [
         "38",
         "94203152.0",
         "2.0",
         "4.0",
         "69.09",
         "3.0",
         "4.3",
         "383.0",
         "13.5",
         "2.55",
         "1.75",
         "83.0",
         "1"
        ],
        [
         "39",
         "94115557.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "7.2",
         "204.0",
         "14.4",
         "4.82",
         "2.38",
         "298.0",
         "1"
        ],
        [
         "40",
         "94120876.0",
         "2.0",
         "3.0",
         "82.0",
         "4.0",
         "10.1",
         "359.0",
         "14.4",
         "6.46",
         "3.64",
         "26.1",
         "0"
        ],
        [
         "41",
         "94121628.0",
         "1.0",
         "3.0",
         "97.0",
         "4.0",
         "4.8",
         "183.0",
         "15.4",
         "3.41",
         "1.39",
         "110.63",
         "1"
        ],
        [
         "42",
         "94131849.0",
         "1.0",
         "2.0",
         "80.74",
         "2.0",
         "4.6",
         "186.0",
         "16.5",
         "3.12",
         "1.48",
         "49.0",
         "1"
        ],
        [
         "43",
         "94344490.0",
         "1.0",
         "3.0",
         "107.0",
         "4.0",
         "4.9",
         "206.0",
         "15.2",
         "2.97",
         "1.92",
         "102.0",
         "1"
        ],
        [
         "44",
         "94348239.0",
         "1.0",
         "3.0",
         "96.36",
         "3.0",
         "5.3",
         "262.0",
         "15.3",
         "3.02",
         "2.28",
         "76.12",
         "1"
        ],
        [
         "45",
         "94311317.0",
         "1.0",
         "2.0",
         "79.0",
         "2.0",
         "5.6",
         "173.0",
         "16.4",
         "3.86",
         "1.74",
         "64.82",
         "1"
        ],
        [
         "46",
         "94316721.0",
         "2.0",
         "3.0",
         "60.0",
         "2.0",
         "5.0",
         "259.0",
         "11.9",
         "3.0",
         "1.99",
         "77.06",
         "1"
        ],
        [
         "47",
         "94276724.0",
         "1.0",
         "3.0",
         "99.0",
         "4.0",
         "4.9",
         "199.0",
         "13.7",
         "2.7",
         "2.21",
         "35.91",
         "0"
        ],
        [
         "48",
         "94301982.0",
         "1.0",
         "4.0",
         "102.51",
         "4.0",
         "6.5",
         "166.0",
         "15.7",
         "4.63",
         "1.87",
         "35.91",
         "0"
        ],
        [
         "49",
         "94303078.0",
         "1.0",
         "3.0",
         "105.69",
         "4.0",
         "6.2",
         "178.0",
         "15.3",
         "3.7",
         "2.5",
         "157.38",
         "1"
        ],
        [
         "50",
         "94247403.0",
         "2.0",
         "4.0",
         "55.0",
         "2.0",
         "6.4",
         "224.0",
         "13.7",
         "4.03",
         "2.36",
         "129.2",
         "1"
        ],
        [
         "51",
         "92348789.0",
         "1.0",
         "4.0",
         "104.0",
         "4.0",
         "10.1",
         "197.0",
         "16.3",
         "6.27",
         "3.8",
         "49.56",
         "1"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 19207
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudoid</th>\n",
       "      <th>dsex</th>\n",
       "      <th>coll_age_gp</th>\n",
       "      <th>d_wt</th>\n",
       "      <th>d_bmi_grp</th>\n",
       "      <th>wbc0</th>\n",
       "      <th>plt0</th>\n",
       "      <th>hgb0</th>\n",
       "      <th>absneut0</th>\n",
       "      <th>absmnc0</th>\n",
       "      <th>abscd34_5pre</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93409976.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>159.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.56</td>\n",
       "      <td>11.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93370093.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>218.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.49</td>\n",
       "      <td>70.20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93323774.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>175.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.87</td>\n",
       "      <td>22.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93344918.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>5.04</td>\n",
       "      <td>2.96</td>\n",
       "      <td>87.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93355053.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>351.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3.16</td>\n",
       "      <td>51.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005</th>\n",
       "      <td>440943238.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>322.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>3.97</td>\n",
       "      <td>2.23</td>\n",
       "      <td>126.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006</th>\n",
       "      <td>440944836.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.93</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>173.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>2.52</td>\n",
       "      <td>2.08</td>\n",
       "      <td>61.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20007</th>\n",
       "      <td>440949006.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>295.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3.54</td>\n",
       "      <td>2.56</td>\n",
       "      <td>237.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20008</th>\n",
       "      <td>440956226.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>211.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.19</td>\n",
       "      <td>70.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20009</th>\n",
       "      <td>441127927.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>363.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>5.92</td>\n",
       "      <td>2.69</td>\n",
       "      <td>120.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19207 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pseudoid  dsex  coll_age_gp    d_wt  d_bmi_grp  wbc0   plt0  hgb0  \\\n",
       "0       93409976.0   1.0          4.0   93.00        4.0   3.8  159.0  15.5   \n",
       "1       93370093.0   2.0          4.0   79.00        3.0   5.5  218.0  13.2   \n",
       "2       93323774.0   1.0          4.0  124.00        4.0   6.1  175.0  15.0   \n",
       "3       93344918.0   1.0          4.0   84.00        3.0   8.0  280.0  15.4   \n",
       "4       93355053.0   2.0          4.0   94.00        4.0   8.1  351.0  13.2   \n",
       "...            ...   ...          ...     ...        ...   ...    ...   ...   \n",
       "20005  440943238.0   1.0          1.0   97.52        3.0   6.2  322.0  15.3   \n",
       "20006  440944836.0   1.0          1.0   78.93        2.0   4.6  173.0  14.7   \n",
       "20007  440949006.0   2.0          1.0   72.58        3.0   6.1  295.0  13.3   \n",
       "20008  440956226.0   1.0          1.0   71.67        3.0   3.8  211.0  14.8   \n",
       "20009  441127927.0   2.0          1.0   93.44        3.0   8.7  363.0  12.6   \n",
       "\n",
       "       absneut0  absmnc0  abscd34_5pre  Count  \n",
       "0          2.24     1.56         11.70      0  \n",
       "1          3.00     2.49         70.20      1  \n",
       "2          3.23     2.87         22.05      0  \n",
       "3          5.04     2.96         87.55      1  \n",
       "4          4.94     3.16         51.00      1  \n",
       "...         ...      ...           ...    ...  \n",
       "20005      3.97     2.23        126.00      1  \n",
       "20006      2.52     2.08         61.03      1  \n",
       "20007      3.54     2.56        237.29      1  \n",
       "20008      1.61     2.19         70.25      1  \n",
       "20009      5.92     2.69        120.98      1  \n",
       "\n",
       "[19207 rows x 12 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df = pre_df.drop(columns=['twodaycoll'])  # drop twodaycoll  as they are not needed for the model\n",
    "pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3714a0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add another column labtype to pre_df and set it to 0\n",
    "pre_df['labtype'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9818c7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pseudoid', 'dsex', 'coll_age_gp', 'd_wt', 'd_bmi_grp', 'wbc0', 'plt0',\n",
       "       'hgb0', 'absneut0', 'absmnc0', 'abscd34_5pre', 'Count', 'labtype'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8606f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Gender",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age-Group",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Weight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BMI Group",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WBC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Platelet",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HGB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Neut Abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MNC Abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CD34 Abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "labtype",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "605296cc-72bc-4777-aeea-68631bca73c8",
       "rows": [
        [
         "0",
         "93409976.0",
         "1.0",
         "4.0",
         "93.0",
         "4.0",
         "3.8",
         "159.0",
         "15.5",
         "2.24",
         "1.56",
         "11.7",
         "0",
         "0"
        ],
        [
         "1",
         "93370093.0",
         "2.0",
         "4.0",
         "79.0",
         "3.0",
         "5.5",
         "218.0",
         "13.2",
         "3.0",
         "2.49",
         "70.2",
         "1",
         "0"
        ],
        [
         "2",
         "93323774.0",
         "1.0",
         "4.0",
         "124.0",
         "4.0",
         "6.1",
         "175.0",
         "15.0",
         "3.23",
         "2.87",
         "22.05",
         "0",
         "0"
        ],
        [
         "3",
         "93344918.0",
         "1.0",
         "4.0",
         "84.0",
         "3.0",
         "8.0",
         "280.0",
         "15.4",
         "5.04",
         "2.96",
         "87.55",
         "1",
         "0"
        ],
        [
         "4",
         "93355053.0",
         "2.0",
         "4.0",
         "94.0",
         "4.0",
         "8.1",
         "351.0",
         "13.2",
         "4.94",
         "3.16",
         "51.0",
         "1",
         "0"
        ],
        [
         "5",
         "93562560.0",
         "1.0",
         "4.0",
         "95.0",
         "3.0",
         "4.2",
         "299.0",
         "16.1",
         "2.18",
         "2.02",
         "76.86",
         "1",
         "0"
        ],
        [
         "6",
         "93568857.0",
         "1.0",
         "3.0",
         "87.09",
         "3.0",
         "7.1",
         "256.0",
         "16.2",
         "4.54",
         "2.56",
         "106.0",
         "1",
         "0"
        ],
        [
         "7",
         "93571163.0",
         "2.0",
         "3.0",
         "54.0",
         "2.0",
         "5.4",
         "244.0",
         "12.9",
         "3.35",
         "2.05",
         "37.96",
         "0",
         "0"
        ],
        [
         "8",
         "93580161.0",
         "1.0",
         "4.0",
         "97.0",
         "3.0",
         "5.5",
         "188.0",
         "15.7",
         "3.41",
         "2.09",
         "46.44",
         "1",
         "0"
        ],
        [
         "9",
         "93525333.0",
         "2.0",
         "4.0",
         "91.63",
         "4.0",
         "5.8",
         "247.0",
         "13.9",
         "3.71",
         "2.09",
         "67.08",
         "1",
         "0"
        ],
        [
         "10",
         "93529830.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "10.3",
         "425.0",
         "12.5",
         "7.27",
         "3.03",
         "81.16",
         "1",
         "0"
        ],
        [
         "11",
         "93530273.0",
         "1.0",
         "3.0",
         "105.23",
         "4.0",
         "5.3",
         "188.0",
         "15.4",
         "3.13",
         "2.17",
         "88.14",
         "1",
         "0"
        ],
        [
         "12",
         "93538145.0",
         "1.0",
         "4.0",
         "119.75",
         "4.0",
         "6.6",
         "192.0",
         "14.2",
         "4.09",
         "2.51",
         "82.8",
         "1",
         "0"
        ],
        [
         "14",
         "93544412.0",
         "1.0",
         "4.0",
         "103.63",
         "4.0",
         "5.6",
         "238.0",
         "17.0",
         "3.26",
         "2.34",
         "97.63",
         "1",
         "0"
        ],
        [
         "15",
         "93469126.0",
         "1.0",
         "3.0",
         "79.0",
         "2.0",
         "5.6",
         "204.0",
         "14.0",
         "3.75",
         "1.85",
         "35.42",
         "0",
         "0"
        ],
        [
         "16",
         "93677034.0",
         "1.0",
         "4.0",
         "87.0",
         "4.0",
         "5.5",
         "173.0",
         "14.2",
         "4.03",
         "1.47",
         "103.6",
         "1",
         "0"
        ],
        [
         "17",
         "93629310.0",
         "2.0",
         "4.0",
         "85.0",
         "4.0",
         "10.8",
         "398.0",
         "15.3",
         "7.48",
         "3.3",
         "93.75",
         "1",
         "0"
        ],
        [
         "18",
         "93650522.0",
         "1.0",
         "3.0",
         "77.27",
         "3.0",
         "5.6",
         "191.0",
         "17.1",
         "3.98",
         "1.62",
         "73.2",
         "1",
         "0"
        ],
        [
         "19",
         "93609903.0",
         "1.0",
         "4.0",
         "112.49",
         "4.0",
         "6.2",
         "198.0",
         "15.2",
         "3.97",
         "2.17",
         "42.08",
         "1",
         "0"
        ],
        [
         "20",
         "93611587.0",
         "1.0",
         "4.0",
         "68.0",
         "2.0",
         "8.2",
         "343.0",
         "14.0",
         "5.17",
         "2.87",
         "270.4",
         "1",
         "0"
        ],
        [
         "21",
         "93612785.0",
         "1.0",
         "4.0",
         "88.0",
         "4.0",
         "8.6",
         "201.0",
         "16.0",
         "6.71",
         "1.89",
         "88.62",
         "1",
         "0"
        ],
        [
         "22",
         "93828609.0",
         "1.0",
         "3.0",
         "88.0",
         "4.0",
         "6.1",
         "207.0",
         "13.0",
         "3.89",
         "2.21",
         "116.5",
         "1",
         "0"
        ],
        [
         "23",
         "93770923.0",
         "1.0",
         "3.0",
         "81.0",
         "2.0",
         "7.8",
         "247.0",
         "14.6",
         "4.24",
         "3.51",
         "122.64",
         "1",
         "0"
        ],
        [
         "24",
         "93722512.0",
         "1.0",
         "3.0",
         "75.45",
         "2.0",
         "5.3",
         "196.0",
         "14.6",
         "3.13",
         "2.17",
         "62.7",
         "1",
         "0"
        ],
        [
         "25",
         "93961139.0",
         "2.0",
         "4.0",
         "87.0",
         "3.0",
         "7.8",
         "287.0",
         "13.8",
         "4.98",
         "2.82",
         "19.26",
         "0",
         "0"
        ],
        [
         "26",
         "93902962.0",
         "2.0",
         "3.0",
         "64.41",
         "2.0",
         "6.0",
         "232.0",
         "13.9",
         "4.44",
         "1.56",
         "52.56",
         "1",
         "0"
        ],
        [
         "27",
         "93912879.0",
         "2.0",
         "3.0",
         "74.84",
         "4.0",
         "6.7",
         "252.0",
         "13.3",
         "4.22",
         "2.41",
         "46.8",
         "1",
         "0"
        ],
        [
         "29",
         "93855245.0",
         "1.0",
         "2.0",
         "93.63",
         "3.0",
         "7.5",
         "191.0",
         "16.7",
         "5.92",
         "1.5",
         "61.75",
         "1",
         "0"
        ],
        [
         "30",
         "94086404.0",
         "2.0",
         "3.0",
         "87.0",
         "4.0",
         "6.3",
         "251.0",
         "13.7",
         "3.53",
         "2.77",
         "102.3",
         "1",
         "0"
        ],
        [
         "31",
         "94101687.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "5.9",
         "286.0",
         "16.3",
         "4.08",
         "1.82",
         "878.4",
         "1",
         "0"
        ],
        [
         "32",
         "94056760.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "6.7",
         "271.0",
         "13.6",
         "3.73",
         "2.97",
         "57.48",
         "1",
         "0"
        ],
        [
         "33",
         "93987175.0",
         "1.0",
         "4.0",
         "96.0",
         "3.0",
         "7.5",
         "318.0",
         "14.5",
         "5.28",
         "2.23",
         "85.2",
         "1",
         "0"
        ],
        [
         "34",
         "93993202.0",
         "2.0",
         "4.0",
         "90.27",
         "4.0",
         "5.7",
         "217.0",
         "14.1",
         "3.31",
         "2.39",
         "106.47",
         "1",
         "0"
        ],
        [
         "35",
         "93994677.0",
         "1.0",
         "2.0",
         "105.9",
         "4.0",
         "5.4",
         "273.0",
         "15.1",
         "3.62",
         "1.78",
         "112.71",
         "1",
         "0"
        ],
        [
         "36",
         "94177942.0",
         "1.0",
         "4.0",
         "69.4",
         "2.0",
         "7.6",
         "275.0",
         "16.2",
         "6.22",
         "1.38",
         "72.24",
         "1",
         "0"
        ],
        [
         "37",
         "94191277.0",
         "2.0",
         "2.0",
         "54.54",
         "2.0",
         "8.4",
         "208.0",
         "13.0",
         "6.47",
         "1.93",
         "15.36",
         "0",
         "0"
        ],
        [
         "38",
         "94203152.0",
         "2.0",
         "4.0",
         "69.09",
         "3.0",
         "4.3",
         "383.0",
         "13.5",
         "2.55",
         "1.75",
         "83.0",
         "1",
         "0"
        ],
        [
         "39",
         "94115557.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "7.2",
         "204.0",
         "14.4",
         "4.82",
         "2.38",
         "298.0",
         "1",
         "0"
        ],
        [
         "40",
         "94120876.0",
         "2.0",
         "3.0",
         "82.0",
         "4.0",
         "10.1",
         "359.0",
         "14.4",
         "6.46",
         "3.64",
         "26.1",
         "0",
         "0"
        ],
        [
         "41",
         "94121628.0",
         "1.0",
         "3.0",
         "97.0",
         "4.0",
         "4.8",
         "183.0",
         "15.4",
         "3.41",
         "1.39",
         "110.63",
         "1",
         "0"
        ],
        [
         "42",
         "94131849.0",
         "1.0",
         "2.0",
         "80.74",
         "2.0",
         "4.6",
         "186.0",
         "16.5",
         "3.12",
         "1.48",
         "49.0",
         "1",
         "0"
        ],
        [
         "43",
         "94344490.0",
         "1.0",
         "3.0",
         "107.0",
         "4.0",
         "4.9",
         "206.0",
         "15.2",
         "2.97",
         "1.92",
         "102.0",
         "1",
         "0"
        ],
        [
         "44",
         "94348239.0",
         "1.0",
         "3.0",
         "96.36",
         "3.0",
         "5.3",
         "262.0",
         "15.3",
         "3.02",
         "2.28",
         "76.12",
         "1",
         "0"
        ],
        [
         "45",
         "94311317.0",
         "1.0",
         "2.0",
         "79.0",
         "2.0",
         "5.6",
         "173.0",
         "16.4",
         "3.86",
         "1.74",
         "64.82",
         "1",
         "0"
        ],
        [
         "46",
         "94316721.0",
         "2.0",
         "3.0",
         "60.0",
         "2.0",
         "5.0",
         "259.0",
         "11.9",
         "3.0",
         "1.99",
         "77.06",
         "1",
         "0"
        ],
        [
         "47",
         "94276724.0",
         "1.0",
         "3.0",
         "99.0",
         "4.0",
         "4.9",
         "199.0",
         "13.7",
         "2.7",
         "2.21",
         "35.91",
         "0",
         "0"
        ],
        [
         "48",
         "94301982.0",
         "1.0",
         "4.0",
         "102.51",
         "4.0",
         "6.5",
         "166.0",
         "15.7",
         "4.63",
         "1.87",
         "35.91",
         "0",
         "0"
        ],
        [
         "49",
         "94303078.0",
         "1.0",
         "3.0",
         "105.69",
         "4.0",
         "6.2",
         "178.0",
         "15.3",
         "3.7",
         "2.5",
         "157.38",
         "1",
         "0"
        ],
        [
         "50",
         "94247403.0",
         "2.0",
         "4.0",
         "55.0",
         "2.0",
         "6.4",
         "224.0",
         "13.7",
         "4.03",
         "2.36",
         "129.2",
         "1",
         "0"
        ],
        [
         "51",
         "92348789.0",
         "1.0",
         "4.0",
         "104.0",
         "4.0",
         "10.1",
         "197.0",
         "16.3",
         "6.27",
         "3.8",
         "49.56",
         "1",
         "0"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 19207
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age-Group</th>\n",
       "      <th>Weight</th>\n",
       "      <th>BMI Group</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Platelet</th>\n",
       "      <th>HGB</th>\n",
       "      <th>Neut Abs</th>\n",
       "      <th>MNC Abs</th>\n",
       "      <th>CD34 Abs</th>\n",
       "      <th>Count</th>\n",
       "      <th>labtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93409976.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>159.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.56</td>\n",
       "      <td>11.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93370093.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>218.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.49</td>\n",
       "      <td>70.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93323774.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>175.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.87</td>\n",
       "      <td>22.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93344918.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>5.04</td>\n",
       "      <td>2.96</td>\n",
       "      <td>87.55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93355053.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>351.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3.16</td>\n",
       "      <td>51.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005</th>\n",
       "      <td>440943238.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>322.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>3.97</td>\n",
       "      <td>2.23</td>\n",
       "      <td>126.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006</th>\n",
       "      <td>440944836.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.93</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>173.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>2.52</td>\n",
       "      <td>2.08</td>\n",
       "      <td>61.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20007</th>\n",
       "      <td>440949006.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>295.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3.54</td>\n",
       "      <td>2.56</td>\n",
       "      <td>237.29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20008</th>\n",
       "      <td>440956226.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>211.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.19</td>\n",
       "      <td>70.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20009</th>\n",
       "      <td>441127927.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>363.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>5.92</td>\n",
       "      <td>2.69</td>\n",
       "      <td>120.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19207 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  Gender  Age-Group  Weight  BMI Group  WBC  Platelet   HGB  \\\n",
       "0       93409976.0     1.0        4.0   93.00        4.0  3.8     159.0  15.5   \n",
       "1       93370093.0     2.0        4.0   79.00        3.0  5.5     218.0  13.2   \n",
       "2       93323774.0     1.0        4.0  124.00        4.0  6.1     175.0  15.0   \n",
       "3       93344918.0     1.0        4.0   84.00        3.0  8.0     280.0  15.4   \n",
       "4       93355053.0     2.0        4.0   94.00        4.0  8.1     351.0  13.2   \n",
       "...            ...     ...        ...     ...        ...  ...       ...   ...   \n",
       "20005  440943238.0     1.0        1.0   97.52        3.0  6.2     322.0  15.3   \n",
       "20006  440944836.0     1.0        1.0   78.93        2.0  4.6     173.0  14.7   \n",
       "20007  440949006.0     2.0        1.0   72.58        3.0  6.1     295.0  13.3   \n",
       "20008  440956226.0     1.0        1.0   71.67        3.0  3.8     211.0  14.8   \n",
       "20009  441127927.0     2.0        1.0   93.44        3.0  8.7     363.0  12.6   \n",
       "\n",
       "       Neut Abs  MNC Abs  CD34 Abs  Count  labtype  \n",
       "0          2.24     1.56     11.70      0        0  \n",
       "1          3.00     2.49     70.20      1        0  \n",
       "2          3.23     2.87     22.05      0        0  \n",
       "3          5.04     2.96     87.55      1        0  \n",
       "4          4.94     3.16     51.00      1        0  \n",
       "...         ...      ...       ...    ...      ...  \n",
       "20005      3.97     2.23    126.00      1        0  \n",
       "20006      2.52     2.08     61.03      1        0  \n",
       "20007      3.54     2.56    237.29      1        0  \n",
       "20008      1.61     2.19     70.25      1        0  \n",
       "20009      5.92     2.69    120.98      1        0  \n",
       "\n",
       "[19207 rows x 13 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename the columns in pre_df\n",
    "pre_df = pre_df.rename(columns={'pseudoid': 'ID', 'dsex' : 'Gender', 'coll_age_gp' : 'Age-Group', 'd_wt' : 'Weight', 'wbc0' : 'WBC', 'plt0' :'Platelet', 'hgb0' : 'HGB',\n",
    "       'absneut0' : 'Neut Abs', 'absmnc0' : 'MNC Abs', 'abscd34_5pre' : 'CD34 Abs', 'd_bmi_grp': 'BMI Group'})\n",
    "pre_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda6a23d",
   "metadata": {},
   "source": [
    "### Defining Post-G-CSF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73be2fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_cols = ['pseudoid', 'twodaycoll', 'dsex', 'coll_age_gp', 'd_wt', 'd_bmi_grp',\n",
    "             'wbc5pre', # white blood cell count at 5 day\n",
    "                'absneut5pre', # absolute neutrophil count at 5 day\n",
    "                'absmnc5pre', # absolute monocyte count at 5 day\n",
    "                'abscd34_5pre', # absolute CD34 count at 5 day\n",
    "                'plt5pre',  # platelet count at 5 day\n",
    "                'hgb5pre', # hemoglobin at 5 day\n",
    "                'Count'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c23120a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pseudoid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "twodaycoll",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dsex",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "coll_age_gp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_wt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_bmi_grp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wbc5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absneut5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absmnc5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "abscd34_5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "plt5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hgb5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "8b7f2e55-ba7a-4686-b04e-5a79468a4060",
       "rows": [
        [
         "0",
         "93409976.0",
         "0.0",
         "1.0",
         "4.0",
         "93.0",
         "4.0",
         "13.0",
         "10.79",
         "2.21",
         "11.7",
         "136.0",
         "14.4",
         "0"
        ],
        [
         "1",
         "93370093.0",
         "0.0",
         "2.0",
         "4.0",
         "79.0",
         "3.0",
         "31.2",
         "26.36",
         "4.8",
         "70.2",
         "232.0",
         "12.2",
         "1"
        ],
        [
         "2",
         "93323774.0",
         "0.0",
         "1.0",
         "4.0",
         "124.0",
         "4.0",
         "31.5",
         "26.46",
         "5.04",
         "22.05",
         "181.0",
         "14.9",
         "0"
        ],
        [
         "3",
         "93344918.0",
         "0.0",
         "1.0",
         "4.0",
         "84.0",
         "3.0",
         "68.4",
         "60.19",
         "8.21",
         "87.55",
         "230.0",
         "15.9",
         "1"
        ],
        [
         "4",
         "93355053.0",
         "0.0",
         "2.0",
         "4.0",
         "94.0",
         "4.0",
         "34.0",
         "26.18",
         "7.82",
         "51.0",
         "278.0",
         "11.7",
         "1"
        ],
        [
         "5",
         "93562560.0",
         "0.0",
         "1.0",
         "4.0",
         "95.0",
         "3.0",
         "54.9",
         "47.21",
         "7.69",
         "76.86",
         "222.0",
         "14.3",
         "1"
        ],
        [
         "6",
         "93568857.0",
         "0.0",
         "1.0",
         "3.0",
         "87.09",
         "3.0",
         "42.4",
         "36.04",
         "6.36",
         "106.0",
         "199.0",
         "14.6",
         "1"
        ],
        [
         "7",
         "93571163.0",
         "0.0",
         "2.0",
         "3.0",
         "54.0",
         "2.0",
         "29.2",
         "23.07",
         "6.13",
         "37.96",
         "267.0",
         "12.1",
         "0"
        ],
        [
         "8",
         "93580161.0",
         "0.0",
         "1.0",
         "4.0",
         "97.0",
         "3.0",
         "38.7",
         "30.19",
         "8.51",
         "46.44",
         "212.0",
         "15.2",
         "1"
        ],
        [
         "9",
         "93525333.0",
         "0.0",
         "2.0",
         "4.0",
         "91.63",
         "4.0",
         "25.8",
         "21.98",
         "3.82",
         "67.08",
         "182.0",
         "13.7",
         "1"
        ],
        [
         "10",
         "93529830.0",
         "0.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "43.4",
         "40.8",
         "2.6",
         "81.16",
         "244.0",
         "11.7",
         "1"
        ],
        [
         "11",
         "93530273.0",
         "0.0",
         "1.0",
         "3.0",
         "105.23",
         "4.0",
         "33.9",
         "27.46",
         "6.44",
         "88.14",
         "135.0",
         "15.7",
         "1"
        ],
        [
         "12",
         "93538145.0",
         "0.0",
         "1.0",
         "4.0",
         "119.75",
         "4.0",
         "41.4",
         "33.53",
         "7.87",
         "82.8",
         "168.0",
         "14.7",
         "1"
        ],
        [
         "14",
         "93544412.0",
         "0.0",
         "1.0",
         "4.0",
         "103.63",
         "4.0",
         "35.5",
         "30.0",
         "5.5",
         "97.63",
         "207.0",
         "15.7",
         "1"
        ],
        [
         "15",
         "93469126.0",
         "0.0",
         "1.0",
         "3.0",
         "79.0",
         "2.0",
         "25.3",
         "23.68",
         "1.62",
         "35.42",
         "131.0",
         "13.5",
         "0"
        ],
        [
         "16",
         "93677034.0",
         "0.0",
         "1.0",
         "4.0",
         "87.0",
         "4.0",
         "28.0",
         "24.81",
         "3.19",
         "103.6",
         "189.0",
         "14.1",
         "1"
        ],
        [
         "17",
         "93629310.0",
         "0.0",
         "2.0",
         "4.0",
         "85.0",
         "4.0",
         "62.5",
         "46.88",
         "15.63",
         "93.75",
         "316.0",
         "14.4",
         "1"
        ],
        [
         "18",
         "93650522.0",
         "0.0",
         "1.0",
         "3.0",
         "77.27",
         "3.0",
         "61.0",
         "55.51",
         "5.49",
         "73.2",
         "176.0",
         "15.9",
         "1"
        ],
        [
         "19",
         "93609903.0",
         "0.0",
         "1.0",
         "4.0",
         "112.49",
         "4.0",
         "52.6",
         "44.39",
         "8.21",
         "42.08",
         "223.0",
         "13.4",
         "1"
        ],
        [
         "20",
         "93611587.0",
         "0.0",
         "1.0",
         "4.0",
         "68.0",
         "2.0",
         "33.8",
         "23.32",
         "10.48",
         "270.4",
         "328.0",
         "13.6",
         "1"
        ],
        [
         "21",
         "93612785.0",
         "0.0",
         "1.0",
         "4.0",
         "88.0",
         "4.0",
         "42.2",
         "27.85",
         "14.35",
         "88.62",
         "200.0",
         "13.0",
         "1"
        ],
        [
         "22",
         "93828609.0",
         "0.0",
         "1.0",
         "3.0",
         "88.0",
         "4.0",
         "46.6",
         "43.34",
         "3.26",
         "116.5",
         "216.0",
         "13.1",
         "1"
        ],
        [
         "23",
         "93770923.0",
         "0.0",
         "1.0",
         "3.0",
         "81.0",
         "2.0",
         "43.8",
         "35.78",
         "8.02",
         "122.64",
         "211.0",
         "13.2",
         "1"
        ],
        [
         "24",
         "93722512.0",
         "0.0",
         "1.0",
         "3.0",
         "75.45",
         "2.0",
         "28.5",
         "24.51",
         "3.99",
         "62.7",
         "185.0",
         "13.3",
         "1"
        ],
        [
         "25",
         "93961139.0",
         "0.0",
         "2.0",
         "4.0",
         "87.0",
         "3.0",
         "32.1",
         "24.72",
         "8.35",
         "19.26",
         "275.0",
         "12.8",
         "0"
        ],
        [
         "26",
         "93902962.0",
         "0.0",
         "2.0",
         "3.0",
         "64.41",
         "2.0",
         "43.8",
         "37.23",
         "6.57",
         "52.56",
         "239.0",
         "13.7",
         "1"
        ],
        [
         "27",
         "93912879.0",
         "0.0",
         "2.0",
         "3.0",
         "74.84",
         "4.0",
         "23.4",
         "18.25",
         "5.15",
         "46.8",
         "205.0",
         "13.1",
         "1"
        ],
        [
         "29",
         "93855245.0",
         "0.0",
         "1.0",
         "2.0",
         "93.63",
         "3.0",
         "47.5",
         "43.23",
         "3.66",
         "61.75",
         "189.0",
         "15.2",
         "1"
        ],
        [
         "30",
         "94086404.0",
         "0.0",
         "2.0",
         "3.0",
         "87.0",
         "4.0",
         "46.5",
         "36.74",
         "9.77",
         "102.3",
         "214.0",
         "12.2",
         "1"
        ],
        [
         "31",
         "94101687.0",
         "0.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "54.9",
         "47.87",
         "6.97",
         "878.4",
         "235.0",
         "16.4",
         "1"
        ],
        [
         "32",
         "94056760.0",
         "0.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "47.9",
         "37.12",
         "10.78",
         "57.48",
         "206.0",
         "13.6",
         "1"
        ],
        [
         "33",
         "93987175.0",
         "0.0",
         "1.0",
         "4.0",
         "96.0",
         "3.0",
         "42.6",
         "35.36",
         "7.24",
         "85.2",
         "249.0",
         "13.5",
         "1"
        ],
        [
         "34",
         "93993202.0",
         "0.0",
         "2.0",
         "4.0",
         "90.27",
         "4.0",
         "50.7",
         "44.51",
         "6.19",
         "106.47",
         "225.0",
         "14.5",
         "1"
        ],
        [
         "35",
         "93994677.0",
         "0.0",
         "1.0",
         "2.0",
         "105.9",
         "4.0",
         "28.9",
         "26.01",
         "2.89",
         "112.71",
         "177.0",
         "14.0",
         "1"
        ],
        [
         "36",
         "94177942.0",
         "0.0",
         "1.0",
         "4.0",
         "69.4",
         "2.0",
         "34.4",
         "27.52",
         "6.88",
         "72.24",
         "262.0",
         "15.6",
         "1"
        ],
        [
         "37",
         "94191277.0",
         "0.0",
         "2.0",
         "2.0",
         "54.54",
         "2.0",
         "38.4",
         "31.87",
         "6.14",
         "15.36",
         "223.0",
         "13.0",
         "0"
        ],
        [
         "38",
         "94203152.0",
         "0.0",
         "2.0",
         "4.0",
         "69.09",
         "3.0",
         "41.5",
         "34.94",
         "6.52",
         "83.0",
         "336.0",
         "12.6",
         "1"
        ],
        [
         "39",
         "94115557.0",
         "0.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "74.5",
         "65.41",
         "9.01",
         "298.0",
         "218.0",
         "14.8",
         "1"
        ],
        [
         "40",
         "94120876.0",
         "0.0",
         "2.0",
         "3.0",
         "82.0",
         "4.0",
         "29.0",
         "19.72",
         "9.28",
         "26.1",
         "306.0",
         "12.5",
         "0"
        ],
        [
         "41",
         "94121628.0",
         "0.0",
         "1.0",
         "3.0",
         "97.0",
         "4.0",
         "29.9",
         "24.82",
         "5.08",
         "110.63",
         "182.0",
         "15.4",
         "1"
        ],
        [
         "42",
         "94131849.0",
         "0.0",
         "1.0",
         "2.0",
         "80.74",
         "2.0",
         "20.0",
         "16.2",
         "3.8",
         "49.0",
         "180.0",
         "16.8",
         "1"
        ],
        [
         "43",
         "94344490.0",
         "0.0",
         "1.0",
         "3.0",
         "107.0",
         "4.0",
         "34.0",
         "28.9",
         "4.76",
         "102.0",
         "186.0",
         "15.2",
         "1"
        ],
        [
         "44",
         "94348239.0",
         "0.0",
         "1.0",
         "3.0",
         "96.36",
         "3.0",
         "34.6",
         "29.76",
         "4.84",
         "76.12",
         "243.0",
         "14.9",
         "1"
        ],
        [
         "45",
         "94311317.0",
         "0.0",
         "1.0",
         "2.0",
         "79.0",
         "2.0",
         "46.3",
         "41.81",
         "4.49",
         "64.82",
         "142.0",
         "14.9",
         "1"
        ],
        [
         "46",
         "94316721.0",
         "0.0",
         "2.0",
         "3.0",
         "60.0",
         "2.0",
         "46.7",
         "40.07",
         "6.63",
         "77.06",
         "232.0",
         "12.5",
         "1"
        ],
        [
         "47",
         "94276724.0",
         "0.0",
         "1.0",
         "3.0",
         "99.0",
         "4.0",
         "28.5",
         "25.37",
         "3.14",
         "35.91",
         "205.0",
         "13.0",
         "0"
        ],
        [
         "48",
         "94301982.0",
         "0.0",
         "1.0",
         "4.0",
         "102.51",
         "4.0",
         "39.9",
         "33.08",
         "6.82",
         "35.91",
         "187.0",
         "15.0",
         "0"
        ],
        [
         "49",
         "94303078.0",
         "0.0",
         "1.0",
         "3.0",
         "105.69",
         "4.0",
         "36.6",
         "31.26",
         "5.34",
         "157.38",
         "141.0",
         "14.3",
         "1"
        ],
        [
         "50",
         "94247403.0",
         "0.0",
         "2.0",
         "4.0",
         "55.0",
         "2.0",
         "32.3",
         "29.55",
         "2.75",
         "129.2",
         "202.0",
         "12.5",
         "1"
        ],
        [
         "51",
         "92348789.0",
         "0.0",
         "1.0",
         "4.0",
         "104.0",
         "4.0",
         "41.3",
         "35.11",
         "7.43",
         "49.56",
         "177.0",
         "15.3",
         "1"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 19617
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudoid</th>\n",
       "      <th>twodaycoll</th>\n",
       "      <th>dsex</th>\n",
       "      <th>coll_age_gp</th>\n",
       "      <th>d_wt</th>\n",
       "      <th>d_bmi_grp</th>\n",
       "      <th>wbc5pre</th>\n",
       "      <th>absneut5pre</th>\n",
       "      <th>absmnc5pre</th>\n",
       "      <th>abscd34_5pre</th>\n",
       "      <th>plt5pre</th>\n",
       "      <th>hgb5pre</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93409976.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.79</td>\n",
       "      <td>2.21</td>\n",
       "      <td>11.70</td>\n",
       "      <td>136.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93370093.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>26.36</td>\n",
       "      <td>4.80</td>\n",
       "      <td>70.20</td>\n",
       "      <td>232.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93323774.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>26.46</td>\n",
       "      <td>5.04</td>\n",
       "      <td>22.05</td>\n",
       "      <td>181.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93344918.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.4</td>\n",
       "      <td>60.19</td>\n",
       "      <td>8.21</td>\n",
       "      <td>87.55</td>\n",
       "      <td>230.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93355053.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.18</td>\n",
       "      <td>7.82</td>\n",
       "      <td>51.00</td>\n",
       "      <td>278.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005</th>\n",
       "      <td>440943238.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.5</td>\n",
       "      <td>44.63</td>\n",
       "      <td>7.88</td>\n",
       "      <td>126.00</td>\n",
       "      <td>296.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006</th>\n",
       "      <td>440944836.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.93</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>31.41</td>\n",
       "      <td>4.49</td>\n",
       "      <td>61.03</td>\n",
       "      <td>191.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20007</th>\n",
       "      <td>440949006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.9</td>\n",
       "      <td>31.51</td>\n",
       "      <td>7.39</td>\n",
       "      <td>237.29</td>\n",
       "      <td>270.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20008</th>\n",
       "      <td>440956226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>22.06</td>\n",
       "      <td>6.04</td>\n",
       "      <td>70.25</td>\n",
       "      <td>195.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20009</th>\n",
       "      <td>441127927.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>46.29</td>\n",
       "      <td>6.31</td>\n",
       "      <td>120.98</td>\n",
       "      <td>294.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19617 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pseudoid  twodaycoll  dsex  coll_age_gp    d_wt  d_bmi_grp  wbc5pre  \\\n",
       "0       93409976.0         0.0   1.0          4.0   93.00        4.0     13.0   \n",
       "1       93370093.0         0.0   2.0          4.0   79.00        3.0     31.2   \n",
       "2       93323774.0         0.0   1.0          4.0  124.00        4.0     31.5   \n",
       "3       93344918.0         0.0   1.0          4.0   84.00        3.0     68.4   \n",
       "4       93355053.0         0.0   2.0          4.0   94.00        4.0     34.0   \n",
       "...            ...         ...   ...          ...     ...        ...      ...   \n",
       "20005  440943238.0         0.0   1.0          1.0   97.52        3.0     52.5   \n",
       "20006  440944836.0         0.0   1.0          1.0   78.93        2.0     35.9   \n",
       "20007  440949006.0         0.0   2.0          1.0   72.58        3.0     38.9   \n",
       "20008  440956226.0         0.0   1.0          1.0   71.67        3.0     28.1   \n",
       "20009  441127927.0         0.0   2.0          1.0   93.44        3.0     52.6   \n",
       "\n",
       "       absneut5pre  absmnc5pre  abscd34_5pre  plt5pre  hgb5pre  Count  \n",
       "0            10.79        2.21         11.70    136.0     14.4      0  \n",
       "1            26.36        4.80         70.20    232.0     12.2      1  \n",
       "2            26.46        5.04         22.05    181.0     14.9      0  \n",
       "3            60.19        8.21         87.55    230.0     15.9      1  \n",
       "4            26.18        7.82         51.00    278.0     11.7      1  \n",
       "...            ...         ...           ...      ...      ...    ...  \n",
       "20005        44.63        7.88        126.00    296.0     14.2      1  \n",
       "20006        31.41        4.49         61.03    191.0     14.8      1  \n",
       "20007        31.51        7.39        237.29    270.0     13.6      1  \n",
       "20008        22.06        6.04         70.25    195.0     14.7      1  \n",
       "20009        46.29        6.31        120.98    294.0     12.2      1  \n",
       "\n",
       "[19617 rows x 13 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a new dataframe with columns from day 5 including the demographics\n",
    "post_df = df[post_cols].copy()\n",
    "post_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09ea91c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pseudoid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "twodaycoll",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dsex",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "coll_age_gp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_wt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_bmi_grp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wbc5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absneut5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absmnc5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "abscd34_5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "plt5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hgb5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "eb0e4574-f65a-438c-8466-f65e490bc7a7",
       "rows": [
        [
         "0",
         "93409976.0",
         "0.0",
         "1.0",
         "4.0",
         "93.0",
         "4.0",
         "13.0",
         "10.79",
         "2.21",
         "11.7",
         "136.0",
         "14.4",
         "0"
        ],
        [
         "1",
         "93370093.0",
         "0.0",
         "2.0",
         "4.0",
         "79.0",
         "3.0",
         "31.2",
         "26.36",
         "4.8",
         "70.2",
         "232.0",
         "12.2",
         "1"
        ],
        [
         "2",
         "93323774.0",
         "0.0",
         "1.0",
         "4.0",
         "124.0",
         "4.0",
         "31.5",
         "26.46",
         "5.04",
         "22.05",
         "181.0",
         "14.9",
         "0"
        ],
        [
         "3",
         "93344918.0",
         "0.0",
         "1.0",
         "4.0",
         "84.0",
         "3.0",
         "68.4",
         "60.19",
         "8.21",
         "87.55",
         "230.0",
         "15.9",
         "1"
        ],
        [
         "4",
         "93355053.0",
         "0.0",
         "2.0",
         "4.0",
         "94.0",
         "4.0",
         "34.0",
         "26.18",
         "7.82",
         "51.0",
         "278.0",
         "11.7",
         "1"
        ],
        [
         "5",
         "93562560.0",
         "0.0",
         "1.0",
         "4.0",
         "95.0",
         "3.0",
         "54.9",
         "47.21",
         "7.69",
         "76.86",
         "222.0",
         "14.3",
         "1"
        ],
        [
         "6",
         "93568857.0",
         "0.0",
         "1.0",
         "3.0",
         "87.09",
         "3.0",
         "42.4",
         "36.04",
         "6.36",
         "106.0",
         "199.0",
         "14.6",
         "1"
        ],
        [
         "7",
         "93571163.0",
         "0.0",
         "2.0",
         "3.0",
         "54.0",
         "2.0",
         "29.2",
         "23.07",
         "6.13",
         "37.96",
         "267.0",
         "12.1",
         "0"
        ],
        [
         "8",
         "93580161.0",
         "0.0",
         "1.0",
         "4.0",
         "97.0",
         "3.0",
         "38.7",
         "30.19",
         "8.51",
         "46.44",
         "212.0",
         "15.2",
         "1"
        ],
        [
         "9",
         "93525333.0",
         "0.0",
         "2.0",
         "4.0",
         "91.63",
         "4.0",
         "25.8",
         "21.98",
         "3.82",
         "67.08",
         "182.0",
         "13.7",
         "1"
        ],
        [
         "10",
         "93529830.0",
         "0.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "43.4",
         "40.8",
         "2.6",
         "81.16",
         "244.0",
         "11.7",
         "1"
        ],
        [
         "11",
         "93530273.0",
         "0.0",
         "1.0",
         "3.0",
         "105.23",
         "4.0",
         "33.9",
         "27.46",
         "6.44",
         "88.14",
         "135.0",
         "15.7",
         "1"
        ],
        [
         "12",
         "93538145.0",
         "0.0",
         "1.0",
         "4.0",
         "119.75",
         "4.0",
         "41.4",
         "33.53",
         "7.87",
         "82.8",
         "168.0",
         "14.7",
         "1"
        ],
        [
         "14",
         "93544412.0",
         "0.0",
         "1.0",
         "4.0",
         "103.63",
         "4.0",
         "35.5",
         "30.0",
         "5.5",
         "97.63",
         "207.0",
         "15.7",
         "1"
        ],
        [
         "15",
         "93469126.0",
         "0.0",
         "1.0",
         "3.0",
         "79.0",
         "2.0",
         "25.3",
         "23.68",
         "1.62",
         "35.42",
         "131.0",
         "13.5",
         "0"
        ],
        [
         "16",
         "93677034.0",
         "0.0",
         "1.0",
         "4.0",
         "87.0",
         "4.0",
         "28.0",
         "24.81",
         "3.19",
         "103.6",
         "189.0",
         "14.1",
         "1"
        ],
        [
         "17",
         "93629310.0",
         "0.0",
         "2.0",
         "4.0",
         "85.0",
         "4.0",
         "62.5",
         "46.88",
         "15.63",
         "93.75",
         "316.0",
         "14.4",
         "1"
        ],
        [
         "18",
         "93650522.0",
         "0.0",
         "1.0",
         "3.0",
         "77.27",
         "3.0",
         "61.0",
         "55.51",
         "5.49",
         "73.2",
         "176.0",
         "15.9",
         "1"
        ],
        [
         "19",
         "93609903.0",
         "0.0",
         "1.0",
         "4.0",
         "112.49",
         "4.0",
         "52.6",
         "44.39",
         "8.21",
         "42.08",
         "223.0",
         "13.4",
         "1"
        ],
        [
         "20",
         "93611587.0",
         "0.0",
         "1.0",
         "4.0",
         "68.0",
         "2.0",
         "33.8",
         "23.32",
         "10.48",
         "270.4",
         "328.0",
         "13.6",
         "1"
        ],
        [
         "21",
         "93612785.0",
         "0.0",
         "1.0",
         "4.0",
         "88.0",
         "4.0",
         "42.2",
         "27.85",
         "14.35",
         "88.62",
         "200.0",
         "13.0",
         "1"
        ],
        [
         "22",
         "93828609.0",
         "0.0",
         "1.0",
         "3.0",
         "88.0",
         "4.0",
         "46.6",
         "43.34",
         "3.26",
         "116.5",
         "216.0",
         "13.1",
         "1"
        ],
        [
         "23",
         "93770923.0",
         "0.0",
         "1.0",
         "3.0",
         "81.0",
         "2.0",
         "43.8",
         "35.78",
         "8.02",
         "122.64",
         "211.0",
         "13.2",
         "1"
        ],
        [
         "24",
         "93722512.0",
         "0.0",
         "1.0",
         "3.0",
         "75.45",
         "2.0",
         "28.5",
         "24.51",
         "3.99",
         "62.7",
         "185.0",
         "13.3",
         "1"
        ],
        [
         "25",
         "93961139.0",
         "0.0",
         "2.0",
         "4.0",
         "87.0",
         "3.0",
         "32.1",
         "24.72",
         "8.35",
         "19.26",
         "275.0",
         "12.8",
         "0"
        ],
        [
         "26",
         "93902962.0",
         "0.0",
         "2.0",
         "3.0",
         "64.41",
         "2.0",
         "43.8",
         "37.23",
         "6.57",
         "52.56",
         "239.0",
         "13.7",
         "1"
        ],
        [
         "27",
         "93912879.0",
         "0.0",
         "2.0",
         "3.0",
         "74.84",
         "4.0",
         "23.4",
         "18.25",
         "5.15",
         "46.8",
         "205.0",
         "13.1",
         "1"
        ],
        [
         "29",
         "93855245.0",
         "0.0",
         "1.0",
         "2.0",
         "93.63",
         "3.0",
         "47.5",
         "43.23",
         "3.66",
         "61.75",
         "189.0",
         "15.2",
         "1"
        ],
        [
         "30",
         "94086404.0",
         "0.0",
         "2.0",
         "3.0",
         "87.0",
         "4.0",
         "46.5",
         "36.74",
         "9.77",
         "102.3",
         "214.0",
         "12.2",
         "1"
        ],
        [
         "31",
         "94101687.0",
         "0.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "54.9",
         "47.87",
         "6.97",
         "878.4",
         "235.0",
         "16.4",
         "1"
        ],
        [
         "32",
         "94056760.0",
         "0.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "47.9",
         "37.12",
         "10.78",
         "57.48",
         "206.0",
         "13.6",
         "1"
        ],
        [
         "33",
         "93987175.0",
         "0.0",
         "1.0",
         "4.0",
         "96.0",
         "3.0",
         "42.6",
         "35.36",
         "7.24",
         "85.2",
         "249.0",
         "13.5",
         "1"
        ],
        [
         "34",
         "93993202.0",
         "0.0",
         "2.0",
         "4.0",
         "90.27",
         "4.0",
         "50.7",
         "44.51",
         "6.19",
         "106.47",
         "225.0",
         "14.5",
         "1"
        ],
        [
         "35",
         "93994677.0",
         "0.0",
         "1.0",
         "2.0",
         "105.9",
         "4.0",
         "28.9",
         "26.01",
         "2.89",
         "112.71",
         "177.0",
         "14.0",
         "1"
        ],
        [
         "36",
         "94177942.0",
         "0.0",
         "1.0",
         "4.0",
         "69.4",
         "2.0",
         "34.4",
         "27.52",
         "6.88",
         "72.24",
         "262.0",
         "15.6",
         "1"
        ],
        [
         "37",
         "94191277.0",
         "0.0",
         "2.0",
         "2.0",
         "54.54",
         "2.0",
         "38.4",
         "31.87",
         "6.14",
         "15.36",
         "223.0",
         "13.0",
         "0"
        ],
        [
         "38",
         "94203152.0",
         "0.0",
         "2.0",
         "4.0",
         "69.09",
         "3.0",
         "41.5",
         "34.94",
         "6.52",
         "83.0",
         "336.0",
         "12.6",
         "1"
        ],
        [
         "39",
         "94115557.0",
         "0.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "74.5",
         "65.41",
         "9.01",
         "298.0",
         "218.0",
         "14.8",
         "1"
        ],
        [
         "40",
         "94120876.0",
         "0.0",
         "2.0",
         "3.0",
         "82.0",
         "4.0",
         "29.0",
         "19.72",
         "9.28",
         "26.1",
         "306.0",
         "12.5",
         "0"
        ],
        [
         "41",
         "94121628.0",
         "0.0",
         "1.0",
         "3.0",
         "97.0",
         "4.0",
         "29.9",
         "24.82",
         "5.08",
         "110.63",
         "182.0",
         "15.4",
         "1"
        ],
        [
         "42",
         "94131849.0",
         "0.0",
         "1.0",
         "2.0",
         "80.74",
         "2.0",
         "20.0",
         "16.2",
         "3.8",
         "49.0",
         "180.0",
         "16.8",
         "1"
        ],
        [
         "43",
         "94344490.0",
         "0.0",
         "1.0",
         "3.0",
         "107.0",
         "4.0",
         "34.0",
         "28.9",
         "4.76",
         "102.0",
         "186.0",
         "15.2",
         "1"
        ],
        [
         "44",
         "94348239.0",
         "0.0",
         "1.0",
         "3.0",
         "96.36",
         "3.0",
         "34.6",
         "29.76",
         "4.84",
         "76.12",
         "243.0",
         "14.9",
         "1"
        ],
        [
         "45",
         "94311317.0",
         "0.0",
         "1.0",
         "2.0",
         "79.0",
         "2.0",
         "46.3",
         "41.81",
         "4.49",
         "64.82",
         "142.0",
         "14.9",
         "1"
        ],
        [
         "46",
         "94316721.0",
         "0.0",
         "2.0",
         "3.0",
         "60.0",
         "2.0",
         "46.7",
         "40.07",
         "6.63",
         "77.06",
         "232.0",
         "12.5",
         "1"
        ],
        [
         "47",
         "94276724.0",
         "0.0",
         "1.0",
         "3.0",
         "99.0",
         "4.0",
         "28.5",
         "25.37",
         "3.14",
         "35.91",
         "205.0",
         "13.0",
         "0"
        ],
        [
         "48",
         "94301982.0",
         "0.0",
         "1.0",
         "4.0",
         "102.51",
         "4.0",
         "39.9",
         "33.08",
         "6.82",
         "35.91",
         "187.0",
         "15.0",
         "0"
        ],
        [
         "49",
         "94303078.0",
         "0.0",
         "1.0",
         "3.0",
         "105.69",
         "4.0",
         "36.6",
         "31.26",
         "5.34",
         "157.38",
         "141.0",
         "14.3",
         "1"
        ],
        [
         "50",
         "94247403.0",
         "0.0",
         "2.0",
         "4.0",
         "55.0",
         "2.0",
         "32.3",
         "29.55",
         "2.75",
         "129.2",
         "202.0",
         "12.5",
         "1"
        ],
        [
         "51",
         "92348789.0",
         "0.0",
         "1.0",
         "4.0",
         "104.0",
         "4.0",
         "41.3",
         "35.11",
         "7.43",
         "49.56",
         "177.0",
         "15.3",
         "1"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 19158
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudoid</th>\n",
       "      <th>twodaycoll</th>\n",
       "      <th>dsex</th>\n",
       "      <th>coll_age_gp</th>\n",
       "      <th>d_wt</th>\n",
       "      <th>d_bmi_grp</th>\n",
       "      <th>wbc5pre</th>\n",
       "      <th>absneut5pre</th>\n",
       "      <th>absmnc5pre</th>\n",
       "      <th>abscd34_5pre</th>\n",
       "      <th>plt5pre</th>\n",
       "      <th>hgb5pre</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93409976.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.79</td>\n",
       "      <td>2.21</td>\n",
       "      <td>11.70</td>\n",
       "      <td>136.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93370093.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>26.36</td>\n",
       "      <td>4.80</td>\n",
       "      <td>70.20</td>\n",
       "      <td>232.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93323774.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>26.46</td>\n",
       "      <td>5.04</td>\n",
       "      <td>22.05</td>\n",
       "      <td>181.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93344918.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.4</td>\n",
       "      <td>60.19</td>\n",
       "      <td>8.21</td>\n",
       "      <td>87.55</td>\n",
       "      <td>230.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93355053.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.18</td>\n",
       "      <td>7.82</td>\n",
       "      <td>51.00</td>\n",
       "      <td>278.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005</th>\n",
       "      <td>440943238.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.5</td>\n",
       "      <td>44.63</td>\n",
       "      <td>7.88</td>\n",
       "      <td>126.00</td>\n",
       "      <td>296.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006</th>\n",
       "      <td>440944836.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.93</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>31.41</td>\n",
       "      <td>4.49</td>\n",
       "      <td>61.03</td>\n",
       "      <td>191.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20007</th>\n",
       "      <td>440949006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.9</td>\n",
       "      <td>31.51</td>\n",
       "      <td>7.39</td>\n",
       "      <td>237.29</td>\n",
       "      <td>270.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20008</th>\n",
       "      <td>440956226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>22.06</td>\n",
       "      <td>6.04</td>\n",
       "      <td>70.25</td>\n",
       "      <td>195.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20009</th>\n",
       "      <td>441127927.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>46.29</td>\n",
       "      <td>6.31</td>\n",
       "      <td>120.98</td>\n",
       "      <td>294.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19158 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pseudoid  twodaycoll  dsex  coll_age_gp    d_wt  d_bmi_grp  wbc5pre  \\\n",
       "0       93409976.0         0.0   1.0          4.0   93.00        4.0     13.0   \n",
       "1       93370093.0         0.0   2.0          4.0   79.00        3.0     31.2   \n",
       "2       93323774.0         0.0   1.0          4.0  124.00        4.0     31.5   \n",
       "3       93344918.0         0.0   1.0          4.0   84.00        3.0     68.4   \n",
       "4       93355053.0         0.0   2.0          4.0   94.00        4.0     34.0   \n",
       "...            ...         ...   ...          ...     ...        ...      ...   \n",
       "20005  440943238.0         0.0   1.0          1.0   97.52        3.0     52.5   \n",
       "20006  440944836.0         0.0   1.0          1.0   78.93        2.0     35.9   \n",
       "20007  440949006.0         0.0   2.0          1.0   72.58        3.0     38.9   \n",
       "20008  440956226.0         0.0   1.0          1.0   71.67        3.0     28.1   \n",
       "20009  441127927.0         0.0   2.0          1.0   93.44        3.0     52.6   \n",
       "\n",
       "       absneut5pre  absmnc5pre  abscd34_5pre  plt5pre  hgb5pre  Count  \n",
       "0            10.79        2.21         11.70    136.0     14.4      0  \n",
       "1            26.36        4.80         70.20    232.0     12.2      1  \n",
       "2            26.46        5.04         22.05    181.0     14.9      0  \n",
       "3            60.19        8.21         87.55    230.0     15.9      1  \n",
       "4            26.18        7.82         51.00    278.0     11.7      1  \n",
       "...            ...         ...           ...      ...      ...    ...  \n",
       "20005        44.63        7.88        126.00    296.0     14.2      1  \n",
       "20006        31.41        4.49         61.03    191.0     14.8      1  \n",
       "20007        31.51        7.39        237.29    270.0     13.6      1  \n",
       "20008        22.06        6.04         70.25    195.0     14.7      1  \n",
       "20009        46.29        6.31        120.98    294.0     12.2      1  \n",
       "\n",
       "[19158 rows x 13 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove any rows with missing data\n",
    "post_df = post_df.dropna()\n",
    "post_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "634cc1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pseudoid is unique in post_df\n"
     ]
    }
   ],
   "source": [
    "if post_df['pseudoid'].is_unique:\n",
    "    print(\"pseudoid is unique in post_df\")\n",
    "else:\n",
    "    print(\"pseudoid is not unique in post_df, dropping duplicates\")\n",
    "    post_df = post_df.drop_duplicates(subset='pseudoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba5e2046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with bmi == 99\n",
    "post_df = post_df[post_df['d_bmi_grp'] != 99].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5585e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pseudoid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "twodaycoll",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dsex",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "coll_age_gp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_wt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_bmi_grp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wbc5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absneut5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absmnc5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "abscd34_5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "plt5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hgb5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "0ebb01a7-23bc-4b43-a160-94420e2ce0f4",
       "rows": [
        [
         "0",
         "93409976.0",
         "0.0",
         "1.0",
         "4.0",
         "93.0",
         "4.0",
         "13.0",
         "10.79",
         "2.21",
         "11.7",
         "136.0",
         "14.4",
         "0"
        ],
        [
         "1",
         "93370093.0",
         "0.0",
         "2.0",
         "4.0",
         "79.0",
         "3.0",
         "31.2",
         "26.36",
         "4.8",
         "70.2",
         "232.0",
         "12.2",
         "1"
        ],
        [
         "2",
         "93323774.0",
         "0.0",
         "1.0",
         "4.0",
         "124.0",
         "4.0",
         "31.5",
         "26.46",
         "5.04",
         "22.05",
         "181.0",
         "14.9",
         "0"
        ],
        [
         "3",
         "93344918.0",
         "0.0",
         "1.0",
         "4.0",
         "84.0",
         "3.0",
         "68.4",
         "60.19",
         "8.21",
         "87.55",
         "230.0",
         "15.9",
         "1"
        ],
        [
         "4",
         "93355053.0",
         "0.0",
         "2.0",
         "4.0",
         "94.0",
         "4.0",
         "34.0",
         "26.18",
         "7.82",
         "51.0",
         "278.0",
         "11.7",
         "1"
        ],
        [
         "5",
         "93562560.0",
         "0.0",
         "1.0",
         "4.0",
         "95.0",
         "3.0",
         "54.9",
         "47.21",
         "7.69",
         "76.86",
         "222.0",
         "14.3",
         "1"
        ],
        [
         "6",
         "93568857.0",
         "0.0",
         "1.0",
         "3.0",
         "87.09",
         "3.0",
         "42.4",
         "36.04",
         "6.36",
         "106.0",
         "199.0",
         "14.6",
         "1"
        ],
        [
         "7",
         "93571163.0",
         "0.0",
         "2.0",
         "3.0",
         "54.0",
         "2.0",
         "29.2",
         "23.07",
         "6.13",
         "37.96",
         "267.0",
         "12.1",
         "0"
        ],
        [
         "8",
         "93580161.0",
         "0.0",
         "1.0",
         "4.0",
         "97.0",
         "3.0",
         "38.7",
         "30.19",
         "8.51",
         "46.44",
         "212.0",
         "15.2",
         "1"
        ],
        [
         "9",
         "93525333.0",
         "0.0",
         "2.0",
         "4.0",
         "91.63",
         "4.0",
         "25.8",
         "21.98",
         "3.82",
         "67.08",
         "182.0",
         "13.7",
         "1"
        ],
        [
         "10",
         "93529830.0",
         "0.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "43.4",
         "40.8",
         "2.6",
         "81.16",
         "244.0",
         "11.7",
         "1"
        ],
        [
         "11",
         "93530273.0",
         "0.0",
         "1.0",
         "3.0",
         "105.23",
         "4.0",
         "33.9",
         "27.46",
         "6.44",
         "88.14",
         "135.0",
         "15.7",
         "1"
        ],
        [
         "12",
         "93538145.0",
         "0.0",
         "1.0",
         "4.0",
         "119.75",
         "4.0",
         "41.4",
         "33.53",
         "7.87",
         "82.8",
         "168.0",
         "14.7",
         "1"
        ],
        [
         "14",
         "93544412.0",
         "0.0",
         "1.0",
         "4.0",
         "103.63",
         "4.0",
         "35.5",
         "30.0",
         "5.5",
         "97.63",
         "207.0",
         "15.7",
         "1"
        ],
        [
         "15",
         "93469126.0",
         "0.0",
         "1.0",
         "3.0",
         "79.0",
         "2.0",
         "25.3",
         "23.68",
         "1.62",
         "35.42",
         "131.0",
         "13.5",
         "0"
        ],
        [
         "16",
         "93677034.0",
         "0.0",
         "1.0",
         "4.0",
         "87.0",
         "4.0",
         "28.0",
         "24.81",
         "3.19",
         "103.6",
         "189.0",
         "14.1",
         "1"
        ],
        [
         "17",
         "93629310.0",
         "0.0",
         "2.0",
         "4.0",
         "85.0",
         "4.0",
         "62.5",
         "46.88",
         "15.63",
         "93.75",
         "316.0",
         "14.4",
         "1"
        ],
        [
         "18",
         "93650522.0",
         "0.0",
         "1.0",
         "3.0",
         "77.27",
         "3.0",
         "61.0",
         "55.51",
         "5.49",
         "73.2",
         "176.0",
         "15.9",
         "1"
        ],
        [
         "19",
         "93609903.0",
         "0.0",
         "1.0",
         "4.0",
         "112.49",
         "4.0",
         "52.6",
         "44.39",
         "8.21",
         "42.08",
         "223.0",
         "13.4",
         "1"
        ],
        [
         "20",
         "93611587.0",
         "0.0",
         "1.0",
         "4.0",
         "68.0",
         "2.0",
         "33.8",
         "23.32",
         "10.48",
         "270.4",
         "328.0",
         "13.6",
         "1"
        ],
        [
         "21",
         "93612785.0",
         "0.0",
         "1.0",
         "4.0",
         "88.0",
         "4.0",
         "42.2",
         "27.85",
         "14.35",
         "88.62",
         "200.0",
         "13.0",
         "1"
        ],
        [
         "22",
         "93828609.0",
         "0.0",
         "1.0",
         "3.0",
         "88.0",
         "4.0",
         "46.6",
         "43.34",
         "3.26",
         "116.5",
         "216.0",
         "13.1",
         "1"
        ],
        [
         "23",
         "93770923.0",
         "0.0",
         "1.0",
         "3.0",
         "81.0",
         "2.0",
         "43.8",
         "35.78",
         "8.02",
         "122.64",
         "211.0",
         "13.2",
         "1"
        ],
        [
         "24",
         "93722512.0",
         "0.0",
         "1.0",
         "3.0",
         "75.45",
         "2.0",
         "28.5",
         "24.51",
         "3.99",
         "62.7",
         "185.0",
         "13.3",
         "1"
        ],
        [
         "25",
         "93961139.0",
         "0.0",
         "2.0",
         "4.0",
         "87.0",
         "3.0",
         "32.1",
         "24.72",
         "8.35",
         "19.26",
         "275.0",
         "12.8",
         "0"
        ],
        [
         "26",
         "93902962.0",
         "0.0",
         "2.0",
         "3.0",
         "64.41",
         "2.0",
         "43.8",
         "37.23",
         "6.57",
         "52.56",
         "239.0",
         "13.7",
         "1"
        ],
        [
         "27",
         "93912879.0",
         "0.0",
         "2.0",
         "3.0",
         "74.84",
         "4.0",
         "23.4",
         "18.25",
         "5.15",
         "46.8",
         "205.0",
         "13.1",
         "1"
        ],
        [
         "29",
         "93855245.0",
         "0.0",
         "1.0",
         "2.0",
         "93.63",
         "3.0",
         "47.5",
         "43.23",
         "3.66",
         "61.75",
         "189.0",
         "15.2",
         "1"
        ],
        [
         "30",
         "94086404.0",
         "0.0",
         "2.0",
         "3.0",
         "87.0",
         "4.0",
         "46.5",
         "36.74",
         "9.77",
         "102.3",
         "214.0",
         "12.2",
         "1"
        ],
        [
         "31",
         "94101687.0",
         "0.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "54.9",
         "47.87",
         "6.97",
         "878.4",
         "235.0",
         "16.4",
         "1"
        ],
        [
         "32",
         "94056760.0",
         "0.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "47.9",
         "37.12",
         "10.78",
         "57.48",
         "206.0",
         "13.6",
         "1"
        ],
        [
         "33",
         "93987175.0",
         "0.0",
         "1.0",
         "4.0",
         "96.0",
         "3.0",
         "42.6",
         "35.36",
         "7.24",
         "85.2",
         "249.0",
         "13.5",
         "1"
        ],
        [
         "34",
         "93993202.0",
         "0.0",
         "2.0",
         "4.0",
         "90.27",
         "4.0",
         "50.7",
         "44.51",
         "6.19",
         "106.47",
         "225.0",
         "14.5",
         "1"
        ],
        [
         "35",
         "93994677.0",
         "0.0",
         "1.0",
         "2.0",
         "105.9",
         "4.0",
         "28.9",
         "26.01",
         "2.89",
         "112.71",
         "177.0",
         "14.0",
         "1"
        ],
        [
         "36",
         "94177942.0",
         "0.0",
         "1.0",
         "4.0",
         "69.4",
         "2.0",
         "34.4",
         "27.52",
         "6.88",
         "72.24",
         "262.0",
         "15.6",
         "1"
        ],
        [
         "37",
         "94191277.0",
         "0.0",
         "2.0",
         "2.0",
         "54.54",
         "2.0",
         "38.4",
         "31.87",
         "6.14",
         "15.36",
         "223.0",
         "13.0",
         "0"
        ],
        [
         "38",
         "94203152.0",
         "0.0",
         "2.0",
         "4.0",
         "69.09",
         "3.0",
         "41.5",
         "34.94",
         "6.52",
         "83.0",
         "336.0",
         "12.6",
         "1"
        ],
        [
         "39",
         "94115557.0",
         "0.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "74.5",
         "65.41",
         "9.01",
         "298.0",
         "218.0",
         "14.8",
         "1"
        ],
        [
         "40",
         "94120876.0",
         "0.0",
         "2.0",
         "3.0",
         "82.0",
         "4.0",
         "29.0",
         "19.72",
         "9.28",
         "26.1",
         "306.0",
         "12.5",
         "0"
        ],
        [
         "41",
         "94121628.0",
         "0.0",
         "1.0",
         "3.0",
         "97.0",
         "4.0",
         "29.9",
         "24.82",
         "5.08",
         "110.63",
         "182.0",
         "15.4",
         "1"
        ],
        [
         "42",
         "94131849.0",
         "0.0",
         "1.0",
         "2.0",
         "80.74",
         "2.0",
         "20.0",
         "16.2",
         "3.8",
         "49.0",
         "180.0",
         "16.8",
         "1"
        ],
        [
         "43",
         "94344490.0",
         "0.0",
         "1.0",
         "3.0",
         "107.0",
         "4.0",
         "34.0",
         "28.9",
         "4.76",
         "102.0",
         "186.0",
         "15.2",
         "1"
        ],
        [
         "44",
         "94348239.0",
         "0.0",
         "1.0",
         "3.0",
         "96.36",
         "3.0",
         "34.6",
         "29.76",
         "4.84",
         "76.12",
         "243.0",
         "14.9",
         "1"
        ],
        [
         "45",
         "94311317.0",
         "0.0",
         "1.0",
         "2.0",
         "79.0",
         "2.0",
         "46.3",
         "41.81",
         "4.49",
         "64.82",
         "142.0",
         "14.9",
         "1"
        ],
        [
         "46",
         "94316721.0",
         "0.0",
         "2.0",
         "3.0",
         "60.0",
         "2.0",
         "46.7",
         "40.07",
         "6.63",
         "77.06",
         "232.0",
         "12.5",
         "1"
        ],
        [
         "47",
         "94276724.0",
         "0.0",
         "1.0",
         "3.0",
         "99.0",
         "4.0",
         "28.5",
         "25.37",
         "3.14",
         "35.91",
         "205.0",
         "13.0",
         "0"
        ],
        [
         "48",
         "94301982.0",
         "0.0",
         "1.0",
         "4.0",
         "102.51",
         "4.0",
         "39.9",
         "33.08",
         "6.82",
         "35.91",
         "187.0",
         "15.0",
         "0"
        ],
        [
         "49",
         "94303078.0",
         "0.0",
         "1.0",
         "3.0",
         "105.69",
         "4.0",
         "36.6",
         "31.26",
         "5.34",
         "157.38",
         "141.0",
         "14.3",
         "1"
        ],
        [
         "50",
         "94247403.0",
         "0.0",
         "2.0",
         "4.0",
         "55.0",
         "2.0",
         "32.3",
         "29.55",
         "2.75",
         "129.2",
         "202.0",
         "12.5",
         "1"
        ],
        [
         "51",
         "92348789.0",
         "0.0",
         "1.0",
         "4.0",
         "104.0",
         "4.0",
         "41.3",
         "35.11",
         "7.43",
         "49.56",
         "177.0",
         "15.3",
         "1"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 19148
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudoid</th>\n",
       "      <th>twodaycoll</th>\n",
       "      <th>dsex</th>\n",
       "      <th>coll_age_gp</th>\n",
       "      <th>d_wt</th>\n",
       "      <th>d_bmi_grp</th>\n",
       "      <th>wbc5pre</th>\n",
       "      <th>absneut5pre</th>\n",
       "      <th>absmnc5pre</th>\n",
       "      <th>abscd34_5pre</th>\n",
       "      <th>plt5pre</th>\n",
       "      <th>hgb5pre</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93409976.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.79</td>\n",
       "      <td>2.21</td>\n",
       "      <td>11.70</td>\n",
       "      <td>136.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93370093.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>26.36</td>\n",
       "      <td>4.80</td>\n",
       "      <td>70.20</td>\n",
       "      <td>232.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93323774.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>26.46</td>\n",
       "      <td>5.04</td>\n",
       "      <td>22.05</td>\n",
       "      <td>181.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93344918.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.4</td>\n",
       "      <td>60.19</td>\n",
       "      <td>8.21</td>\n",
       "      <td>87.55</td>\n",
       "      <td>230.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93355053.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.18</td>\n",
       "      <td>7.82</td>\n",
       "      <td>51.00</td>\n",
       "      <td>278.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005</th>\n",
       "      <td>440943238.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.5</td>\n",
       "      <td>44.63</td>\n",
       "      <td>7.88</td>\n",
       "      <td>126.00</td>\n",
       "      <td>296.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006</th>\n",
       "      <td>440944836.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.93</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>31.41</td>\n",
       "      <td>4.49</td>\n",
       "      <td>61.03</td>\n",
       "      <td>191.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20007</th>\n",
       "      <td>440949006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.9</td>\n",
       "      <td>31.51</td>\n",
       "      <td>7.39</td>\n",
       "      <td>237.29</td>\n",
       "      <td>270.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20008</th>\n",
       "      <td>440956226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>22.06</td>\n",
       "      <td>6.04</td>\n",
       "      <td>70.25</td>\n",
       "      <td>195.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20009</th>\n",
       "      <td>441127927.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>46.29</td>\n",
       "      <td>6.31</td>\n",
       "      <td>120.98</td>\n",
       "      <td>294.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19148 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pseudoid  twodaycoll  dsex  coll_age_gp    d_wt  d_bmi_grp  wbc5pre  \\\n",
       "0       93409976.0         0.0   1.0          4.0   93.00        4.0     13.0   \n",
       "1       93370093.0         0.0   2.0          4.0   79.00        3.0     31.2   \n",
       "2       93323774.0         0.0   1.0          4.0  124.00        4.0     31.5   \n",
       "3       93344918.0         0.0   1.0          4.0   84.00        3.0     68.4   \n",
       "4       93355053.0         0.0   2.0          4.0   94.00        4.0     34.0   \n",
       "...            ...         ...   ...          ...     ...        ...      ...   \n",
       "20005  440943238.0         0.0   1.0          1.0   97.52        3.0     52.5   \n",
       "20006  440944836.0         0.0   1.0          1.0   78.93        2.0     35.9   \n",
       "20007  440949006.0         0.0   2.0          1.0   72.58        3.0     38.9   \n",
       "20008  440956226.0         0.0   1.0          1.0   71.67        3.0     28.1   \n",
       "20009  441127927.0         0.0   2.0          1.0   93.44        3.0     52.6   \n",
       "\n",
       "       absneut5pre  absmnc5pre  abscd34_5pre  plt5pre  hgb5pre  Count  \n",
       "0            10.79        2.21         11.70    136.0     14.4      0  \n",
       "1            26.36        4.80         70.20    232.0     12.2      1  \n",
       "2            26.46        5.04         22.05    181.0     14.9      0  \n",
       "3            60.19        8.21         87.55    230.0     15.9      1  \n",
       "4            26.18        7.82         51.00    278.0     11.7      1  \n",
       "...            ...         ...           ...      ...      ...    ...  \n",
       "20005        44.63        7.88        126.00    296.0     14.2      1  \n",
       "20006        31.41        4.49         61.03    191.0     14.8      1  \n",
       "20007        31.51        7.39        237.29    270.0     13.6      1  \n",
       "20008        22.06        6.04         70.25    195.0     14.7      1  \n",
       "20009        46.29        6.31        120.98    294.0     12.2      1  \n",
       "\n",
       "[19148 rows x 13 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd2e50cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pseudoid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dsex",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "coll_age_gp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_wt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_bmi_grp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wbc5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absneut5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absmnc5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "abscd34_5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "plt5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hgb5pre",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b1d160b4-4442-44b9-9bb8-abc342ad4f0e",
       "rows": [
        [
         "0",
         "93409976.0",
         "1.0",
         "4.0",
         "93.0",
         "4.0",
         "13.0",
         "10.79",
         "2.21",
         "11.7",
         "136.0",
         "14.4",
         "0"
        ],
        [
         "1",
         "93370093.0",
         "2.0",
         "4.0",
         "79.0",
         "3.0",
         "31.2",
         "26.36",
         "4.8",
         "70.2",
         "232.0",
         "12.2",
         "1"
        ],
        [
         "2",
         "93323774.0",
         "1.0",
         "4.0",
         "124.0",
         "4.0",
         "31.5",
         "26.46",
         "5.04",
         "22.05",
         "181.0",
         "14.9",
         "0"
        ],
        [
         "3",
         "93344918.0",
         "1.0",
         "4.0",
         "84.0",
         "3.0",
         "68.4",
         "60.19",
         "8.21",
         "87.55",
         "230.0",
         "15.9",
         "1"
        ],
        [
         "4",
         "93355053.0",
         "2.0",
         "4.0",
         "94.0",
         "4.0",
         "34.0",
         "26.18",
         "7.82",
         "51.0",
         "278.0",
         "11.7",
         "1"
        ],
        [
         "5",
         "93562560.0",
         "1.0",
         "4.0",
         "95.0",
         "3.0",
         "54.9",
         "47.21",
         "7.69",
         "76.86",
         "222.0",
         "14.3",
         "1"
        ],
        [
         "6",
         "93568857.0",
         "1.0",
         "3.0",
         "87.09",
         "3.0",
         "42.4",
         "36.04",
         "6.36",
         "106.0",
         "199.0",
         "14.6",
         "1"
        ],
        [
         "7",
         "93571163.0",
         "2.0",
         "3.0",
         "54.0",
         "2.0",
         "29.2",
         "23.07",
         "6.13",
         "37.96",
         "267.0",
         "12.1",
         "0"
        ],
        [
         "8",
         "93580161.0",
         "1.0",
         "4.0",
         "97.0",
         "3.0",
         "38.7",
         "30.19",
         "8.51",
         "46.44",
         "212.0",
         "15.2",
         "1"
        ],
        [
         "9",
         "93525333.0",
         "2.0",
         "4.0",
         "91.63",
         "4.0",
         "25.8",
         "21.98",
         "3.82",
         "67.08",
         "182.0",
         "13.7",
         "1"
        ],
        [
         "10",
         "93529830.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "43.4",
         "40.8",
         "2.6",
         "81.16",
         "244.0",
         "11.7",
         "1"
        ],
        [
         "11",
         "93530273.0",
         "1.0",
         "3.0",
         "105.23",
         "4.0",
         "33.9",
         "27.46",
         "6.44",
         "88.14",
         "135.0",
         "15.7",
         "1"
        ],
        [
         "12",
         "93538145.0",
         "1.0",
         "4.0",
         "119.75",
         "4.0",
         "41.4",
         "33.53",
         "7.87",
         "82.8",
         "168.0",
         "14.7",
         "1"
        ],
        [
         "14",
         "93544412.0",
         "1.0",
         "4.0",
         "103.63",
         "4.0",
         "35.5",
         "30.0",
         "5.5",
         "97.63",
         "207.0",
         "15.7",
         "1"
        ],
        [
         "15",
         "93469126.0",
         "1.0",
         "3.0",
         "79.0",
         "2.0",
         "25.3",
         "23.68",
         "1.62",
         "35.42",
         "131.0",
         "13.5",
         "0"
        ],
        [
         "16",
         "93677034.0",
         "1.0",
         "4.0",
         "87.0",
         "4.0",
         "28.0",
         "24.81",
         "3.19",
         "103.6",
         "189.0",
         "14.1",
         "1"
        ],
        [
         "17",
         "93629310.0",
         "2.0",
         "4.0",
         "85.0",
         "4.0",
         "62.5",
         "46.88",
         "15.63",
         "93.75",
         "316.0",
         "14.4",
         "1"
        ],
        [
         "18",
         "93650522.0",
         "1.0",
         "3.0",
         "77.27",
         "3.0",
         "61.0",
         "55.51",
         "5.49",
         "73.2",
         "176.0",
         "15.9",
         "1"
        ],
        [
         "19",
         "93609903.0",
         "1.0",
         "4.0",
         "112.49",
         "4.0",
         "52.6",
         "44.39",
         "8.21",
         "42.08",
         "223.0",
         "13.4",
         "1"
        ],
        [
         "20",
         "93611587.0",
         "1.0",
         "4.0",
         "68.0",
         "2.0",
         "33.8",
         "23.32",
         "10.48",
         "270.4",
         "328.0",
         "13.6",
         "1"
        ],
        [
         "21",
         "93612785.0",
         "1.0",
         "4.0",
         "88.0",
         "4.0",
         "42.2",
         "27.85",
         "14.35",
         "88.62",
         "200.0",
         "13.0",
         "1"
        ],
        [
         "22",
         "93828609.0",
         "1.0",
         "3.0",
         "88.0",
         "4.0",
         "46.6",
         "43.34",
         "3.26",
         "116.5",
         "216.0",
         "13.1",
         "1"
        ],
        [
         "23",
         "93770923.0",
         "1.0",
         "3.0",
         "81.0",
         "2.0",
         "43.8",
         "35.78",
         "8.02",
         "122.64",
         "211.0",
         "13.2",
         "1"
        ],
        [
         "24",
         "93722512.0",
         "1.0",
         "3.0",
         "75.45",
         "2.0",
         "28.5",
         "24.51",
         "3.99",
         "62.7",
         "185.0",
         "13.3",
         "1"
        ],
        [
         "25",
         "93961139.0",
         "2.0",
         "4.0",
         "87.0",
         "3.0",
         "32.1",
         "24.72",
         "8.35",
         "19.26",
         "275.0",
         "12.8",
         "0"
        ],
        [
         "26",
         "93902962.0",
         "2.0",
         "3.0",
         "64.41",
         "2.0",
         "43.8",
         "37.23",
         "6.57",
         "52.56",
         "239.0",
         "13.7",
         "1"
        ],
        [
         "27",
         "93912879.0",
         "2.0",
         "3.0",
         "74.84",
         "4.0",
         "23.4",
         "18.25",
         "5.15",
         "46.8",
         "205.0",
         "13.1",
         "1"
        ],
        [
         "29",
         "93855245.0",
         "1.0",
         "2.0",
         "93.63",
         "3.0",
         "47.5",
         "43.23",
         "3.66",
         "61.75",
         "189.0",
         "15.2",
         "1"
        ],
        [
         "30",
         "94086404.0",
         "2.0",
         "3.0",
         "87.0",
         "4.0",
         "46.5",
         "36.74",
         "9.77",
         "102.3",
         "214.0",
         "12.2",
         "1"
        ],
        [
         "31",
         "94101687.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "54.9",
         "47.87",
         "6.97",
         "878.4",
         "235.0",
         "16.4",
         "1"
        ],
        [
         "32",
         "94056760.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "47.9",
         "37.12",
         "10.78",
         "57.48",
         "206.0",
         "13.6",
         "1"
        ],
        [
         "33",
         "93987175.0",
         "1.0",
         "4.0",
         "96.0",
         "3.0",
         "42.6",
         "35.36",
         "7.24",
         "85.2",
         "249.0",
         "13.5",
         "1"
        ],
        [
         "34",
         "93993202.0",
         "2.0",
         "4.0",
         "90.27",
         "4.0",
         "50.7",
         "44.51",
         "6.19",
         "106.47",
         "225.0",
         "14.5",
         "1"
        ],
        [
         "35",
         "93994677.0",
         "1.0",
         "2.0",
         "105.9",
         "4.0",
         "28.9",
         "26.01",
         "2.89",
         "112.71",
         "177.0",
         "14.0",
         "1"
        ],
        [
         "36",
         "94177942.0",
         "1.0",
         "4.0",
         "69.4",
         "2.0",
         "34.4",
         "27.52",
         "6.88",
         "72.24",
         "262.0",
         "15.6",
         "1"
        ],
        [
         "37",
         "94191277.0",
         "2.0",
         "2.0",
         "54.54",
         "2.0",
         "38.4",
         "31.87",
         "6.14",
         "15.36",
         "223.0",
         "13.0",
         "0"
        ],
        [
         "38",
         "94203152.0",
         "2.0",
         "4.0",
         "69.09",
         "3.0",
         "41.5",
         "34.94",
         "6.52",
         "83.0",
         "336.0",
         "12.6",
         "1"
        ],
        [
         "39",
         "94115557.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "74.5",
         "65.41",
         "9.01",
         "298.0",
         "218.0",
         "14.8",
         "1"
        ],
        [
         "40",
         "94120876.0",
         "2.0",
         "3.0",
         "82.0",
         "4.0",
         "29.0",
         "19.72",
         "9.28",
         "26.1",
         "306.0",
         "12.5",
         "0"
        ],
        [
         "41",
         "94121628.0",
         "1.0",
         "3.0",
         "97.0",
         "4.0",
         "29.9",
         "24.82",
         "5.08",
         "110.63",
         "182.0",
         "15.4",
         "1"
        ],
        [
         "42",
         "94131849.0",
         "1.0",
         "2.0",
         "80.74",
         "2.0",
         "20.0",
         "16.2",
         "3.8",
         "49.0",
         "180.0",
         "16.8",
         "1"
        ],
        [
         "43",
         "94344490.0",
         "1.0",
         "3.0",
         "107.0",
         "4.0",
         "34.0",
         "28.9",
         "4.76",
         "102.0",
         "186.0",
         "15.2",
         "1"
        ],
        [
         "44",
         "94348239.0",
         "1.0",
         "3.0",
         "96.36",
         "3.0",
         "34.6",
         "29.76",
         "4.84",
         "76.12",
         "243.0",
         "14.9",
         "1"
        ],
        [
         "45",
         "94311317.0",
         "1.0",
         "2.0",
         "79.0",
         "2.0",
         "46.3",
         "41.81",
         "4.49",
         "64.82",
         "142.0",
         "14.9",
         "1"
        ],
        [
         "46",
         "94316721.0",
         "2.0",
         "3.0",
         "60.0",
         "2.0",
         "46.7",
         "40.07",
         "6.63",
         "77.06",
         "232.0",
         "12.5",
         "1"
        ],
        [
         "47",
         "94276724.0",
         "1.0",
         "3.0",
         "99.0",
         "4.0",
         "28.5",
         "25.37",
         "3.14",
         "35.91",
         "205.0",
         "13.0",
         "0"
        ],
        [
         "48",
         "94301982.0",
         "1.0",
         "4.0",
         "102.51",
         "4.0",
         "39.9",
         "33.08",
         "6.82",
         "35.91",
         "187.0",
         "15.0",
         "0"
        ],
        [
         "49",
         "94303078.0",
         "1.0",
         "3.0",
         "105.69",
         "4.0",
         "36.6",
         "31.26",
         "5.34",
         "157.38",
         "141.0",
         "14.3",
         "1"
        ],
        [
         "50",
         "94247403.0",
         "2.0",
         "4.0",
         "55.0",
         "2.0",
         "32.3",
         "29.55",
         "2.75",
         "129.2",
         "202.0",
         "12.5",
         "1"
        ],
        [
         "51",
         "92348789.0",
         "1.0",
         "4.0",
         "104.0",
         "4.0",
         "41.3",
         "35.11",
         "7.43",
         "49.56",
         "177.0",
         "15.3",
         "1"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 19148
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudoid</th>\n",
       "      <th>dsex</th>\n",
       "      <th>coll_age_gp</th>\n",
       "      <th>d_wt</th>\n",
       "      <th>d_bmi_grp</th>\n",
       "      <th>wbc5pre</th>\n",
       "      <th>absneut5pre</th>\n",
       "      <th>absmnc5pre</th>\n",
       "      <th>abscd34_5pre</th>\n",
       "      <th>plt5pre</th>\n",
       "      <th>hgb5pre</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93409976.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.79</td>\n",
       "      <td>2.21</td>\n",
       "      <td>11.70</td>\n",
       "      <td>136.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93370093.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>26.36</td>\n",
       "      <td>4.80</td>\n",
       "      <td>70.20</td>\n",
       "      <td>232.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93323774.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>26.46</td>\n",
       "      <td>5.04</td>\n",
       "      <td>22.05</td>\n",
       "      <td>181.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93344918.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.4</td>\n",
       "      <td>60.19</td>\n",
       "      <td>8.21</td>\n",
       "      <td>87.55</td>\n",
       "      <td>230.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93355053.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.18</td>\n",
       "      <td>7.82</td>\n",
       "      <td>51.00</td>\n",
       "      <td>278.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005</th>\n",
       "      <td>440943238.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.5</td>\n",
       "      <td>44.63</td>\n",
       "      <td>7.88</td>\n",
       "      <td>126.00</td>\n",
       "      <td>296.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006</th>\n",
       "      <td>440944836.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.93</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>31.41</td>\n",
       "      <td>4.49</td>\n",
       "      <td>61.03</td>\n",
       "      <td>191.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20007</th>\n",
       "      <td>440949006.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.9</td>\n",
       "      <td>31.51</td>\n",
       "      <td>7.39</td>\n",
       "      <td>237.29</td>\n",
       "      <td>270.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20008</th>\n",
       "      <td>440956226.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>22.06</td>\n",
       "      <td>6.04</td>\n",
       "      <td>70.25</td>\n",
       "      <td>195.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20009</th>\n",
       "      <td>441127927.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>46.29</td>\n",
       "      <td>6.31</td>\n",
       "      <td>120.98</td>\n",
       "      <td>294.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19148 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pseudoid  dsex  coll_age_gp    d_wt  d_bmi_grp  wbc5pre  \\\n",
       "0       93409976.0   1.0          4.0   93.00        4.0     13.0   \n",
       "1       93370093.0   2.0          4.0   79.00        3.0     31.2   \n",
       "2       93323774.0   1.0          4.0  124.00        4.0     31.5   \n",
       "3       93344918.0   1.0          4.0   84.00        3.0     68.4   \n",
       "4       93355053.0   2.0          4.0   94.00        4.0     34.0   \n",
       "...            ...   ...          ...     ...        ...      ...   \n",
       "20005  440943238.0   1.0          1.0   97.52        3.0     52.5   \n",
       "20006  440944836.0   1.0          1.0   78.93        2.0     35.9   \n",
       "20007  440949006.0   2.0          1.0   72.58        3.0     38.9   \n",
       "20008  440956226.0   1.0          1.0   71.67        3.0     28.1   \n",
       "20009  441127927.0   2.0          1.0   93.44        3.0     52.6   \n",
       "\n",
       "       absneut5pre  absmnc5pre  abscd34_5pre  plt5pre  hgb5pre  Count  \n",
       "0            10.79        2.21         11.70    136.0     14.4      0  \n",
       "1            26.36        4.80         70.20    232.0     12.2      1  \n",
       "2            26.46        5.04         22.05    181.0     14.9      0  \n",
       "3            60.19        8.21         87.55    230.0     15.9      1  \n",
       "4            26.18        7.82         51.00    278.0     11.7      1  \n",
       "...            ...         ...           ...      ...      ...    ...  \n",
       "20005        44.63        7.88        126.00    296.0     14.2      1  \n",
       "20006        31.41        4.49         61.03    191.0     14.8      1  \n",
       "20007        31.51        7.39        237.29    270.0     13.6      1  \n",
       "20008        22.06        6.04         70.25    195.0     14.7      1  \n",
       "20009        46.29        6.31        120.98    294.0     12.2      1  \n",
       "\n",
       "[19148 rows x 12 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df = post_df.drop(columns=['twodaycoll'])  # drop twodaycoll as they are not needed for the model\n",
    "post_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48b3e170",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df['labtype'] = 1  # add another column labtype to post_df and set it to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "651a20b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pseudoid', 'dsex', 'coll_age_gp', 'd_wt', 'd_bmi_grp', 'wbc5pre',\n",
       "       'absneut5pre', 'absmnc5pre', 'abscd34_5pre', 'plt5pre', 'hgb5pre',\n",
       "       'Count', 'labtype'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6260f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns of post_df\n",
    "post_df = post_df.rename(columns={'pseudoid': 'ID', 'dsex' : 'Gender', 'coll_age_gp' : 'Age-Group', 'd_wt' : 'Weight',\n",
    "         'wbc5pre' : 'WBC', 'plt5pre' :'Platelet', 'hgb5pre' : 'HGB', 'd_bmi_grp': 'BMI Group',\n",
    "         'absneut5pre' : 'Neut Abs', 'absmnc5pre' : 'MNC Abs', 'abscd34_5pre' : 'CD34 Abs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "216a0fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Gender",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age-Group",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Weight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BMI Group",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WBC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Neut Abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MNC Abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CD34 Abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Platelet",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HGB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "labtype",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "93b4f588-543b-4c1a-abe9-40cd952ebc6b",
       "rows": [
        [
         "0",
         "93409976.0",
         "1.0",
         "4.0",
         "93.0",
         "4.0",
         "13.0",
         "10.79",
         "2.21",
         "11.7",
         "136.0",
         "14.4",
         "0",
         "1"
        ],
        [
         "1",
         "93370093.0",
         "2.0",
         "4.0",
         "79.0",
         "3.0",
         "31.2",
         "26.36",
         "4.8",
         "70.2",
         "232.0",
         "12.2",
         "1",
         "1"
        ],
        [
         "2",
         "93323774.0",
         "1.0",
         "4.0",
         "124.0",
         "4.0",
         "31.5",
         "26.46",
         "5.04",
         "22.05",
         "181.0",
         "14.9",
         "0",
         "1"
        ],
        [
         "3",
         "93344918.0",
         "1.0",
         "4.0",
         "84.0",
         "3.0",
         "68.4",
         "60.19",
         "8.21",
         "87.55",
         "230.0",
         "15.9",
         "1",
         "1"
        ],
        [
         "4",
         "93355053.0",
         "2.0",
         "4.0",
         "94.0",
         "4.0",
         "34.0",
         "26.18",
         "7.82",
         "51.0",
         "278.0",
         "11.7",
         "1",
         "1"
        ],
        [
         "5",
         "93562560.0",
         "1.0",
         "4.0",
         "95.0",
         "3.0",
         "54.9",
         "47.21",
         "7.69",
         "76.86",
         "222.0",
         "14.3",
         "1",
         "1"
        ],
        [
         "6",
         "93568857.0",
         "1.0",
         "3.0",
         "87.09",
         "3.0",
         "42.4",
         "36.04",
         "6.36",
         "106.0",
         "199.0",
         "14.6",
         "1",
         "1"
        ],
        [
         "7",
         "93571163.0",
         "2.0",
         "3.0",
         "54.0",
         "2.0",
         "29.2",
         "23.07",
         "6.13",
         "37.96",
         "267.0",
         "12.1",
         "0",
         "1"
        ],
        [
         "8",
         "93580161.0",
         "1.0",
         "4.0",
         "97.0",
         "3.0",
         "38.7",
         "30.19",
         "8.51",
         "46.44",
         "212.0",
         "15.2",
         "1",
         "1"
        ],
        [
         "9",
         "93525333.0",
         "2.0",
         "4.0",
         "91.63",
         "4.0",
         "25.8",
         "21.98",
         "3.82",
         "67.08",
         "182.0",
         "13.7",
         "1",
         "1"
        ],
        [
         "10",
         "93529830.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "43.4",
         "40.8",
         "2.6",
         "81.16",
         "244.0",
         "11.7",
         "1",
         "1"
        ],
        [
         "11",
         "93530273.0",
         "1.0",
         "3.0",
         "105.23",
         "4.0",
         "33.9",
         "27.46",
         "6.44",
         "88.14",
         "135.0",
         "15.7",
         "1",
         "1"
        ],
        [
         "12",
         "93538145.0",
         "1.0",
         "4.0",
         "119.75",
         "4.0",
         "41.4",
         "33.53",
         "7.87",
         "82.8",
         "168.0",
         "14.7",
         "1",
         "1"
        ],
        [
         "14",
         "93544412.0",
         "1.0",
         "4.0",
         "103.63",
         "4.0",
         "35.5",
         "30.0",
         "5.5",
         "97.63",
         "207.0",
         "15.7",
         "1",
         "1"
        ],
        [
         "15",
         "93469126.0",
         "1.0",
         "3.0",
         "79.0",
         "2.0",
         "25.3",
         "23.68",
         "1.62",
         "35.42",
         "131.0",
         "13.5",
         "0",
         "1"
        ],
        [
         "16",
         "93677034.0",
         "1.0",
         "4.0",
         "87.0",
         "4.0",
         "28.0",
         "24.81",
         "3.19",
         "103.6",
         "189.0",
         "14.1",
         "1",
         "1"
        ],
        [
         "17",
         "93629310.0",
         "2.0",
         "4.0",
         "85.0",
         "4.0",
         "62.5",
         "46.88",
         "15.63",
         "93.75",
         "316.0",
         "14.4",
         "1",
         "1"
        ],
        [
         "18",
         "93650522.0",
         "1.0",
         "3.0",
         "77.27",
         "3.0",
         "61.0",
         "55.51",
         "5.49",
         "73.2",
         "176.0",
         "15.9",
         "1",
         "1"
        ],
        [
         "19",
         "93609903.0",
         "1.0",
         "4.0",
         "112.49",
         "4.0",
         "52.6",
         "44.39",
         "8.21",
         "42.08",
         "223.0",
         "13.4",
         "1",
         "1"
        ],
        [
         "20",
         "93611587.0",
         "1.0",
         "4.0",
         "68.0",
         "2.0",
         "33.8",
         "23.32",
         "10.48",
         "270.4",
         "328.0",
         "13.6",
         "1",
         "1"
        ],
        [
         "21",
         "93612785.0",
         "1.0",
         "4.0",
         "88.0",
         "4.0",
         "42.2",
         "27.85",
         "14.35",
         "88.62",
         "200.0",
         "13.0",
         "1",
         "1"
        ],
        [
         "22",
         "93828609.0",
         "1.0",
         "3.0",
         "88.0",
         "4.0",
         "46.6",
         "43.34",
         "3.26",
         "116.5",
         "216.0",
         "13.1",
         "1",
         "1"
        ],
        [
         "23",
         "93770923.0",
         "1.0",
         "3.0",
         "81.0",
         "2.0",
         "43.8",
         "35.78",
         "8.02",
         "122.64",
         "211.0",
         "13.2",
         "1",
         "1"
        ],
        [
         "24",
         "93722512.0",
         "1.0",
         "3.0",
         "75.45",
         "2.0",
         "28.5",
         "24.51",
         "3.99",
         "62.7",
         "185.0",
         "13.3",
         "1",
         "1"
        ],
        [
         "25",
         "93961139.0",
         "2.0",
         "4.0",
         "87.0",
         "3.0",
         "32.1",
         "24.72",
         "8.35",
         "19.26",
         "275.0",
         "12.8",
         "0",
         "1"
        ],
        [
         "26",
         "93902962.0",
         "2.0",
         "3.0",
         "64.41",
         "2.0",
         "43.8",
         "37.23",
         "6.57",
         "52.56",
         "239.0",
         "13.7",
         "1",
         "1"
        ],
        [
         "27",
         "93912879.0",
         "2.0",
         "3.0",
         "74.84",
         "4.0",
         "23.4",
         "18.25",
         "5.15",
         "46.8",
         "205.0",
         "13.1",
         "1",
         "1"
        ],
        [
         "29",
         "93855245.0",
         "1.0",
         "2.0",
         "93.63",
         "3.0",
         "47.5",
         "43.23",
         "3.66",
         "61.75",
         "189.0",
         "15.2",
         "1",
         "1"
        ],
        [
         "30",
         "94086404.0",
         "2.0",
         "3.0",
         "87.0",
         "4.0",
         "46.5",
         "36.74",
         "9.77",
         "102.3",
         "214.0",
         "12.2",
         "1",
         "1"
        ],
        [
         "31",
         "94101687.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "54.9",
         "47.87",
         "6.97",
         "878.4",
         "235.0",
         "16.4",
         "1",
         "1"
        ],
        [
         "32",
         "94056760.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "47.9",
         "37.12",
         "10.78",
         "57.48",
         "206.0",
         "13.6",
         "1",
         "1"
        ],
        [
         "33",
         "93987175.0",
         "1.0",
         "4.0",
         "96.0",
         "3.0",
         "42.6",
         "35.36",
         "7.24",
         "85.2",
         "249.0",
         "13.5",
         "1",
         "1"
        ],
        [
         "34",
         "93993202.0",
         "2.0",
         "4.0",
         "90.27",
         "4.0",
         "50.7",
         "44.51",
         "6.19",
         "106.47",
         "225.0",
         "14.5",
         "1",
         "1"
        ],
        [
         "35",
         "93994677.0",
         "1.0",
         "2.0",
         "105.9",
         "4.0",
         "28.9",
         "26.01",
         "2.89",
         "112.71",
         "177.0",
         "14.0",
         "1",
         "1"
        ],
        [
         "36",
         "94177942.0",
         "1.0",
         "4.0",
         "69.4",
         "2.0",
         "34.4",
         "27.52",
         "6.88",
         "72.24",
         "262.0",
         "15.6",
         "1",
         "1"
        ],
        [
         "37",
         "94191277.0",
         "2.0",
         "2.0",
         "54.54",
         "2.0",
         "38.4",
         "31.87",
         "6.14",
         "15.36",
         "223.0",
         "13.0",
         "0",
         "1"
        ],
        [
         "38",
         "94203152.0",
         "2.0",
         "4.0",
         "69.09",
         "3.0",
         "41.5",
         "34.94",
         "6.52",
         "83.0",
         "336.0",
         "12.6",
         "1",
         "1"
        ],
        [
         "39",
         "94115557.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "74.5",
         "65.41",
         "9.01",
         "298.0",
         "218.0",
         "14.8",
         "1",
         "1"
        ],
        [
         "40",
         "94120876.0",
         "2.0",
         "3.0",
         "82.0",
         "4.0",
         "29.0",
         "19.72",
         "9.28",
         "26.1",
         "306.0",
         "12.5",
         "0",
         "1"
        ],
        [
         "41",
         "94121628.0",
         "1.0",
         "3.0",
         "97.0",
         "4.0",
         "29.9",
         "24.82",
         "5.08",
         "110.63",
         "182.0",
         "15.4",
         "1",
         "1"
        ],
        [
         "42",
         "94131849.0",
         "1.0",
         "2.0",
         "80.74",
         "2.0",
         "20.0",
         "16.2",
         "3.8",
         "49.0",
         "180.0",
         "16.8",
         "1",
         "1"
        ],
        [
         "43",
         "94344490.0",
         "1.0",
         "3.0",
         "107.0",
         "4.0",
         "34.0",
         "28.9",
         "4.76",
         "102.0",
         "186.0",
         "15.2",
         "1",
         "1"
        ],
        [
         "44",
         "94348239.0",
         "1.0",
         "3.0",
         "96.36",
         "3.0",
         "34.6",
         "29.76",
         "4.84",
         "76.12",
         "243.0",
         "14.9",
         "1",
         "1"
        ],
        [
         "45",
         "94311317.0",
         "1.0",
         "2.0",
         "79.0",
         "2.0",
         "46.3",
         "41.81",
         "4.49",
         "64.82",
         "142.0",
         "14.9",
         "1",
         "1"
        ],
        [
         "46",
         "94316721.0",
         "2.0",
         "3.0",
         "60.0",
         "2.0",
         "46.7",
         "40.07",
         "6.63",
         "77.06",
         "232.0",
         "12.5",
         "1",
         "1"
        ],
        [
         "47",
         "94276724.0",
         "1.0",
         "3.0",
         "99.0",
         "4.0",
         "28.5",
         "25.37",
         "3.14",
         "35.91",
         "205.0",
         "13.0",
         "0",
         "1"
        ],
        [
         "48",
         "94301982.0",
         "1.0",
         "4.0",
         "102.51",
         "4.0",
         "39.9",
         "33.08",
         "6.82",
         "35.91",
         "187.0",
         "15.0",
         "0",
         "1"
        ],
        [
         "49",
         "94303078.0",
         "1.0",
         "3.0",
         "105.69",
         "4.0",
         "36.6",
         "31.26",
         "5.34",
         "157.38",
         "141.0",
         "14.3",
         "1",
         "1"
        ],
        [
         "50",
         "94247403.0",
         "2.0",
         "4.0",
         "55.0",
         "2.0",
         "32.3",
         "29.55",
         "2.75",
         "129.2",
         "202.0",
         "12.5",
         "1",
         "1"
        ],
        [
         "51",
         "92348789.0",
         "1.0",
         "4.0",
         "104.0",
         "4.0",
         "41.3",
         "35.11",
         "7.43",
         "49.56",
         "177.0",
         "15.3",
         "1",
         "1"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 19148
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age-Group</th>\n",
       "      <th>Weight</th>\n",
       "      <th>BMI Group</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Neut Abs</th>\n",
       "      <th>MNC Abs</th>\n",
       "      <th>CD34 Abs</th>\n",
       "      <th>Platelet</th>\n",
       "      <th>HGB</th>\n",
       "      <th>Count</th>\n",
       "      <th>labtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93409976.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.79</td>\n",
       "      <td>2.21</td>\n",
       "      <td>11.70</td>\n",
       "      <td>136.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93370093.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>26.36</td>\n",
       "      <td>4.80</td>\n",
       "      <td>70.20</td>\n",
       "      <td>232.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93323774.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>26.46</td>\n",
       "      <td>5.04</td>\n",
       "      <td>22.05</td>\n",
       "      <td>181.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93344918.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.4</td>\n",
       "      <td>60.19</td>\n",
       "      <td>8.21</td>\n",
       "      <td>87.55</td>\n",
       "      <td>230.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93355053.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.18</td>\n",
       "      <td>7.82</td>\n",
       "      <td>51.00</td>\n",
       "      <td>278.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005</th>\n",
       "      <td>440943238.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.5</td>\n",
       "      <td>44.63</td>\n",
       "      <td>7.88</td>\n",
       "      <td>126.00</td>\n",
       "      <td>296.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006</th>\n",
       "      <td>440944836.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.93</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>31.41</td>\n",
       "      <td>4.49</td>\n",
       "      <td>61.03</td>\n",
       "      <td>191.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20007</th>\n",
       "      <td>440949006.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.9</td>\n",
       "      <td>31.51</td>\n",
       "      <td>7.39</td>\n",
       "      <td>237.29</td>\n",
       "      <td>270.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20008</th>\n",
       "      <td>440956226.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>22.06</td>\n",
       "      <td>6.04</td>\n",
       "      <td>70.25</td>\n",
       "      <td>195.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20009</th>\n",
       "      <td>441127927.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>46.29</td>\n",
       "      <td>6.31</td>\n",
       "      <td>120.98</td>\n",
       "      <td>294.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19148 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  Gender  Age-Group  Weight  BMI Group   WBC  Neut Abs  \\\n",
       "0       93409976.0     1.0        4.0   93.00        4.0  13.0     10.79   \n",
       "1       93370093.0     2.0        4.0   79.00        3.0  31.2     26.36   \n",
       "2       93323774.0     1.0        4.0  124.00        4.0  31.5     26.46   \n",
       "3       93344918.0     1.0        4.0   84.00        3.0  68.4     60.19   \n",
       "4       93355053.0     2.0        4.0   94.00        4.0  34.0     26.18   \n",
       "...            ...     ...        ...     ...        ...   ...       ...   \n",
       "20005  440943238.0     1.0        1.0   97.52        3.0  52.5     44.63   \n",
       "20006  440944836.0     1.0        1.0   78.93        2.0  35.9     31.41   \n",
       "20007  440949006.0     2.0        1.0   72.58        3.0  38.9     31.51   \n",
       "20008  440956226.0     1.0        1.0   71.67        3.0  28.1     22.06   \n",
       "20009  441127927.0     2.0        1.0   93.44        3.0  52.6     46.29   \n",
       "\n",
       "       MNC Abs  CD34 Abs  Platelet   HGB  Count  labtype  \n",
       "0         2.21     11.70     136.0  14.4      0        1  \n",
       "1         4.80     70.20     232.0  12.2      1        1  \n",
       "2         5.04     22.05     181.0  14.9      0        1  \n",
       "3         8.21     87.55     230.0  15.9      1        1  \n",
       "4         7.82     51.00     278.0  11.7      1        1  \n",
       "...        ...       ...       ...   ...    ...      ...  \n",
       "20005     7.88    126.00     296.0  14.2      1        1  \n",
       "20006     4.49     61.03     191.0  14.8      1        1  \n",
       "20007     7.39    237.29     270.0  13.6      1        1  \n",
       "20008     6.04     70.25     195.0  14.7      1        1  \n",
       "20009     6.31    120.98     294.0  12.2      1        1  \n",
       "\n",
       "[19148 rows x 13 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d86dbad",
   "metadata": {},
   "source": [
    "#### Concatenating the pre and post dataframes\n",
    "we concatenate the pre and post dataframes to create a single dataframe that contains all the relevant information for both pre and post G-CSF mobilization. This allows us to analyze the data in a unified manner, making it easier to compare the effects of G-CSF on the donors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf838cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of Pre-G-csf:\n",
      " Index(['ID', 'Gender', 'Age-Group', 'Weight', 'BMI Group', 'WBC', 'Platelet',\n",
      "       'HGB', 'Neut Abs', 'MNC Abs', 'CD34 Abs', 'Count', 'labtype'],\n",
      "      dtype='object')\n",
      "Columns of Post-G-csf:\n",
      " Index(['ID', 'Gender', 'Age-Group', 'Weight', 'BMI Group', 'WBC', 'Neut Abs',\n",
      "       'MNC Abs', 'CD34 Abs', 'Platelet', 'HGB', 'Count', 'labtype'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(f'Columns of Pre-G-csf:\\n', pre_df.columns)\n",
    "print(f'Columns of Post-G-csf:\\n', post_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "735b58e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Gender",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age-Group",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Weight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BMI Group",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WBC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Platelet",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HGB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Neut Abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MNC Abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CD34 Abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "labtype",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "75ae3201-6cf9-48d0-a0ad-aa6d2ed6cfd9",
       "rows": [
        [
         "0",
         "93409976.0",
         "1.0",
         "4.0",
         "93.0",
         "4.0",
         "3.8",
         "159.0",
         "15.5",
         "2.24",
         "1.56",
         "11.7",
         "0",
         "0"
        ],
        [
         "1",
         "93370093.0",
         "2.0",
         "4.0",
         "79.0",
         "3.0",
         "5.5",
         "218.0",
         "13.2",
         "3.0",
         "2.49",
         "70.2",
         "1",
         "0"
        ],
        [
         "2",
         "93323774.0",
         "1.0",
         "4.0",
         "124.0",
         "4.0",
         "6.1",
         "175.0",
         "15.0",
         "3.23",
         "2.87",
         "22.05",
         "0",
         "0"
        ],
        [
         "3",
         "93344918.0",
         "1.0",
         "4.0",
         "84.0",
         "3.0",
         "8.0",
         "280.0",
         "15.4",
         "5.04",
         "2.96",
         "87.55",
         "1",
         "0"
        ],
        [
         "4",
         "93355053.0",
         "2.0",
         "4.0",
         "94.0",
         "4.0",
         "8.1",
         "351.0",
         "13.2",
         "4.94",
         "3.16",
         "51.0",
         "1",
         "0"
        ],
        [
         "5",
         "93562560.0",
         "1.0",
         "4.0",
         "95.0",
         "3.0",
         "4.2",
         "299.0",
         "16.1",
         "2.18",
         "2.02",
         "76.86",
         "1",
         "0"
        ],
        [
         "6",
         "93568857.0",
         "1.0",
         "3.0",
         "87.09",
         "3.0",
         "7.1",
         "256.0",
         "16.2",
         "4.54",
         "2.56",
         "106.0",
         "1",
         "0"
        ],
        [
         "7",
         "93571163.0",
         "2.0",
         "3.0",
         "54.0",
         "2.0",
         "5.4",
         "244.0",
         "12.9",
         "3.35",
         "2.05",
         "37.96",
         "0",
         "0"
        ],
        [
         "8",
         "93580161.0",
         "1.0",
         "4.0",
         "97.0",
         "3.0",
         "5.5",
         "188.0",
         "15.7",
         "3.41",
         "2.09",
         "46.44",
         "1",
         "0"
        ],
        [
         "9",
         "93525333.0",
         "2.0",
         "4.0",
         "91.63",
         "4.0",
         "5.8",
         "247.0",
         "13.9",
         "3.71",
         "2.09",
         "67.08",
         "1",
         "0"
        ],
        [
         "10",
         "93529830.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "10.3",
         "425.0",
         "12.5",
         "7.27",
         "3.03",
         "81.16",
         "1",
         "0"
        ],
        [
         "11",
         "93530273.0",
         "1.0",
         "3.0",
         "105.23",
         "4.0",
         "5.3",
         "188.0",
         "15.4",
         "3.13",
         "2.17",
         "88.14",
         "1",
         "0"
        ],
        [
         "12",
         "93538145.0",
         "1.0",
         "4.0",
         "119.75",
         "4.0",
         "6.6",
         "192.0",
         "14.2",
         "4.09",
         "2.51",
         "82.8",
         "1",
         "0"
        ],
        [
         "13",
         "93544412.0",
         "1.0",
         "4.0",
         "103.63",
         "4.0",
         "5.6",
         "238.0",
         "17.0",
         "3.26",
         "2.34",
         "97.63",
         "1",
         "0"
        ],
        [
         "14",
         "93469126.0",
         "1.0",
         "3.0",
         "79.0",
         "2.0",
         "5.6",
         "204.0",
         "14.0",
         "3.75",
         "1.85",
         "35.42",
         "0",
         "0"
        ],
        [
         "15",
         "93677034.0",
         "1.0",
         "4.0",
         "87.0",
         "4.0",
         "5.5",
         "173.0",
         "14.2",
         "4.03",
         "1.47",
         "103.6",
         "1",
         "0"
        ],
        [
         "16",
         "93629310.0",
         "2.0",
         "4.0",
         "85.0",
         "4.0",
         "10.8",
         "398.0",
         "15.3",
         "7.48",
         "3.3",
         "93.75",
         "1",
         "0"
        ],
        [
         "17",
         "93650522.0",
         "1.0",
         "3.0",
         "77.27",
         "3.0",
         "5.6",
         "191.0",
         "17.1",
         "3.98",
         "1.62",
         "73.2",
         "1",
         "0"
        ],
        [
         "18",
         "93609903.0",
         "1.0",
         "4.0",
         "112.49",
         "4.0",
         "6.2",
         "198.0",
         "15.2",
         "3.97",
         "2.17",
         "42.08",
         "1",
         "0"
        ],
        [
         "19",
         "93611587.0",
         "1.0",
         "4.0",
         "68.0",
         "2.0",
         "8.2",
         "343.0",
         "14.0",
         "5.17",
         "2.87",
         "270.4",
         "1",
         "0"
        ],
        [
         "20",
         "93612785.0",
         "1.0",
         "4.0",
         "88.0",
         "4.0",
         "8.6",
         "201.0",
         "16.0",
         "6.71",
         "1.89",
         "88.62",
         "1",
         "0"
        ],
        [
         "21",
         "93828609.0",
         "1.0",
         "3.0",
         "88.0",
         "4.0",
         "6.1",
         "207.0",
         "13.0",
         "3.89",
         "2.21",
         "116.5",
         "1",
         "0"
        ],
        [
         "22",
         "93770923.0",
         "1.0",
         "3.0",
         "81.0",
         "2.0",
         "7.8",
         "247.0",
         "14.6",
         "4.24",
         "3.51",
         "122.64",
         "1",
         "0"
        ],
        [
         "23",
         "93722512.0",
         "1.0",
         "3.0",
         "75.45",
         "2.0",
         "5.3",
         "196.0",
         "14.6",
         "3.13",
         "2.17",
         "62.7",
         "1",
         "0"
        ],
        [
         "24",
         "93961139.0",
         "2.0",
         "4.0",
         "87.0",
         "3.0",
         "7.8",
         "287.0",
         "13.8",
         "4.98",
         "2.82",
         "19.26",
         "0",
         "0"
        ],
        [
         "25",
         "93902962.0",
         "2.0",
         "3.0",
         "64.41",
         "2.0",
         "6.0",
         "232.0",
         "13.9",
         "4.44",
         "1.56",
         "52.56",
         "1",
         "0"
        ],
        [
         "26",
         "93912879.0",
         "2.0",
         "3.0",
         "74.84",
         "4.0",
         "6.7",
         "252.0",
         "13.3",
         "4.22",
         "2.41",
         "46.8",
         "1",
         "0"
        ],
        [
         "27",
         "93855245.0",
         "1.0",
         "2.0",
         "93.63",
         "3.0",
         "7.5",
         "191.0",
         "16.7",
         "5.92",
         "1.5",
         "61.75",
         "1",
         "0"
        ],
        [
         "28",
         "94086404.0",
         "2.0",
         "3.0",
         "87.0",
         "4.0",
         "6.3",
         "251.0",
         "13.7",
         "3.53",
         "2.77",
         "102.3",
         "1",
         "0"
        ],
        [
         "29",
         "94101687.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "5.9",
         "286.0",
         "16.3",
         "4.08",
         "1.82",
         "878.4",
         "1",
         "0"
        ],
        [
         "30",
         "94056760.0",
         "2.0",
         "4.0",
         "66.0",
         "2.0",
         "6.7",
         "271.0",
         "13.6",
         "3.73",
         "2.97",
         "57.48",
         "1",
         "0"
        ],
        [
         "31",
         "93987175.0",
         "1.0",
         "4.0",
         "96.0",
         "3.0",
         "7.5",
         "318.0",
         "14.5",
         "5.28",
         "2.23",
         "85.2",
         "1",
         "0"
        ],
        [
         "32",
         "93993202.0",
         "2.0",
         "4.0",
         "90.27",
         "4.0",
         "5.7",
         "217.0",
         "14.1",
         "3.31",
         "2.39",
         "106.47",
         "1",
         "0"
        ],
        [
         "33",
         "93994677.0",
         "1.0",
         "2.0",
         "105.9",
         "4.0",
         "5.4",
         "273.0",
         "15.1",
         "3.62",
         "1.78",
         "112.71",
         "1",
         "0"
        ],
        [
         "34",
         "94177942.0",
         "1.0",
         "4.0",
         "69.4",
         "2.0",
         "7.6",
         "275.0",
         "16.2",
         "6.22",
         "1.38",
         "72.24",
         "1",
         "0"
        ],
        [
         "35",
         "94191277.0",
         "2.0",
         "2.0",
         "54.54",
         "2.0",
         "8.4",
         "208.0",
         "13.0",
         "6.47",
         "1.93",
         "15.36",
         "0",
         "0"
        ],
        [
         "36",
         "94203152.0",
         "2.0",
         "4.0",
         "69.09",
         "3.0",
         "4.3",
         "383.0",
         "13.5",
         "2.55",
         "1.75",
         "83.0",
         "1",
         "0"
        ],
        [
         "37",
         "94115557.0",
         "1.0",
         "4.0",
         "75.0",
         "3.0",
         "7.2",
         "204.0",
         "14.4",
         "4.82",
         "2.38",
         "298.0",
         "1",
         "0"
        ],
        [
         "38",
         "94120876.0",
         "2.0",
         "3.0",
         "82.0",
         "4.0",
         "10.1",
         "359.0",
         "14.4",
         "6.46",
         "3.64",
         "26.1",
         "0",
         "0"
        ],
        [
         "39",
         "94121628.0",
         "1.0",
         "3.0",
         "97.0",
         "4.0",
         "4.8",
         "183.0",
         "15.4",
         "3.41",
         "1.39",
         "110.63",
         "1",
         "0"
        ],
        [
         "40",
         "94131849.0",
         "1.0",
         "2.0",
         "80.74",
         "2.0",
         "4.6",
         "186.0",
         "16.5",
         "3.12",
         "1.48",
         "49.0",
         "1",
         "0"
        ],
        [
         "41",
         "94344490.0",
         "1.0",
         "3.0",
         "107.0",
         "4.0",
         "4.9",
         "206.0",
         "15.2",
         "2.97",
         "1.92",
         "102.0",
         "1",
         "0"
        ],
        [
         "42",
         "94348239.0",
         "1.0",
         "3.0",
         "96.36",
         "3.0",
         "5.3",
         "262.0",
         "15.3",
         "3.02",
         "2.28",
         "76.12",
         "1",
         "0"
        ],
        [
         "43",
         "94311317.0",
         "1.0",
         "2.0",
         "79.0",
         "2.0",
         "5.6",
         "173.0",
         "16.4",
         "3.86",
         "1.74",
         "64.82",
         "1",
         "0"
        ],
        [
         "44",
         "94316721.0",
         "2.0",
         "3.0",
         "60.0",
         "2.0",
         "5.0",
         "259.0",
         "11.9",
         "3.0",
         "1.99",
         "77.06",
         "1",
         "0"
        ],
        [
         "45",
         "94276724.0",
         "1.0",
         "3.0",
         "99.0",
         "4.0",
         "4.9",
         "199.0",
         "13.7",
         "2.7",
         "2.21",
         "35.91",
         "0",
         "0"
        ],
        [
         "46",
         "94301982.0",
         "1.0",
         "4.0",
         "102.51",
         "4.0",
         "6.5",
         "166.0",
         "15.7",
         "4.63",
         "1.87",
         "35.91",
         "0",
         "0"
        ],
        [
         "47",
         "94303078.0",
         "1.0",
         "3.0",
         "105.69",
         "4.0",
         "6.2",
         "178.0",
         "15.3",
         "3.7",
         "2.5",
         "157.38",
         "1",
         "0"
        ],
        [
         "48",
         "94247403.0",
         "2.0",
         "4.0",
         "55.0",
         "2.0",
         "6.4",
         "224.0",
         "13.7",
         "4.03",
         "2.36",
         "129.2",
         "1",
         "0"
        ],
        [
         "49",
         "92348789.0",
         "1.0",
         "4.0",
         "104.0",
         "4.0",
         "10.1",
         "197.0",
         "16.3",
         "6.27",
         "3.8",
         "49.56",
         "1",
         "0"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 38355
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age-Group</th>\n",
       "      <th>Weight</th>\n",
       "      <th>BMI Group</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Platelet</th>\n",
       "      <th>HGB</th>\n",
       "      <th>Neut Abs</th>\n",
       "      <th>MNC Abs</th>\n",
       "      <th>CD34 Abs</th>\n",
       "      <th>Count</th>\n",
       "      <th>labtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93409976.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>159.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.56</td>\n",
       "      <td>11.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93370093.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>218.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.49</td>\n",
       "      <td>70.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93323774.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>175.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.87</td>\n",
       "      <td>22.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93344918.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>5.04</td>\n",
       "      <td>2.96</td>\n",
       "      <td>87.55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93355053.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>351.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3.16</td>\n",
       "      <td>51.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38350</th>\n",
       "      <td>440943238.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.5</td>\n",
       "      <td>296.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>44.63</td>\n",
       "      <td>7.88</td>\n",
       "      <td>126.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38351</th>\n",
       "      <td>440944836.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.93</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>191.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>31.41</td>\n",
       "      <td>4.49</td>\n",
       "      <td>61.03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38352</th>\n",
       "      <td>440949006.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.9</td>\n",
       "      <td>270.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>31.51</td>\n",
       "      <td>7.39</td>\n",
       "      <td>237.29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38353</th>\n",
       "      <td>440956226.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>195.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>22.06</td>\n",
       "      <td>6.04</td>\n",
       "      <td>70.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38354</th>\n",
       "      <td>441127927.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>294.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>46.29</td>\n",
       "      <td>6.31</td>\n",
       "      <td>120.98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38355 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  Gender  Age-Group  Weight  BMI Group   WBC  Platelet  \\\n",
       "0       93409976.0     1.0        4.0   93.00        4.0   3.8     159.0   \n",
       "1       93370093.0     2.0        4.0   79.00        3.0   5.5     218.0   \n",
       "2       93323774.0     1.0        4.0  124.00        4.0   6.1     175.0   \n",
       "3       93344918.0     1.0        4.0   84.00        3.0   8.0     280.0   \n",
       "4       93355053.0     2.0        4.0   94.00        4.0   8.1     351.0   \n",
       "...            ...     ...        ...     ...        ...   ...       ...   \n",
       "38350  440943238.0     1.0        1.0   97.52        3.0  52.5     296.0   \n",
       "38351  440944836.0     1.0        1.0   78.93        2.0  35.9     191.0   \n",
       "38352  440949006.0     2.0        1.0   72.58        3.0  38.9     270.0   \n",
       "38353  440956226.0     1.0        1.0   71.67        3.0  28.1     195.0   \n",
       "38354  441127927.0     2.0        1.0   93.44        3.0  52.6     294.0   \n",
       "\n",
       "        HGB  Neut Abs  MNC Abs  CD34 Abs  Count  labtype  \n",
       "0      15.5      2.24     1.56     11.70      0        0  \n",
       "1      13.2      3.00     2.49     70.20      1        0  \n",
       "2      15.0      3.23     2.87     22.05      0        0  \n",
       "3      15.4      5.04     2.96     87.55      1        0  \n",
       "4      13.2      4.94     3.16     51.00      1        0  \n",
       "...     ...       ...      ...       ...    ...      ...  \n",
       "38350  14.2     44.63     7.88    126.00      1        1  \n",
       "38351  14.8     31.41     4.49     61.03      1        1  \n",
       "38352  13.6     31.51     7.39    237.29      1        1  \n",
       "38353  14.7     22.06     6.04     70.25      1        1  \n",
       "38354  12.2     46.29     6.31    120.98      1        1  \n",
       "\n",
       "[38355 rows x 13 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = pd.concat([pre_df, post_df], ignore_index=True)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1e7fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4a14092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the combined dataframe to a csv file\n",
    "df_combined.to_csv(here() / config.data / 'interim'  / 'cibmtr_prepost_unnormalized_weight.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aefd42ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count\n",
      "1    33774\n",
      "0     4581\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the count of each class in the Count column\n",
    "print(df_combined['Count'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceaaeb7",
   "metadata": {},
   "source": [
    "# Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a59eeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = pd.read_csv(here() / config.data / 'interim'  / 'cibmtr_prepost_unnormalized_weight.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cf2777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change age group to categorical\n",
    "dataset['Age-Group'] = dataset['Age-Group'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5fcc677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move labtype to the 3rd column\n",
    "cols = dataset.columns.tolist()\n",
    "cols.insert(2, cols.pop(cols.index('labtype')))\n",
    "dataset = dataset[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ef40dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['CD34 Abs'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2c9c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one-hot encoding for categorical variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "categorical_cols = ['Age-Group', 'BMI Group',]\n",
    "\n",
    "# fit the encoder on the categorical columns\n",
    "encoder.fit(dataset[categorical_cols])\n",
    "# transform the categorical columns\n",
    "encoded_cols = encoder.transform(dataset[categorical_cols])\n",
    "# create a new dataframe with the encoded columns\n",
    "encoded_df = pd.DataFrame(encoded_cols, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "# drop the original categorical columns\n",
    "dataset = dataset.drop(columns=categorical_cols)\n",
    "# concatenate the encoded columns with the original dataframe\n",
    "dataset = pd.concat([dataset, encoded_df], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e7c4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Neut Pct \n",
    "# calculate Neut Pct as Neut Abs / WBC * 100\n",
    "dataset['Neut Pct'] = dataset['Neut Abs'] / dataset['WBC'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8bc4f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the dataset to a csv file\n",
    "# dataset.to_csv(here() / config.data / 'interim'  / 'cibmtr_prepost_normalized_wt_bmi_neut.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904f6f1a",
   "metadata": {},
   "source": [
    "# Model Preparation starts from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0b962a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Gender",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "labtype",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Weight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WBC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Platelet",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HGB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Neut Abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MNC Abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Age-Group_1.0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age-Group_2.0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age-Group_3.0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age-Group_4.0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BMI Group_1.0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BMI Group_2.0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BMI Group_3.0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BMI Group_4.0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Neut Pct",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c4495842-ad4d-46bf-8591-1b90dada1485",
       "rows": [
        [
         "0",
         "1.0",
         "0",
         "93.0",
         "3.8",
         "159.0",
         "15.5",
         "2.24",
         "1.56",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "58.94736842105264"
        ],
        [
         "1",
         "2.0",
         "0",
         "79.0",
         "5.5",
         "218.0",
         "13.2",
         "3.0",
         "2.49",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "54.54545454545454"
        ],
        [
         "2",
         "1.0",
         "0",
         "124.0",
         "6.1",
         "175.0",
         "15.0",
         "3.23",
         "2.87",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "52.95081967213115"
        ],
        [
         "3",
         "1.0",
         "0",
         "84.0",
         "8.0",
         "280.0",
         "15.4",
         "5.04",
         "2.96",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "63.0"
        ],
        [
         "4",
         "2.0",
         "0",
         "94.0",
         "8.1",
         "351.0",
         "13.2",
         "4.94",
         "3.16",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "60.98765432098766"
        ],
        [
         "5",
         "1.0",
         "0",
         "95.0",
         "4.2",
         "299.0",
         "16.1",
         "2.18",
         "2.02",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "51.90476190476191"
        ],
        [
         "6",
         "1.0",
         "0",
         "87.09",
         "7.1",
         "256.0",
         "16.2",
         "4.54",
         "2.56",
         "1",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "63.94366197183099"
        ],
        [
         "7",
         "2.0",
         "0",
         "54.0",
         "5.4",
         "244.0",
         "12.9",
         "3.35",
         "2.05",
         "0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "62.03703703703704"
        ],
        [
         "8",
         "1.0",
         "0",
         "97.0",
         "5.5",
         "188.0",
         "15.7",
         "3.41",
         "2.09",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "62.0"
        ],
        [
         "9",
         "2.0",
         "0",
         "91.63",
         "5.8",
         "247.0",
         "13.9",
         "3.71",
         "2.09",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "63.96551724137931"
        ],
        [
         "10",
         "2.0",
         "0",
         "66.0",
         "10.3",
         "425.0",
         "12.5",
         "7.27",
         "3.03",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "70.58252427184465"
        ],
        [
         "11",
         "1.0",
         "0",
         "105.23",
         "5.3",
         "188.0",
         "15.4",
         "3.13",
         "2.17",
         "1",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "59.0566037735849"
        ],
        [
         "12",
         "1.0",
         "0",
         "119.75",
         "6.6",
         "192.0",
         "14.2",
         "4.09",
         "2.51",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "61.969696969696976"
        ],
        [
         "13",
         "1.0",
         "0",
         "103.63",
         "5.6",
         "238.0",
         "17.0",
         "3.26",
         "2.34",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "58.21428571428572"
        ],
        [
         "14",
         "1.0",
         "0",
         "79.0",
         "5.6",
         "204.0",
         "14.0",
         "3.75",
         "1.85",
         "0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "66.96428571428572"
        ],
        [
         "15",
         "1.0",
         "0",
         "87.0",
         "5.5",
         "173.0",
         "14.2",
         "4.03",
         "1.47",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "73.27272727272728"
        ],
        [
         "16",
         "2.0",
         "0",
         "85.0",
         "10.8",
         "398.0",
         "15.3",
         "7.48",
         "3.3",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "69.25925925925925"
        ],
        [
         "17",
         "1.0",
         "0",
         "77.27",
         "5.6",
         "191.0",
         "17.1",
         "3.98",
         "1.62",
         "1",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "71.07142857142857"
        ],
        [
         "18",
         "1.0",
         "0",
         "112.49",
         "6.2",
         "198.0",
         "15.2",
         "3.97",
         "2.17",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "64.03225806451613"
        ],
        [
         "19",
         "1.0",
         "0",
         "68.0",
         "8.2",
         "343.0",
         "14.0",
         "5.17",
         "2.87",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "63.04878048780488"
        ],
        [
         "20",
         "1.0",
         "0",
         "88.0",
         "8.6",
         "201.0",
         "16.0",
         "6.71",
         "1.89",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "78.0232558139535"
        ],
        [
         "21",
         "1.0",
         "0",
         "88.0",
         "6.1",
         "207.0",
         "13.0",
         "3.89",
         "2.21",
         "1",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "63.770491803278695"
        ],
        [
         "22",
         "1.0",
         "0",
         "81.0",
         "7.8",
         "247.0",
         "14.6",
         "4.24",
         "3.51",
         "1",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "54.358974358974365"
        ],
        [
         "23",
         "1.0",
         "0",
         "75.45",
         "5.3",
         "196.0",
         "14.6",
         "3.13",
         "2.17",
         "1",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "59.0566037735849"
        ],
        [
         "24",
         "2.0",
         "0",
         "87.0",
         "7.8",
         "287.0",
         "13.8",
         "4.98",
         "2.82",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "63.846153846153854"
        ],
        [
         "25",
         "2.0",
         "0",
         "64.41",
         "6.0",
         "232.0",
         "13.9",
         "4.44",
         "1.56",
         "1",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "74.00000000000001"
        ],
        [
         "26",
         "2.0",
         "0",
         "74.84",
         "6.7",
         "252.0",
         "13.3",
         "4.22",
         "2.41",
         "1",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "62.98507462686567"
        ],
        [
         "27",
         "1.0",
         "0",
         "93.63",
         "7.5",
         "191.0",
         "16.7",
         "5.92",
         "1.5",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "78.93333333333334"
        ],
        [
         "28",
         "2.0",
         "0",
         "87.0",
         "6.3",
         "251.0",
         "13.7",
         "3.53",
         "2.77",
         "1",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "56.03174603174603"
        ],
        [
         "29",
         "1.0",
         "0",
         "75.0",
         "5.9",
         "286.0",
         "16.3",
         "4.08",
         "1.82",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "69.15254237288136"
        ],
        [
         "30",
         "2.0",
         "0",
         "66.0",
         "6.7",
         "271.0",
         "13.6",
         "3.73",
         "2.97",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "55.67164179104478"
        ],
        [
         "31",
         "1.0",
         "0",
         "96.0",
         "7.5",
         "318.0",
         "14.5",
         "5.28",
         "2.23",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "70.4"
        ],
        [
         "32",
         "2.0",
         "0",
         "90.27",
         "5.7",
         "217.0",
         "14.1",
         "3.31",
         "2.39",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "58.07017543859649"
        ],
        [
         "33",
         "1.0",
         "0",
         "105.9",
         "5.4",
         "273.0",
         "15.1",
         "3.62",
         "1.78",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "67.03703703703704"
        ],
        [
         "34",
         "1.0",
         "0",
         "69.4",
         "7.6",
         "275.0",
         "16.2",
         "6.22",
         "1.38",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "81.84210526315789"
        ],
        [
         "35",
         "2.0",
         "0",
         "54.54",
         "8.4",
         "208.0",
         "13.0",
         "6.47",
         "1.93",
         "0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "77.02380952380952"
        ],
        [
         "36",
         "2.0",
         "0",
         "69.09",
         "4.3",
         "383.0",
         "13.5",
         "2.55",
         "1.75",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "59.302325581395344"
        ],
        [
         "37",
         "1.0",
         "0",
         "75.0",
         "7.2",
         "204.0",
         "14.4",
         "4.82",
         "2.38",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "66.94444444444446"
        ],
        [
         "38",
         "2.0",
         "0",
         "82.0",
         "10.1",
         "359.0",
         "14.4",
         "6.46",
         "3.64",
         "0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "63.96039603960397"
        ],
        [
         "39",
         "1.0",
         "0",
         "97.0",
         "4.8",
         "183.0",
         "15.4",
         "3.41",
         "1.39",
         "1",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "71.04166666666667"
        ],
        [
         "40",
         "1.0",
         "0",
         "80.74",
         "4.6",
         "186.0",
         "16.5",
         "3.12",
         "1.48",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "67.82608695652175"
        ],
        [
         "41",
         "1.0",
         "0",
         "107.0",
         "4.9",
         "206.0",
         "15.2",
         "2.97",
         "1.92",
         "1",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "60.61224489795919"
        ],
        [
         "42",
         "1.0",
         "0",
         "96.36",
         "5.3",
         "262.0",
         "15.3",
         "3.02",
         "2.28",
         "1",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "56.9811320754717"
        ],
        [
         "43",
         "1.0",
         "0",
         "79.0",
         "5.6",
         "173.0",
         "16.4",
         "3.86",
         "1.74",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "68.92857142857143"
        ],
        [
         "44",
         "2.0",
         "0",
         "60.0",
         "5.0",
         "259.0",
         "11.9",
         "3.0",
         "1.99",
         "1",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "60.0"
        ],
        [
         "45",
         "1.0",
         "0",
         "99.0",
         "4.9",
         "199.0",
         "13.7",
         "2.7",
         "2.21",
         "0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "55.10204081632652"
        ],
        [
         "46",
         "1.0",
         "0",
         "102.51",
         "6.5",
         "166.0",
         "15.7",
         "4.63",
         "1.87",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "71.23076923076923"
        ],
        [
         "47",
         "1.0",
         "0",
         "105.69",
         "6.2",
         "178.0",
         "15.3",
         "3.7",
         "2.5",
         "1",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "59.67741935483871"
        ],
        [
         "48",
         "2.0",
         "0",
         "55.0",
         "6.4",
         "224.0",
         "13.7",
         "4.03",
         "2.36",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "62.96874999999999"
        ],
        [
         "49",
         "1.0",
         "0",
         "104.0",
         "10.1",
         "197.0",
         "16.3",
         "6.27",
         "3.8",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "62.07920792079208"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 38355
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>labtype</th>\n",
       "      <th>Weight</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Platelet</th>\n",
       "      <th>HGB</th>\n",
       "      <th>Neut Abs</th>\n",
       "      <th>MNC Abs</th>\n",
       "      <th>Count</th>\n",
       "      <th>Age-Group_1.0</th>\n",
       "      <th>Age-Group_2.0</th>\n",
       "      <th>Age-Group_3.0</th>\n",
       "      <th>Age-Group_4.0</th>\n",
       "      <th>BMI Group_1.0</th>\n",
       "      <th>BMI Group_2.0</th>\n",
       "      <th>BMI Group_3.0</th>\n",
       "      <th>BMI Group_4.0</th>\n",
       "      <th>Neut Pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>3.8</td>\n",
       "      <td>159.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>5.5</td>\n",
       "      <td>218.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>124.00</td>\n",
       "      <td>6.1</td>\n",
       "      <td>175.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.950820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>5.04</td>\n",
       "      <td>2.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>94.00</td>\n",
       "      <td>8.1</td>\n",
       "      <td>351.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.987654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38350</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>97.52</td>\n",
       "      <td>52.5</td>\n",
       "      <td>296.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>44.63</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.009524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38351</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>78.93</td>\n",
       "      <td>35.9</td>\n",
       "      <td>191.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>31.41</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.493036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38352</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>72.58</td>\n",
       "      <td>38.9</td>\n",
       "      <td>270.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>31.51</td>\n",
       "      <td>7.39</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.002571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38353</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.67</td>\n",
       "      <td>28.1</td>\n",
       "      <td>195.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>22.06</td>\n",
       "      <td>6.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.505338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38354</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>93.44</td>\n",
       "      <td>52.6</td>\n",
       "      <td>294.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>46.29</td>\n",
       "      <td>6.31</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.003802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38355 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gender  labtype  Weight   WBC  Platelet   HGB  Neut Abs  MNC Abs  \\\n",
       "0         1.0        0   93.00   3.8     159.0  15.5      2.24     1.56   \n",
       "1         2.0        0   79.00   5.5     218.0  13.2      3.00     2.49   \n",
       "2         1.0        0  124.00   6.1     175.0  15.0      3.23     2.87   \n",
       "3         1.0        0   84.00   8.0     280.0  15.4      5.04     2.96   \n",
       "4         2.0        0   94.00   8.1     351.0  13.2      4.94     3.16   \n",
       "...       ...      ...     ...   ...       ...   ...       ...      ...   \n",
       "38350     1.0        1   97.52  52.5     296.0  14.2     44.63     7.88   \n",
       "38351     1.0        1   78.93  35.9     191.0  14.8     31.41     4.49   \n",
       "38352     2.0        1   72.58  38.9     270.0  13.6     31.51     7.39   \n",
       "38353     1.0        1   71.67  28.1     195.0  14.7     22.06     6.04   \n",
       "38354     2.0        1   93.44  52.6     294.0  12.2     46.29     6.31   \n",
       "\n",
       "       Count  Age-Group_1.0  Age-Group_2.0  Age-Group_3.0  Age-Group_4.0  \\\n",
       "0          0            0.0            0.0            0.0            1.0   \n",
       "1          1            0.0            0.0            0.0            1.0   \n",
       "2          0            0.0            0.0            0.0            1.0   \n",
       "3          1            0.0            0.0            0.0            1.0   \n",
       "4          1            0.0            0.0            0.0            1.0   \n",
       "...      ...            ...            ...            ...            ...   \n",
       "38350      1            1.0            0.0            0.0            0.0   \n",
       "38351      1            1.0            0.0            0.0            0.0   \n",
       "38352      1            1.0            0.0            0.0            0.0   \n",
       "38353      1            1.0            0.0            0.0            0.0   \n",
       "38354      1            1.0            0.0            0.0            0.0   \n",
       "\n",
       "       BMI Group_1.0  BMI Group_2.0  BMI Group_3.0  BMI Group_4.0   Neut Pct  \n",
       "0                0.0            0.0            0.0            1.0  58.947368  \n",
       "1                0.0            0.0            1.0            0.0  54.545455  \n",
       "2                0.0            0.0            0.0            1.0  52.950820  \n",
       "3                0.0            0.0            1.0            0.0  63.000000  \n",
       "4                0.0            0.0            0.0            1.0  60.987654  \n",
       "...              ...            ...            ...            ...        ...  \n",
       "38350            0.0            0.0            1.0            0.0  85.009524  \n",
       "38351            0.0            1.0            0.0            0.0  87.493036  \n",
       "38352            0.0            0.0            1.0            0.0  81.002571  \n",
       "38353            0.0            0.0            1.0            0.0  78.505338  \n",
       "38354            0.0            0.0            1.0            0.0  88.003802  \n",
       "\n",
       "[38355 rows x 18 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "dataset = pd.read_csv(here() / config.data / 'interim'  / 'cibmtr_prepost_normalized_wt_bmi_neut.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07818ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with nan or missing values\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81f03ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Gender",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "labtype",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Weight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WBC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Platelet",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HGB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Neut Abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MNC Abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age-Group_1.0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age-Group_2.0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age-Group_3.0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age-Group_4.0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BMI Group_1.0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BMI Group_2.0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BMI Group_3.0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BMI Group_4.0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Neut Pct",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "0920caee-c57c-455c-8513-4d511eec8104",
       "rows": [
        [
         "0",
         "1.0",
         "0",
         "93.0",
         "3.8",
         "159.0",
         "15.5",
         "2.24",
         "1.56",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "58.94736842105264",
         "0"
        ],
        [
         "1",
         "2.0",
         "0",
         "79.0",
         "5.5",
         "218.0",
         "13.2",
         "3.0",
         "2.49",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "54.54545454545454",
         "1"
        ],
        [
         "2",
         "1.0",
         "0",
         "124.0",
         "6.1",
         "175.0",
         "15.0",
         "3.23",
         "2.87",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "52.95081967213115",
         "0"
        ],
        [
         "3",
         "1.0",
         "0",
         "84.0",
         "8.0",
         "280.0",
         "15.4",
         "5.04",
         "2.96",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "63.0",
         "1"
        ],
        [
         "4",
         "2.0",
         "0",
         "94.0",
         "8.1",
         "351.0",
         "13.2",
         "4.94",
         "3.16",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "60.98765432098766",
         "1"
        ],
        [
         "5",
         "1.0",
         "0",
         "95.0",
         "4.2",
         "299.0",
         "16.1",
         "2.18",
         "2.02",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "51.90476190476191",
         "1"
        ],
        [
         "6",
         "1.0",
         "0",
         "87.09",
         "7.1",
         "256.0",
         "16.2",
         "4.54",
         "2.56",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "63.94366197183099",
         "1"
        ],
        [
         "7",
         "2.0",
         "0",
         "54.0",
         "5.4",
         "244.0",
         "12.9",
         "3.35",
         "2.05",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "62.03703703703704",
         "0"
        ],
        [
         "8",
         "1.0",
         "0",
         "97.0",
         "5.5",
         "188.0",
         "15.7",
         "3.41",
         "2.09",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "62.0",
         "1"
        ],
        [
         "9",
         "2.0",
         "0",
         "91.63",
         "5.8",
         "247.0",
         "13.9",
         "3.71",
         "2.09",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "63.96551724137931",
         "1"
        ],
        [
         "10",
         "2.0",
         "0",
         "66.0",
         "10.3",
         "425.0",
         "12.5",
         "7.27",
         "3.03",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "70.58252427184465",
         "1"
        ],
        [
         "11",
         "1.0",
         "0",
         "105.23",
         "5.3",
         "188.0",
         "15.4",
         "3.13",
         "2.17",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "59.0566037735849",
         "1"
        ],
        [
         "12",
         "1.0",
         "0",
         "119.75",
         "6.6",
         "192.0",
         "14.2",
         "4.09",
         "2.51",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "61.969696969696976",
         "1"
        ],
        [
         "13",
         "1.0",
         "0",
         "103.63",
         "5.6",
         "238.0",
         "17.0",
         "3.26",
         "2.34",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "58.21428571428572",
         "1"
        ],
        [
         "14",
         "1.0",
         "0",
         "79.0",
         "5.6",
         "204.0",
         "14.0",
         "3.75",
         "1.85",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "66.96428571428572",
         "0"
        ],
        [
         "15",
         "1.0",
         "0",
         "87.0",
         "5.5",
         "173.0",
         "14.2",
         "4.03",
         "1.47",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "73.27272727272728",
         "1"
        ],
        [
         "16",
         "2.0",
         "0",
         "85.0",
         "10.8",
         "398.0",
         "15.3",
         "7.48",
         "3.3",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "69.25925925925925",
         "1"
        ],
        [
         "17",
         "1.0",
         "0",
         "77.27",
         "5.6",
         "191.0",
         "17.1",
         "3.98",
         "1.62",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "71.07142857142857",
         "1"
        ],
        [
         "18",
         "1.0",
         "0",
         "112.49",
         "6.2",
         "198.0",
         "15.2",
         "3.97",
         "2.17",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "64.03225806451613",
         "1"
        ],
        [
         "19",
         "1.0",
         "0",
         "68.0",
         "8.2",
         "343.0",
         "14.0",
         "5.17",
         "2.87",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "63.04878048780488",
         "1"
        ],
        [
         "20",
         "1.0",
         "0",
         "88.0",
         "8.6",
         "201.0",
         "16.0",
         "6.71",
         "1.89",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "78.0232558139535",
         "1"
        ],
        [
         "21",
         "1.0",
         "0",
         "88.0",
         "6.1",
         "207.0",
         "13.0",
         "3.89",
         "2.21",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "63.770491803278695",
         "1"
        ],
        [
         "22",
         "1.0",
         "0",
         "81.0",
         "7.8",
         "247.0",
         "14.6",
         "4.24",
         "3.51",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "54.358974358974365",
         "1"
        ],
        [
         "23",
         "1.0",
         "0",
         "75.45",
         "5.3",
         "196.0",
         "14.6",
         "3.13",
         "2.17",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "59.0566037735849",
         "1"
        ],
        [
         "24",
         "2.0",
         "0",
         "87.0",
         "7.8",
         "287.0",
         "13.8",
         "4.98",
         "2.82",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "63.846153846153854",
         "0"
        ],
        [
         "25",
         "2.0",
         "0",
         "64.41",
         "6.0",
         "232.0",
         "13.9",
         "4.44",
         "1.56",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "74.00000000000001",
         "1"
        ],
        [
         "26",
         "2.0",
         "0",
         "74.84",
         "6.7",
         "252.0",
         "13.3",
         "4.22",
         "2.41",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "62.98507462686567",
         "1"
        ],
        [
         "27",
         "1.0",
         "0",
         "93.63",
         "7.5",
         "191.0",
         "16.7",
         "5.92",
         "1.5",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "78.93333333333334",
         "1"
        ],
        [
         "28",
         "2.0",
         "0",
         "87.0",
         "6.3",
         "251.0",
         "13.7",
         "3.53",
         "2.77",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "56.03174603174603",
         "1"
        ],
        [
         "29",
         "1.0",
         "0",
         "75.0",
         "5.9",
         "286.0",
         "16.3",
         "4.08",
         "1.82",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "69.15254237288136",
         "1"
        ],
        [
         "30",
         "2.0",
         "0",
         "66.0",
         "6.7",
         "271.0",
         "13.6",
         "3.73",
         "2.97",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "55.67164179104478",
         "1"
        ],
        [
         "31",
         "1.0",
         "0",
         "96.0",
         "7.5",
         "318.0",
         "14.5",
         "5.28",
         "2.23",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "70.4",
         "1"
        ],
        [
         "32",
         "2.0",
         "0",
         "90.27",
         "5.7",
         "217.0",
         "14.1",
         "3.31",
         "2.39",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "58.07017543859649",
         "1"
        ],
        [
         "33",
         "1.0",
         "0",
         "105.9",
         "5.4",
         "273.0",
         "15.1",
         "3.62",
         "1.78",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "67.03703703703704",
         "1"
        ],
        [
         "34",
         "1.0",
         "0",
         "69.4",
         "7.6",
         "275.0",
         "16.2",
         "6.22",
         "1.38",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "81.84210526315789",
         "1"
        ],
        [
         "35",
         "2.0",
         "0",
         "54.54",
         "8.4",
         "208.0",
         "13.0",
         "6.47",
         "1.93",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "77.02380952380952",
         "0"
        ],
        [
         "36",
         "2.0",
         "0",
         "69.09",
         "4.3",
         "383.0",
         "13.5",
         "2.55",
         "1.75",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "59.302325581395344",
         "1"
        ],
        [
         "37",
         "1.0",
         "0",
         "75.0",
         "7.2",
         "204.0",
         "14.4",
         "4.82",
         "2.38",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "66.94444444444446",
         "1"
        ],
        [
         "38",
         "2.0",
         "0",
         "82.0",
         "10.1",
         "359.0",
         "14.4",
         "6.46",
         "3.64",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "63.96039603960397",
         "0"
        ],
        [
         "39",
         "1.0",
         "0",
         "97.0",
         "4.8",
         "183.0",
         "15.4",
         "3.41",
         "1.39",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "71.04166666666667",
         "1"
        ],
        [
         "40",
         "1.0",
         "0",
         "80.74",
         "4.6",
         "186.0",
         "16.5",
         "3.12",
         "1.48",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "67.82608695652175",
         "1"
        ],
        [
         "41",
         "1.0",
         "0",
         "107.0",
         "4.9",
         "206.0",
         "15.2",
         "2.97",
         "1.92",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "60.61224489795919",
         "1"
        ],
        [
         "42",
         "1.0",
         "0",
         "96.36",
         "5.3",
         "262.0",
         "15.3",
         "3.02",
         "2.28",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "56.9811320754717",
         "1"
        ],
        [
         "43",
         "1.0",
         "0",
         "79.0",
         "5.6",
         "173.0",
         "16.4",
         "3.86",
         "1.74",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "68.92857142857143",
         "1"
        ],
        [
         "44",
         "2.0",
         "0",
         "60.0",
         "5.0",
         "259.0",
         "11.9",
         "3.0",
         "1.99",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "60.0",
         "1"
        ],
        [
         "45",
         "1.0",
         "0",
         "99.0",
         "4.9",
         "199.0",
         "13.7",
         "2.7",
         "2.21",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "55.10204081632652",
         "0"
        ],
        [
         "46",
         "1.0",
         "0",
         "102.51",
         "6.5",
         "166.0",
         "15.7",
         "4.63",
         "1.87",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "71.23076923076923",
         "0"
        ],
        [
         "47",
         "1.0",
         "0",
         "105.69",
         "6.2",
         "178.0",
         "15.3",
         "3.7",
         "2.5",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "59.67741935483871",
         "1"
        ],
        [
         "48",
         "2.0",
         "0",
         "55.0",
         "6.4",
         "224.0",
         "13.7",
         "4.03",
         "2.36",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "62.96874999999999",
         "1"
        ],
        [
         "49",
         "1.0",
         "0",
         "104.0",
         "10.1",
         "197.0",
         "16.3",
         "6.27",
         "3.8",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "62.07920792079208",
         "1"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 38355
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>labtype</th>\n",
       "      <th>Weight</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Platelet</th>\n",
       "      <th>HGB</th>\n",
       "      <th>Neut Abs</th>\n",
       "      <th>MNC Abs</th>\n",
       "      <th>Age-Group_1.0</th>\n",
       "      <th>Age-Group_2.0</th>\n",
       "      <th>Age-Group_3.0</th>\n",
       "      <th>Age-Group_4.0</th>\n",
       "      <th>BMI Group_1.0</th>\n",
       "      <th>BMI Group_2.0</th>\n",
       "      <th>BMI Group_3.0</th>\n",
       "      <th>BMI Group_4.0</th>\n",
       "      <th>Neut Pct</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>3.8</td>\n",
       "      <td>159.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.947368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>5.5</td>\n",
       "      <td>218.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>124.00</td>\n",
       "      <td>6.1</td>\n",
       "      <td>175.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.950820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>5.04</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>94.00</td>\n",
       "      <td>8.1</td>\n",
       "      <td>351.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.987654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38350</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>97.52</td>\n",
       "      <td>52.5</td>\n",
       "      <td>296.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>44.63</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.009524</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38351</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>78.93</td>\n",
       "      <td>35.9</td>\n",
       "      <td>191.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>31.41</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.493036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38352</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>72.58</td>\n",
       "      <td>38.9</td>\n",
       "      <td>270.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>31.51</td>\n",
       "      <td>7.39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.002571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38353</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.67</td>\n",
       "      <td>28.1</td>\n",
       "      <td>195.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>22.06</td>\n",
       "      <td>6.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.505338</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38354</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>93.44</td>\n",
       "      <td>52.6</td>\n",
       "      <td>294.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>46.29</td>\n",
       "      <td>6.31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.003802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38355 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gender  labtype  Weight   WBC  Platelet   HGB  Neut Abs  MNC Abs  \\\n",
       "0         1.0        0   93.00   3.8     159.0  15.5      2.24     1.56   \n",
       "1         2.0        0   79.00   5.5     218.0  13.2      3.00     2.49   \n",
       "2         1.0        0  124.00   6.1     175.0  15.0      3.23     2.87   \n",
       "3         1.0        0   84.00   8.0     280.0  15.4      5.04     2.96   \n",
       "4         2.0        0   94.00   8.1     351.0  13.2      4.94     3.16   \n",
       "...       ...      ...     ...   ...       ...   ...       ...      ...   \n",
       "38350     1.0        1   97.52  52.5     296.0  14.2     44.63     7.88   \n",
       "38351     1.0        1   78.93  35.9     191.0  14.8     31.41     4.49   \n",
       "38352     2.0        1   72.58  38.9     270.0  13.6     31.51     7.39   \n",
       "38353     1.0        1   71.67  28.1     195.0  14.7     22.06     6.04   \n",
       "38354     2.0        1   93.44  52.6     294.0  12.2     46.29     6.31   \n",
       "\n",
       "       Age-Group_1.0  Age-Group_2.0  Age-Group_3.0  Age-Group_4.0  \\\n",
       "0                0.0            0.0            0.0            1.0   \n",
       "1                0.0            0.0            0.0            1.0   \n",
       "2                0.0            0.0            0.0            1.0   \n",
       "3                0.0            0.0            0.0            1.0   \n",
       "4                0.0            0.0            0.0            1.0   \n",
       "...              ...            ...            ...            ...   \n",
       "38350            1.0            0.0            0.0            0.0   \n",
       "38351            1.0            0.0            0.0            0.0   \n",
       "38352            1.0            0.0            0.0            0.0   \n",
       "38353            1.0            0.0            0.0            0.0   \n",
       "38354            1.0            0.0            0.0            0.0   \n",
       "\n",
       "       BMI Group_1.0  BMI Group_2.0  BMI Group_3.0  BMI Group_4.0   Neut Pct  \\\n",
       "0                0.0            0.0            0.0            1.0  58.947368   \n",
       "1                0.0            0.0            1.0            0.0  54.545455   \n",
       "2                0.0            0.0            0.0            1.0  52.950820   \n",
       "3                0.0            0.0            1.0            0.0  63.000000   \n",
       "4                0.0            0.0            0.0            1.0  60.987654   \n",
       "...              ...            ...            ...            ...        ...   \n",
       "38350            0.0            0.0            1.0            0.0  85.009524   \n",
       "38351            0.0            1.0            0.0            0.0  87.493036   \n",
       "38352            0.0            0.0            1.0            0.0  81.002571   \n",
       "38353            0.0            0.0            1.0            0.0  78.505338   \n",
       "38354            0.0            0.0            1.0            0.0  88.003802   \n",
       "\n",
       "       Count  \n",
       "0          0  \n",
       "1          1  \n",
       "2          0  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "38350      1  \n",
       "38351      1  \n",
       "38352      1  \n",
       "38353      1  \n",
       "38354      1  \n",
       "\n",
       "[38355 rows x 18 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move Count to the last column\n",
    "cols = dataset.columns.tolist()\n",
    "cols.append(cols.pop(cols.index('Count')))\n",
    "dataset = dataset[cols]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65f7a793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply linear normalization\n",
    "df_temp = dataset.iloc[:,:-1]\n",
    "dataset.iloc[:,:-1] = (df_temp - df_temp.min()) / (df_temp.max() - df_temp.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c55cf1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = dataset.iloc[:,:-1]\n",
    "y = dataset.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7b71ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversample the bad mobilizers to balance the dataset with SMOTE\n",
    "oversample = SMOTE(random_state=42, sampling_strategy='minority', k_neighbors=5)\n",
    "X, y = oversample.fit_resample(X, y,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b737bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y in to binary classes\n",
    "y = (y > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a913462d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (67548, 17)\n",
      "Shape of y: (67548,)\n"
     ]
    }
   ],
   "source": [
    "# print the shape of X and y\n",
    "print(f'Shape of X: {X.shape}')\n",
    "print(f'Shape of y: {y.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51b16bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d259ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES    = df.columns.difference(['Count'])   # all but target\n",
    "NUMERICS    = FEATURES.difference(['labtype']) # all numeric features\n",
    "\n",
    "# X_full      = df[FEATURES].copy()\n",
    "# y_full      = df['Count'].values\n",
    "X_full = X.copy()\n",
    "y_full = y.values\n",
    "\n",
    "# perform train-test split\n",
    "# 80% train, 20% test, then 80% train, 20% validation\n",
    "X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
    "    X_full, y_full, test_size=0.20, random_state=RANDOM_STATE, stratify=y_full)\n",
    "\n",
    "X_val, X_test, y_val, y_test   = train_test_split(\n",
    "    X_tmp,  y_tmp,  test_size=0.20, random_state=RANDOM_STATE, stratify=y_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "478f4058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    27019\n",
      "0    27019\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_train[NUMERICS] = scaler.fit_transform(X_train[NUMERICS])\n",
    "# X_val[NUMERICS]   = scaler.transform(X_val[NUMERICS])\n",
    "# X_test[NUMERICS]  = scaler.transform(X_test[NUMERICS])\n",
    "\n",
    "# # SMOTE on *training* fold only     #\n",
    "# smote = SMOTE(random_state=RANDOM_STATE)\n",
    "# X_tr_over, y_tr_over = smote.fit_resample(X_train, y_train)\n",
    "# print(pd.Series(y_tr_over).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "561942eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_over = X_train.copy()\n",
    "y_tr_over = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ff6d612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CBC_Attn_CLF\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CBC_Attn_CLF\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
       "\n",
       " features             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
       "\n",
       " labtype              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
       "\n",
       " feature_attention_2  [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>),              <span style=\"color: #00af00; text-decoration-color: #00af00\">560</span>  features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FeatureAttention</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)]                    labtype[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "\n",
       " dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">4,488</span>  feature_attentio \n",
       "\n",
       " dropout_12           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span>  dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">33,920</span>  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  dense_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " dropout_13           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
       "\n",
       " dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span>  dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "\n",
       " dropout_14           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
       "\n",
       " dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span>  dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "\n",
       " dropout_15           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
       "\n",
       " dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span>  dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "\n",
       " dropout_16           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
       "\n",
       " dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>  dropout_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "\n",
       " dropout_17           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
       "\n",
       " dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>  dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " features             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  -                 \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
       "\n",
       " labtype              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   \u001b[38;5;34m0\u001b[0m  -                 \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
       "\n",
       " feature_attention_2  [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m),              \u001b[38;5;34m560\u001b[0m  features[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   \n",
       " (\u001b[38;5;33mFeatureAttention\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)]                    labtype[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "\n",
       " dense_20 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m264\u001b[0m)             \u001b[38;5;34m4,488\u001b[0m  feature_attentio \n",
       "\n",
       " dropout_12           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m264\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  dense_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m264\u001b[0m)             \u001b[38;5;34m1,056\u001b[0m  dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " dense_21 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m33,920\u001b[0m  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               \u001b[38;5;34m512\u001b[0m  dense_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " dropout_13           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
       "\n",
       " dense_22 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)              \u001b[38;5;34m8,256\u001b[0m  dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "\n",
       " dropout_14           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  dense_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
       "\n",
       " dense_23 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)              \u001b[38;5;34m2,080\u001b[0m  dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "\n",
       " dropout_15           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  dense_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
       "\n",
       " dense_24 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                 \u001b[38;5;34m264\u001b[0m  dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "\n",
       " dropout_16           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   \u001b[38;5;34m0\u001b[0m  dense_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
       "\n",
       " dense_25 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                  \u001b[38;5;34m36\u001b[0m  dropout_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "\n",
       " dropout_17           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   \u001b[38;5;34m0\u001b[0m  dense_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
       "\n",
       " dense_26 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   \u001b[38;5;34m5\u001b[0m  dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,177</span> (199.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m51,177\u001b[0m (199.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,393</span> (196.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,393\u001b[0m (196.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">784</span> (3.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m784\u001b[0m (3.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ###################################################################################\n",
    "# Building a custom attention layer for feature-wise attention modulated by labtype #\n",
    "# ###################################################################################\n",
    "\n",
    "n_feat = len(NUMERICS)  # numeric  + age + gender   (excl. labtype)\n",
    "\n",
    "#  Inputs \n",
    "feat_in = layers.Input(shape=(n_feat,),   name='features')   # tensor A\n",
    "lab_in  = layers.Input(shape=(1,),        name='labtype')    # tensor B\n",
    "\n",
    "#  Custom feature-wise attention modulated by labtype \n",
    "class FeatureAttention(layers.Layer):\n",
    "    def __init__(self, units, **kw):\n",
    "        super().__init__(**kw)\n",
    "        self.hid  = layers.Dense(units, activation='tanh')  # hidden layer\n",
    "        self.alpha = layers.Dense(units, activation='softmax')  # attention weights\n",
    "\n",
    "    def call(self, inputs):\n",
    "        feats, lab = inputs\n",
    "        x = tf.concat([feats, lab], axis=-1)      # (batch, units+1)\n",
    "        e = self.hid(x)\n",
    "        a = self.alpha(e)                         # (batch, units)  row-softmax\n",
    "        return feats * a, a                       # return both for later\n",
    "\n",
    "att_layer             = FeatureAttention(n_feat)\n",
    "att_out, att_weights  = att_layer([feat_in, lab_in])\n",
    "\n",
    "#  Down-stream classifier \n",
    "x = layers.Dense(264, activation='leaky_relu', \n",
    "                 kernel_initializer='normal',\n",
    "                 kernel_regularizer = regularizers.l2(0.0000045)\n",
    "                 )(att_out)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(128, activation='leaky_relu', \n",
    "                 kernel_initializer='normal', \n",
    "                 kernel_regularizer=regularizers.l2(0.0000045)\n",
    "                 )(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(64, activation='leaky_relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(32, activation='leaky_relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(8, activation='leaky_relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(4, activation='leaky_relu')(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "logit = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model   = models.Model(inputs=[feat_in, lab_in], outputs=logit, name='CBC_Attn_CLF')\n",
    "att_extractor = models.Model(inputs=[feat_in, lab_in], outputs=att_weights)\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    metrics=[tf.keras.metrics.AUC(name='auc'),\n",
    "        tf.keras.metrics.BinaryAccuracy(name='acc')])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68c8227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing numpy matric\n",
    "def split_xy(frame):\n",
    "    f = frame.drop(columns=['labtype']).values.astype(np.float32)\n",
    "    l = frame[['labtype']].values.astype(np.float32)\n",
    "    return f, l\n",
    "\n",
    "X_tr_f, X_tr_lab = split_xy(X_tr_over)\n",
    "X_v_f,  X_v_lab  = split_xy(X_val)\n",
    "X_te_f, X_te_lab = split_xy(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a519239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import callbacks\n",
    "# es = callbacks.EarlyStopping(monitor='val_auc', mode='max',\n",
    "#                              patience=20, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c424e668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7000\n",
      "106/106 - 4s - 33ms/step - acc: 0.5789 - auc: 0.6081 - loss: 0.6845 - val_acc: 0.5000 - val_auc: 0.5642 - val_loss: 0.6933\n",
      "Epoch 2/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.6083 - auc: 0.6483 - loss: 0.6602 - val_acc: 0.5787 - val_auc: 0.6410 - val_loss: 0.6921\n",
      "Epoch 3/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.6227 - auc: 0.6683 - loss: 0.6483 - val_acc: 0.6564 - val_auc: 0.6949 - val_loss: 0.6895\n",
      "Epoch 4/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.6328 - auc: 0.6835 - loss: 0.6383 - val_acc: 0.6541 - val_auc: 0.7179 - val_loss: 0.6833\n",
      "Epoch 5/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.6449 - auc: 0.6984 - loss: 0.6307 - val_acc: 0.6626 - val_auc: 0.7303 - val_loss: 0.6652\n",
      "Epoch 6/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.6542 - auc: 0.7095 - loss: 0.6235 - val_acc: 0.6767 - val_auc: 0.7455 - val_loss: 0.6341\n",
      "Epoch 7/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.6622 - auc: 0.7168 - loss: 0.6190 - val_acc: 0.6812 - val_auc: 0.7515 - val_loss: 0.6100\n",
      "Epoch 8/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.6685 - auc: 0.7244 - loss: 0.6136 - val_acc: 0.6822 - val_auc: 0.7548 - val_loss: 0.5957\n",
      "Epoch 9/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6719 - auc: 0.7294 - loss: 0.6105 - val_acc: 0.6895 - val_auc: 0.7602 - val_loss: 0.5892\n",
      "Epoch 10/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6720 - auc: 0.7334 - loss: 0.6062 - val_acc: 0.6902 - val_auc: 0.7617 - val_loss: 0.5839\n",
      "Epoch 11/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.6772 - auc: 0.7380 - loss: 0.6031 - val_acc: 0.6908 - val_auc: 0.7635 - val_loss: 0.5817\n",
      "Epoch 12/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.6799 - auc: 0.7417 - loss: 0.5994 - val_acc: 0.6916 - val_auc: 0.7655 - val_loss: 0.5818\n",
      "Epoch 13/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6832 - auc: 0.7449 - loss: 0.5979 - val_acc: 0.6966 - val_auc: 0.7667 - val_loss: 0.5795\n",
      "Epoch 14/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.6833 - auc: 0.7456 - loss: 0.5969 - val_acc: 0.6972 - val_auc: 0.7682 - val_loss: 0.5775\n",
      "Epoch 15/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.6836 - auc: 0.7474 - loss: 0.5952 - val_acc: 0.6980 - val_auc: 0.7690 - val_loss: 0.5771\n",
      "Epoch 16/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.6846 - auc: 0.7487 - loss: 0.5932 - val_acc: 0.6964 - val_auc: 0.7682 - val_loss: 0.5751\n",
      "Epoch 17/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6860 - auc: 0.7492 - loss: 0.5934 - val_acc: 0.6977 - val_auc: 0.7687 - val_loss: 0.5764\n",
      "Epoch 18/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6852 - auc: 0.7503 - loss: 0.5927 - val_acc: 0.6980 - val_auc: 0.7703 - val_loss: 0.5748\n",
      "Epoch 19/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6872 - auc: 0.7521 - loss: 0.5907 - val_acc: 0.6994 - val_auc: 0.7707 - val_loss: 0.5729\n",
      "Epoch 20/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6871 - auc: 0.7518 - loss: 0.5912 - val_acc: 0.6987 - val_auc: 0.7712 - val_loss: 0.5746\n",
      "Epoch 21/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6889 - auc: 0.7545 - loss: 0.5888 - val_acc: 0.6989 - val_auc: 0.7721 - val_loss: 0.5741\n",
      "Epoch 22/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.6912 - auc: 0.7557 - loss: 0.5882 - val_acc: 0.6987 - val_auc: 0.7714 - val_loss: 0.5743\n",
      "Epoch 23/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6904 - auc: 0.7564 - loss: 0.5874 - val_acc: 0.6991 - val_auc: 0.7727 - val_loss: 0.5711\n",
      "Epoch 24/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6906 - auc: 0.7565 - loss: 0.5867 - val_acc: 0.7011 - val_auc: 0.7728 - val_loss: 0.5711\n",
      "Epoch 25/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6909 - auc: 0.7584 - loss: 0.5844 - val_acc: 0.7008 - val_auc: 0.7732 - val_loss: 0.5715\n",
      "Epoch 26/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6939 - auc: 0.7589 - loss: 0.5851 - val_acc: 0.7012 - val_auc: 0.7734 - val_loss: 0.5715\n",
      "Epoch 27/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6922 - auc: 0.7588 - loss: 0.5844 - val_acc: 0.7002 - val_auc: 0.7733 - val_loss: 0.5714\n",
      "Epoch 28/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6925 - auc: 0.7582 - loss: 0.5849 - val_acc: 0.7015 - val_auc: 0.7741 - val_loss: 0.5705\n",
      "Epoch 29/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6937 - auc: 0.7599 - loss: 0.5837 - val_acc: 0.7019 - val_auc: 0.7746 - val_loss: 0.5695\n",
      "Epoch 30/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.6937 - auc: 0.7605 - loss: 0.5834 - val_acc: 0.7023 - val_auc: 0.7748 - val_loss: 0.5704\n",
      "Epoch 31/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6952 - auc: 0.7616 - loss: 0.5820 - val_acc: 0.7024 - val_auc: 0.7745 - val_loss: 0.5698\n",
      "Epoch 32/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6910 - auc: 0.7600 - loss: 0.5830 - val_acc: 0.7052 - val_auc: 0.7758 - val_loss: 0.5686\n",
      "Epoch 33/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.6958 - auc: 0.7623 - loss: 0.5806 - val_acc: 0.7050 - val_auc: 0.7746 - val_loss: 0.5691\n",
      "Epoch 34/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6939 - auc: 0.7618 - loss: 0.5819 - val_acc: 0.7049 - val_auc: 0.7756 - val_loss: 0.5691\n",
      "Epoch 35/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.6938 - auc: 0.7620 - loss: 0.5812 - val_acc: 0.7028 - val_auc: 0.7756 - val_loss: 0.5677\n",
      "Epoch 36/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.6942 - auc: 0.7625 - loss: 0.5806 - val_acc: 0.7027 - val_auc: 0.7754 - val_loss: 0.5692\n",
      "Epoch 37/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.6941 - auc: 0.7631 - loss: 0.5805 - val_acc: 0.7026 - val_auc: 0.7759 - val_loss: 0.5677\n",
      "Epoch 38/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6948 - auc: 0.7636 - loss: 0.5796 - val_acc: 0.7005 - val_auc: 0.7768 - val_loss: 0.5682\n",
      "Epoch 39/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6947 - auc: 0.7630 - loss: 0.5799 - val_acc: 0.7021 - val_auc: 0.7768 - val_loss: 0.5692\n",
      "Epoch 40/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6964 - auc: 0.7652 - loss: 0.5784 - val_acc: 0.7048 - val_auc: 0.7771 - val_loss: 0.5675\n",
      "Epoch 41/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6973 - auc: 0.7653 - loss: 0.5781 - val_acc: 0.7071 - val_auc: 0.7772 - val_loss: 0.5659\n",
      "Epoch 42/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6962 - auc: 0.7651 - loss: 0.5787 - val_acc: 0.7014 - val_auc: 0.7771 - val_loss: 0.5673\n",
      "Epoch 43/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6960 - auc: 0.7661 - loss: 0.5778 - val_acc: 0.7060 - val_auc: 0.7767 - val_loss: 0.5676\n",
      "Epoch 44/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6955 - auc: 0.7636 - loss: 0.5802 - val_acc: 0.7045 - val_auc: 0.7769 - val_loss: 0.5679\n",
      "Epoch 45/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.6977 - auc: 0.7672 - loss: 0.5763 - val_acc: 0.7044 - val_auc: 0.7774 - val_loss: 0.5669\n",
      "Epoch 46/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6981 - auc: 0.7673 - loss: 0.5762 - val_acc: 0.7043 - val_auc: 0.7777 - val_loss: 0.5661\n",
      "Epoch 47/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6963 - auc: 0.7656 - loss: 0.5773 - val_acc: 0.7056 - val_auc: 0.7775 - val_loss: 0.5658\n",
      "Epoch 48/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6984 - auc: 0.7664 - loss: 0.5770 - val_acc: 0.7072 - val_auc: 0.7777 - val_loss: 0.5659\n",
      "Epoch 49/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.6981 - auc: 0.7672 - loss: 0.5761 - val_acc: 0.7062 - val_auc: 0.7776 - val_loss: 0.5664\n",
      "Epoch 50/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6994 - auc: 0.7672 - loss: 0.5764 - val_acc: 0.7076 - val_auc: 0.7785 - val_loss: 0.5653\n",
      "Epoch 51/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.6979 - auc: 0.7684 - loss: 0.5745 - val_acc: 0.7063 - val_auc: 0.7793 - val_loss: 0.5638\n",
      "Epoch 52/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6985 - auc: 0.7694 - loss: 0.5734 - val_acc: 0.7060 - val_auc: 0.7789 - val_loss: 0.5647\n",
      "Epoch 53/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6995 - auc: 0.7679 - loss: 0.5761 - val_acc: 0.7071 - val_auc: 0.7786 - val_loss: 0.5647\n",
      "Epoch 54/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6994 - auc: 0.7692 - loss: 0.5744 - val_acc: 0.7061 - val_auc: 0.7795 - val_loss: 0.5638\n",
      "Epoch 55/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.6997 - auc: 0.7682 - loss: 0.5746 - val_acc: 0.7066 - val_auc: 0.7798 - val_loss: 0.5655\n",
      "Epoch 56/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6990 - auc: 0.7683 - loss: 0.5745 - val_acc: 0.7080 - val_auc: 0.7802 - val_loss: 0.5650\n",
      "Epoch 57/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7004 - auc: 0.7698 - loss: 0.5731 - val_acc: 0.7076 - val_auc: 0.7797 - val_loss: 0.5642\n",
      "Epoch 58/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.6989 - auc: 0.7683 - loss: 0.5743 - val_acc: 0.7057 - val_auc: 0.7793 - val_loss: 0.5644\n",
      "Epoch 59/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6995 - auc: 0.7698 - loss: 0.5730 - val_acc: 0.7071 - val_auc: 0.7801 - val_loss: 0.5645\n",
      "Epoch 60/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6993 - auc: 0.7693 - loss: 0.5740 - val_acc: 0.7065 - val_auc: 0.7806 - val_loss: 0.5624\n",
      "Epoch 61/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6991 - auc: 0.7693 - loss: 0.5731 - val_acc: 0.7072 - val_auc: 0.7803 - val_loss: 0.5630\n",
      "Epoch 62/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7001 - auc: 0.7699 - loss: 0.5727 - val_acc: 0.7049 - val_auc: 0.7798 - val_loss: 0.5652\n",
      "Epoch 63/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7013 - auc: 0.7719 - loss: 0.5716 - val_acc: 0.7065 - val_auc: 0.7804 - val_loss: 0.5646\n",
      "Epoch 64/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6995 - auc: 0.7704 - loss: 0.5729 - val_acc: 0.7079 - val_auc: 0.7804 - val_loss: 0.5644\n",
      "Epoch 65/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7007 - auc: 0.7716 - loss: 0.5714 - val_acc: 0.7060 - val_auc: 0.7804 - val_loss: 0.5634\n",
      "Epoch 66/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6994 - auc: 0.7707 - loss: 0.5721 - val_acc: 0.7073 - val_auc: 0.7809 - val_loss: 0.5629\n",
      "Epoch 67/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7002 - auc: 0.7719 - loss: 0.5714 - val_acc: 0.7073 - val_auc: 0.7811 - val_loss: 0.5628\n",
      "Epoch 68/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7009 - auc: 0.7717 - loss: 0.5711 - val_acc: 0.7076 - val_auc: 0.7813 - val_loss: 0.5619\n",
      "Epoch 69/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.6997 - auc: 0.7707 - loss: 0.5718 - val_acc: 0.7073 - val_auc: 0.7813 - val_loss: 0.5624\n",
      "Epoch 70/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7015 - auc: 0.7708 - loss: 0.5712 - val_acc: 0.7069 - val_auc: 0.7815 - val_loss: 0.5607\n",
      "Epoch 71/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7011 - auc: 0.7717 - loss: 0.5707 - val_acc: 0.7058 - val_auc: 0.7813 - val_loss: 0.5624\n",
      "Epoch 72/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7024 - auc: 0.7733 - loss: 0.5688 - val_acc: 0.7077 - val_auc: 0.7815 - val_loss: 0.5614\n",
      "Epoch 73/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7020 - auc: 0.7720 - loss: 0.5714 - val_acc: 0.7069 - val_auc: 0.7823 - val_loss: 0.5617\n",
      "Epoch 74/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7024 - auc: 0.7732 - loss: 0.5691 - val_acc: 0.7067 - val_auc: 0.7816 - val_loss: 0.5621\n",
      "Epoch 75/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7019 - auc: 0.7731 - loss: 0.5689 - val_acc: 0.7085 - val_auc: 0.7826 - val_loss: 0.5608\n",
      "Epoch 76/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7017 - auc: 0.7732 - loss: 0.5691 - val_acc: 0.7068 - val_auc: 0.7829 - val_loss: 0.5614\n",
      "Epoch 77/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7022 - auc: 0.7724 - loss: 0.5703 - val_acc: 0.7061 - val_auc: 0.7825 - val_loss: 0.5609\n",
      "Epoch 78/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7037 - auc: 0.7742 - loss: 0.5685 - val_acc: 0.7072 - val_auc: 0.7827 - val_loss: 0.5608\n",
      "Epoch 79/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7024 - auc: 0.7724 - loss: 0.5695 - val_acc: 0.7054 - val_auc: 0.7824 - val_loss: 0.5621\n",
      "Epoch 80/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7021 - auc: 0.7743 - loss: 0.5686 - val_acc: 0.7066 - val_auc: 0.7828 - val_loss: 0.5599\n",
      "Epoch 81/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7024 - auc: 0.7737 - loss: 0.5684 - val_acc: 0.7063 - val_auc: 0.7824 - val_loss: 0.5607\n",
      "Epoch 82/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7022 - auc: 0.7736 - loss: 0.5691 - val_acc: 0.7085 - val_auc: 0.7838 - val_loss: 0.5589\n",
      "Epoch 83/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7037 - auc: 0.7752 - loss: 0.5674 - val_acc: 0.7061 - val_auc: 0.7834 - val_loss: 0.5598\n",
      "Epoch 84/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7029 - auc: 0.7752 - loss: 0.5672 - val_acc: 0.7046 - val_auc: 0.7832 - val_loss: 0.5598\n",
      "Epoch 85/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7023 - auc: 0.7740 - loss: 0.5684 - val_acc: 0.7074 - val_auc: 0.7845 - val_loss: 0.5581\n",
      "Epoch 86/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7032 - auc: 0.7750 - loss: 0.5669 - val_acc: 0.7061 - val_auc: 0.7837 - val_loss: 0.5594\n",
      "Epoch 87/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7036 - auc: 0.7755 - loss: 0.5670 - val_acc: 0.7060 - val_auc: 0.7837 - val_loss: 0.5589\n",
      "Epoch 88/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7038 - auc: 0.7753 - loss: 0.5674 - val_acc: 0.7071 - val_auc: 0.7849 - val_loss: 0.5579\n",
      "Epoch 89/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7042 - auc: 0.7769 - loss: 0.5662 - val_acc: 0.7079 - val_auc: 0.7846 - val_loss: 0.5577\n",
      "Epoch 90/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7038 - auc: 0.7759 - loss: 0.5666 - val_acc: 0.7052 - val_auc: 0.7852 - val_loss: 0.5568\n",
      "Epoch 91/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7032 - auc: 0.7759 - loss: 0.5659 - val_acc: 0.7046 - val_auc: 0.7849 - val_loss: 0.5583\n",
      "Epoch 92/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7030 - auc: 0.7759 - loss: 0.5657 - val_acc: 0.7090 - val_auc: 0.7864 - val_loss: 0.5558\n",
      "Epoch 93/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7031 - auc: 0.7769 - loss: 0.5648 - val_acc: 0.7084 - val_auc: 0.7857 - val_loss: 0.5569\n",
      "Epoch 94/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7050 - auc: 0.7761 - loss: 0.5659 - val_acc: 0.7066 - val_auc: 0.7849 - val_loss: 0.5573\n",
      "Epoch 95/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7047 - auc: 0.7767 - loss: 0.5655 - val_acc: 0.7093 - val_auc: 0.7860 - val_loss: 0.5562\n",
      "Epoch 96/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7037 - auc: 0.7760 - loss: 0.5657 - val_acc: 0.7079 - val_auc: 0.7861 - val_loss: 0.5576\n",
      "Epoch 97/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7058 - auc: 0.7770 - loss: 0.5656 - val_acc: 0.7075 - val_auc: 0.7851 - val_loss: 0.5569\n",
      "Epoch 98/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7046 - auc: 0.7770 - loss: 0.5650 - val_acc: 0.7089 - val_auc: 0.7861 - val_loss: 0.5563\n",
      "Epoch 99/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7038 - auc: 0.7780 - loss: 0.5636 - val_acc: 0.7095 - val_auc: 0.7863 - val_loss: 0.5560\n",
      "Epoch 100/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7051 - auc: 0.7781 - loss: 0.5640 - val_acc: 0.7092 - val_auc: 0.7865 - val_loss: 0.5559\n",
      "Epoch 101/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7054 - auc: 0.7775 - loss: 0.5641 - val_acc: 0.7114 - val_auc: 0.7865 - val_loss: 0.5555\n",
      "Epoch 102/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7060 - auc: 0.7780 - loss: 0.5642 - val_acc: 0.7098 - val_auc: 0.7872 - val_loss: 0.5554\n",
      "Epoch 103/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7054 - auc: 0.7791 - loss: 0.5629 - val_acc: 0.7081 - val_auc: 0.7864 - val_loss: 0.5552\n",
      "Epoch 104/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7054 - auc: 0.7789 - loss: 0.5630 - val_acc: 0.7103 - val_auc: 0.7880 - val_loss: 0.5529\n",
      "Epoch 105/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7067 - auc: 0.7786 - loss: 0.5638 - val_acc: 0.7112 - val_auc: 0.7875 - val_loss: 0.5538\n",
      "Epoch 106/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7078 - auc: 0.7780 - loss: 0.5645 - val_acc: 0.7095 - val_auc: 0.7871 - val_loss: 0.5558\n",
      "Epoch 107/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7067 - auc: 0.7789 - loss: 0.5626 - val_acc: 0.7101 - val_auc: 0.7879 - val_loss: 0.5529\n",
      "Epoch 108/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7079 - auc: 0.7804 - loss: 0.5625 - val_acc: 0.7097 - val_auc: 0.7878 - val_loss: 0.5552\n",
      "Epoch 109/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7060 - auc: 0.7784 - loss: 0.5627 - val_acc: 0.7102 - val_auc: 0.7888 - val_loss: 0.5532\n",
      "Epoch 110/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7063 - auc: 0.7794 - loss: 0.5616 - val_acc: 0.7117 - val_auc: 0.7879 - val_loss: 0.5544\n",
      "Epoch 111/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7070 - auc: 0.7803 - loss: 0.5616 - val_acc: 0.7108 - val_auc: 0.7877 - val_loss: 0.5544\n",
      "Epoch 112/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7067 - auc: 0.7808 - loss: 0.5614 - val_acc: 0.7097 - val_auc: 0.7884 - val_loss: 0.5530\n",
      "Epoch 113/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7063 - auc: 0.7800 - loss: 0.5613 - val_acc: 0.7098 - val_auc: 0.7880 - val_loss: 0.5537\n",
      "Epoch 114/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7072 - auc: 0.7798 - loss: 0.5616 - val_acc: 0.7105 - val_auc: 0.7884 - val_loss: 0.5527\n",
      "Epoch 115/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7068 - auc: 0.7810 - loss: 0.5608 - val_acc: 0.7131 - val_auc: 0.7890 - val_loss: 0.5537\n",
      "Epoch 116/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7079 - auc: 0.7813 - loss: 0.5603 - val_acc: 0.7131 - val_auc: 0.7896 - val_loss: 0.5514\n",
      "Epoch 117/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7083 - auc: 0.7813 - loss: 0.5597 - val_acc: 0.7119 - val_auc: 0.7893 - val_loss: 0.5520\n",
      "Epoch 118/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7063 - auc: 0.7811 - loss: 0.5602 - val_acc: 0.7128 - val_auc: 0.7891 - val_loss: 0.5525\n",
      "Epoch 119/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7077 - auc: 0.7814 - loss: 0.5602 - val_acc: 0.7150 - val_auc: 0.7898 - val_loss: 0.5514\n",
      "Epoch 120/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7079 - auc: 0.7814 - loss: 0.5601 - val_acc: 0.7124 - val_auc: 0.7893 - val_loss: 0.5521\n",
      "Epoch 121/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7088 - auc: 0.7826 - loss: 0.5593 - val_acc: 0.7136 - val_auc: 0.7908 - val_loss: 0.5514\n",
      "Epoch 122/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7085 - auc: 0.7821 - loss: 0.5595 - val_acc: 0.7110 - val_auc: 0.7902 - val_loss: 0.5502\n",
      "Epoch 123/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7094 - auc: 0.7817 - loss: 0.5597 - val_acc: 0.7094 - val_auc: 0.7901 - val_loss: 0.5497\n",
      "Epoch 124/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7087 - auc: 0.7825 - loss: 0.5585 - val_acc: 0.7142 - val_auc: 0.7911 - val_loss: 0.5489\n",
      "Epoch 125/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7089 - auc: 0.7824 - loss: 0.5593 - val_acc: 0.7113 - val_auc: 0.7907 - val_loss: 0.5509\n",
      "Epoch 126/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7092 - auc: 0.7831 - loss: 0.5580 - val_acc: 0.7145 - val_auc: 0.7919 - val_loss: 0.5490\n",
      "Epoch 127/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7098 - auc: 0.7822 - loss: 0.5586 - val_acc: 0.7121 - val_auc: 0.7905 - val_loss: 0.5504\n",
      "Epoch 128/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7076 - auc: 0.7833 - loss: 0.5582 - val_acc: 0.7100 - val_auc: 0.7916 - val_loss: 0.5496\n",
      "Epoch 129/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7089 - auc: 0.7830 - loss: 0.5586 - val_acc: 0.7153 - val_auc: 0.7920 - val_loss: 0.5491\n",
      "Epoch 130/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7106 - auc: 0.7838 - loss: 0.5577 - val_acc: 0.7116 - val_auc: 0.7908 - val_loss: 0.5497\n",
      "Epoch 131/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7104 - auc: 0.7845 - loss: 0.5575 - val_acc: 0.7113 - val_auc: 0.7910 - val_loss: 0.5490\n",
      "Epoch 132/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7108 - auc: 0.7831 - loss: 0.5583 - val_acc: 0.7129 - val_auc: 0.7912 - val_loss: 0.5492\n",
      "Epoch 133/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7096 - auc: 0.7835 - loss: 0.5571 - val_acc: 0.7141 - val_auc: 0.7921 - val_loss: 0.5476\n",
      "Epoch 134/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7099 - auc: 0.7842 - loss: 0.5571 - val_acc: 0.7119 - val_auc: 0.7921 - val_loss: 0.5478\n",
      "Epoch 135/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7111 - auc: 0.7843 - loss: 0.5577 - val_acc: 0.7110 - val_auc: 0.7918 - val_loss: 0.5487\n",
      "Epoch 136/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7093 - auc: 0.7837 - loss: 0.5572 - val_acc: 0.7139 - val_auc: 0.7922 - val_loss: 0.5479\n",
      "Epoch 137/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7094 - auc: 0.7842 - loss: 0.5566 - val_acc: 0.7140 - val_auc: 0.7927 - val_loss: 0.5472\n",
      "Epoch 138/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7109 - auc: 0.7853 - loss: 0.5556 - val_acc: 0.7136 - val_auc: 0.7921 - val_loss: 0.5474\n",
      "Epoch 139/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7106 - auc: 0.7841 - loss: 0.5571 - val_acc: 0.7137 - val_auc: 0.7927 - val_loss: 0.5471\n",
      "Epoch 140/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7100 - auc: 0.7847 - loss: 0.5567 - val_acc: 0.7140 - val_auc: 0.7927 - val_loss: 0.5474\n",
      "Epoch 141/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7111 - auc: 0.7857 - loss: 0.5547 - val_acc: 0.7127 - val_auc: 0.7928 - val_loss: 0.5478\n",
      "Epoch 142/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7109 - auc: 0.7850 - loss: 0.5564 - val_acc: 0.7132 - val_auc: 0.7939 - val_loss: 0.5449\n",
      "Epoch 143/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7111 - auc: 0.7861 - loss: 0.5542 - val_acc: 0.7148 - val_auc: 0.7944 - val_loss: 0.5456\n",
      "Epoch 144/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7113 - auc: 0.7853 - loss: 0.5555 - val_acc: 0.7126 - val_auc: 0.7928 - val_loss: 0.5471\n",
      "Epoch 145/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7099 - auc: 0.7850 - loss: 0.5552 - val_acc: 0.7115 - val_auc: 0.7924 - val_loss: 0.5478\n",
      "Epoch 146/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7111 - auc: 0.7854 - loss: 0.5551 - val_acc: 0.7135 - val_auc: 0.7930 - val_loss: 0.5472\n",
      "Epoch 147/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7101 - auc: 0.7856 - loss: 0.5552 - val_acc: 0.7165 - val_auc: 0.7943 - val_loss: 0.5470\n",
      "Epoch 148/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7126 - auc: 0.7858 - loss: 0.5553 - val_acc: 0.7143 - val_auc: 0.7937 - val_loss: 0.5457\n",
      "Epoch 149/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7103 - auc: 0.7865 - loss: 0.5545 - val_acc: 0.7150 - val_auc: 0.7943 - val_loss: 0.5460\n",
      "Epoch 150/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7126 - auc: 0.7866 - loss: 0.5539 - val_acc: 0.7138 - val_auc: 0.7946 - val_loss: 0.5449\n",
      "Epoch 151/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7118 - auc: 0.7866 - loss: 0.5540 - val_acc: 0.7144 - val_auc: 0.7945 - val_loss: 0.5451\n",
      "Epoch 152/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7123 - auc: 0.7869 - loss: 0.5534 - val_acc: 0.7135 - val_auc: 0.7947 - val_loss: 0.5447\n",
      "Epoch 153/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7123 - auc: 0.7867 - loss: 0.5541 - val_acc: 0.7161 - val_auc: 0.7945 - val_loss: 0.5452\n",
      "Epoch 154/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7116 - auc: 0.7875 - loss: 0.5535 - val_acc: 0.7158 - val_auc: 0.7952 - val_loss: 0.5449\n",
      "Epoch 155/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7146 - auc: 0.7889 - loss: 0.5523 - val_acc: 0.7176 - val_auc: 0.7955 - val_loss: 0.5433\n",
      "Epoch 156/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7124 - auc: 0.7872 - loss: 0.5529 - val_acc: 0.7138 - val_auc: 0.7946 - val_loss: 0.5449\n",
      "Epoch 157/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7123 - auc: 0.7876 - loss: 0.5532 - val_acc: 0.7151 - val_auc: 0.7948 - val_loss: 0.5454\n",
      "Epoch 158/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7153 - auc: 0.7872 - loss: 0.5548 - val_acc: 0.7149 - val_auc: 0.7950 - val_loss: 0.5440\n",
      "Epoch 159/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7141 - auc: 0.7873 - loss: 0.5536 - val_acc: 0.7152 - val_auc: 0.7959 - val_loss: 0.5443\n",
      "Epoch 160/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7142 - auc: 0.7877 - loss: 0.5527 - val_acc: 0.7135 - val_auc: 0.7951 - val_loss: 0.5446\n",
      "Epoch 161/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7141 - auc: 0.7890 - loss: 0.5524 - val_acc: 0.7169 - val_auc: 0.7960 - val_loss: 0.5418\n",
      "Epoch 162/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7125 - auc: 0.7883 - loss: 0.5521 - val_acc: 0.7125 - val_auc: 0.7961 - val_loss: 0.5438\n",
      "Epoch 163/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7136 - auc: 0.7887 - loss: 0.5510 - val_acc: 0.7150 - val_auc: 0.7950 - val_loss: 0.5440\n",
      "Epoch 164/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7133 - auc: 0.7886 - loss: 0.5513 - val_acc: 0.7172 - val_auc: 0.7966 - val_loss: 0.5415\n",
      "Epoch 165/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7139 - auc: 0.7893 - loss: 0.5503 - val_acc: 0.7172 - val_auc: 0.7960 - val_loss: 0.5434\n",
      "Epoch 166/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7148 - auc: 0.7894 - loss: 0.5517 - val_acc: 0.7169 - val_auc: 0.7966 - val_loss: 0.5422\n",
      "Epoch 167/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7132 - auc: 0.7894 - loss: 0.5506 - val_acc: 0.7163 - val_auc: 0.7966 - val_loss: 0.5421\n",
      "Epoch 168/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7154 - auc: 0.7894 - loss: 0.5507 - val_acc: 0.7191 - val_auc: 0.7973 - val_loss: 0.5409\n",
      "Epoch 169/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7167 - auc: 0.7902 - loss: 0.5504 - val_acc: 0.7172 - val_auc: 0.7970 - val_loss: 0.5433\n",
      "Epoch 170/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7151 - auc: 0.7904 - loss: 0.5497 - val_acc: 0.7189 - val_auc: 0.7972 - val_loss: 0.5425\n",
      "Epoch 171/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7149 - auc: 0.7886 - loss: 0.5512 - val_acc: 0.7189 - val_auc: 0.7980 - val_loss: 0.5401\n",
      "Epoch 172/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7154 - auc: 0.7902 - loss: 0.5510 - val_acc: 0.7184 - val_auc: 0.7982 - val_loss: 0.5395\n",
      "Epoch 173/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7131 - auc: 0.7904 - loss: 0.5497 - val_acc: 0.7172 - val_auc: 0.7972 - val_loss: 0.5416\n",
      "Epoch 174/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7147 - auc: 0.7900 - loss: 0.5503 - val_acc: 0.7170 - val_auc: 0.7969 - val_loss: 0.5430\n",
      "Epoch 175/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7156 - auc: 0.7899 - loss: 0.5502 - val_acc: 0.7180 - val_auc: 0.7976 - val_loss: 0.5414\n",
      "Epoch 176/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7167 - auc: 0.7909 - loss: 0.5487 - val_acc: 0.7180 - val_auc: 0.7984 - val_loss: 0.5394\n",
      "Epoch 177/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7148 - auc: 0.7905 - loss: 0.5501 - val_acc: 0.7196 - val_auc: 0.7985 - val_loss: 0.5401\n",
      "Epoch 178/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7167 - auc: 0.7922 - loss: 0.5473 - val_acc: 0.7201 - val_auc: 0.7980 - val_loss: 0.5401\n",
      "Epoch 179/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7161 - auc: 0.7908 - loss: 0.5497 - val_acc: 0.7199 - val_auc: 0.7988 - val_loss: 0.5405\n",
      "Epoch 180/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7153 - auc: 0.7914 - loss: 0.5484 - val_acc: 0.7210 - val_auc: 0.7987 - val_loss: 0.5407\n",
      "Epoch 181/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7162 - auc: 0.7914 - loss: 0.5480 - val_acc: 0.7190 - val_auc: 0.7992 - val_loss: 0.5401\n",
      "Epoch 182/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7150 - auc: 0.7911 - loss: 0.5486 - val_acc: 0.7207 - val_auc: 0.7987 - val_loss: 0.5399\n",
      "Epoch 183/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7168 - auc: 0.7919 - loss: 0.5477 - val_acc: 0.7179 - val_auc: 0.7994 - val_loss: 0.5391\n",
      "Epoch 184/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7178 - auc: 0.7926 - loss: 0.5472 - val_acc: 0.7187 - val_auc: 0.7991 - val_loss: 0.5386\n",
      "Epoch 185/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7171 - auc: 0.7914 - loss: 0.5490 - val_acc: 0.7217 - val_auc: 0.7991 - val_loss: 0.5386\n",
      "Epoch 186/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7179 - auc: 0.7924 - loss: 0.5473 - val_acc: 0.7210 - val_auc: 0.7992 - val_loss: 0.5398\n",
      "Epoch 187/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7172 - auc: 0.7917 - loss: 0.5485 - val_acc: 0.7221 - val_auc: 0.7999 - val_loss: 0.5387\n",
      "Epoch 188/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7181 - auc: 0.7921 - loss: 0.5477 - val_acc: 0.7187 - val_auc: 0.8003 - val_loss: 0.5385\n",
      "Epoch 189/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7183 - auc: 0.7927 - loss: 0.5473 - val_acc: 0.7212 - val_auc: 0.7989 - val_loss: 0.5395\n",
      "Epoch 190/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7179 - auc: 0.7929 - loss: 0.5469 - val_acc: 0.7210 - val_auc: 0.8001 - val_loss: 0.5388\n",
      "Epoch 191/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7177 - auc: 0.7932 - loss: 0.5465 - val_acc: 0.7209 - val_auc: 0.8001 - val_loss: 0.5376\n",
      "Epoch 192/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7165 - auc: 0.7932 - loss: 0.5463 - val_acc: 0.7202 - val_auc: 0.7991 - val_loss: 0.5388\n",
      "Epoch 193/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7180 - auc: 0.7929 - loss: 0.5465 - val_acc: 0.7244 - val_auc: 0.8002 - val_loss: 0.5385\n",
      "Epoch 194/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7177 - auc: 0.7924 - loss: 0.5472 - val_acc: 0.7241 - val_auc: 0.8009 - val_loss: 0.5370\n",
      "Epoch 195/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7168 - auc: 0.7926 - loss: 0.5472 - val_acc: 0.7234 - val_auc: 0.8014 - val_loss: 0.5360\n",
      "Epoch 196/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7168 - auc: 0.7934 - loss: 0.5452 - val_acc: 0.7229 - val_auc: 0.8003 - val_loss: 0.5377\n",
      "Epoch 197/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7181 - auc: 0.7928 - loss: 0.5468 - val_acc: 0.7219 - val_auc: 0.8003 - val_loss: 0.5366\n",
      "Epoch 198/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7193 - auc: 0.7937 - loss: 0.5460 - val_acc: 0.7214 - val_auc: 0.8005 - val_loss: 0.5372\n",
      "Epoch 199/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7186 - auc: 0.7938 - loss: 0.5458 - val_acc: 0.7209 - val_auc: 0.8014 - val_loss: 0.5361\n",
      "Epoch 200/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7180 - auc: 0.7934 - loss: 0.5460 - val_acc: 0.7208 - val_auc: 0.8011 - val_loss: 0.5360\n",
      "Epoch 201/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7177 - auc: 0.7942 - loss: 0.5455 - val_acc: 0.7234 - val_auc: 0.8026 - val_loss: 0.5350\n",
      "Epoch 202/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7181 - auc: 0.7931 - loss: 0.5463 - val_acc: 0.7218 - val_auc: 0.8013 - val_loss: 0.5372\n",
      "Epoch 203/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7186 - auc: 0.7938 - loss: 0.5461 - val_acc: 0.7251 - val_auc: 0.8012 - val_loss: 0.5363\n",
      "Epoch 204/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7194 - auc: 0.7941 - loss: 0.5456 - val_acc: 0.7239 - val_auc: 0.8018 - val_loss: 0.5363\n",
      "Epoch 205/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7180 - auc: 0.7945 - loss: 0.5450 - val_acc: 0.7216 - val_auc: 0.8018 - val_loss: 0.5366\n",
      "Epoch 206/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7205 - auc: 0.7953 - loss: 0.5435 - val_acc: 0.7242 - val_auc: 0.8031 - val_loss: 0.5338\n",
      "Epoch 207/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7197 - auc: 0.7939 - loss: 0.5457 - val_acc: 0.7222 - val_auc: 0.8017 - val_loss: 0.5369\n",
      "Epoch 208/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7183 - auc: 0.7943 - loss: 0.5450 - val_acc: 0.7228 - val_auc: 0.8020 - val_loss: 0.5348\n",
      "Epoch 209/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7197 - auc: 0.7958 - loss: 0.5429 - val_acc: 0.7252 - val_auc: 0.8028 - val_loss: 0.5348\n",
      "Epoch 210/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7185 - auc: 0.7944 - loss: 0.5448 - val_acc: 0.7245 - val_auc: 0.8046 - val_loss: 0.5326\n",
      "Epoch 211/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7185 - auc: 0.7942 - loss: 0.5452 - val_acc: 0.7244 - val_auc: 0.8026 - val_loss: 0.5347\n",
      "Epoch 212/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7205 - auc: 0.7944 - loss: 0.5446 - val_acc: 0.7207 - val_auc: 0.8031 - val_loss: 0.5349\n",
      "Epoch 213/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7200 - auc: 0.7961 - loss: 0.5436 - val_acc: 0.7266 - val_auc: 0.8029 - val_loss: 0.5356\n",
      "Epoch 214/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7180 - auc: 0.7950 - loss: 0.5441 - val_acc: 0.7228 - val_auc: 0.8033 - val_loss: 0.5334\n",
      "Epoch 215/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7210 - auc: 0.7959 - loss: 0.5438 - val_acc: 0.7229 - val_auc: 0.8030 - val_loss: 0.5340\n",
      "Epoch 216/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7197 - auc: 0.7950 - loss: 0.5436 - val_acc: 0.7249 - val_auc: 0.8028 - val_loss: 0.5334\n",
      "Epoch 217/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7194 - auc: 0.7965 - loss: 0.5427 - val_acc: 0.7227 - val_auc: 0.8020 - val_loss: 0.5351\n",
      "Epoch 218/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7208 - auc: 0.7975 - loss: 0.5415 - val_acc: 0.7260 - val_auc: 0.8039 - val_loss: 0.5326\n",
      "Epoch 219/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7186 - auc: 0.7962 - loss: 0.5425 - val_acc: 0.7259 - val_auc: 0.8043 - val_loss: 0.5341\n",
      "Epoch 220/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7197 - auc: 0.7956 - loss: 0.5436 - val_acc: 0.7251 - val_auc: 0.8041 - val_loss: 0.5326\n",
      "Epoch 221/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7217 - auc: 0.7959 - loss: 0.5433 - val_acc: 0.7218 - val_auc: 0.8038 - val_loss: 0.5330\n",
      "Epoch 222/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7200 - auc: 0.7953 - loss: 0.5439 - val_acc: 0.7260 - val_auc: 0.8044 - val_loss: 0.5332\n",
      "Epoch 223/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7198 - auc: 0.7962 - loss: 0.5423 - val_acc: 0.7236 - val_auc: 0.8050 - val_loss: 0.5315\n",
      "Epoch 224/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7197 - auc: 0.7947 - loss: 0.5436 - val_acc: 0.7248 - val_auc: 0.8035 - val_loss: 0.5326\n",
      "Epoch 225/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7214 - auc: 0.7972 - loss: 0.5418 - val_acc: 0.7264 - val_auc: 0.8053 - val_loss: 0.5318\n",
      "Epoch 226/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7211 - auc: 0.7964 - loss: 0.5436 - val_acc: 0.7248 - val_auc: 0.8033 - val_loss: 0.5330\n",
      "Epoch 227/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7212 - auc: 0.7975 - loss: 0.5416 - val_acc: 0.7258 - val_auc: 0.8048 - val_loss: 0.5326\n",
      "Epoch 228/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7207 - auc: 0.7970 - loss: 0.5421 - val_acc: 0.7284 - val_auc: 0.8051 - val_loss: 0.5313\n",
      "Epoch 229/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7213 - auc: 0.7975 - loss: 0.5411 - val_acc: 0.7276 - val_auc: 0.8055 - val_loss: 0.5321\n",
      "Epoch 230/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7198 - auc: 0.7971 - loss: 0.5419 - val_acc: 0.7264 - val_auc: 0.8046 - val_loss: 0.5314\n",
      "Epoch 231/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7224 - auc: 0.7973 - loss: 0.5412 - val_acc: 0.7257 - val_auc: 0.8049 - val_loss: 0.5323\n",
      "Epoch 232/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7209 - auc: 0.7968 - loss: 0.5422 - val_acc: 0.7289 - val_auc: 0.8055 - val_loss: 0.5318\n",
      "Epoch 233/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7215 - auc: 0.7976 - loss: 0.5412 - val_acc: 0.7254 - val_auc: 0.8049 - val_loss: 0.5325\n",
      "Epoch 234/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7218 - auc: 0.7979 - loss: 0.5402 - val_acc: 0.7267 - val_auc: 0.8054 - val_loss: 0.5302\n",
      "Epoch 235/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7223 - auc: 0.7973 - loss: 0.5414 - val_acc: 0.7259 - val_auc: 0.8052 - val_loss: 0.5307\n",
      "Epoch 236/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7216 - auc: 0.7983 - loss: 0.5411 - val_acc: 0.7258 - val_auc: 0.8043 - val_loss: 0.5319\n",
      "Epoch 237/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7211 - auc: 0.7972 - loss: 0.5413 - val_acc: 0.7263 - val_auc: 0.8057 - val_loss: 0.5304\n",
      "Epoch 238/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7212 - auc: 0.7976 - loss: 0.5411 - val_acc: 0.7265 - val_auc: 0.8067 - val_loss: 0.5294\n",
      "Epoch 239/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7243 - auc: 0.7985 - loss: 0.5410 - val_acc: 0.7245 - val_auc: 0.8055 - val_loss: 0.5307\n",
      "Epoch 240/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7219 - auc: 0.7982 - loss: 0.5403 - val_acc: 0.7278 - val_auc: 0.8063 - val_loss: 0.5308\n",
      "Epoch 241/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7240 - auc: 0.7990 - loss: 0.5391 - val_acc: 0.7303 - val_auc: 0.8058 - val_loss: 0.5294\n",
      "Epoch 242/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7240 - auc: 0.7995 - loss: 0.5390 - val_acc: 0.7232 - val_auc: 0.8065 - val_loss: 0.5315\n",
      "Epoch 243/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7211 - auc: 0.7971 - loss: 0.5415 - val_acc: 0.7265 - val_auc: 0.8059 - val_loss: 0.5302\n",
      "Epoch 244/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7218 - auc: 0.7986 - loss: 0.5395 - val_acc: 0.7264 - val_auc: 0.8062 - val_loss: 0.5297\n",
      "Epoch 245/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7218 - auc: 0.7990 - loss: 0.5397 - val_acc: 0.7280 - val_auc: 0.8071 - val_loss: 0.5286\n",
      "Epoch 246/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7225 - auc: 0.7988 - loss: 0.5392 - val_acc: 0.7251 - val_auc: 0.8067 - val_loss: 0.5290\n",
      "Epoch 247/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7229 - auc: 0.7995 - loss: 0.5391 - val_acc: 0.7258 - val_auc: 0.8075 - val_loss: 0.5288\n",
      "Epoch 248/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7219 - auc: 0.7983 - loss: 0.5400 - val_acc: 0.7263 - val_auc: 0.8082 - val_loss: 0.5267\n",
      "Epoch 249/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7228 - auc: 0.7990 - loss: 0.5391 - val_acc: 0.7299 - val_auc: 0.8070 - val_loss: 0.5298\n",
      "Epoch 250/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7247 - auc: 0.7993 - loss: 0.5392 - val_acc: 0.7280 - val_auc: 0.8069 - val_loss: 0.5288\n",
      "Epoch 251/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7233 - auc: 0.7995 - loss: 0.5387 - val_acc: 0.7274 - val_auc: 0.8082 - val_loss: 0.5282\n",
      "Epoch 252/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7226 - auc: 0.7995 - loss: 0.5385 - val_acc: 0.7270 - val_auc: 0.8067 - val_loss: 0.5288\n",
      "Epoch 253/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7235 - auc: 0.8013 - loss: 0.5373 - val_acc: 0.7270 - val_auc: 0.8079 - val_loss: 0.5290\n",
      "Epoch 254/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7246 - auc: 0.8003 - loss: 0.5383 - val_acc: 0.7269 - val_auc: 0.8078 - val_loss: 0.5279\n",
      "Epoch 255/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7238 - auc: 0.7996 - loss: 0.5390 - val_acc: 0.7310 - val_auc: 0.8082 - val_loss: 0.5278\n",
      "Epoch 256/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7248 - auc: 0.8005 - loss: 0.5381 - val_acc: 0.7290 - val_auc: 0.8080 - val_loss: 0.5267\n",
      "Epoch 257/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7240 - auc: 0.8006 - loss: 0.5378 - val_acc: 0.7309 - val_auc: 0.8076 - val_loss: 0.5286\n",
      "Epoch 258/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7246 - auc: 0.8013 - loss: 0.5369 - val_acc: 0.7277 - val_auc: 0.8062 - val_loss: 0.5284\n",
      "Epoch 259/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7241 - auc: 0.8005 - loss: 0.5371 - val_acc: 0.7296 - val_auc: 0.8082 - val_loss: 0.5273\n",
      "Epoch 260/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7240 - auc: 0.8000 - loss: 0.5377 - val_acc: 0.7296 - val_auc: 0.8095 - val_loss: 0.5260\n",
      "Epoch 261/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7256 - auc: 0.8001 - loss: 0.5378 - val_acc: 0.7300 - val_auc: 0.8081 - val_loss: 0.5281\n",
      "Epoch 262/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7246 - auc: 0.8000 - loss: 0.5376 - val_acc: 0.7272 - val_auc: 0.8079 - val_loss: 0.5274\n",
      "Epoch 263/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7225 - auc: 0.8005 - loss: 0.5380 - val_acc: 0.7275 - val_auc: 0.8080 - val_loss: 0.5289\n",
      "Epoch 264/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7248 - auc: 0.8007 - loss: 0.5370 - val_acc: 0.7280 - val_auc: 0.8093 - val_loss: 0.5253\n",
      "Epoch 265/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7250 - auc: 0.8017 - loss: 0.5359 - val_acc: 0.7296 - val_auc: 0.8098 - val_loss: 0.5258\n",
      "Epoch 266/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7234 - auc: 0.8007 - loss: 0.5373 - val_acc: 0.7280 - val_auc: 0.8089 - val_loss: 0.5266\n",
      "Epoch 267/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7268 - auc: 0.8022 - loss: 0.5360 - val_acc: 0.7283 - val_auc: 0.8096 - val_loss: 0.5261\n",
      "Epoch 268/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7242 - auc: 0.8011 - loss: 0.5375 - val_acc: 0.7286 - val_auc: 0.8094 - val_loss: 0.5257\n",
      "Epoch 269/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7256 - auc: 0.8024 - loss: 0.5358 - val_acc: 0.7302 - val_auc: 0.8094 - val_loss: 0.5261\n",
      "Epoch 270/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7254 - auc: 0.8026 - loss: 0.5347 - val_acc: 0.7297 - val_auc: 0.8085 - val_loss: 0.5258\n",
      "Epoch 271/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7244 - auc: 0.8010 - loss: 0.5371 - val_acc: 0.7315 - val_auc: 0.8105 - val_loss: 0.5241\n",
      "Epoch 272/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7249 - auc: 0.8012 - loss: 0.5364 - val_acc: 0.7299 - val_auc: 0.8094 - val_loss: 0.5257\n",
      "Epoch 273/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7252 - auc: 0.8003 - loss: 0.5379 - val_acc: 0.7309 - val_auc: 0.8096 - val_loss: 0.5256\n",
      "Epoch 274/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7264 - auc: 0.8022 - loss: 0.5361 - val_acc: 0.7305 - val_auc: 0.8092 - val_loss: 0.5254\n",
      "Epoch 275/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7246 - auc: 0.8015 - loss: 0.5355 - val_acc: 0.7320 - val_auc: 0.8108 - val_loss: 0.5250\n",
      "Epoch 276/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7256 - auc: 0.8020 - loss: 0.5352 - val_acc: 0.7317 - val_auc: 0.8113 - val_loss: 0.5243\n",
      "Epoch 277/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7257 - auc: 0.8031 - loss: 0.5348 - val_acc: 0.7320 - val_auc: 0.8102 - val_loss: 0.5243\n",
      "Epoch 278/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7253 - auc: 0.8023 - loss: 0.5354 - val_acc: 0.7295 - val_auc: 0.8110 - val_loss: 0.5231\n",
      "Epoch 279/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7267 - auc: 0.8021 - loss: 0.5355 - val_acc: 0.7315 - val_auc: 0.8115 - val_loss: 0.5236\n",
      "Epoch 280/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7269 - auc: 0.8031 - loss: 0.5346 - val_acc: 0.7315 - val_auc: 0.8094 - val_loss: 0.5248\n",
      "Epoch 281/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7248 - auc: 0.8021 - loss: 0.5348 - val_acc: 0.7322 - val_auc: 0.8112 - val_loss: 0.5239\n",
      "Epoch 282/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7258 - auc: 0.8021 - loss: 0.5355 - val_acc: 0.7321 - val_auc: 0.8106 - val_loss: 0.5236\n",
      "Epoch 283/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7247 - auc: 0.8018 - loss: 0.5358 - val_acc: 0.7307 - val_auc: 0.8114 - val_loss: 0.5231\n",
      "Epoch 284/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7245 - auc: 0.8014 - loss: 0.5367 - val_acc: 0.7315 - val_auc: 0.8105 - val_loss: 0.5239\n",
      "Epoch 285/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7267 - auc: 0.8043 - loss: 0.5334 - val_acc: 0.7333 - val_auc: 0.8112 - val_loss: 0.5242\n",
      "Epoch 286/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7259 - auc: 0.8027 - loss: 0.5357 - val_acc: 0.7325 - val_auc: 0.8122 - val_loss: 0.5223\n",
      "Epoch 287/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7269 - auc: 0.8032 - loss: 0.5344 - val_acc: 0.7328 - val_auc: 0.8110 - val_loss: 0.5234\n",
      "Epoch 288/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7257 - auc: 0.8034 - loss: 0.5348 - val_acc: 0.7321 - val_auc: 0.8105 - val_loss: 0.5237\n",
      "Epoch 289/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7249 - auc: 0.8019 - loss: 0.5353 - val_acc: 0.7318 - val_auc: 0.8101 - val_loss: 0.5251\n",
      "Epoch 290/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7261 - auc: 0.8039 - loss: 0.5339 - val_acc: 0.7306 - val_auc: 0.8128 - val_loss: 0.5214\n",
      "Epoch 291/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7263 - auc: 0.8040 - loss: 0.5330 - val_acc: 0.7324 - val_auc: 0.8135 - val_loss: 0.5213\n",
      "Epoch 292/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7251 - auc: 0.8032 - loss: 0.5338 - val_acc: 0.7333 - val_auc: 0.8130 - val_loss: 0.5216\n",
      "Epoch 293/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7272 - auc: 0.8035 - loss: 0.5342 - val_acc: 0.7331 - val_auc: 0.8120 - val_loss: 0.5217\n",
      "Epoch 294/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7270 - auc: 0.8044 - loss: 0.5331 - val_acc: 0.7320 - val_auc: 0.8123 - val_loss: 0.5227\n",
      "Epoch 295/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7266 - auc: 0.8026 - loss: 0.5345 - val_acc: 0.7314 - val_auc: 0.8120 - val_loss: 0.5221\n",
      "Epoch 296/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7278 - auc: 0.8043 - loss: 0.5330 - val_acc: 0.7336 - val_auc: 0.8128 - val_loss: 0.5222\n",
      "Epoch 297/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7274 - auc: 0.8037 - loss: 0.5337 - val_acc: 0.7333 - val_auc: 0.8119 - val_loss: 0.5244\n",
      "Epoch 298/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7256 - auc: 0.8031 - loss: 0.5341 - val_acc: 0.7308 - val_auc: 0.8117 - val_loss: 0.5226\n",
      "Epoch 299/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7277 - auc: 0.8042 - loss: 0.5331 - val_acc: 0.7316 - val_auc: 0.8114 - val_loss: 0.5216\n",
      "Epoch 300/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7270 - auc: 0.8040 - loss: 0.5336 - val_acc: 0.7314 - val_auc: 0.8123 - val_loss: 0.5216\n",
      "Epoch 301/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7273 - auc: 0.8042 - loss: 0.5324 - val_acc: 0.7321 - val_auc: 0.8121 - val_loss: 0.5219\n",
      "Epoch 302/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7271 - auc: 0.8039 - loss: 0.5324 - val_acc: 0.7336 - val_auc: 0.8123 - val_loss: 0.5219\n",
      "Epoch 303/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7286 - auc: 0.8050 - loss: 0.5319 - val_acc: 0.7309 - val_auc: 0.8129 - val_loss: 0.5206\n",
      "Epoch 304/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7272 - auc: 0.8040 - loss: 0.5329 - val_acc: 0.7341 - val_auc: 0.8133 - val_loss: 0.5205\n",
      "Epoch 305/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7268 - auc: 0.8037 - loss: 0.5341 - val_acc: 0.7346 - val_auc: 0.8139 - val_loss: 0.5194\n",
      "Epoch 306/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7277 - auc: 0.8047 - loss: 0.5324 - val_acc: 0.7324 - val_auc: 0.8138 - val_loss: 0.5198\n",
      "Epoch 307/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7281 - auc: 0.8057 - loss: 0.5314 - val_acc: 0.7306 - val_auc: 0.8125 - val_loss: 0.5207\n",
      "Epoch 308/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7274 - auc: 0.8042 - loss: 0.5337 - val_acc: 0.7330 - val_auc: 0.8144 - val_loss: 0.5197\n",
      "Epoch 309/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7279 - auc: 0.8046 - loss: 0.5317 - val_acc: 0.7316 - val_auc: 0.8125 - val_loss: 0.5211\n",
      "Epoch 310/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7270 - auc: 0.8051 - loss: 0.5313 - val_acc: 0.7347 - val_auc: 0.8135 - val_loss: 0.5204\n",
      "Epoch 311/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7276 - auc: 0.8043 - loss: 0.5328 - val_acc: 0.7354 - val_auc: 0.8138 - val_loss: 0.5207\n",
      "Epoch 312/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7272 - auc: 0.8053 - loss: 0.5314 - val_acc: 0.7334 - val_auc: 0.8134 - val_loss: 0.5202\n",
      "Epoch 313/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7273 - auc: 0.8046 - loss: 0.5329 - val_acc: 0.7350 - val_auc: 0.8132 - val_loss: 0.5212\n",
      "Epoch 314/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7300 - auc: 0.8056 - loss: 0.5316 - val_acc: 0.7334 - val_auc: 0.8142 - val_loss: 0.5203\n",
      "Epoch 315/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7297 - auc: 0.8057 - loss: 0.5317 - val_acc: 0.7326 - val_auc: 0.8130 - val_loss: 0.5213\n",
      "Epoch 316/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7288 - auc: 0.8050 - loss: 0.5320 - val_acc: 0.7325 - val_auc: 0.8139 - val_loss: 0.5195\n",
      "Epoch 317/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7294 - auc: 0.8068 - loss: 0.5292 - val_acc: 0.7336 - val_auc: 0.8131 - val_loss: 0.5208\n",
      "Epoch 318/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7307 - auc: 0.8065 - loss: 0.5304 - val_acc: 0.7337 - val_auc: 0.8141 - val_loss: 0.5218\n",
      "Epoch 319/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7296 - auc: 0.8068 - loss: 0.5299 - val_acc: 0.7346 - val_auc: 0.8135 - val_loss: 0.5198\n",
      "Epoch 320/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7293 - auc: 0.8060 - loss: 0.5306 - val_acc: 0.7342 - val_auc: 0.8142 - val_loss: 0.5204\n",
      "Epoch 321/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7293 - auc: 0.8062 - loss: 0.5304 - val_acc: 0.7343 - val_auc: 0.8150 - val_loss: 0.5187\n",
      "Epoch 322/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7292 - auc: 0.8058 - loss: 0.5303 - val_acc: 0.7324 - val_auc: 0.8141 - val_loss: 0.5195\n",
      "Epoch 323/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7294 - auc: 0.8059 - loss: 0.5312 - val_acc: 0.7333 - val_auc: 0.8142 - val_loss: 0.5192\n",
      "Epoch 324/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7288 - auc: 0.8056 - loss: 0.5306 - val_acc: 0.7340 - val_auc: 0.8152 - val_loss: 0.5179\n",
      "Epoch 325/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7291 - auc: 0.8071 - loss: 0.5296 - val_acc: 0.7339 - val_auc: 0.8144 - val_loss: 0.5191\n",
      "Epoch 326/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7259 - auc: 0.8047 - loss: 0.5323 - val_acc: 0.7345 - val_auc: 0.8150 - val_loss: 0.5182\n",
      "Epoch 327/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7279 - auc: 0.8055 - loss: 0.5317 - val_acc: 0.7349 - val_auc: 0.8158 - val_loss: 0.5179\n",
      "Epoch 328/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7283 - auc: 0.8054 - loss: 0.5316 - val_acc: 0.7321 - val_auc: 0.8137 - val_loss: 0.5194\n",
      "Epoch 329/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7309 - auc: 0.8068 - loss: 0.5298 - val_acc: 0.7313 - val_auc: 0.8154 - val_loss: 0.5178\n",
      "Epoch 330/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7294 - auc: 0.8061 - loss: 0.5300 - val_acc: 0.7351 - val_auc: 0.8159 - val_loss: 0.5172\n",
      "Epoch 331/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7288 - auc: 0.8065 - loss: 0.5296 - val_acc: 0.7358 - val_auc: 0.8150 - val_loss: 0.5178\n",
      "Epoch 332/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7312 - auc: 0.8071 - loss: 0.5292 - val_acc: 0.7335 - val_auc: 0.8148 - val_loss: 0.5189\n",
      "Epoch 333/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7288 - auc: 0.8066 - loss: 0.5298 - val_acc: 0.7354 - val_auc: 0.8167 - val_loss: 0.5161\n",
      "Epoch 334/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7278 - auc: 0.8059 - loss: 0.5308 - val_acc: 0.7374 - val_auc: 0.8155 - val_loss: 0.5172\n",
      "Epoch 335/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7294 - auc: 0.8066 - loss: 0.5299 - val_acc: 0.7343 - val_auc: 0.8159 - val_loss: 0.5196\n",
      "Epoch 336/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7293 - auc: 0.8072 - loss: 0.5291 - val_acc: 0.7350 - val_auc: 0.8149 - val_loss: 0.5174\n",
      "Epoch 337/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7282 - auc: 0.8055 - loss: 0.5307 - val_acc: 0.7349 - val_auc: 0.8151 - val_loss: 0.5184\n",
      "Epoch 338/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7306 - auc: 0.8076 - loss: 0.5293 - val_acc: 0.7331 - val_auc: 0.8151 - val_loss: 0.5168\n",
      "Epoch 339/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7299 - auc: 0.8072 - loss: 0.5293 - val_acc: 0.7374 - val_auc: 0.8166 - val_loss: 0.5157\n",
      "Epoch 340/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7280 - auc: 0.8066 - loss: 0.5295 - val_acc: 0.7358 - val_auc: 0.8160 - val_loss: 0.5171\n",
      "Epoch 341/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7297 - auc: 0.8096 - loss: 0.5264 - val_acc: 0.7370 - val_auc: 0.8166 - val_loss: 0.5165\n",
      "Epoch 342/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7289 - auc: 0.8067 - loss: 0.5298 - val_acc: 0.7365 - val_auc: 0.8157 - val_loss: 0.5170\n",
      "Epoch 343/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7281 - auc: 0.8057 - loss: 0.5308 - val_acc: 0.7357 - val_auc: 0.8171 - val_loss: 0.5158\n",
      "Epoch 344/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7306 - auc: 0.8087 - loss: 0.5275 - val_acc: 0.7352 - val_auc: 0.8167 - val_loss: 0.5155\n",
      "Epoch 345/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7317 - auc: 0.8081 - loss: 0.5290 - val_acc: 0.7347 - val_auc: 0.8155 - val_loss: 0.5169\n",
      "Epoch 346/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7292 - auc: 0.8073 - loss: 0.5291 - val_acc: 0.7370 - val_auc: 0.8163 - val_loss: 0.5168\n",
      "Epoch 347/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7285 - auc: 0.8066 - loss: 0.5299 - val_acc: 0.7347 - val_auc: 0.8165 - val_loss: 0.5164\n",
      "Epoch 348/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7308 - auc: 0.8084 - loss: 0.5287 - val_acc: 0.7355 - val_auc: 0.8171 - val_loss: 0.5174\n",
      "Epoch 349/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7301 - auc: 0.8079 - loss: 0.5276 - val_acc: 0.7339 - val_auc: 0.8139 - val_loss: 0.5186\n",
      "Epoch 350/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7308 - auc: 0.8079 - loss: 0.5286 - val_acc: 0.7379 - val_auc: 0.8165 - val_loss: 0.5163\n",
      "Epoch 351/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7302 - auc: 0.8067 - loss: 0.5297 - val_acc: 0.7355 - val_auc: 0.8168 - val_loss: 0.5161\n",
      "Epoch 352/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7307 - auc: 0.8084 - loss: 0.5277 - val_acc: 0.7369 - val_auc: 0.8163 - val_loss: 0.5157\n",
      "Epoch 353/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7304 - auc: 0.8091 - loss: 0.5268 - val_acc: 0.7348 - val_auc: 0.8172 - val_loss: 0.5162\n",
      "Epoch 354/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7313 - auc: 0.8081 - loss: 0.5271 - val_acc: 0.7364 - val_auc: 0.8165 - val_loss: 0.5163\n",
      "Epoch 355/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7315 - auc: 0.8086 - loss: 0.5285 - val_acc: 0.7354 - val_auc: 0.8165 - val_loss: 0.5161\n",
      "Epoch 356/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7307 - auc: 0.8081 - loss: 0.5277 - val_acc: 0.7362 - val_auc: 0.8184 - val_loss: 0.5137\n",
      "Epoch 357/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7322 - auc: 0.8095 - loss: 0.5267 - val_acc: 0.7374 - val_auc: 0.8180 - val_loss: 0.5149\n",
      "Epoch 358/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7278 - auc: 0.8065 - loss: 0.5292 - val_acc: 0.7368 - val_auc: 0.8187 - val_loss: 0.5133\n",
      "Epoch 359/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7324 - auc: 0.8079 - loss: 0.5281 - val_acc: 0.7358 - val_auc: 0.8169 - val_loss: 0.5164\n",
      "Epoch 360/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7329 - auc: 0.8097 - loss: 0.5260 - val_acc: 0.7358 - val_auc: 0.8175 - val_loss: 0.5160\n",
      "Epoch 361/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7321 - auc: 0.8092 - loss: 0.5266 - val_acc: 0.7374 - val_auc: 0.8177 - val_loss: 0.5149\n",
      "Epoch 362/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7326 - auc: 0.8096 - loss: 0.5271 - val_acc: 0.7364 - val_auc: 0.8180 - val_loss: 0.5166\n",
      "Epoch 363/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7329 - auc: 0.8090 - loss: 0.5264 - val_acc: 0.7348 - val_auc: 0.8178 - val_loss: 0.5143\n",
      "Epoch 364/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7332 - auc: 0.8097 - loss: 0.5259 - val_acc: 0.7396 - val_auc: 0.8201 - val_loss: 0.5127\n",
      "Epoch 365/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7304 - auc: 0.8077 - loss: 0.5294 - val_acc: 0.7367 - val_auc: 0.8182 - val_loss: 0.5156\n",
      "Epoch 366/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7317 - auc: 0.8080 - loss: 0.5288 - val_acc: 0.7392 - val_auc: 0.8182 - val_loss: 0.5140\n",
      "Epoch 367/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7315 - auc: 0.8087 - loss: 0.5275 - val_acc: 0.7382 - val_auc: 0.8185 - val_loss: 0.5133\n",
      "Epoch 368/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7319 - auc: 0.8094 - loss: 0.5271 - val_acc: 0.7383 - val_auc: 0.8190 - val_loss: 0.5143\n",
      "Epoch 369/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7312 - auc: 0.8096 - loss: 0.5258 - val_acc: 0.7354 - val_auc: 0.8192 - val_loss: 0.5143\n",
      "Epoch 370/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7315 - auc: 0.8108 - loss: 0.5251 - val_acc: 0.7373 - val_auc: 0.8190 - val_loss: 0.5131\n",
      "Epoch 371/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7309 - auc: 0.8084 - loss: 0.5268 - val_acc: 0.7379 - val_auc: 0.8187 - val_loss: 0.5131\n",
      "Epoch 372/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7323 - auc: 0.8097 - loss: 0.5267 - val_acc: 0.7369 - val_auc: 0.8187 - val_loss: 0.5149\n",
      "Epoch 373/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7311 - auc: 0.8080 - loss: 0.5283 - val_acc: 0.7376 - val_auc: 0.8185 - val_loss: 0.5143\n",
      "Epoch 374/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7330 - auc: 0.8101 - loss: 0.5259 - val_acc: 0.7380 - val_auc: 0.8186 - val_loss: 0.5151\n",
      "Epoch 375/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7338 - auc: 0.8106 - loss: 0.5247 - val_acc: 0.7384 - val_auc: 0.8193 - val_loss: 0.5118\n",
      "Epoch 376/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7335 - auc: 0.8093 - loss: 0.5264 - val_acc: 0.7405 - val_auc: 0.8206 - val_loss: 0.5115\n",
      "Epoch 377/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7332 - auc: 0.8095 - loss: 0.5263 - val_acc: 0.7362 - val_auc: 0.8187 - val_loss: 0.5148\n",
      "Epoch 378/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7316 - auc: 0.8097 - loss: 0.5261 - val_acc: 0.7368 - val_auc: 0.8185 - val_loss: 0.5146\n",
      "Epoch 379/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7341 - auc: 0.8091 - loss: 0.5261 - val_acc: 0.7398 - val_auc: 0.8187 - val_loss: 0.5138\n",
      "Epoch 380/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7323 - auc: 0.8106 - loss: 0.5260 - val_acc: 0.7363 - val_auc: 0.8186 - val_loss: 0.5126\n",
      "Epoch 381/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7310 - auc: 0.8093 - loss: 0.5257 - val_acc: 0.7390 - val_auc: 0.8194 - val_loss: 0.5125\n",
      "Epoch 382/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7320 - auc: 0.8093 - loss: 0.5255 - val_acc: 0.7393 - val_auc: 0.8193 - val_loss: 0.5133\n",
      "Epoch 383/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7331 - auc: 0.8098 - loss: 0.5255 - val_acc: 0.7375 - val_auc: 0.8199 - val_loss: 0.5124\n",
      "Epoch 384/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7322 - auc: 0.8109 - loss: 0.5246 - val_acc: 0.7380 - val_auc: 0.8200 - val_loss: 0.5126\n",
      "Epoch 385/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7325 - auc: 0.8100 - loss: 0.5259 - val_acc: 0.7403 - val_auc: 0.8206 - val_loss: 0.5131\n",
      "Epoch 386/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7328 - auc: 0.8107 - loss: 0.5254 - val_acc: 0.7389 - val_auc: 0.8175 - val_loss: 0.5140\n",
      "Epoch 387/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7337 - auc: 0.8114 - loss: 0.5244 - val_acc: 0.7399 - val_auc: 0.8205 - val_loss: 0.5108\n",
      "Epoch 388/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7322 - auc: 0.8097 - loss: 0.5265 - val_acc: 0.7386 - val_auc: 0.8198 - val_loss: 0.5120\n",
      "Epoch 389/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7338 - auc: 0.8115 - loss: 0.5246 - val_acc: 0.7363 - val_auc: 0.8188 - val_loss: 0.5130\n",
      "Epoch 390/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7332 - auc: 0.8111 - loss: 0.5245 - val_acc: 0.7379 - val_auc: 0.8189 - val_loss: 0.5132\n",
      "Epoch 391/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7349 - auc: 0.8112 - loss: 0.5241 - val_acc: 0.7393 - val_auc: 0.8211 - val_loss: 0.5106\n",
      "Epoch 392/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7329 - auc: 0.8103 - loss: 0.5241 - val_acc: 0.7386 - val_auc: 0.8202 - val_loss: 0.5113\n",
      "Epoch 393/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7341 - auc: 0.8112 - loss: 0.5242 - val_acc: 0.7413 - val_auc: 0.8200 - val_loss: 0.5120\n",
      "Epoch 394/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7326 - auc: 0.8108 - loss: 0.5247 - val_acc: 0.7380 - val_auc: 0.8194 - val_loss: 0.5129\n",
      "Epoch 395/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7353 - auc: 0.8114 - loss: 0.5243 - val_acc: 0.7400 - val_auc: 0.8206 - val_loss: 0.5103\n",
      "Epoch 396/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7337 - auc: 0.8117 - loss: 0.5230 - val_acc: 0.7370 - val_auc: 0.8197 - val_loss: 0.5116\n",
      "Epoch 397/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7324 - auc: 0.8113 - loss: 0.5240 - val_acc: 0.7383 - val_auc: 0.8212 - val_loss: 0.5105\n",
      "Epoch 398/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7324 - auc: 0.8111 - loss: 0.5244 - val_acc: 0.7382 - val_auc: 0.8214 - val_loss: 0.5108\n",
      "Epoch 399/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7317 - auc: 0.8116 - loss: 0.5246 - val_acc: 0.7397 - val_auc: 0.8214 - val_loss: 0.5111\n",
      "Epoch 400/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7334 - auc: 0.8111 - loss: 0.5257 - val_acc: 0.7379 - val_auc: 0.8210 - val_loss: 0.5107\n",
      "Epoch 401/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7344 - auc: 0.8104 - loss: 0.5254 - val_acc: 0.7361 - val_auc: 0.8218 - val_loss: 0.5101\n",
      "Epoch 402/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7330 - auc: 0.8107 - loss: 0.5254 - val_acc: 0.7376 - val_auc: 0.8203 - val_loss: 0.5102\n",
      "Epoch 403/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7332 - auc: 0.8115 - loss: 0.5241 - val_acc: 0.7401 - val_auc: 0.8209 - val_loss: 0.5106\n",
      "Epoch 404/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7327 - auc: 0.8109 - loss: 0.5242 - val_acc: 0.7392 - val_auc: 0.8222 - val_loss: 0.5095\n",
      "Epoch 405/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7338 - auc: 0.8121 - loss: 0.5228 - val_acc: 0.7385 - val_auc: 0.8219 - val_loss: 0.5092\n",
      "Epoch 406/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7337 - auc: 0.8116 - loss: 0.5235 - val_acc: 0.7388 - val_auc: 0.8217 - val_loss: 0.5101\n",
      "Epoch 407/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7334 - auc: 0.8104 - loss: 0.5245 - val_acc: 0.7395 - val_auc: 0.8218 - val_loss: 0.5101\n",
      "Epoch 408/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7326 - auc: 0.8113 - loss: 0.5233 - val_acc: 0.7388 - val_auc: 0.8200 - val_loss: 0.5106\n",
      "Epoch 409/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7325 - auc: 0.8109 - loss: 0.5237 - val_acc: 0.7390 - val_auc: 0.8214 - val_loss: 0.5100\n",
      "Epoch 410/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7327 - auc: 0.8111 - loss: 0.5241 - val_acc: 0.7420 - val_auc: 0.8224 - val_loss: 0.5087\n",
      "Epoch 411/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7336 - auc: 0.8111 - loss: 0.5241 - val_acc: 0.7399 - val_auc: 0.8213 - val_loss: 0.5107\n",
      "Epoch 412/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7330 - auc: 0.8129 - loss: 0.5231 - val_acc: 0.7406 - val_auc: 0.8222 - val_loss: 0.5106\n",
      "Epoch 413/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7339 - auc: 0.8123 - loss: 0.5228 - val_acc: 0.7378 - val_auc: 0.8196 - val_loss: 0.5131\n",
      "Epoch 414/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7341 - auc: 0.8107 - loss: 0.5261 - val_acc: 0.7397 - val_auc: 0.8223 - val_loss: 0.5093\n",
      "Epoch 415/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7346 - auc: 0.8126 - loss: 0.5220 - val_acc: 0.7397 - val_auc: 0.8230 - val_loss: 0.5080\n",
      "Epoch 416/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7357 - auc: 0.8134 - loss: 0.5215 - val_acc: 0.7393 - val_auc: 0.8225 - val_loss: 0.5088\n",
      "Epoch 417/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7345 - auc: 0.8115 - loss: 0.5234 - val_acc: 0.7384 - val_auc: 0.8219 - val_loss: 0.5099\n",
      "Epoch 418/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7355 - auc: 0.8130 - loss: 0.5217 - val_acc: 0.7396 - val_auc: 0.8216 - val_loss: 0.5097\n",
      "Epoch 419/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7329 - auc: 0.8117 - loss: 0.5231 - val_acc: 0.7392 - val_auc: 0.8224 - val_loss: 0.5081\n",
      "Epoch 420/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7346 - auc: 0.8120 - loss: 0.5226 - val_acc: 0.7373 - val_auc: 0.8218 - val_loss: 0.5094\n",
      "Epoch 421/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7344 - auc: 0.8124 - loss: 0.5225 - val_acc: 0.7414 - val_auc: 0.8229 - val_loss: 0.5084\n",
      "Epoch 422/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7372 - auc: 0.8131 - loss: 0.5220 - val_acc: 0.7395 - val_auc: 0.8220 - val_loss: 0.5097\n",
      "Epoch 423/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7337 - auc: 0.8126 - loss: 0.5220 - val_acc: 0.7390 - val_auc: 0.8221 - val_loss: 0.5104\n",
      "Epoch 424/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7360 - auc: 0.8139 - loss: 0.5214 - val_acc: 0.7404 - val_auc: 0.8223 - val_loss: 0.5085\n",
      "Epoch 425/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7343 - auc: 0.8133 - loss: 0.5221 - val_acc: 0.7408 - val_auc: 0.8214 - val_loss: 0.5100\n",
      "Epoch 426/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7382 - auc: 0.8140 - loss: 0.5213 - val_acc: 0.7409 - val_auc: 0.8235 - val_loss: 0.5084\n",
      "Epoch 427/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7327 - auc: 0.8123 - loss: 0.5229 - val_acc: 0.7381 - val_auc: 0.8217 - val_loss: 0.5083\n",
      "Epoch 428/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7352 - auc: 0.8127 - loss: 0.5228 - val_acc: 0.7369 - val_auc: 0.8227 - val_loss: 0.5082\n",
      "Epoch 429/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7346 - auc: 0.8128 - loss: 0.5224 - val_acc: 0.7405 - val_auc: 0.8218 - val_loss: 0.5086\n",
      "Epoch 430/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7353 - auc: 0.8120 - loss: 0.5228 - val_acc: 0.7382 - val_auc: 0.8226 - val_loss: 0.5077\n",
      "Epoch 431/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7356 - auc: 0.8147 - loss: 0.5198 - val_acc: 0.7413 - val_auc: 0.8231 - val_loss: 0.5080\n",
      "Epoch 432/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7346 - auc: 0.8128 - loss: 0.5211 - val_acc: 0.7416 - val_auc: 0.8239 - val_loss: 0.5065\n",
      "Epoch 433/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7355 - auc: 0.8141 - loss: 0.5209 - val_acc: 0.7394 - val_auc: 0.8226 - val_loss: 0.5089\n",
      "Epoch 434/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7349 - auc: 0.8134 - loss: 0.5214 - val_acc: 0.7389 - val_auc: 0.8230 - val_loss: 0.5072\n",
      "Epoch 435/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7357 - auc: 0.8132 - loss: 0.5221 - val_acc: 0.7407 - val_auc: 0.8226 - val_loss: 0.5091\n",
      "Epoch 436/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7349 - auc: 0.8123 - loss: 0.5224 - val_acc: 0.7397 - val_auc: 0.8228 - val_loss: 0.5085\n",
      "Epoch 437/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7364 - auc: 0.8139 - loss: 0.5211 - val_acc: 0.7429 - val_auc: 0.8227 - val_loss: 0.5096\n",
      "Epoch 438/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7371 - auc: 0.8136 - loss: 0.5216 - val_acc: 0.7418 - val_auc: 0.8223 - val_loss: 0.5087\n",
      "Epoch 439/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7342 - auc: 0.8134 - loss: 0.5219 - val_acc: 0.7399 - val_auc: 0.8228 - val_loss: 0.5072\n",
      "Epoch 440/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7360 - auc: 0.8153 - loss: 0.5191 - val_acc: 0.7397 - val_auc: 0.8238 - val_loss: 0.5084\n",
      "Epoch 441/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7362 - auc: 0.8132 - loss: 0.5216 - val_acc: 0.7437 - val_auc: 0.8236 - val_loss: 0.5070\n",
      "Epoch 442/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7367 - auc: 0.8134 - loss: 0.5213 - val_acc: 0.7431 - val_auc: 0.8217 - val_loss: 0.5099\n",
      "Epoch 443/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7356 - auc: 0.8128 - loss: 0.5229 - val_acc: 0.7407 - val_auc: 0.8236 - val_loss: 0.5075\n",
      "Epoch 444/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7364 - auc: 0.8148 - loss: 0.5200 - val_acc: 0.7438 - val_auc: 0.8245 - val_loss: 0.5056\n",
      "Epoch 445/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7359 - auc: 0.8139 - loss: 0.5200 - val_acc: 0.7429 - val_auc: 0.8242 - val_loss: 0.5069\n",
      "Epoch 446/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7353 - auc: 0.8141 - loss: 0.5196 - val_acc: 0.7415 - val_auc: 0.8238 - val_loss: 0.5075\n",
      "Epoch 447/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7360 - auc: 0.8139 - loss: 0.5207 - val_acc: 0.7410 - val_auc: 0.8236 - val_loss: 0.5079\n",
      "Epoch 448/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7362 - auc: 0.8142 - loss: 0.5203 - val_acc: 0.7428 - val_auc: 0.8232 - val_loss: 0.5070\n",
      "Epoch 449/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7361 - auc: 0.8143 - loss: 0.5199 - val_acc: 0.7403 - val_auc: 0.8241 - val_loss: 0.5063\n",
      "Epoch 450/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7365 - auc: 0.8139 - loss: 0.5203 - val_acc: 0.7419 - val_auc: 0.8227 - val_loss: 0.5074\n",
      "Epoch 451/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7354 - auc: 0.8129 - loss: 0.5217 - val_acc: 0.7439 - val_auc: 0.8243 - val_loss: 0.5067\n",
      "Epoch 452/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7366 - auc: 0.8159 - loss: 0.5185 - val_acc: 0.7423 - val_auc: 0.8239 - val_loss: 0.5070\n",
      "Epoch 453/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7385 - auc: 0.8155 - loss: 0.5194 - val_acc: 0.7406 - val_auc: 0.8229 - val_loss: 0.5080\n",
      "Epoch 454/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7367 - auc: 0.8150 - loss: 0.5190 - val_acc: 0.7420 - val_auc: 0.8244 - val_loss: 0.5074\n",
      "Epoch 455/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7360 - auc: 0.8134 - loss: 0.5212 - val_acc: 0.7432 - val_auc: 0.8242 - val_loss: 0.5067\n",
      "Epoch 456/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7356 - auc: 0.8148 - loss: 0.5192 - val_acc: 0.7427 - val_auc: 0.8249 - val_loss: 0.5071\n",
      "Epoch 457/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7370 - auc: 0.8147 - loss: 0.5192 - val_acc: 0.7421 - val_auc: 0.8244 - val_loss: 0.5065\n",
      "Epoch 458/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7360 - auc: 0.8142 - loss: 0.5210 - val_acc: 0.7420 - val_auc: 0.8250 - val_loss: 0.5048\n",
      "Epoch 459/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7367 - auc: 0.8154 - loss: 0.5189 - val_acc: 0.7407 - val_auc: 0.8242 - val_loss: 0.5060\n",
      "Epoch 460/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7372 - auc: 0.8160 - loss: 0.5182 - val_acc: 0.7406 - val_auc: 0.8238 - val_loss: 0.5065\n",
      "Epoch 461/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7355 - auc: 0.8135 - loss: 0.5212 - val_acc: 0.7429 - val_auc: 0.8244 - val_loss: 0.5058\n",
      "Epoch 462/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7358 - auc: 0.8135 - loss: 0.5210 - val_acc: 0.7413 - val_auc: 0.8256 - val_loss: 0.5045\n",
      "Epoch 463/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7369 - auc: 0.8144 - loss: 0.5199 - val_acc: 0.7433 - val_auc: 0.8250 - val_loss: 0.5054\n",
      "Epoch 464/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7379 - auc: 0.8159 - loss: 0.5179 - val_acc: 0.7426 - val_auc: 0.8254 - val_loss: 0.5056\n",
      "Epoch 465/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7374 - auc: 0.8148 - loss: 0.5201 - val_acc: 0.7442 - val_auc: 0.8261 - val_loss: 0.5042\n",
      "Epoch 466/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7361 - auc: 0.8148 - loss: 0.5195 - val_acc: 0.7425 - val_auc: 0.8238 - val_loss: 0.5063\n",
      "Epoch 467/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7366 - auc: 0.8149 - loss: 0.5194 - val_acc: 0.7407 - val_auc: 0.8238 - val_loss: 0.5061\n",
      "Epoch 468/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7356 - auc: 0.8150 - loss: 0.5185 - val_acc: 0.7452 - val_auc: 0.8256 - val_loss: 0.5056\n",
      "Epoch 469/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7369 - auc: 0.8146 - loss: 0.5209 - val_acc: 0.7442 - val_auc: 0.8256 - val_loss: 0.5062\n",
      "Epoch 470/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7362 - auc: 0.8142 - loss: 0.5208 - val_acc: 0.7409 - val_auc: 0.8257 - val_loss: 0.5044\n",
      "Epoch 471/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7388 - auc: 0.8155 - loss: 0.5197 - val_acc: 0.7420 - val_auc: 0.8270 - val_loss: 0.5030\n",
      "Epoch 472/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7374 - auc: 0.8160 - loss: 0.5182 - val_acc: 0.7444 - val_auc: 0.8251 - val_loss: 0.5060\n",
      "Epoch 473/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7380 - auc: 0.8153 - loss: 0.5188 - val_acc: 0.7432 - val_auc: 0.8249 - val_loss: 0.5058\n",
      "Epoch 474/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7369 - auc: 0.8155 - loss: 0.5181 - val_acc: 0.7432 - val_auc: 0.8262 - val_loss: 0.5043\n",
      "Epoch 475/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7354 - auc: 0.8135 - loss: 0.5210 - val_acc: 0.7444 - val_auc: 0.8248 - val_loss: 0.5050\n",
      "Epoch 476/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7359 - auc: 0.8148 - loss: 0.5189 - val_acc: 0.7425 - val_auc: 0.8240 - val_loss: 0.5059\n",
      "Epoch 477/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7368 - auc: 0.8158 - loss: 0.5178 - val_acc: 0.7400 - val_auc: 0.8237 - val_loss: 0.5072\n",
      "Epoch 478/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7377 - auc: 0.8160 - loss: 0.5183 - val_acc: 0.7449 - val_auc: 0.8256 - val_loss: 0.5033\n",
      "Epoch 479/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7365 - auc: 0.8157 - loss: 0.5190 - val_acc: 0.7451 - val_auc: 0.8264 - val_loss: 0.5040\n",
      "Epoch 480/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7382 - auc: 0.8175 - loss: 0.5166 - val_acc: 0.7442 - val_auc: 0.8258 - val_loss: 0.5058\n",
      "Epoch 481/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7376 - auc: 0.8149 - loss: 0.5189 - val_acc: 0.7454 - val_auc: 0.8257 - val_loss: 0.5037\n",
      "Epoch 482/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7391 - auc: 0.8161 - loss: 0.5172 - val_acc: 0.7429 - val_auc: 0.8256 - val_loss: 0.5053\n",
      "Epoch 483/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7378 - auc: 0.8149 - loss: 0.5200 - val_acc: 0.7413 - val_auc: 0.8226 - val_loss: 0.5094\n",
      "Epoch 484/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7375 - auc: 0.8156 - loss: 0.5193 - val_acc: 0.7412 - val_auc: 0.8259 - val_loss: 0.5035\n",
      "Epoch 485/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7378 - auc: 0.8160 - loss: 0.5175 - val_acc: 0.7442 - val_auc: 0.8256 - val_loss: 0.5046\n",
      "Epoch 486/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7378 - auc: 0.8161 - loss: 0.5180 - val_acc: 0.7449 - val_auc: 0.8270 - val_loss: 0.5024\n",
      "Epoch 487/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7355 - auc: 0.8156 - loss: 0.5181 - val_acc: 0.7436 - val_auc: 0.8264 - val_loss: 0.5036\n",
      "Epoch 488/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7361 - auc: 0.8161 - loss: 0.5180 - val_acc: 0.7435 - val_auc: 0.8258 - val_loss: 0.5032\n",
      "Epoch 489/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7364 - auc: 0.8157 - loss: 0.5178 - val_acc: 0.7425 - val_auc: 0.8251 - val_loss: 0.5048\n",
      "Epoch 490/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7397 - auc: 0.8170 - loss: 0.5172 - val_acc: 0.7453 - val_auc: 0.8246 - val_loss: 0.5050\n",
      "Epoch 491/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7372 - auc: 0.8164 - loss: 0.5175 - val_acc: 0.7449 - val_auc: 0.8274 - val_loss: 0.5026\n",
      "Epoch 492/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7381 - auc: 0.8172 - loss: 0.5169 - val_acc: 0.7427 - val_auc: 0.8274 - val_loss: 0.5035\n",
      "Epoch 493/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7372 - auc: 0.8162 - loss: 0.5184 - val_acc: 0.7432 - val_auc: 0.8255 - val_loss: 0.5058\n",
      "Epoch 494/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7371 - auc: 0.8154 - loss: 0.5184 - val_acc: 0.7456 - val_auc: 0.8257 - val_loss: 0.5033\n",
      "Epoch 495/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7375 - auc: 0.8166 - loss: 0.5171 - val_acc: 0.7432 - val_auc: 0.8267 - val_loss: 0.5048\n",
      "Epoch 496/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7371 - auc: 0.8163 - loss: 0.5175 - val_acc: 0.7440 - val_auc: 0.8271 - val_loss: 0.5029\n",
      "Epoch 497/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7397 - auc: 0.8184 - loss: 0.5152 - val_acc: 0.7433 - val_auc: 0.8249 - val_loss: 0.5044\n",
      "Epoch 498/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7372 - auc: 0.8164 - loss: 0.5172 - val_acc: 0.7414 - val_auc: 0.8253 - val_loss: 0.5038\n",
      "Epoch 499/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7391 - auc: 0.8162 - loss: 0.5176 - val_acc: 0.7417 - val_auc: 0.8259 - val_loss: 0.5054\n",
      "Epoch 500/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7399 - auc: 0.8178 - loss: 0.5158 - val_acc: 0.7458 - val_auc: 0.8276 - val_loss: 0.5017\n",
      "Epoch 501/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7397 - auc: 0.8174 - loss: 0.5163 - val_acc: 0.7450 - val_auc: 0.8264 - val_loss: 0.5036\n",
      "Epoch 502/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7374 - auc: 0.8163 - loss: 0.5175 - val_acc: 0.7443 - val_auc: 0.8272 - val_loss: 0.5027\n",
      "Epoch 503/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7373 - auc: 0.8166 - loss: 0.5161 - val_acc: 0.7466 - val_auc: 0.8284 - val_loss: 0.5010\n",
      "Epoch 504/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7389 - auc: 0.8169 - loss: 0.5174 - val_acc: 0.7446 - val_auc: 0.8261 - val_loss: 0.5026\n",
      "Epoch 505/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7378 - auc: 0.8163 - loss: 0.5177 - val_acc: 0.7426 - val_auc: 0.8257 - val_loss: 0.5032\n",
      "Epoch 506/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7390 - auc: 0.8170 - loss: 0.5165 - val_acc: 0.7468 - val_auc: 0.8274 - val_loss: 0.5026\n",
      "Epoch 507/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7387 - auc: 0.8169 - loss: 0.5166 - val_acc: 0.7423 - val_auc: 0.8271 - val_loss: 0.5019\n",
      "Epoch 508/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7375 - auc: 0.8154 - loss: 0.5184 - val_acc: 0.7413 - val_auc: 0.8254 - val_loss: 0.5053\n",
      "Epoch 509/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7372 - auc: 0.8171 - loss: 0.5165 - val_acc: 0.7453 - val_auc: 0.8287 - val_loss: 0.5006\n",
      "Epoch 510/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7390 - auc: 0.8171 - loss: 0.5167 - val_acc: 0.7466 - val_auc: 0.8262 - val_loss: 0.5046\n",
      "Epoch 511/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7387 - auc: 0.8175 - loss: 0.5158 - val_acc: 0.7422 - val_auc: 0.8257 - val_loss: 0.5049\n",
      "Epoch 512/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7408 - auc: 0.8182 - loss: 0.5161 - val_acc: 0.7466 - val_auc: 0.8283 - val_loss: 0.5000\n",
      "Epoch 513/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7390 - auc: 0.8181 - loss: 0.5159 - val_acc: 0.7444 - val_auc: 0.8280 - val_loss: 0.5011\n",
      "Epoch 514/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7384 - auc: 0.8172 - loss: 0.5166 - val_acc: 0.7444 - val_auc: 0.8267 - val_loss: 0.5020\n",
      "Epoch 515/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7388 - auc: 0.8168 - loss: 0.5161 - val_acc: 0.7440 - val_auc: 0.8281 - val_loss: 0.5012\n",
      "Epoch 516/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7386 - auc: 0.8172 - loss: 0.5169 - val_acc: 0.7446 - val_auc: 0.8281 - val_loss: 0.5021\n",
      "Epoch 517/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7385 - auc: 0.8174 - loss: 0.5165 - val_acc: 0.7444 - val_auc: 0.8281 - val_loss: 0.5002\n",
      "Epoch 518/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7385 - auc: 0.8177 - loss: 0.5164 - val_acc: 0.7452 - val_auc: 0.8275 - val_loss: 0.5025\n",
      "Epoch 519/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7378 - auc: 0.8171 - loss: 0.5163 - val_acc: 0.7457 - val_auc: 0.8276 - val_loss: 0.5025\n",
      "Epoch 520/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7375 - auc: 0.8173 - loss: 0.5155 - val_acc: 0.7450 - val_auc: 0.8284 - val_loss: 0.5014\n",
      "Epoch 521/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7375 - auc: 0.8173 - loss: 0.5163 - val_acc: 0.7472 - val_auc: 0.8286 - val_loss: 0.5000\n",
      "Epoch 522/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7385 - auc: 0.8175 - loss: 0.5166 - val_acc: 0.7456 - val_auc: 0.8292 - val_loss: 0.5007\n",
      "Epoch 523/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7393 - auc: 0.8178 - loss: 0.5147 - val_acc: 0.7469 - val_auc: 0.8276 - val_loss: 0.5026\n",
      "Epoch 524/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7380 - auc: 0.8178 - loss: 0.5153 - val_acc: 0.7447 - val_auc: 0.8290 - val_loss: 0.5013\n",
      "Epoch 525/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7389 - auc: 0.8166 - loss: 0.5170 - val_acc: 0.7443 - val_auc: 0.8281 - val_loss: 0.5005\n",
      "Epoch 526/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7377 - auc: 0.8167 - loss: 0.5173 - val_acc: 0.7458 - val_auc: 0.8278 - val_loss: 0.5012\n",
      "Epoch 527/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7391 - auc: 0.8179 - loss: 0.5151 - val_acc: 0.7446 - val_auc: 0.8270 - val_loss: 0.5018\n",
      "Epoch 528/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7396 - auc: 0.8186 - loss: 0.5150 - val_acc: 0.7446 - val_auc: 0.8275 - val_loss: 0.5016\n",
      "Epoch 529/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7398 - auc: 0.8178 - loss: 0.5164 - val_acc: 0.7454 - val_auc: 0.8281 - val_loss: 0.5008\n",
      "Epoch 530/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7383 - auc: 0.8172 - loss: 0.5166 - val_acc: 0.7428 - val_auc: 0.8271 - val_loss: 0.5012\n",
      "Epoch 531/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7404 - auc: 0.8182 - loss: 0.5150 - val_acc: 0.7444 - val_auc: 0.8274 - val_loss: 0.5011\n",
      "Epoch 532/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7404 - auc: 0.8184 - loss: 0.5154 - val_acc: 0.7449 - val_auc: 0.8284 - val_loss: 0.5005\n",
      "Epoch 533/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7397 - auc: 0.8178 - loss: 0.5166 - val_acc: 0.7455 - val_auc: 0.8279 - val_loss: 0.5007\n",
      "Epoch 534/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7404 - auc: 0.8196 - loss: 0.5134 - val_acc: 0.7458 - val_auc: 0.8274 - val_loss: 0.5011\n",
      "Epoch 535/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7416 - auc: 0.8192 - loss: 0.5146 - val_acc: 0.7467 - val_auc: 0.8285 - val_loss: 0.5002\n",
      "Epoch 536/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7397 - auc: 0.8182 - loss: 0.5145 - val_acc: 0.7439 - val_auc: 0.8282 - val_loss: 0.4999\n",
      "Epoch 537/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7411 - auc: 0.8192 - loss: 0.5140 - val_acc: 0.7426 - val_auc: 0.8276 - val_loss: 0.5025\n",
      "Epoch 538/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7377 - auc: 0.8180 - loss: 0.5155 - val_acc: 0.7447 - val_auc: 0.8277 - val_loss: 0.5003\n",
      "Epoch 539/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7409 - auc: 0.8178 - loss: 0.5164 - val_acc: 0.7469 - val_auc: 0.8291 - val_loss: 0.5001\n",
      "Epoch 540/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7402 - auc: 0.8183 - loss: 0.5149 - val_acc: 0.7443 - val_auc: 0.8259 - val_loss: 0.5037\n",
      "Epoch 541/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7402 - auc: 0.8182 - loss: 0.5149 - val_acc: 0.7457 - val_auc: 0.8291 - val_loss: 0.4993\n",
      "Epoch 542/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7392 - auc: 0.8187 - loss: 0.5139 - val_acc: 0.7456 - val_auc: 0.8300 - val_loss: 0.4990\n",
      "Epoch 543/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7408 - auc: 0.8193 - loss: 0.5140 - val_acc: 0.7472 - val_auc: 0.8283 - val_loss: 0.4992\n",
      "Epoch 544/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7390 - auc: 0.8185 - loss: 0.5146 - val_acc: 0.7462 - val_auc: 0.8277 - val_loss: 0.5015\n",
      "Epoch 545/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7386 - auc: 0.8180 - loss: 0.5144 - val_acc: 0.7432 - val_auc: 0.8284 - val_loss: 0.5001\n",
      "Epoch 546/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7413 - auc: 0.8207 - loss: 0.5128 - val_acc: 0.7451 - val_auc: 0.8288 - val_loss: 0.4986\n",
      "Epoch 547/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7386 - auc: 0.8186 - loss: 0.5150 - val_acc: 0.7457 - val_auc: 0.8279 - val_loss: 0.4994\n",
      "Epoch 548/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7388 - auc: 0.8175 - loss: 0.5154 - val_acc: 0.7438 - val_auc: 0.8267 - val_loss: 0.5019\n",
      "Epoch 549/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7392 - auc: 0.8169 - loss: 0.5168 - val_acc: 0.7443 - val_auc: 0.8282 - val_loss: 0.4999\n",
      "Epoch 550/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7380 - auc: 0.8179 - loss: 0.5153 - val_acc: 0.7453 - val_auc: 0.8273 - val_loss: 0.5002\n",
      "Epoch 551/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7398 - auc: 0.8188 - loss: 0.5152 - val_acc: 0.7467 - val_auc: 0.8306 - val_loss: 0.4976\n",
      "Epoch 552/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7404 - auc: 0.8195 - loss: 0.5128 - val_acc: 0.7466 - val_auc: 0.8283 - val_loss: 0.5004\n",
      "Epoch 553/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7411 - auc: 0.8196 - loss: 0.5146 - val_acc: 0.7429 - val_auc: 0.8293 - val_loss: 0.4994\n",
      "Epoch 554/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7405 - auc: 0.8186 - loss: 0.5145 - val_acc: 0.7439 - val_auc: 0.8293 - val_loss: 0.5006\n",
      "Epoch 555/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7403 - auc: 0.8178 - loss: 0.5167 - val_acc: 0.7481 - val_auc: 0.8298 - val_loss: 0.4999\n",
      "Epoch 556/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7395 - auc: 0.8174 - loss: 0.5163 - val_acc: 0.7433 - val_auc: 0.8281 - val_loss: 0.5008\n",
      "Epoch 557/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7376 - auc: 0.8187 - loss: 0.5140 - val_acc: 0.7429 - val_auc: 0.8282 - val_loss: 0.4998\n",
      "Epoch 558/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7382 - auc: 0.8177 - loss: 0.5148 - val_acc: 0.7469 - val_auc: 0.8288 - val_loss: 0.4993\n",
      "Epoch 559/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7424 - auc: 0.8198 - loss: 0.5128 - val_acc: 0.7452 - val_auc: 0.8290 - val_loss: 0.4987\n",
      "Epoch 560/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7412 - auc: 0.8208 - loss: 0.5111 - val_acc: 0.7469 - val_auc: 0.8293 - val_loss: 0.5000\n",
      "Epoch 561/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7404 - auc: 0.8193 - loss: 0.5144 - val_acc: 0.7466 - val_auc: 0.8289 - val_loss: 0.4991\n",
      "Epoch 562/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7412 - auc: 0.8193 - loss: 0.5142 - val_acc: 0.7470 - val_auc: 0.8297 - val_loss: 0.4994\n",
      "Epoch 563/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7407 - auc: 0.8202 - loss: 0.5121 - val_acc: 0.7431 - val_auc: 0.8280 - val_loss: 0.5002\n",
      "Epoch 564/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7398 - auc: 0.8195 - loss: 0.5119 - val_acc: 0.7454 - val_auc: 0.8297 - val_loss: 0.4990\n",
      "Epoch 565/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7421 - auc: 0.8199 - loss: 0.5132 - val_acc: 0.7432 - val_auc: 0.8283 - val_loss: 0.5006\n",
      "Epoch 566/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7419 - auc: 0.8202 - loss: 0.5134 - val_acc: 0.7455 - val_auc: 0.8300 - val_loss: 0.4974\n",
      "Epoch 567/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7403 - auc: 0.8203 - loss: 0.5127 - val_acc: 0.7457 - val_auc: 0.8300 - val_loss: 0.4979\n",
      "Epoch 568/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7412 - auc: 0.8201 - loss: 0.5133 - val_acc: 0.7469 - val_auc: 0.8297 - val_loss: 0.4993\n",
      "Epoch 569/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7404 - auc: 0.8207 - loss: 0.5121 - val_acc: 0.7440 - val_auc: 0.8267 - val_loss: 0.5014\n",
      "Epoch 570/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7400 - auc: 0.8192 - loss: 0.5139 - val_acc: 0.7456 - val_auc: 0.8290 - val_loss: 0.5006\n",
      "Epoch 571/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7421 - auc: 0.8198 - loss: 0.5133 - val_acc: 0.7474 - val_auc: 0.8304 - val_loss: 0.4973\n",
      "Epoch 572/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7393 - auc: 0.8188 - loss: 0.5129 - val_acc: 0.7473 - val_auc: 0.8288 - val_loss: 0.5003\n",
      "Epoch 573/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7421 - auc: 0.8210 - loss: 0.5111 - val_acc: 0.7448 - val_auc: 0.8290 - val_loss: 0.4981\n",
      "Epoch 574/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7421 - auc: 0.8206 - loss: 0.5119 - val_acc: 0.7464 - val_auc: 0.8304 - val_loss: 0.4985\n",
      "Epoch 575/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7411 - auc: 0.8194 - loss: 0.5136 - val_acc: 0.7462 - val_auc: 0.8308 - val_loss: 0.4965\n",
      "Epoch 576/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7407 - auc: 0.8195 - loss: 0.5133 - val_acc: 0.7472 - val_auc: 0.8292 - val_loss: 0.4991\n",
      "Epoch 577/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7422 - auc: 0.8209 - loss: 0.5117 - val_acc: 0.7474 - val_auc: 0.8298 - val_loss: 0.4978\n",
      "Epoch 578/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7411 - auc: 0.8192 - loss: 0.5130 - val_acc: 0.7449 - val_auc: 0.8293 - val_loss: 0.4980\n",
      "Epoch 579/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7404 - auc: 0.8190 - loss: 0.5133 - val_acc: 0.7476 - val_auc: 0.8302 - val_loss: 0.4976\n",
      "Epoch 580/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7406 - auc: 0.8205 - loss: 0.5123 - val_acc: 0.7475 - val_auc: 0.8283 - val_loss: 0.4996\n",
      "Epoch 581/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7402 - auc: 0.8207 - loss: 0.5115 - val_acc: 0.7469 - val_auc: 0.8300 - val_loss: 0.4988\n",
      "Epoch 582/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7415 - auc: 0.8211 - loss: 0.5113 - val_acc: 0.7480 - val_auc: 0.8303 - val_loss: 0.4963\n",
      "Epoch 583/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7395 - auc: 0.8203 - loss: 0.5117 - val_acc: 0.7469 - val_auc: 0.8302 - val_loss: 0.4988\n",
      "Epoch 584/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7420 - auc: 0.8201 - loss: 0.5127 - val_acc: 0.7495 - val_auc: 0.8310 - val_loss: 0.4970\n",
      "Epoch 585/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7418 - auc: 0.8201 - loss: 0.5126 - val_acc: 0.7479 - val_auc: 0.8309 - val_loss: 0.4975\n",
      "Epoch 586/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7410 - auc: 0.8199 - loss: 0.5126 - val_acc: 0.7476 - val_auc: 0.8295 - val_loss: 0.4992\n",
      "Epoch 587/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7419 - auc: 0.8210 - loss: 0.5119 - val_acc: 0.7455 - val_auc: 0.8312 - val_loss: 0.4968\n",
      "Epoch 588/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7412 - auc: 0.8203 - loss: 0.5125 - val_acc: 0.7464 - val_auc: 0.8291 - val_loss: 0.5002\n",
      "Epoch 589/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7423 - auc: 0.8204 - loss: 0.5118 - val_acc: 0.7457 - val_auc: 0.8291 - val_loss: 0.4993\n",
      "Epoch 590/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7419 - auc: 0.8210 - loss: 0.5112 - val_acc: 0.7496 - val_auc: 0.8318 - val_loss: 0.4956\n",
      "Epoch 591/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7426 - auc: 0.8229 - loss: 0.5085 - val_acc: 0.7469 - val_auc: 0.8302 - val_loss: 0.4978\n",
      "Epoch 592/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7413 - auc: 0.8205 - loss: 0.5123 - val_acc: 0.7473 - val_auc: 0.8309 - val_loss: 0.4971\n",
      "Epoch 593/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7407 - auc: 0.8205 - loss: 0.5121 - val_acc: 0.7447 - val_auc: 0.8287 - val_loss: 0.4998\n",
      "Epoch 594/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7414 - auc: 0.8199 - loss: 0.5120 - val_acc: 0.7465 - val_auc: 0.8304 - val_loss: 0.4975\n",
      "Epoch 595/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7407 - auc: 0.8210 - loss: 0.5105 - val_acc: 0.7482 - val_auc: 0.8316 - val_loss: 0.4970\n",
      "Epoch 596/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7418 - auc: 0.8195 - loss: 0.5140 - val_acc: 0.7482 - val_auc: 0.8311 - val_loss: 0.4980\n",
      "Epoch 597/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7423 - auc: 0.8213 - loss: 0.5109 - val_acc: 0.7481 - val_auc: 0.8314 - val_loss: 0.4971\n",
      "Epoch 598/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7424 - auc: 0.8213 - loss: 0.5116 - val_acc: 0.7464 - val_auc: 0.8289 - val_loss: 0.5006\n",
      "Epoch 599/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7425 - auc: 0.8197 - loss: 0.5132 - val_acc: 0.7469 - val_auc: 0.8300 - val_loss: 0.4977\n",
      "Epoch 600/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7425 - auc: 0.8226 - loss: 0.5097 - val_acc: 0.7480 - val_auc: 0.8310 - val_loss: 0.4966\n",
      "Epoch 601/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7429 - auc: 0.8215 - loss: 0.5107 - val_acc: 0.7475 - val_auc: 0.8306 - val_loss: 0.4985\n",
      "Epoch 602/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7439 - auc: 0.8214 - loss: 0.5114 - val_acc: 0.7470 - val_auc: 0.8303 - val_loss: 0.4975\n",
      "Epoch 603/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7413 - auc: 0.8211 - loss: 0.5095 - val_acc: 0.7488 - val_auc: 0.8313 - val_loss: 0.4956\n",
      "Epoch 604/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7421 - auc: 0.8213 - loss: 0.5101 - val_acc: 0.7456 - val_auc: 0.8302 - val_loss: 0.4966\n",
      "Epoch 605/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7426 - auc: 0.8206 - loss: 0.5114 - val_acc: 0.7460 - val_auc: 0.8310 - val_loss: 0.4967\n",
      "Epoch 606/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7415 - auc: 0.8202 - loss: 0.5130 - val_acc: 0.7476 - val_auc: 0.8314 - val_loss: 0.4962\n",
      "Epoch 607/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7428 - auc: 0.8204 - loss: 0.5115 - val_acc: 0.7488 - val_auc: 0.8331 - val_loss: 0.4953\n",
      "Epoch 608/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7425 - auc: 0.8225 - loss: 0.5089 - val_acc: 0.7494 - val_auc: 0.8315 - val_loss: 0.4962\n",
      "Epoch 609/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7436 - auc: 0.8214 - loss: 0.5115 - val_acc: 0.7500 - val_auc: 0.8329 - val_loss: 0.4942\n",
      "Epoch 610/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7405 - auc: 0.8212 - loss: 0.5107 - val_acc: 0.7511 - val_auc: 0.8327 - val_loss: 0.4940\n",
      "Epoch 611/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7418 - auc: 0.8205 - loss: 0.5112 - val_acc: 0.7481 - val_auc: 0.8300 - val_loss: 0.4970\n",
      "Epoch 612/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7429 - auc: 0.8220 - loss: 0.5104 - val_acc: 0.7497 - val_auc: 0.8314 - val_loss: 0.4968\n",
      "Epoch 613/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7406 - auc: 0.8206 - loss: 0.5114 - val_acc: 0.7454 - val_auc: 0.8290 - val_loss: 0.4989\n",
      "Epoch 614/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7410 - auc: 0.8205 - loss: 0.5122 - val_acc: 0.7462 - val_auc: 0.8296 - val_loss: 0.4970\n",
      "Epoch 615/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7429 - auc: 0.8214 - loss: 0.5109 - val_acc: 0.7477 - val_auc: 0.8305 - val_loss: 0.4973\n",
      "Epoch 616/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7414 - auc: 0.8197 - loss: 0.5127 - val_acc: 0.7477 - val_auc: 0.8329 - val_loss: 0.4953\n",
      "Epoch 617/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7450 - auc: 0.8232 - loss: 0.5093 - val_acc: 0.7504 - val_auc: 0.8320 - val_loss: 0.4962\n",
      "Epoch 618/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7437 - auc: 0.8218 - loss: 0.5099 - val_acc: 0.7490 - val_auc: 0.8321 - val_loss: 0.4948\n",
      "Epoch 619/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7419 - auc: 0.8217 - loss: 0.5100 - val_acc: 0.7464 - val_auc: 0.8310 - val_loss: 0.4974\n",
      "Epoch 620/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7422 - auc: 0.8216 - loss: 0.5096 - val_acc: 0.7470 - val_auc: 0.8302 - val_loss: 0.4972\n",
      "Epoch 621/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7429 - auc: 0.8216 - loss: 0.5104 - val_acc: 0.7495 - val_auc: 0.8324 - val_loss: 0.4951\n",
      "Epoch 622/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7433 - auc: 0.8213 - loss: 0.5109 - val_acc: 0.7471 - val_auc: 0.8321 - val_loss: 0.4954\n",
      "Epoch 623/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7422 - auc: 0.8217 - loss: 0.5103 - val_acc: 0.7486 - val_auc: 0.8303 - val_loss: 0.4961\n",
      "Epoch 624/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7425 - auc: 0.8218 - loss: 0.5106 - val_acc: 0.7484 - val_auc: 0.8319 - val_loss: 0.4941\n",
      "Epoch 625/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7433 - auc: 0.8224 - loss: 0.5092 - val_acc: 0.7490 - val_auc: 0.8319 - val_loss: 0.4959\n",
      "Epoch 626/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7441 - auc: 0.8215 - loss: 0.5105 - val_acc: 0.7485 - val_auc: 0.8327 - val_loss: 0.4946\n",
      "Epoch 627/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7423 - auc: 0.8230 - loss: 0.5090 - val_acc: 0.7476 - val_auc: 0.8315 - val_loss: 0.4961\n",
      "Epoch 628/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7430 - auc: 0.8219 - loss: 0.5101 - val_acc: 0.7483 - val_auc: 0.8308 - val_loss: 0.4955\n",
      "Epoch 629/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7412 - auc: 0.8205 - loss: 0.5116 - val_acc: 0.7463 - val_auc: 0.8319 - val_loss: 0.4987\n",
      "Epoch 630/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7420 - auc: 0.8215 - loss: 0.5107 - val_acc: 0.7505 - val_auc: 0.8330 - val_loss: 0.4948\n",
      "Epoch 631/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7426 - auc: 0.8224 - loss: 0.5091 - val_acc: 0.7469 - val_auc: 0.8317 - val_loss: 0.4951\n",
      "Epoch 632/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7455 - auc: 0.8230 - loss: 0.5098 - val_acc: 0.7489 - val_auc: 0.8320 - val_loss: 0.4956\n",
      "Epoch 633/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7434 - auc: 0.8220 - loss: 0.5096 - val_acc: 0.7482 - val_auc: 0.8306 - val_loss: 0.4959\n",
      "Epoch 634/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7445 - auc: 0.8225 - loss: 0.5089 - val_acc: 0.7465 - val_auc: 0.8323 - val_loss: 0.4951\n",
      "Epoch 635/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7438 - auc: 0.8213 - loss: 0.5107 - val_acc: 0.7481 - val_auc: 0.8323 - val_loss: 0.4958\n",
      "Epoch 636/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7422 - auc: 0.8220 - loss: 0.5111 - val_acc: 0.7489 - val_auc: 0.8334 - val_loss: 0.4931\n",
      "Epoch 637/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7432 - auc: 0.8227 - loss: 0.5090 - val_acc: 0.7478 - val_auc: 0.8319 - val_loss: 0.4944\n",
      "Epoch 638/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7441 - auc: 0.8226 - loss: 0.5089 - val_acc: 0.7481 - val_auc: 0.8316 - val_loss: 0.4971\n",
      "Epoch 639/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7446 - auc: 0.8233 - loss: 0.5086 - val_acc: 0.7536 - val_auc: 0.8328 - val_loss: 0.4939\n",
      "Epoch 640/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7432 - auc: 0.8225 - loss: 0.5093 - val_acc: 0.7489 - val_auc: 0.8332 - val_loss: 0.4938\n",
      "Epoch 641/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7447 - auc: 0.8241 - loss: 0.5075 - val_acc: 0.7500 - val_auc: 0.8333 - val_loss: 0.4948\n",
      "Epoch 642/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7441 - auc: 0.8227 - loss: 0.5096 - val_acc: 0.7486 - val_auc: 0.8324 - val_loss: 0.4942\n",
      "Epoch 643/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7432 - auc: 0.8236 - loss: 0.5085 - val_acc: 0.7480 - val_auc: 0.8334 - val_loss: 0.4946\n",
      "Epoch 644/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7437 - auc: 0.8228 - loss: 0.5090 - val_acc: 0.7516 - val_auc: 0.8331 - val_loss: 0.4929\n",
      "Epoch 645/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7442 - auc: 0.8225 - loss: 0.5095 - val_acc: 0.7490 - val_auc: 0.8338 - val_loss: 0.4946\n",
      "Epoch 646/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7443 - auc: 0.8246 - loss: 0.5066 - val_acc: 0.7494 - val_auc: 0.8330 - val_loss: 0.4930\n",
      "Epoch 647/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7446 - auc: 0.8229 - loss: 0.5085 - val_acc: 0.7480 - val_auc: 0.8327 - val_loss: 0.4940\n",
      "Epoch 648/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7437 - auc: 0.8219 - loss: 0.5103 - val_acc: 0.7485 - val_auc: 0.8339 - val_loss: 0.4923\n",
      "Epoch 649/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7439 - auc: 0.8238 - loss: 0.5075 - val_acc: 0.7467 - val_auc: 0.8314 - val_loss: 0.4958\n",
      "Epoch 650/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7416 - auc: 0.8209 - loss: 0.5108 - val_acc: 0.7484 - val_auc: 0.8319 - val_loss: 0.4948\n",
      "Epoch 651/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7452 - auc: 0.8245 - loss: 0.5070 - val_acc: 0.7469 - val_auc: 0.8322 - val_loss: 0.4945\n",
      "Epoch 652/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7437 - auc: 0.8229 - loss: 0.5085 - val_acc: 0.7483 - val_auc: 0.8326 - val_loss: 0.4935\n",
      "Epoch 653/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7441 - auc: 0.8235 - loss: 0.5081 - val_acc: 0.7503 - val_auc: 0.8326 - val_loss: 0.4956\n",
      "Epoch 654/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7418 - auc: 0.8213 - loss: 0.5103 - val_acc: 0.7481 - val_auc: 0.8339 - val_loss: 0.4924\n",
      "Epoch 655/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7429 - auc: 0.8228 - loss: 0.5086 - val_acc: 0.7511 - val_auc: 0.8338 - val_loss: 0.4924\n",
      "Epoch 656/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7444 - auc: 0.8243 - loss: 0.5073 - val_acc: 0.7501 - val_auc: 0.8349 - val_loss: 0.4905\n",
      "Epoch 657/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7446 - auc: 0.8221 - loss: 0.5092 - val_acc: 0.7476 - val_auc: 0.8318 - val_loss: 0.4951\n",
      "Epoch 658/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7451 - auc: 0.8224 - loss: 0.5085 - val_acc: 0.7493 - val_auc: 0.8324 - val_loss: 0.4951\n",
      "Epoch 659/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7453 - auc: 0.8237 - loss: 0.5081 - val_acc: 0.7457 - val_auc: 0.8318 - val_loss: 0.4959\n",
      "Epoch 660/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7437 - auc: 0.8233 - loss: 0.5082 - val_acc: 0.7507 - val_auc: 0.8339 - val_loss: 0.4926\n",
      "Epoch 661/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7439 - auc: 0.8235 - loss: 0.5085 - val_acc: 0.7503 - val_auc: 0.8337 - val_loss: 0.4928\n",
      "Epoch 662/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7430 - auc: 0.8226 - loss: 0.5089 - val_acc: 0.7484 - val_auc: 0.8333 - val_loss: 0.4938\n",
      "Epoch 663/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7452 - auc: 0.8230 - loss: 0.5085 - val_acc: 0.7481 - val_auc: 0.8330 - val_loss: 0.4938\n",
      "Epoch 664/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7475 - auc: 0.8248 - loss: 0.5061 - val_acc: 0.7514 - val_auc: 0.8343 - val_loss: 0.4924\n",
      "Epoch 665/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7450 - auc: 0.8243 - loss: 0.5069 - val_acc: 0.7499 - val_auc: 0.8341 - val_loss: 0.4927\n",
      "Epoch 666/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7461 - auc: 0.8251 - loss: 0.5068 - val_acc: 0.7476 - val_auc: 0.8324 - val_loss: 0.4949\n",
      "Epoch 667/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7441 - auc: 0.8235 - loss: 0.5080 - val_acc: 0.7506 - val_auc: 0.8331 - val_loss: 0.4938\n",
      "Epoch 668/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7451 - auc: 0.8234 - loss: 0.5086 - val_acc: 0.7472 - val_auc: 0.8322 - val_loss: 0.4948\n",
      "Epoch 669/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7447 - auc: 0.8241 - loss: 0.5065 - val_acc: 0.7488 - val_auc: 0.8327 - val_loss: 0.4951\n",
      "Epoch 670/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7458 - auc: 0.8238 - loss: 0.5076 - val_acc: 0.7491 - val_auc: 0.8335 - val_loss: 0.4928\n",
      "Epoch 671/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7438 - auc: 0.8237 - loss: 0.5076 - val_acc: 0.7501 - val_auc: 0.8337 - val_loss: 0.4944\n",
      "Epoch 672/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7433 - auc: 0.8231 - loss: 0.5078 - val_acc: 0.7501 - val_auc: 0.8321 - val_loss: 0.4947\n",
      "Epoch 673/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7465 - auc: 0.8235 - loss: 0.5091 - val_acc: 0.7498 - val_auc: 0.8344 - val_loss: 0.4915\n",
      "Epoch 674/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7445 - auc: 0.8241 - loss: 0.5065 - val_acc: 0.7509 - val_auc: 0.8353 - val_loss: 0.4909\n",
      "Epoch 675/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7461 - auc: 0.8248 - loss: 0.5071 - val_acc: 0.7494 - val_auc: 0.8348 - val_loss: 0.4911\n",
      "Epoch 676/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7437 - auc: 0.8232 - loss: 0.5080 - val_acc: 0.7496 - val_auc: 0.8346 - val_loss: 0.4936\n",
      "Epoch 677/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7445 - auc: 0.8249 - loss: 0.5061 - val_acc: 0.7492 - val_auc: 0.8332 - val_loss: 0.4933\n",
      "Epoch 678/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7464 - auc: 0.8250 - loss: 0.5068 - val_acc: 0.7472 - val_auc: 0.8327 - val_loss: 0.4940\n",
      "Epoch 679/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7443 - auc: 0.8240 - loss: 0.5076 - val_acc: 0.7517 - val_auc: 0.8330 - val_loss: 0.4930\n",
      "Epoch 680/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7448 - auc: 0.8239 - loss: 0.5072 - val_acc: 0.7498 - val_auc: 0.8337 - val_loss: 0.4917\n",
      "Epoch 681/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7452 - auc: 0.8239 - loss: 0.5069 - val_acc: 0.7509 - val_auc: 0.8348 - val_loss: 0.4908\n",
      "Epoch 682/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7429 - auc: 0.8236 - loss: 0.5086 - val_acc: 0.7491 - val_auc: 0.8332 - val_loss: 0.4948\n",
      "Epoch 683/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7437 - auc: 0.8242 - loss: 0.5072 - val_acc: 0.7475 - val_auc: 0.8326 - val_loss: 0.4936\n",
      "Epoch 684/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7447 - auc: 0.8234 - loss: 0.5083 - val_acc: 0.7501 - val_auc: 0.8322 - val_loss: 0.4946\n",
      "Epoch 685/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7443 - auc: 0.8234 - loss: 0.5075 - val_acc: 0.7509 - val_auc: 0.8352 - val_loss: 0.4908\n",
      "Epoch 686/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7448 - auc: 0.8241 - loss: 0.5070 - val_acc: 0.7499 - val_auc: 0.8340 - val_loss: 0.4938\n",
      "Epoch 687/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7460 - auc: 0.8250 - loss: 0.5057 - val_acc: 0.7499 - val_auc: 0.8329 - val_loss: 0.4937\n",
      "Epoch 688/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7443 - auc: 0.8234 - loss: 0.5073 - val_acc: 0.7492 - val_auc: 0.8351 - val_loss: 0.4904\n",
      "Epoch 689/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7454 - auc: 0.8252 - loss: 0.5058 - val_acc: 0.7517 - val_auc: 0.8344 - val_loss: 0.4921\n",
      "Epoch 690/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7458 - auc: 0.8255 - loss: 0.5056 - val_acc: 0.7486 - val_auc: 0.8326 - val_loss: 0.4955\n",
      "Epoch 691/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7467 - auc: 0.8247 - loss: 0.5066 - val_acc: 0.7500 - val_auc: 0.8348 - val_loss: 0.4906\n",
      "Epoch 692/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7449 - auc: 0.8238 - loss: 0.5083 - val_acc: 0.7503 - val_auc: 0.8344 - val_loss: 0.4912\n",
      "Epoch 693/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7446 - auc: 0.8235 - loss: 0.5076 - val_acc: 0.7488 - val_auc: 0.8329 - val_loss: 0.4936\n",
      "Epoch 694/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7470 - auc: 0.8248 - loss: 0.5062 - val_acc: 0.7486 - val_auc: 0.8322 - val_loss: 0.4942\n",
      "Epoch 695/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7451 - auc: 0.8248 - loss: 0.5065 - val_acc: 0.7520 - val_auc: 0.8345 - val_loss: 0.4924\n",
      "Epoch 696/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7457 - auc: 0.8237 - loss: 0.5081 - val_acc: 0.7495 - val_auc: 0.8339 - val_loss: 0.4918\n",
      "Epoch 697/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7443 - auc: 0.8245 - loss: 0.5075 - val_acc: 0.7497 - val_auc: 0.8349 - val_loss: 0.4907\n",
      "Epoch 698/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7448 - auc: 0.8233 - loss: 0.5079 - val_acc: 0.7497 - val_auc: 0.8350 - val_loss: 0.4909\n",
      "Epoch 699/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7441 - auc: 0.8240 - loss: 0.5078 - val_acc: 0.7487 - val_auc: 0.8325 - val_loss: 0.4941\n",
      "Epoch 700/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7454 - auc: 0.8243 - loss: 0.5066 - val_acc: 0.7528 - val_auc: 0.8356 - val_loss: 0.4895\n",
      "Epoch 701/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7446 - auc: 0.8245 - loss: 0.5067 - val_acc: 0.7504 - val_auc: 0.8353 - val_loss: 0.4905\n",
      "Epoch 702/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7458 - auc: 0.8257 - loss: 0.5054 - val_acc: 0.7513 - val_auc: 0.8348 - val_loss: 0.4897\n",
      "Epoch 703/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7453 - auc: 0.8240 - loss: 0.5060 - val_acc: 0.7516 - val_auc: 0.8343 - val_loss: 0.4923\n",
      "Epoch 704/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7479 - auc: 0.8254 - loss: 0.5070 - val_acc: 0.7500 - val_auc: 0.8328 - val_loss: 0.4936\n",
      "Epoch 705/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7450 - auc: 0.8234 - loss: 0.5075 - val_acc: 0.7520 - val_auc: 0.8351 - val_loss: 0.4917\n",
      "Epoch 706/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7457 - auc: 0.8243 - loss: 0.5069 - val_acc: 0.7507 - val_auc: 0.8346 - val_loss: 0.4909\n",
      "Epoch 707/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7458 - auc: 0.8248 - loss: 0.5058 - val_acc: 0.7485 - val_auc: 0.8337 - val_loss: 0.4951\n",
      "Epoch 708/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7445 - auc: 0.8246 - loss: 0.5057 - val_acc: 0.7535 - val_auc: 0.8358 - val_loss: 0.4899\n",
      "Epoch 709/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7451 - auc: 0.8249 - loss: 0.5063 - val_acc: 0.7513 - val_auc: 0.8360 - val_loss: 0.4891\n",
      "Epoch 710/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7457 - auc: 0.8245 - loss: 0.5067 - val_acc: 0.7492 - val_auc: 0.8347 - val_loss: 0.4916\n",
      "Epoch 711/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7464 - auc: 0.8250 - loss: 0.5065 - val_acc: 0.7506 - val_auc: 0.8329 - val_loss: 0.4927\n",
      "Epoch 712/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7462 - auc: 0.8250 - loss: 0.5064 - val_acc: 0.7494 - val_auc: 0.8333 - val_loss: 0.4933\n",
      "Epoch 713/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7459 - auc: 0.8242 - loss: 0.5064 - val_acc: 0.7513 - val_auc: 0.8352 - val_loss: 0.4907\n",
      "Epoch 714/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7453 - auc: 0.8245 - loss: 0.5079 - val_acc: 0.7523 - val_auc: 0.8351 - val_loss: 0.4898\n",
      "Epoch 715/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7459 - auc: 0.8251 - loss: 0.5062 - val_acc: 0.7505 - val_auc: 0.8344 - val_loss: 0.4920\n",
      "Epoch 716/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7483 - auc: 0.8263 - loss: 0.5049 - val_acc: 0.7510 - val_auc: 0.8330 - val_loss: 0.4923\n",
      "Epoch 717/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7445 - auc: 0.8238 - loss: 0.5067 - val_acc: 0.7501 - val_auc: 0.8344 - val_loss: 0.4915\n",
      "Epoch 718/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7446 - auc: 0.8245 - loss: 0.5065 - val_acc: 0.7494 - val_auc: 0.8359 - val_loss: 0.4912\n",
      "Epoch 719/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7451 - auc: 0.8259 - loss: 0.5053 - val_acc: 0.7530 - val_auc: 0.8354 - val_loss: 0.4911\n",
      "Epoch 720/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7458 - auc: 0.8248 - loss: 0.5053 - val_acc: 0.7525 - val_auc: 0.8360 - val_loss: 0.4897\n",
      "Epoch 721/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7462 - auc: 0.8267 - loss: 0.5039 - val_acc: 0.7520 - val_auc: 0.8352 - val_loss: 0.4918\n",
      "Epoch 722/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7463 - auc: 0.8250 - loss: 0.5055 - val_acc: 0.7533 - val_auc: 0.8340 - val_loss: 0.4916\n",
      "Epoch 723/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7463 - auc: 0.8251 - loss: 0.5051 - val_acc: 0.7504 - val_auc: 0.8351 - val_loss: 0.4903\n",
      "Epoch 724/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7453 - auc: 0.8249 - loss: 0.5073 - val_acc: 0.7526 - val_auc: 0.8356 - val_loss: 0.4896\n",
      "Epoch 725/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7444 - auc: 0.8256 - loss: 0.5045 - val_acc: 0.7521 - val_auc: 0.8363 - val_loss: 0.4896\n",
      "Epoch 726/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7452 - auc: 0.8236 - loss: 0.5073 - val_acc: 0.7516 - val_auc: 0.8351 - val_loss: 0.4919\n",
      "Epoch 727/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7450 - auc: 0.8248 - loss: 0.5066 - val_acc: 0.7508 - val_auc: 0.8344 - val_loss: 0.4910\n",
      "Epoch 728/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7483 - auc: 0.8273 - loss: 0.5033 - val_acc: 0.7521 - val_auc: 0.8361 - val_loss: 0.4890\n",
      "Epoch 729/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7443 - auc: 0.8236 - loss: 0.5083 - val_acc: 0.7526 - val_auc: 0.8356 - val_loss: 0.4898\n",
      "Epoch 730/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7453 - auc: 0.8253 - loss: 0.5053 - val_acc: 0.7509 - val_auc: 0.8353 - val_loss: 0.4900\n",
      "Epoch 731/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7446 - auc: 0.8252 - loss: 0.5048 - val_acc: 0.7531 - val_auc: 0.8350 - val_loss: 0.4909\n",
      "Epoch 732/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7474 - auc: 0.8267 - loss: 0.5038 - val_acc: 0.7524 - val_auc: 0.8320 - val_loss: 0.4936\n",
      "Epoch 733/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7473 - auc: 0.8260 - loss: 0.5042 - val_acc: 0.7524 - val_auc: 0.8339 - val_loss: 0.4917\n",
      "Epoch 734/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7477 - auc: 0.8256 - loss: 0.5053 - val_acc: 0.7521 - val_auc: 0.8366 - val_loss: 0.4896\n",
      "Epoch 735/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7455 - auc: 0.8248 - loss: 0.5065 - val_acc: 0.7507 - val_auc: 0.8352 - val_loss: 0.4906\n",
      "Epoch 736/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7471 - auc: 0.8258 - loss: 0.5052 - val_acc: 0.7528 - val_auc: 0.8350 - val_loss: 0.4905\n",
      "Epoch 737/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7462 - auc: 0.8258 - loss: 0.5051 - val_acc: 0.7515 - val_auc: 0.8356 - val_loss: 0.4898\n",
      "Epoch 738/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7456 - auc: 0.8256 - loss: 0.5057 - val_acc: 0.7550 - val_auc: 0.8368 - val_loss: 0.4886\n",
      "Epoch 739/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7462 - auc: 0.8253 - loss: 0.5053 - val_acc: 0.7526 - val_auc: 0.8369 - val_loss: 0.4907\n",
      "Epoch 740/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7487 - auc: 0.8260 - loss: 0.5038 - val_acc: 0.7528 - val_auc: 0.8363 - val_loss: 0.4879\n",
      "Epoch 741/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7457 - auc: 0.8253 - loss: 0.5051 - val_acc: 0.7520 - val_auc: 0.8362 - val_loss: 0.4888\n",
      "Epoch 742/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7475 - auc: 0.8258 - loss: 0.5048 - val_acc: 0.7524 - val_auc: 0.8366 - val_loss: 0.4890\n",
      "Epoch 743/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7460 - auc: 0.8248 - loss: 0.5066 - val_acc: 0.7539 - val_auc: 0.8364 - val_loss: 0.4885\n",
      "Epoch 744/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7472 - auc: 0.8251 - loss: 0.5067 - val_acc: 0.7524 - val_auc: 0.8363 - val_loss: 0.4892\n",
      "Epoch 745/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7447 - auc: 0.8266 - loss: 0.5038 - val_acc: 0.7515 - val_auc: 0.8372 - val_loss: 0.4876\n",
      "Epoch 746/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7453 - auc: 0.8254 - loss: 0.5056 - val_acc: 0.7533 - val_auc: 0.8358 - val_loss: 0.4897\n",
      "Epoch 747/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7487 - auc: 0.8261 - loss: 0.5044 - val_acc: 0.7518 - val_auc: 0.8355 - val_loss: 0.4892\n",
      "Epoch 748/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7458 - auc: 0.8261 - loss: 0.5041 - val_acc: 0.7519 - val_auc: 0.8365 - val_loss: 0.4893\n",
      "Epoch 749/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7449 - auc: 0.8255 - loss: 0.5053 - val_acc: 0.7525 - val_auc: 0.8359 - val_loss: 0.4901\n",
      "Epoch 750/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7480 - auc: 0.8274 - loss: 0.5036 - val_acc: 0.7542 - val_auc: 0.8358 - val_loss: 0.4895\n",
      "Epoch 751/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7462 - auc: 0.8274 - loss: 0.5034 - val_acc: 0.7513 - val_auc: 0.8360 - val_loss: 0.4885\n",
      "Epoch 752/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7487 - auc: 0.8268 - loss: 0.5036 - val_acc: 0.7534 - val_auc: 0.8353 - val_loss: 0.4894\n",
      "Epoch 753/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7459 - auc: 0.8248 - loss: 0.5063 - val_acc: 0.7516 - val_auc: 0.8372 - val_loss: 0.4887\n",
      "Epoch 754/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7463 - auc: 0.8260 - loss: 0.5043 - val_acc: 0.7506 - val_auc: 0.8359 - val_loss: 0.4890\n",
      "Epoch 755/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7475 - auc: 0.8260 - loss: 0.5050 - val_acc: 0.7500 - val_auc: 0.8358 - val_loss: 0.4911\n",
      "Epoch 756/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7450 - auc: 0.8254 - loss: 0.5055 - val_acc: 0.7480 - val_auc: 0.8363 - val_loss: 0.4898\n",
      "Epoch 757/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7467 - auc: 0.8264 - loss: 0.5039 - val_acc: 0.7498 - val_auc: 0.8351 - val_loss: 0.4907\n",
      "Epoch 758/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7469 - auc: 0.8253 - loss: 0.5053 - val_acc: 0.7537 - val_auc: 0.8373 - val_loss: 0.4893\n",
      "Epoch 759/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7494 - auc: 0.8263 - loss: 0.5046 - val_acc: 0.7543 - val_auc: 0.8367 - val_loss: 0.4883\n",
      "Epoch 760/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7469 - auc: 0.8260 - loss: 0.5046 - val_acc: 0.7530 - val_auc: 0.8369 - val_loss: 0.4896\n",
      "Epoch 761/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7486 - auc: 0.8267 - loss: 0.5041 - val_acc: 0.7512 - val_auc: 0.8364 - val_loss: 0.4889\n",
      "Epoch 762/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7477 - auc: 0.8266 - loss: 0.5042 - val_acc: 0.7531 - val_auc: 0.8373 - val_loss: 0.4876\n",
      "Epoch 763/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7489 - auc: 0.8265 - loss: 0.5041 - val_acc: 0.7522 - val_auc: 0.8360 - val_loss: 0.4893\n",
      "Epoch 764/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7480 - auc: 0.8264 - loss: 0.5035 - val_acc: 0.7538 - val_auc: 0.8363 - val_loss: 0.4884\n",
      "Epoch 765/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7470 - auc: 0.8267 - loss: 0.5038 - val_acc: 0.7523 - val_auc: 0.8361 - val_loss: 0.4904\n",
      "Epoch 766/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7468 - auc: 0.8262 - loss: 0.5050 - val_acc: 0.7523 - val_auc: 0.8367 - val_loss: 0.4885\n",
      "Epoch 767/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7499 - auc: 0.8281 - loss: 0.5030 - val_acc: 0.7509 - val_auc: 0.8348 - val_loss: 0.4897\n",
      "Epoch 768/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7467 - auc: 0.8264 - loss: 0.5038 - val_acc: 0.7530 - val_auc: 0.8364 - val_loss: 0.4890\n",
      "Epoch 769/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7487 - auc: 0.8270 - loss: 0.5034 - val_acc: 0.7506 - val_auc: 0.8362 - val_loss: 0.4894\n",
      "Epoch 770/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7496 - auc: 0.8269 - loss: 0.5037 - val_acc: 0.7535 - val_auc: 0.8365 - val_loss: 0.4891\n",
      "Epoch 771/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7468 - auc: 0.8279 - loss: 0.5014 - val_acc: 0.7528 - val_auc: 0.8370 - val_loss: 0.4881\n",
      "Epoch 772/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7474 - auc: 0.8264 - loss: 0.5042 - val_acc: 0.7542 - val_auc: 0.8379 - val_loss: 0.4863\n",
      "Epoch 773/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7467 - auc: 0.8259 - loss: 0.5042 - val_acc: 0.7525 - val_auc: 0.8367 - val_loss: 0.4892\n",
      "Epoch 774/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7473 - auc: 0.8261 - loss: 0.5039 - val_acc: 0.7531 - val_auc: 0.8367 - val_loss: 0.4906\n",
      "Epoch 775/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7500 - auc: 0.8273 - loss: 0.5030 - val_acc: 0.7530 - val_auc: 0.8376 - val_loss: 0.4872\n",
      "Epoch 776/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7458 - auc: 0.8261 - loss: 0.5050 - val_acc: 0.7522 - val_auc: 0.8376 - val_loss: 0.4897\n",
      "Epoch 777/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7479 - auc: 0.8281 - loss: 0.5022 - val_acc: 0.7514 - val_auc: 0.8336 - val_loss: 0.4920\n",
      "Epoch 778/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7479 - auc: 0.8265 - loss: 0.5041 - val_acc: 0.7563 - val_auc: 0.8391 - val_loss: 0.4858\n",
      "Epoch 779/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7472 - auc: 0.8270 - loss: 0.5032 - val_acc: 0.7561 - val_auc: 0.8381 - val_loss: 0.4859\n",
      "Epoch 780/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7471 - auc: 0.8270 - loss: 0.5034 - val_acc: 0.7547 - val_auc: 0.8392 - val_loss: 0.4850\n",
      "Epoch 781/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7475 - auc: 0.8260 - loss: 0.5042 - val_acc: 0.7488 - val_auc: 0.8356 - val_loss: 0.4903\n",
      "Epoch 782/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7468 - auc: 0.8259 - loss: 0.5039 - val_acc: 0.7537 - val_auc: 0.8366 - val_loss: 0.4891\n",
      "Epoch 783/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7462 - auc: 0.8261 - loss: 0.5047 - val_acc: 0.7527 - val_auc: 0.8363 - val_loss: 0.4890\n",
      "Epoch 784/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7487 - auc: 0.8271 - loss: 0.5030 - val_acc: 0.7549 - val_auc: 0.8395 - val_loss: 0.4862\n",
      "Epoch 785/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7473 - auc: 0.8267 - loss: 0.5041 - val_acc: 0.7543 - val_auc: 0.8363 - val_loss: 0.4890\n",
      "Epoch 786/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7497 - auc: 0.8278 - loss: 0.5020 - val_acc: 0.7502 - val_auc: 0.8358 - val_loss: 0.4889\n",
      "Epoch 787/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7470 - auc: 0.8268 - loss: 0.5038 - val_acc: 0.7522 - val_auc: 0.8356 - val_loss: 0.4894\n",
      "Epoch 788/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7485 - auc: 0.8289 - loss: 0.5012 - val_acc: 0.7540 - val_auc: 0.8375 - val_loss: 0.4869\n",
      "Epoch 789/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7483 - auc: 0.8282 - loss: 0.5013 - val_acc: 0.7540 - val_auc: 0.8390 - val_loss: 0.4859\n",
      "Epoch 790/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7453 - auc: 0.8272 - loss: 0.5027 - val_acc: 0.7530 - val_auc: 0.8354 - val_loss: 0.4893\n",
      "Epoch 791/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7475 - auc: 0.8264 - loss: 0.5043 - val_acc: 0.7517 - val_auc: 0.8356 - val_loss: 0.4905\n",
      "Epoch 792/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7468 - auc: 0.8269 - loss: 0.5029 - val_acc: 0.7519 - val_auc: 0.8374 - val_loss: 0.4871\n",
      "Epoch 793/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7486 - auc: 0.8276 - loss: 0.5028 - val_acc: 0.7539 - val_auc: 0.8380 - val_loss: 0.4876\n",
      "Epoch 794/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7491 - auc: 0.8284 - loss: 0.5022 - val_acc: 0.7554 - val_auc: 0.8374 - val_loss: 0.4876\n",
      "Epoch 795/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7481 - auc: 0.8268 - loss: 0.5046 - val_acc: 0.7508 - val_auc: 0.8356 - val_loss: 0.4899\n",
      "Epoch 796/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7473 - auc: 0.8276 - loss: 0.5028 - val_acc: 0.7531 - val_auc: 0.8379 - val_loss: 0.4873\n",
      "Epoch 797/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7498 - auc: 0.8280 - loss: 0.5019 - val_acc: 0.7544 - val_auc: 0.8369 - val_loss: 0.4871\n",
      "Epoch 798/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7493 - auc: 0.8283 - loss: 0.5018 - val_acc: 0.7568 - val_auc: 0.8386 - val_loss: 0.4851\n",
      "Epoch 799/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7475 - auc: 0.8274 - loss: 0.5028 - val_acc: 0.7513 - val_auc: 0.8354 - val_loss: 0.4891\n",
      "Epoch 800/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7448 - auc: 0.8253 - loss: 0.5057 - val_acc: 0.7544 - val_auc: 0.8371 - val_loss: 0.4883\n",
      "Epoch 801/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7484 - auc: 0.8274 - loss: 0.5029 - val_acc: 0.7517 - val_auc: 0.8360 - val_loss: 0.4900\n",
      "Epoch 802/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7473 - auc: 0.8283 - loss: 0.5017 - val_acc: 0.7527 - val_auc: 0.8376 - val_loss: 0.4878\n",
      "Epoch 803/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7490 - auc: 0.8279 - loss: 0.5023 - val_acc: 0.7539 - val_auc: 0.8368 - val_loss: 0.4875\n",
      "Epoch 804/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7487 - auc: 0.8278 - loss: 0.5017 - val_acc: 0.7543 - val_auc: 0.8392 - val_loss: 0.4850\n",
      "Epoch 805/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7486 - auc: 0.8271 - loss: 0.5035 - val_acc: 0.7552 - val_auc: 0.8372 - val_loss: 0.4896\n",
      "Epoch 806/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7505 - auc: 0.8285 - loss: 0.5018 - val_acc: 0.7550 - val_auc: 0.8386 - val_loss: 0.4854\n",
      "Epoch 807/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7502 - auc: 0.8284 - loss: 0.5017 - val_acc: 0.7524 - val_auc: 0.8353 - val_loss: 0.4895\n",
      "Epoch 808/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7477 - auc: 0.8270 - loss: 0.5034 - val_acc: 0.7519 - val_auc: 0.8346 - val_loss: 0.4903\n",
      "Epoch 809/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7488 - auc: 0.8264 - loss: 0.5039 - val_acc: 0.7543 - val_auc: 0.8376 - val_loss: 0.4876\n",
      "Epoch 810/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7479 - auc: 0.8279 - loss: 0.5032 - val_acc: 0.7504 - val_auc: 0.8368 - val_loss: 0.4889\n",
      "Epoch 811/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7485 - auc: 0.8284 - loss: 0.5010 - val_acc: 0.7533 - val_auc: 0.8383 - val_loss: 0.4865\n",
      "Epoch 812/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7489 - auc: 0.8272 - loss: 0.5032 - val_acc: 0.7539 - val_auc: 0.8387 - val_loss: 0.4865\n",
      "Epoch 813/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7496 - auc: 0.8278 - loss: 0.5016 - val_acc: 0.7538 - val_auc: 0.8380 - val_loss: 0.4865\n",
      "Epoch 814/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7499 - auc: 0.8278 - loss: 0.5024 - val_acc: 0.7538 - val_auc: 0.8376 - val_loss: 0.4869\n",
      "Epoch 815/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7489 - auc: 0.8279 - loss: 0.5019 - val_acc: 0.7533 - val_auc: 0.8388 - val_loss: 0.4860\n",
      "Epoch 816/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7501 - auc: 0.8293 - loss: 0.5005 - val_acc: 0.7531 - val_auc: 0.8386 - val_loss: 0.4864\n",
      "Epoch 817/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7487 - auc: 0.8283 - loss: 0.5018 - val_acc: 0.7519 - val_auc: 0.8388 - val_loss: 0.4866\n",
      "Epoch 818/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7476 - auc: 0.8272 - loss: 0.5036 - val_acc: 0.7531 - val_auc: 0.8387 - val_loss: 0.4854\n",
      "Epoch 819/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7478 - auc: 0.8271 - loss: 0.5022 - val_acc: 0.7544 - val_auc: 0.8385 - val_loss: 0.4866\n",
      "Epoch 820/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7509 - auc: 0.8297 - loss: 0.4997 - val_acc: 0.7531 - val_auc: 0.8389 - val_loss: 0.4849\n",
      "Epoch 821/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7488 - auc: 0.8272 - loss: 0.5031 - val_acc: 0.7547 - val_auc: 0.8399 - val_loss: 0.4836\n",
      "Epoch 822/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7494 - auc: 0.8281 - loss: 0.5025 - val_acc: 0.7565 - val_auc: 0.8386 - val_loss: 0.4844\n",
      "Epoch 823/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7473 - auc: 0.8276 - loss: 0.5021 - val_acc: 0.7554 - val_auc: 0.8397 - val_loss: 0.4853\n",
      "Epoch 824/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7487 - auc: 0.8276 - loss: 0.5020 - val_acc: 0.7545 - val_auc: 0.8396 - val_loss: 0.4868\n",
      "Epoch 825/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7499 - auc: 0.8291 - loss: 0.5008 - val_acc: 0.7544 - val_auc: 0.8394 - val_loss: 0.4844\n",
      "Epoch 826/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7478 - auc: 0.8284 - loss: 0.5003 - val_acc: 0.7506 - val_auc: 0.8366 - val_loss: 0.4884\n",
      "Epoch 827/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7494 - auc: 0.8285 - loss: 0.5019 - val_acc: 0.7537 - val_auc: 0.8379 - val_loss: 0.4878\n",
      "Epoch 828/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7482 - auc: 0.8279 - loss: 0.5026 - val_acc: 0.7547 - val_auc: 0.8389 - val_loss: 0.4869\n",
      "Epoch 829/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7471 - auc: 0.8267 - loss: 0.5037 - val_acc: 0.7528 - val_auc: 0.8371 - val_loss: 0.4872\n",
      "Epoch 830/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7462 - auc: 0.8268 - loss: 0.5037 - val_acc: 0.7523 - val_auc: 0.8379 - val_loss: 0.4868\n",
      "Epoch 831/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7472 - auc: 0.8275 - loss: 0.5024 - val_acc: 0.7553 - val_auc: 0.8391 - val_loss: 0.4857\n",
      "Epoch 832/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7504 - auc: 0.8286 - loss: 0.5017 - val_acc: 0.7576 - val_auc: 0.8392 - val_loss: 0.4856\n",
      "Epoch 833/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7505 - auc: 0.8285 - loss: 0.5018 - val_acc: 0.7556 - val_auc: 0.8393 - val_loss: 0.4841\n",
      "Epoch 834/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7497 - auc: 0.8291 - loss: 0.5004 - val_acc: 0.7548 - val_auc: 0.8389 - val_loss: 0.4851\n",
      "Epoch 835/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7493 - auc: 0.8285 - loss: 0.5015 - val_acc: 0.7517 - val_auc: 0.8372 - val_loss: 0.4880\n",
      "Epoch 836/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7493 - auc: 0.8295 - loss: 0.5008 - val_acc: 0.7555 - val_auc: 0.8390 - val_loss: 0.4865\n",
      "Epoch 837/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7499 - auc: 0.8287 - loss: 0.5017 - val_acc: 0.7544 - val_auc: 0.8398 - val_loss: 0.4847\n",
      "Epoch 838/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7504 - auc: 0.8294 - loss: 0.5008 - val_acc: 0.7548 - val_auc: 0.8401 - val_loss: 0.4841\n",
      "Epoch 839/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7486 - auc: 0.8277 - loss: 0.5035 - val_acc: 0.7526 - val_auc: 0.8393 - val_loss: 0.4867\n",
      "Epoch 840/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7490 - auc: 0.8306 - loss: 0.4989 - val_acc: 0.7551 - val_auc: 0.8397 - val_loss: 0.4851\n",
      "Epoch 841/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7509 - auc: 0.8299 - loss: 0.4998 - val_acc: 0.7556 - val_auc: 0.8385 - val_loss: 0.4866\n",
      "Epoch 842/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7502 - auc: 0.8286 - loss: 0.5021 - val_acc: 0.7572 - val_auc: 0.8389 - val_loss: 0.4851\n",
      "Epoch 843/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7510 - auc: 0.8295 - loss: 0.5002 - val_acc: 0.7571 - val_auc: 0.8398 - val_loss: 0.4847\n",
      "Epoch 844/7000\n",
      "106/106 - 2s - 14ms/step - acc: 0.7504 - auc: 0.8299 - loss: 0.5001 - val_acc: 0.7580 - val_auc: 0.8391 - val_loss: 0.4847\n",
      "Epoch 845/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7506 - auc: 0.8289 - loss: 0.5007 - val_acc: 0.7575 - val_auc: 0.8385 - val_loss: 0.4857\n",
      "Epoch 846/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7503 - auc: 0.8284 - loss: 0.5020 - val_acc: 0.7559 - val_auc: 0.8394 - val_loss: 0.4857\n",
      "Epoch 847/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7480 - auc: 0.8280 - loss: 0.5026 - val_acc: 0.7568 - val_auc: 0.8388 - val_loss: 0.4864\n",
      "Epoch 848/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7484 - auc: 0.8285 - loss: 0.5011 - val_acc: 0.7570 - val_auc: 0.8392 - val_loss: 0.4843\n",
      "Epoch 849/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7486 - auc: 0.8278 - loss: 0.5026 - val_acc: 0.7565 - val_auc: 0.8392 - val_loss: 0.4853\n",
      "Epoch 850/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7506 - auc: 0.8295 - loss: 0.4997 - val_acc: 0.7556 - val_auc: 0.8384 - val_loss: 0.4866\n",
      "Epoch 851/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7493 - auc: 0.8279 - loss: 0.5032 - val_acc: 0.7582 - val_auc: 0.8393 - val_loss: 0.4849\n",
      "Epoch 852/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7503 - auc: 0.8293 - loss: 0.4996 - val_acc: 0.7555 - val_auc: 0.8379 - val_loss: 0.4858\n",
      "Epoch 853/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7503 - auc: 0.8300 - loss: 0.5006 - val_acc: 0.7556 - val_auc: 0.8389 - val_loss: 0.4856\n",
      "Epoch 854/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7498 - auc: 0.8289 - loss: 0.4997 - val_acc: 0.7564 - val_auc: 0.8392 - val_loss: 0.4857\n",
      "Epoch 855/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7486 - auc: 0.8281 - loss: 0.5011 - val_acc: 0.7554 - val_auc: 0.8385 - val_loss: 0.4871\n",
      "Epoch 856/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7512 - auc: 0.8305 - loss: 0.4990 - val_acc: 0.7580 - val_auc: 0.8384 - val_loss: 0.4863\n",
      "Epoch 857/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7491 - auc: 0.8285 - loss: 0.5017 - val_acc: 0.7558 - val_auc: 0.8395 - val_loss: 0.4856\n",
      "Epoch 858/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7490 - auc: 0.8277 - loss: 0.5028 - val_acc: 0.7580 - val_auc: 0.8399 - val_loss: 0.4841\n",
      "Epoch 859/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7500 - auc: 0.8284 - loss: 0.5012 - val_acc: 0.7593 - val_auc: 0.8413 - val_loss: 0.4824\n",
      "Epoch 860/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7487 - auc: 0.8275 - loss: 0.5017 - val_acc: 0.7557 - val_auc: 0.8395 - val_loss: 0.4842\n",
      "Epoch 861/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7511 - auc: 0.8298 - loss: 0.4994 - val_acc: 0.7568 - val_auc: 0.8386 - val_loss: 0.4859\n",
      "Epoch 862/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7478 - auc: 0.8276 - loss: 0.5015 - val_acc: 0.7574 - val_auc: 0.8393 - val_loss: 0.4852\n",
      "Epoch 863/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7522 - auc: 0.8306 - loss: 0.4992 - val_acc: 0.7560 - val_auc: 0.8393 - val_loss: 0.4850\n",
      "Epoch 864/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7493 - auc: 0.8296 - loss: 0.4996 - val_acc: 0.7554 - val_auc: 0.8399 - val_loss: 0.4837\n",
      "Epoch 865/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7510 - auc: 0.8294 - loss: 0.4998 - val_acc: 0.7583 - val_auc: 0.8399 - val_loss: 0.4841\n",
      "Epoch 866/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7502 - auc: 0.8300 - loss: 0.4996 - val_acc: 0.7546 - val_auc: 0.8398 - val_loss: 0.4866\n",
      "Epoch 867/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7486 - auc: 0.8283 - loss: 0.5014 - val_acc: 0.7558 - val_auc: 0.8397 - val_loss: 0.4843\n",
      "Epoch 868/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7504 - auc: 0.8302 - loss: 0.4993 - val_acc: 0.7544 - val_auc: 0.8393 - val_loss: 0.4853\n",
      "Epoch 869/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7496 - auc: 0.8304 - loss: 0.4997 - val_acc: 0.7578 - val_auc: 0.8386 - val_loss: 0.4859\n",
      "Epoch 870/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7497 - auc: 0.8291 - loss: 0.5005 - val_acc: 0.7563 - val_auc: 0.8392 - val_loss: 0.4848\n",
      "Epoch 871/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7490 - auc: 0.8294 - loss: 0.5004 - val_acc: 0.7556 - val_auc: 0.8399 - val_loss: 0.4847\n",
      "Epoch 872/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7494 - auc: 0.8300 - loss: 0.4992 - val_acc: 0.7546 - val_auc: 0.8387 - val_loss: 0.4853\n",
      "Epoch 873/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7480 - auc: 0.8296 - loss: 0.4988 - val_acc: 0.7564 - val_auc: 0.8394 - val_loss: 0.4847\n",
      "Epoch 874/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7497 - auc: 0.8298 - loss: 0.4990 - val_acc: 0.7556 - val_auc: 0.8375 - val_loss: 0.4875\n",
      "Epoch 875/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7511 - auc: 0.8304 - loss: 0.4986 - val_acc: 0.7576 - val_auc: 0.8413 - val_loss: 0.4824\n",
      "Epoch 876/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7478 - auc: 0.8288 - loss: 0.4997 - val_acc: 0.7556 - val_auc: 0.8400 - val_loss: 0.4840\n",
      "Epoch 877/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7504 - auc: 0.8291 - loss: 0.5007 - val_acc: 0.7572 - val_auc: 0.8400 - val_loss: 0.4852\n",
      "Epoch 878/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7515 - auc: 0.8290 - loss: 0.5012 - val_acc: 0.7538 - val_auc: 0.8399 - val_loss: 0.4836\n",
      "Epoch 879/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7485 - auc: 0.8298 - loss: 0.5002 - val_acc: 0.7560 - val_auc: 0.8411 - val_loss: 0.4838\n",
      "Epoch 880/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7525 - auc: 0.8306 - loss: 0.4991 - val_acc: 0.7577 - val_auc: 0.8401 - val_loss: 0.4861\n",
      "Epoch 881/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7511 - auc: 0.8302 - loss: 0.5001 - val_acc: 0.7543 - val_auc: 0.8396 - val_loss: 0.4855\n",
      "Epoch 882/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7491 - auc: 0.8289 - loss: 0.4999 - val_acc: 0.7569 - val_auc: 0.8374 - val_loss: 0.4870\n",
      "Epoch 883/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7490 - auc: 0.8293 - loss: 0.5001 - val_acc: 0.7543 - val_auc: 0.8405 - val_loss: 0.4833\n",
      "Epoch 884/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7497 - auc: 0.8291 - loss: 0.5008 - val_acc: 0.7575 - val_auc: 0.8403 - val_loss: 0.4833\n",
      "Epoch 885/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7493 - auc: 0.8290 - loss: 0.5010 - val_acc: 0.7557 - val_auc: 0.8401 - val_loss: 0.4841\n",
      "Epoch 886/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7510 - auc: 0.8305 - loss: 0.4992 - val_acc: 0.7573 - val_auc: 0.8416 - val_loss: 0.4819\n",
      "Epoch 887/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7503 - auc: 0.8291 - loss: 0.4998 - val_acc: 0.7556 - val_auc: 0.8384 - val_loss: 0.4854\n",
      "Epoch 888/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7515 - auc: 0.8302 - loss: 0.5002 - val_acc: 0.7549 - val_auc: 0.8390 - val_loss: 0.4843\n",
      "Epoch 889/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7502 - auc: 0.8296 - loss: 0.4998 - val_acc: 0.7572 - val_auc: 0.8396 - val_loss: 0.4835\n",
      "Epoch 890/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7503 - auc: 0.8294 - loss: 0.5004 - val_acc: 0.7566 - val_auc: 0.8404 - val_loss: 0.4853\n",
      "Epoch 891/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7496 - auc: 0.8294 - loss: 0.5000 - val_acc: 0.7568 - val_auc: 0.8393 - val_loss: 0.4851\n",
      "Epoch 892/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7498 - auc: 0.8298 - loss: 0.4998 - val_acc: 0.7572 - val_auc: 0.8401 - val_loss: 0.4839\n",
      "Epoch 893/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7464 - auc: 0.8278 - loss: 0.5019 - val_acc: 0.7584 - val_auc: 0.8409 - val_loss: 0.4833\n",
      "Epoch 894/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7519 - auc: 0.8297 - loss: 0.4999 - val_acc: 0.7573 - val_auc: 0.8408 - val_loss: 0.4823\n",
      "Epoch 895/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7503 - auc: 0.8294 - loss: 0.5000 - val_acc: 0.7538 - val_auc: 0.8383 - val_loss: 0.4858\n",
      "Epoch 896/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7535 - auc: 0.8315 - loss: 0.4977 - val_acc: 0.7582 - val_auc: 0.8398 - val_loss: 0.4836\n",
      "Epoch 897/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7520 - auc: 0.8316 - loss: 0.4978 - val_acc: 0.7540 - val_auc: 0.8371 - val_loss: 0.4869\n",
      "Epoch 898/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7488 - auc: 0.8290 - loss: 0.5008 - val_acc: 0.7584 - val_auc: 0.8416 - val_loss: 0.4809\n",
      "Epoch 899/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7481 - auc: 0.8278 - loss: 0.5015 - val_acc: 0.7565 - val_auc: 0.8387 - val_loss: 0.4852\n",
      "Epoch 900/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7508 - auc: 0.8304 - loss: 0.4994 - val_acc: 0.7590 - val_auc: 0.8422 - val_loss: 0.4814\n",
      "Epoch 901/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7493 - auc: 0.8290 - loss: 0.5000 - val_acc: 0.7588 - val_auc: 0.8404 - val_loss: 0.4844\n",
      "Epoch 902/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7498 - auc: 0.8291 - loss: 0.5004 - val_acc: 0.7575 - val_auc: 0.8404 - val_loss: 0.4832\n",
      "Epoch 903/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7524 - auc: 0.8314 - loss: 0.4978 - val_acc: 0.7563 - val_auc: 0.8401 - val_loss: 0.4832\n",
      "Epoch 904/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7496 - auc: 0.8298 - loss: 0.4999 - val_acc: 0.7565 - val_auc: 0.8406 - val_loss: 0.4826\n",
      "Epoch 905/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7510 - auc: 0.8299 - loss: 0.5002 - val_acc: 0.7557 - val_auc: 0.8385 - val_loss: 0.4855\n",
      "Epoch 906/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7500 - auc: 0.8308 - loss: 0.4977 - val_acc: 0.7594 - val_auc: 0.8411 - val_loss: 0.4816\n",
      "Epoch 907/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7496 - auc: 0.8300 - loss: 0.4991 - val_acc: 0.7556 - val_auc: 0.8394 - val_loss: 0.4838\n",
      "Epoch 908/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7507 - auc: 0.8302 - loss: 0.4997 - val_acc: 0.7568 - val_auc: 0.8403 - val_loss: 0.4836\n",
      "Epoch 909/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7516 - auc: 0.8320 - loss: 0.4968 - val_acc: 0.7579 - val_auc: 0.8411 - val_loss: 0.4815\n",
      "Epoch 910/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7534 - auc: 0.8327 - loss: 0.4957 - val_acc: 0.7596 - val_auc: 0.8407 - val_loss: 0.4817\n",
      "Epoch 911/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7518 - auc: 0.8302 - loss: 0.4991 - val_acc: 0.7581 - val_auc: 0.8413 - val_loss: 0.4819\n",
      "Epoch 912/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7495 - auc: 0.8279 - loss: 0.5015 - val_acc: 0.7597 - val_auc: 0.8417 - val_loss: 0.4813\n",
      "Epoch 913/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7516 - auc: 0.8303 - loss: 0.4989 - val_acc: 0.7546 - val_auc: 0.8391 - val_loss: 0.4853\n",
      "Epoch 914/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7507 - auc: 0.8318 - loss: 0.4977 - val_acc: 0.7568 - val_auc: 0.8405 - val_loss: 0.4831\n",
      "Epoch 915/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7513 - auc: 0.8309 - loss: 0.4978 - val_acc: 0.7574 - val_auc: 0.8401 - val_loss: 0.4832\n",
      "Epoch 916/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7495 - auc: 0.8288 - loss: 0.5007 - val_acc: 0.7605 - val_auc: 0.8416 - val_loss: 0.4819\n",
      "Epoch 917/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7516 - auc: 0.8316 - loss: 0.4975 - val_acc: 0.7580 - val_auc: 0.8412 - val_loss: 0.4824\n",
      "Epoch 918/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7520 - auc: 0.8300 - loss: 0.4993 - val_acc: 0.7571 - val_auc: 0.8411 - val_loss: 0.4828\n",
      "Epoch 919/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7513 - auc: 0.8305 - loss: 0.4984 - val_acc: 0.7605 - val_auc: 0.8405 - val_loss: 0.4833\n",
      "Epoch 920/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7518 - auc: 0.8307 - loss: 0.4990 - val_acc: 0.7581 - val_auc: 0.8408 - val_loss: 0.4823\n",
      "Epoch 921/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7504 - auc: 0.8298 - loss: 0.4996 - val_acc: 0.7564 - val_auc: 0.8404 - val_loss: 0.4845\n",
      "Epoch 922/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7510 - auc: 0.8309 - loss: 0.4977 - val_acc: 0.7561 - val_auc: 0.8389 - val_loss: 0.4849\n",
      "Epoch 923/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7520 - auc: 0.8305 - loss: 0.4992 - val_acc: 0.7563 - val_auc: 0.8385 - val_loss: 0.4847\n",
      "Epoch 924/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7526 - auc: 0.8310 - loss: 0.4981 - val_acc: 0.7580 - val_auc: 0.8412 - val_loss: 0.4850\n",
      "Epoch 925/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7506 - auc: 0.8293 - loss: 0.4994 - val_acc: 0.7534 - val_auc: 0.8375 - val_loss: 0.4860\n",
      "Epoch 926/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7505 - auc: 0.8294 - loss: 0.4998 - val_acc: 0.7574 - val_auc: 0.8406 - val_loss: 0.4831\n",
      "Epoch 927/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7517 - auc: 0.8301 - loss: 0.4992 - val_acc: 0.7577 - val_auc: 0.8402 - val_loss: 0.4831\n",
      "Epoch 928/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7530 - auc: 0.8315 - loss: 0.4972 - val_acc: 0.7564 - val_auc: 0.8398 - val_loss: 0.4835\n",
      "Epoch 929/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7524 - auc: 0.8319 - loss: 0.4971 - val_acc: 0.7556 - val_auc: 0.8397 - val_loss: 0.4838\n",
      "Epoch 930/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7530 - auc: 0.8305 - loss: 0.4989 - val_acc: 0.7574 - val_auc: 0.8419 - val_loss: 0.4806\n",
      "Epoch 931/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7479 - auc: 0.8288 - loss: 0.5004 - val_acc: 0.7578 - val_auc: 0.8399 - val_loss: 0.4847\n",
      "Epoch 932/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7535 - auc: 0.8322 - loss: 0.4961 - val_acc: 0.7573 - val_auc: 0.8403 - val_loss: 0.4822\n",
      "Epoch 933/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7512 - auc: 0.8308 - loss: 0.4993 - val_acc: 0.7574 - val_auc: 0.8417 - val_loss: 0.4817\n",
      "Epoch 934/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7505 - auc: 0.8301 - loss: 0.4996 - val_acc: 0.7547 - val_auc: 0.8407 - val_loss: 0.4839\n",
      "Epoch 935/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7528 - auc: 0.8319 - loss: 0.4968 - val_acc: 0.7560 - val_auc: 0.8403 - val_loss: 0.4834\n",
      "Epoch 936/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7507 - auc: 0.8311 - loss: 0.4981 - val_acc: 0.7595 - val_auc: 0.8416 - val_loss: 0.4832\n",
      "Epoch 937/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7512 - auc: 0.8318 - loss: 0.4971 - val_acc: 0.7578 - val_auc: 0.8397 - val_loss: 0.4835\n",
      "Epoch 938/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7512 - auc: 0.8319 - loss: 0.4973 - val_acc: 0.7593 - val_auc: 0.8416 - val_loss: 0.4824\n",
      "Epoch 939/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7497 - auc: 0.8297 - loss: 0.4997 - val_acc: 0.7597 - val_auc: 0.8414 - val_loss: 0.4815\n",
      "Epoch 940/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7520 - auc: 0.8314 - loss: 0.4978 - val_acc: 0.7564 - val_auc: 0.8400 - val_loss: 0.4839\n",
      "Epoch 941/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7513 - auc: 0.8317 - loss: 0.4981 - val_acc: 0.7558 - val_auc: 0.8398 - val_loss: 0.4842\n",
      "Epoch 942/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7510 - auc: 0.8301 - loss: 0.4988 - val_acc: 0.7609 - val_auc: 0.8418 - val_loss: 0.4814\n",
      "Epoch 943/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7492 - auc: 0.8291 - loss: 0.4996 - val_acc: 0.7559 - val_auc: 0.8401 - val_loss: 0.4826\n",
      "Epoch 944/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7525 - auc: 0.8324 - loss: 0.4967 - val_acc: 0.7587 - val_auc: 0.8411 - val_loss: 0.4829\n",
      "Epoch 945/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7520 - auc: 0.8311 - loss: 0.4978 - val_acc: 0.7580 - val_auc: 0.8406 - val_loss: 0.4828\n",
      "Epoch 946/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7529 - auc: 0.8316 - loss: 0.4984 - val_acc: 0.7575 - val_auc: 0.8415 - val_loss: 0.4827\n",
      "Epoch 947/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7514 - auc: 0.8302 - loss: 0.4983 - val_acc: 0.7578 - val_auc: 0.8406 - val_loss: 0.4820\n",
      "Epoch 948/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7532 - auc: 0.8317 - loss: 0.4973 - val_acc: 0.7574 - val_auc: 0.8414 - val_loss: 0.4816\n",
      "Epoch 949/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7510 - auc: 0.8302 - loss: 0.4991 - val_acc: 0.7586 - val_auc: 0.8427 - val_loss: 0.4804\n",
      "Epoch 950/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7507 - auc: 0.8307 - loss: 0.4985 - val_acc: 0.7574 - val_auc: 0.8430 - val_loss: 0.4797\n",
      "Epoch 951/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7520 - auc: 0.8308 - loss: 0.4983 - val_acc: 0.7572 - val_auc: 0.8414 - val_loss: 0.4816\n",
      "Epoch 952/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7511 - auc: 0.8310 - loss: 0.4975 - val_acc: 0.7583 - val_auc: 0.8408 - val_loss: 0.4822\n",
      "Epoch 953/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7529 - auc: 0.8310 - loss: 0.4992 - val_acc: 0.7616 - val_auc: 0.8436 - val_loss: 0.4805\n",
      "Epoch 954/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7525 - auc: 0.8304 - loss: 0.4989 - val_acc: 0.7611 - val_auc: 0.8437 - val_loss: 0.4786\n",
      "Epoch 955/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7518 - auc: 0.8314 - loss: 0.4983 - val_acc: 0.7606 - val_auc: 0.8428 - val_loss: 0.4803\n",
      "Epoch 956/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7519 - auc: 0.8307 - loss: 0.4987 - val_acc: 0.7580 - val_auc: 0.8418 - val_loss: 0.4804\n",
      "Epoch 957/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7530 - auc: 0.8318 - loss: 0.4968 - val_acc: 0.7584 - val_auc: 0.8413 - val_loss: 0.4820\n",
      "Epoch 958/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7523 - auc: 0.8320 - loss: 0.4975 - val_acc: 0.7593 - val_auc: 0.8425 - val_loss: 0.4809\n",
      "Epoch 959/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7519 - auc: 0.8305 - loss: 0.4987 - val_acc: 0.7558 - val_auc: 0.8412 - val_loss: 0.4821\n",
      "Epoch 960/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7523 - auc: 0.8317 - loss: 0.4979 - val_acc: 0.7582 - val_auc: 0.8423 - val_loss: 0.4811\n",
      "Epoch 961/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7522 - auc: 0.8312 - loss: 0.4976 - val_acc: 0.7617 - val_auc: 0.8429 - val_loss: 0.4802\n",
      "Epoch 962/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7519 - auc: 0.8309 - loss: 0.4976 - val_acc: 0.7590 - val_auc: 0.8434 - val_loss: 0.4781\n",
      "Epoch 963/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7502 - auc: 0.8307 - loss: 0.4982 - val_acc: 0.7605 - val_auc: 0.8431 - val_loss: 0.4799\n",
      "Epoch 964/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7523 - auc: 0.8324 - loss: 0.4974 - val_acc: 0.7593 - val_auc: 0.8418 - val_loss: 0.4804\n",
      "Epoch 965/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7502 - auc: 0.8319 - loss: 0.4971 - val_acc: 0.7589 - val_auc: 0.8425 - val_loss: 0.4791\n",
      "Epoch 966/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7526 - auc: 0.8329 - loss: 0.4953 - val_acc: 0.7582 - val_auc: 0.8416 - val_loss: 0.4805\n",
      "Epoch 967/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7517 - auc: 0.8328 - loss: 0.4961 - val_acc: 0.7596 - val_auc: 0.8406 - val_loss: 0.4830\n",
      "Epoch 968/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7514 - auc: 0.8313 - loss: 0.4966 - val_acc: 0.7564 - val_auc: 0.8424 - val_loss: 0.4806\n",
      "Epoch 969/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7517 - auc: 0.8318 - loss: 0.4970 - val_acc: 0.7595 - val_auc: 0.8422 - val_loss: 0.4817\n",
      "Epoch 970/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7530 - auc: 0.8322 - loss: 0.4957 - val_acc: 0.7585 - val_auc: 0.8421 - val_loss: 0.4799\n",
      "Epoch 971/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7519 - auc: 0.8314 - loss: 0.4970 - val_acc: 0.7574 - val_auc: 0.8417 - val_loss: 0.4811\n",
      "Epoch 972/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7521 - auc: 0.8325 - loss: 0.4965 - val_acc: 0.7596 - val_auc: 0.8422 - val_loss: 0.4808\n",
      "Epoch 973/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7546 - auc: 0.8329 - loss: 0.4954 - val_acc: 0.7579 - val_auc: 0.8412 - val_loss: 0.4814\n",
      "Epoch 974/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7515 - auc: 0.8310 - loss: 0.4984 - val_acc: 0.7592 - val_auc: 0.8411 - val_loss: 0.4825\n",
      "Epoch 975/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7519 - auc: 0.8320 - loss: 0.4967 - val_acc: 0.7573 - val_auc: 0.8411 - val_loss: 0.4819\n",
      "Epoch 976/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7515 - auc: 0.8318 - loss: 0.4968 - val_acc: 0.7587 - val_auc: 0.8418 - val_loss: 0.4811\n",
      "Epoch 977/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7520 - auc: 0.8319 - loss: 0.4964 - val_acc: 0.7580 - val_auc: 0.8415 - val_loss: 0.4818\n",
      "Epoch 978/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7521 - auc: 0.8313 - loss: 0.4966 - val_acc: 0.7593 - val_auc: 0.8422 - val_loss: 0.4800\n",
      "Epoch 979/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7514 - auc: 0.8317 - loss: 0.4967 - val_acc: 0.7583 - val_auc: 0.8419 - val_loss: 0.4815\n",
      "Epoch 980/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7526 - auc: 0.8322 - loss: 0.4970 - val_acc: 0.7584 - val_auc: 0.8424 - val_loss: 0.4812\n",
      "Epoch 981/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7515 - auc: 0.8308 - loss: 0.4981 - val_acc: 0.7624 - val_auc: 0.8427 - val_loss: 0.4807\n",
      "Epoch 982/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7542 - auc: 0.8326 - loss: 0.4966 - val_acc: 0.7597 - val_auc: 0.8413 - val_loss: 0.4821\n",
      "Epoch 983/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7533 - auc: 0.8326 - loss: 0.4959 - val_acc: 0.7594 - val_auc: 0.8419 - val_loss: 0.4800\n",
      "Epoch 984/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7507 - auc: 0.8325 - loss: 0.4968 - val_acc: 0.7593 - val_auc: 0.8421 - val_loss: 0.4811\n",
      "Epoch 985/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7508 - auc: 0.8320 - loss: 0.4968 - val_acc: 0.7575 - val_auc: 0.8409 - val_loss: 0.4824\n",
      "Epoch 986/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7538 - auc: 0.8328 - loss: 0.4959 - val_acc: 0.7591 - val_auc: 0.8428 - val_loss: 0.4795\n",
      "Epoch 987/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7531 - auc: 0.8320 - loss: 0.4971 - val_acc: 0.7604 - val_auc: 0.8441 - val_loss: 0.4783\n",
      "Epoch 988/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7505 - auc: 0.8313 - loss: 0.4982 - val_acc: 0.7581 - val_auc: 0.8416 - val_loss: 0.4807\n",
      "Epoch 989/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7545 - auc: 0.8325 - loss: 0.4960 - val_acc: 0.7605 - val_auc: 0.8426 - val_loss: 0.4795\n",
      "Epoch 990/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7528 - auc: 0.8327 - loss: 0.4959 - val_acc: 0.7594 - val_auc: 0.8425 - val_loss: 0.4793\n",
      "Epoch 991/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7518 - auc: 0.8317 - loss: 0.4957 - val_acc: 0.7565 - val_auc: 0.8434 - val_loss: 0.4788\n",
      "Epoch 992/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7504 - auc: 0.8295 - loss: 0.4996 - val_acc: 0.7571 - val_auc: 0.8410 - val_loss: 0.4808\n",
      "Epoch 993/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7522 - auc: 0.8322 - loss: 0.4964 - val_acc: 0.7597 - val_auc: 0.8412 - val_loss: 0.4811\n",
      "Epoch 994/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7525 - auc: 0.8322 - loss: 0.4962 - val_acc: 0.7603 - val_auc: 0.8435 - val_loss: 0.4805\n",
      "Epoch 995/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7529 - auc: 0.8322 - loss: 0.4971 - val_acc: 0.7591 - val_auc: 0.8434 - val_loss: 0.4792\n",
      "Epoch 996/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7543 - auc: 0.8333 - loss: 0.4953 - val_acc: 0.7606 - val_auc: 0.8432 - val_loss: 0.4798\n",
      "Epoch 997/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7531 - auc: 0.8319 - loss: 0.4965 - val_acc: 0.7580 - val_auc: 0.8422 - val_loss: 0.4798\n",
      "Epoch 998/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7535 - auc: 0.8329 - loss: 0.4952 - val_acc: 0.7596 - val_auc: 0.8432 - val_loss: 0.4790\n",
      "Epoch 999/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7525 - auc: 0.8326 - loss: 0.4961 - val_acc: 0.7587 - val_auc: 0.8427 - val_loss: 0.4801\n",
      "Epoch 1000/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7549 - auc: 0.8333 - loss: 0.4959 - val_acc: 0.7577 - val_auc: 0.8419 - val_loss: 0.4802\n",
      "Epoch 1001/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7544 - auc: 0.8335 - loss: 0.4948 - val_acc: 0.7603 - val_auc: 0.8434 - val_loss: 0.4789\n",
      "Epoch 1002/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7532 - auc: 0.8322 - loss: 0.4966 - val_acc: 0.7590 - val_auc: 0.8418 - val_loss: 0.4815\n",
      "Epoch 1003/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7546 - auc: 0.8335 - loss: 0.4939 - val_acc: 0.7605 - val_auc: 0.8423 - val_loss: 0.4803\n",
      "Epoch 1004/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7534 - auc: 0.8340 - loss: 0.4947 - val_acc: 0.7582 - val_auc: 0.8437 - val_loss: 0.4785\n",
      "Epoch 1005/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7535 - auc: 0.8329 - loss: 0.4957 - val_acc: 0.7594 - val_auc: 0.8433 - val_loss: 0.4784\n",
      "Epoch 1006/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7510 - auc: 0.8303 - loss: 0.4987 - val_acc: 0.7599 - val_auc: 0.8438 - val_loss: 0.4785\n",
      "Epoch 1007/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7517 - auc: 0.8315 - loss: 0.4967 - val_acc: 0.7585 - val_auc: 0.8433 - val_loss: 0.4798\n",
      "Epoch 1008/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7533 - auc: 0.8325 - loss: 0.4968 - val_acc: 0.7587 - val_auc: 0.8443 - val_loss: 0.4781\n",
      "Epoch 1009/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7515 - auc: 0.8318 - loss: 0.4972 - val_acc: 0.7593 - val_auc: 0.8432 - val_loss: 0.4800\n",
      "Epoch 1010/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7548 - auc: 0.8328 - loss: 0.4960 - val_acc: 0.7583 - val_auc: 0.8421 - val_loss: 0.4803\n",
      "Epoch 1011/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7542 - auc: 0.8343 - loss: 0.4937 - val_acc: 0.7599 - val_auc: 0.8436 - val_loss: 0.4790\n",
      "Epoch 1012/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7534 - auc: 0.8322 - loss: 0.4961 - val_acc: 0.7578 - val_auc: 0.8418 - val_loss: 0.4815\n",
      "Epoch 1013/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7554 - auc: 0.8333 - loss: 0.4951 - val_acc: 0.7600 - val_auc: 0.8429 - val_loss: 0.4780\n",
      "Epoch 1014/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7526 - auc: 0.8326 - loss: 0.4966 - val_acc: 0.7599 - val_auc: 0.8424 - val_loss: 0.4805\n",
      "Epoch 1015/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7535 - auc: 0.8324 - loss: 0.4968 - val_acc: 0.7599 - val_auc: 0.8427 - val_loss: 0.4798\n",
      "Epoch 1016/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7524 - auc: 0.8311 - loss: 0.4981 - val_acc: 0.7594 - val_auc: 0.8432 - val_loss: 0.4797\n",
      "Epoch 1017/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7504 - auc: 0.8321 - loss: 0.4958 - val_acc: 0.7580 - val_auc: 0.8428 - val_loss: 0.4799\n",
      "Epoch 1018/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7527 - auc: 0.8323 - loss: 0.4964 - val_acc: 0.7615 - val_auc: 0.8438 - val_loss: 0.4776\n",
      "Epoch 1019/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7531 - auc: 0.8328 - loss: 0.4947 - val_acc: 0.7591 - val_auc: 0.8416 - val_loss: 0.4823\n",
      "Epoch 1020/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7525 - auc: 0.8323 - loss: 0.4962 - val_acc: 0.7607 - val_auc: 0.8433 - val_loss: 0.4792\n",
      "Epoch 1021/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7522 - auc: 0.8335 - loss: 0.4941 - val_acc: 0.7614 - val_auc: 0.8435 - val_loss: 0.4783\n",
      "Epoch 1022/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7523 - auc: 0.8324 - loss: 0.4967 - val_acc: 0.7600 - val_auc: 0.8439 - val_loss: 0.4777\n",
      "Epoch 1023/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7549 - auc: 0.8336 - loss: 0.4947 - val_acc: 0.7609 - val_auc: 0.8440 - val_loss: 0.4785\n",
      "Epoch 1024/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7545 - auc: 0.8329 - loss: 0.4953 - val_acc: 0.7578 - val_auc: 0.8431 - val_loss: 0.4783\n",
      "Epoch 1025/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7527 - auc: 0.8328 - loss: 0.4952 - val_acc: 0.7589 - val_auc: 0.8438 - val_loss: 0.4778\n",
      "Epoch 1026/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7529 - auc: 0.8339 - loss: 0.4934 - val_acc: 0.7617 - val_auc: 0.8437 - val_loss: 0.4774\n",
      "Epoch 1027/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7514 - auc: 0.8323 - loss: 0.4957 - val_acc: 0.7589 - val_auc: 0.8429 - val_loss: 0.4786\n",
      "Epoch 1028/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7529 - auc: 0.8335 - loss: 0.4938 - val_acc: 0.7613 - val_auc: 0.8447 - val_loss: 0.4777\n",
      "Epoch 1029/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7522 - auc: 0.8322 - loss: 0.4971 - val_acc: 0.7567 - val_auc: 0.8436 - val_loss: 0.4807\n",
      "Epoch 1030/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7515 - auc: 0.8326 - loss: 0.4953 - val_acc: 0.7605 - val_auc: 0.8425 - val_loss: 0.4794\n",
      "Epoch 1031/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7531 - auc: 0.8324 - loss: 0.4971 - val_acc: 0.7590 - val_auc: 0.8431 - val_loss: 0.4796\n",
      "Epoch 1032/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7549 - auc: 0.8330 - loss: 0.4956 - val_acc: 0.7569 - val_auc: 0.8427 - val_loss: 0.4807\n",
      "Epoch 1033/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7521 - auc: 0.8329 - loss: 0.4941 - val_acc: 0.7567 - val_auc: 0.8424 - val_loss: 0.4798\n",
      "Epoch 1034/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7544 - auc: 0.8329 - loss: 0.4965 - val_acc: 0.7601 - val_auc: 0.8446 - val_loss: 0.4778\n",
      "Epoch 1035/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7537 - auc: 0.8341 - loss: 0.4941 - val_acc: 0.7608 - val_auc: 0.8439 - val_loss: 0.4786\n",
      "Epoch 1036/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7548 - auc: 0.8335 - loss: 0.4951 - val_acc: 0.7587 - val_auc: 0.8427 - val_loss: 0.4793\n",
      "Epoch 1037/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7561 - auc: 0.8350 - loss: 0.4933 - val_acc: 0.7607 - val_auc: 0.8444 - val_loss: 0.4777\n",
      "Epoch 1038/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7526 - auc: 0.8326 - loss: 0.4961 - val_acc: 0.7592 - val_auc: 0.8427 - val_loss: 0.4798\n",
      "Epoch 1039/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7538 - auc: 0.8325 - loss: 0.4956 - val_acc: 0.7602 - val_auc: 0.8418 - val_loss: 0.4803\n",
      "Epoch 1040/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7523 - auc: 0.8317 - loss: 0.4966 - val_acc: 0.7634 - val_auc: 0.8455 - val_loss: 0.4769\n",
      "Epoch 1041/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7528 - auc: 0.8328 - loss: 0.4956 - val_acc: 0.7572 - val_auc: 0.8432 - val_loss: 0.4783\n",
      "Epoch 1042/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7534 - auc: 0.8332 - loss: 0.4953 - val_acc: 0.7625 - val_auc: 0.8461 - val_loss: 0.4756\n",
      "Epoch 1043/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7543 - auc: 0.8345 - loss: 0.4937 - val_acc: 0.7613 - val_auc: 0.8452 - val_loss: 0.4765\n",
      "Epoch 1044/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7518 - auc: 0.8331 - loss: 0.4941 - val_acc: 0.7610 - val_auc: 0.8444 - val_loss: 0.4775\n",
      "Epoch 1045/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7531 - auc: 0.8328 - loss: 0.4958 - val_acc: 0.7623 - val_auc: 0.8452 - val_loss: 0.4771\n",
      "Epoch 1046/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7539 - auc: 0.8330 - loss: 0.4950 - val_acc: 0.7593 - val_auc: 0.8442 - val_loss: 0.4784\n",
      "Epoch 1047/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7540 - auc: 0.8341 - loss: 0.4928 - val_acc: 0.7602 - val_auc: 0.8441 - val_loss: 0.4779\n",
      "Epoch 1048/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7544 - auc: 0.8332 - loss: 0.4935 - val_acc: 0.7588 - val_auc: 0.8424 - val_loss: 0.4796\n",
      "Epoch 1049/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7554 - auc: 0.8353 - loss: 0.4933 - val_acc: 0.7596 - val_auc: 0.8450 - val_loss: 0.4767\n",
      "Epoch 1050/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7522 - auc: 0.8336 - loss: 0.4942 - val_acc: 0.7602 - val_auc: 0.8434 - val_loss: 0.4788\n",
      "Epoch 1051/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7543 - auc: 0.8339 - loss: 0.4939 - val_acc: 0.7590 - val_auc: 0.8447 - val_loss: 0.4772\n",
      "Epoch 1052/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7545 - auc: 0.8337 - loss: 0.4946 - val_acc: 0.7595 - val_auc: 0.8448 - val_loss: 0.4772\n",
      "Epoch 1053/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7549 - auc: 0.8329 - loss: 0.4957 - val_acc: 0.7601 - val_auc: 0.8439 - val_loss: 0.4777\n",
      "Epoch 1054/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7555 - auc: 0.8347 - loss: 0.4927 - val_acc: 0.7607 - val_auc: 0.8431 - val_loss: 0.4789\n",
      "Epoch 1055/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7535 - auc: 0.8336 - loss: 0.4952 - val_acc: 0.7594 - val_auc: 0.8442 - val_loss: 0.4766\n",
      "Epoch 1056/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7538 - auc: 0.8326 - loss: 0.4958 - val_acc: 0.7614 - val_auc: 0.8450 - val_loss: 0.4764\n",
      "Epoch 1057/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7544 - auc: 0.8331 - loss: 0.4958 - val_acc: 0.7599 - val_auc: 0.8451 - val_loss: 0.4771\n",
      "Epoch 1058/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7552 - auc: 0.8337 - loss: 0.4944 - val_acc: 0.7615 - val_auc: 0.8461 - val_loss: 0.4763\n",
      "Epoch 1059/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7563 - auc: 0.8351 - loss: 0.4925 - val_acc: 0.7599 - val_auc: 0.8457 - val_loss: 0.4766\n",
      "Epoch 1060/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7564 - auc: 0.8342 - loss: 0.4938 - val_acc: 0.7602 - val_auc: 0.8446 - val_loss: 0.4780\n",
      "Epoch 1061/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7530 - auc: 0.8335 - loss: 0.4944 - val_acc: 0.7600 - val_auc: 0.8425 - val_loss: 0.4808\n",
      "Epoch 1062/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7541 - auc: 0.8330 - loss: 0.4945 - val_acc: 0.7624 - val_auc: 0.8449 - val_loss: 0.4761\n",
      "Epoch 1063/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7539 - auc: 0.8349 - loss: 0.4936 - val_acc: 0.7614 - val_auc: 0.8442 - val_loss: 0.4785\n",
      "Epoch 1064/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7544 - auc: 0.8333 - loss: 0.4951 - val_acc: 0.7608 - val_auc: 0.8457 - val_loss: 0.4770\n",
      "Epoch 1065/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7538 - auc: 0.8338 - loss: 0.4941 - val_acc: 0.7598 - val_auc: 0.8446 - val_loss: 0.4773\n",
      "Epoch 1066/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7533 - auc: 0.8333 - loss: 0.4960 - val_acc: 0.7616 - val_auc: 0.8442 - val_loss: 0.4799\n",
      "Epoch 1067/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7549 - auc: 0.8346 - loss: 0.4930 - val_acc: 0.7609 - val_auc: 0.8445 - val_loss: 0.4762\n",
      "Epoch 1068/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7547 - auc: 0.8337 - loss: 0.4941 - val_acc: 0.7604 - val_auc: 0.8445 - val_loss: 0.4772\n",
      "Epoch 1069/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7545 - auc: 0.8345 - loss: 0.4936 - val_acc: 0.7595 - val_auc: 0.8424 - val_loss: 0.4790\n",
      "Epoch 1070/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7573 - auc: 0.8366 - loss: 0.4916 - val_acc: 0.7600 - val_auc: 0.8444 - val_loss: 0.4784\n",
      "Epoch 1071/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7547 - auc: 0.8333 - loss: 0.4942 - val_acc: 0.7600 - val_auc: 0.8444 - val_loss: 0.4775\n",
      "Epoch 1072/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7540 - auc: 0.8339 - loss: 0.4935 - val_acc: 0.7596 - val_auc: 0.8422 - val_loss: 0.4796\n",
      "Epoch 1073/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7530 - auc: 0.8328 - loss: 0.4955 - val_acc: 0.7618 - val_auc: 0.8444 - val_loss: 0.4769\n",
      "Epoch 1074/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7534 - auc: 0.8335 - loss: 0.4943 - val_acc: 0.7599 - val_auc: 0.8441 - val_loss: 0.4787\n",
      "Epoch 1075/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7543 - auc: 0.8334 - loss: 0.4947 - val_acc: 0.7611 - val_auc: 0.8447 - val_loss: 0.4772\n",
      "Epoch 1076/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7549 - auc: 0.8334 - loss: 0.4951 - val_acc: 0.7613 - val_auc: 0.8458 - val_loss: 0.4752\n",
      "Epoch 1077/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7527 - auc: 0.8320 - loss: 0.4955 - val_acc: 0.7591 - val_auc: 0.8432 - val_loss: 0.4783\n",
      "Epoch 1078/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7552 - auc: 0.8330 - loss: 0.4959 - val_acc: 0.7618 - val_auc: 0.8452 - val_loss: 0.4759\n",
      "Epoch 1079/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7527 - auc: 0.8330 - loss: 0.4955 - val_acc: 0.7613 - val_auc: 0.8445 - val_loss: 0.4765\n",
      "Epoch 1080/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7553 - auc: 0.8346 - loss: 0.4930 - val_acc: 0.7601 - val_auc: 0.8448 - val_loss: 0.4767\n",
      "Epoch 1081/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7577 - auc: 0.8356 - loss: 0.4916 - val_acc: 0.7609 - val_auc: 0.8447 - val_loss: 0.4766\n",
      "Epoch 1082/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7544 - auc: 0.8327 - loss: 0.4957 - val_acc: 0.7615 - val_auc: 0.8461 - val_loss: 0.4767\n",
      "Epoch 1083/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7547 - auc: 0.8326 - loss: 0.4957 - val_acc: 0.7622 - val_auc: 0.8448 - val_loss: 0.4762\n",
      "Epoch 1084/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7562 - auc: 0.8349 - loss: 0.4923 - val_acc: 0.7617 - val_auc: 0.8457 - val_loss: 0.4760\n",
      "Epoch 1085/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7547 - auc: 0.8334 - loss: 0.4954 - val_acc: 0.7612 - val_auc: 0.8432 - val_loss: 0.4780\n",
      "Epoch 1086/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7544 - auc: 0.8332 - loss: 0.4945 - val_acc: 0.7621 - val_auc: 0.8439 - val_loss: 0.4785\n",
      "Epoch 1087/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7554 - auc: 0.8344 - loss: 0.4926 - val_acc: 0.7624 - val_auc: 0.8448 - val_loss: 0.4764\n",
      "Epoch 1088/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7552 - auc: 0.8341 - loss: 0.4945 - val_acc: 0.7616 - val_auc: 0.8436 - val_loss: 0.4786\n",
      "Epoch 1089/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7551 - auc: 0.8350 - loss: 0.4927 - val_acc: 0.7648 - val_auc: 0.8455 - val_loss: 0.4754\n",
      "Epoch 1090/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7526 - auc: 0.8328 - loss: 0.4955 - val_acc: 0.7618 - val_auc: 0.8413 - val_loss: 0.4805\n",
      "Epoch 1091/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7531 - auc: 0.8324 - loss: 0.4952 - val_acc: 0.7609 - val_auc: 0.8448 - val_loss: 0.4760\n",
      "Epoch 1092/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7545 - auc: 0.8350 - loss: 0.4928 - val_acc: 0.7638 - val_auc: 0.8456 - val_loss: 0.4761\n",
      "Epoch 1093/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7554 - auc: 0.8348 - loss: 0.4930 - val_acc: 0.7624 - val_auc: 0.8464 - val_loss: 0.4749\n",
      "Epoch 1094/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7570 - auc: 0.8348 - loss: 0.4926 - val_acc: 0.7611 - val_auc: 0.8455 - val_loss: 0.4749\n",
      "Epoch 1095/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7549 - auc: 0.8343 - loss: 0.4941 - val_acc: 0.7605 - val_auc: 0.8442 - val_loss: 0.4768\n",
      "Epoch 1096/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7544 - auc: 0.8345 - loss: 0.4926 - val_acc: 0.7608 - val_auc: 0.8447 - val_loss: 0.4762\n",
      "Epoch 1097/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7547 - auc: 0.8337 - loss: 0.4936 - val_acc: 0.7631 - val_auc: 0.8452 - val_loss: 0.4752\n",
      "Epoch 1098/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7543 - auc: 0.8340 - loss: 0.4943 - val_acc: 0.7605 - val_auc: 0.8444 - val_loss: 0.4773\n",
      "Epoch 1099/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7541 - auc: 0.8330 - loss: 0.4953 - val_acc: 0.7623 - val_auc: 0.8453 - val_loss: 0.4767\n",
      "Epoch 1100/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7556 - auc: 0.8348 - loss: 0.4930 - val_acc: 0.7638 - val_auc: 0.8458 - val_loss: 0.4754\n",
      "Epoch 1101/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7535 - auc: 0.8332 - loss: 0.4955 - val_acc: 0.7624 - val_auc: 0.8437 - val_loss: 0.4779\n",
      "Epoch 1102/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7553 - auc: 0.8345 - loss: 0.4938 - val_acc: 0.7617 - val_auc: 0.8441 - val_loss: 0.4773\n",
      "Epoch 1103/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7554 - auc: 0.8331 - loss: 0.4949 - val_acc: 0.7580 - val_auc: 0.8428 - val_loss: 0.4804\n",
      "Epoch 1104/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7551 - auc: 0.8333 - loss: 0.4946 - val_acc: 0.7621 - val_auc: 0.8438 - val_loss: 0.4794\n",
      "Epoch 1105/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7556 - auc: 0.8349 - loss: 0.4933 - val_acc: 0.7600 - val_auc: 0.8462 - val_loss: 0.4752\n",
      "Epoch 1106/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7559 - auc: 0.8358 - loss: 0.4918 - val_acc: 0.7624 - val_auc: 0.8454 - val_loss: 0.4754\n",
      "Epoch 1107/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7557 - auc: 0.8335 - loss: 0.4948 - val_acc: 0.7605 - val_auc: 0.8445 - val_loss: 0.4771\n",
      "Epoch 1108/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7569 - auc: 0.8354 - loss: 0.4929 - val_acc: 0.7644 - val_auc: 0.8452 - val_loss: 0.4761\n",
      "Epoch 1109/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7556 - auc: 0.8350 - loss: 0.4922 - val_acc: 0.7636 - val_auc: 0.8470 - val_loss: 0.4747\n",
      "Epoch 1110/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7560 - auc: 0.8351 - loss: 0.4924 - val_acc: 0.7637 - val_auc: 0.8453 - val_loss: 0.4748\n",
      "Epoch 1111/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7543 - auc: 0.8345 - loss: 0.4923 - val_acc: 0.7626 - val_auc: 0.8433 - val_loss: 0.4783\n",
      "Epoch 1112/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7506 - auc: 0.8328 - loss: 0.4946 - val_acc: 0.7607 - val_auc: 0.8441 - val_loss: 0.4775\n",
      "Epoch 1113/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7551 - auc: 0.8349 - loss: 0.4929 - val_acc: 0.7630 - val_auc: 0.8450 - val_loss: 0.4765\n",
      "Epoch 1114/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7545 - auc: 0.8338 - loss: 0.4945 - val_acc: 0.7621 - val_auc: 0.8444 - val_loss: 0.4772\n",
      "Epoch 1115/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7557 - auc: 0.8347 - loss: 0.4937 - val_acc: 0.7654 - val_auc: 0.8451 - val_loss: 0.4754\n",
      "Epoch 1116/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7554 - auc: 0.8356 - loss: 0.4921 - val_acc: 0.7631 - val_auc: 0.8458 - val_loss: 0.4747\n",
      "Epoch 1117/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7558 - auc: 0.8358 - loss: 0.4909 - val_acc: 0.7598 - val_auc: 0.8443 - val_loss: 0.4776\n",
      "Epoch 1118/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7550 - auc: 0.8330 - loss: 0.4954 - val_acc: 0.7630 - val_auc: 0.8458 - val_loss: 0.4765\n",
      "Epoch 1119/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7562 - auc: 0.8357 - loss: 0.4923 - val_acc: 0.7630 - val_auc: 0.8453 - val_loss: 0.4762\n",
      "Epoch 1120/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7555 - auc: 0.8338 - loss: 0.4931 - val_acc: 0.7666 - val_auc: 0.8462 - val_loss: 0.4753\n",
      "Epoch 1121/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7569 - auc: 0.8355 - loss: 0.4907 - val_acc: 0.7639 - val_auc: 0.8446 - val_loss: 0.4772\n",
      "Epoch 1122/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7544 - auc: 0.8343 - loss: 0.4940 - val_acc: 0.7626 - val_auc: 0.8454 - val_loss: 0.4762\n",
      "Epoch 1123/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7554 - auc: 0.8350 - loss: 0.4931 - val_acc: 0.7612 - val_auc: 0.8464 - val_loss: 0.4739\n",
      "Epoch 1124/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7537 - auc: 0.8330 - loss: 0.4953 - val_acc: 0.7637 - val_auc: 0.8458 - val_loss: 0.4755\n",
      "Epoch 1125/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7558 - auc: 0.8356 - loss: 0.4923 - val_acc: 0.7639 - val_auc: 0.8458 - val_loss: 0.4748\n",
      "Epoch 1126/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7552 - auc: 0.8351 - loss: 0.4918 - val_acc: 0.7658 - val_auc: 0.8454 - val_loss: 0.4759\n",
      "Epoch 1127/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7574 - auc: 0.8356 - loss: 0.4916 - val_acc: 0.7613 - val_auc: 0.8443 - val_loss: 0.4782\n",
      "Epoch 1128/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7567 - auc: 0.8348 - loss: 0.4930 - val_acc: 0.7667 - val_auc: 0.8480 - val_loss: 0.4735\n",
      "Epoch 1129/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7562 - auc: 0.8351 - loss: 0.4929 - val_acc: 0.7630 - val_auc: 0.8444 - val_loss: 0.4768\n",
      "Epoch 1130/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7551 - auc: 0.8341 - loss: 0.4946 - val_acc: 0.7655 - val_auc: 0.8459 - val_loss: 0.4752\n",
      "Epoch 1131/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7553 - auc: 0.8339 - loss: 0.4937 - val_acc: 0.7627 - val_auc: 0.8447 - val_loss: 0.4755\n",
      "Epoch 1132/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7550 - auc: 0.8343 - loss: 0.4937 - val_acc: 0.7619 - val_auc: 0.8447 - val_loss: 0.4760\n",
      "Epoch 1133/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7573 - auc: 0.8364 - loss: 0.4907 - val_acc: 0.7642 - val_auc: 0.8462 - val_loss: 0.4745\n",
      "Epoch 1134/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7552 - auc: 0.8347 - loss: 0.4924 - val_acc: 0.7619 - val_auc: 0.8433 - val_loss: 0.4801\n",
      "Epoch 1135/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7559 - auc: 0.8358 - loss: 0.4922 - val_acc: 0.7629 - val_auc: 0.8452 - val_loss: 0.4760\n",
      "Epoch 1136/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7559 - auc: 0.8354 - loss: 0.4916 - val_acc: 0.7639 - val_auc: 0.8453 - val_loss: 0.4755\n",
      "Epoch 1137/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7569 - auc: 0.8368 - loss: 0.4905 - val_acc: 0.7612 - val_auc: 0.8456 - val_loss: 0.4765\n",
      "Epoch 1138/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7560 - auc: 0.8346 - loss: 0.4932 - val_acc: 0.7635 - val_auc: 0.8455 - val_loss: 0.4751\n",
      "Epoch 1139/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7555 - auc: 0.8344 - loss: 0.4929 - val_acc: 0.7662 - val_auc: 0.8482 - val_loss: 0.4724\n",
      "Epoch 1140/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7547 - auc: 0.8349 - loss: 0.4926 - val_acc: 0.7645 - val_auc: 0.8459 - val_loss: 0.4750\n",
      "Epoch 1141/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7541 - auc: 0.8349 - loss: 0.4927 - val_acc: 0.7658 - val_auc: 0.8457 - val_loss: 0.4761\n",
      "Epoch 1142/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7547 - auc: 0.8350 - loss: 0.4928 - val_acc: 0.7642 - val_auc: 0.8471 - val_loss: 0.4736\n",
      "Epoch 1143/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7547 - auc: 0.8351 - loss: 0.4927 - val_acc: 0.7628 - val_auc: 0.8447 - val_loss: 0.4760\n",
      "Epoch 1144/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7572 - auc: 0.8357 - loss: 0.4910 - val_acc: 0.7639 - val_auc: 0.8447 - val_loss: 0.4777\n",
      "Epoch 1145/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7559 - auc: 0.8358 - loss: 0.4902 - val_acc: 0.7634 - val_auc: 0.8469 - val_loss: 0.4739\n",
      "Epoch 1146/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7574 - auc: 0.8367 - loss: 0.4907 - val_acc: 0.7621 - val_auc: 0.8457 - val_loss: 0.4756\n",
      "Epoch 1147/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7571 - auc: 0.8367 - loss: 0.4907 - val_acc: 0.7621 - val_auc: 0.8444 - val_loss: 0.4791\n",
      "Epoch 1148/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7564 - auc: 0.8357 - loss: 0.4910 - val_acc: 0.7613 - val_auc: 0.8457 - val_loss: 0.4745\n",
      "Epoch 1149/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7566 - auc: 0.8354 - loss: 0.4919 - val_acc: 0.7618 - val_auc: 0.8439 - val_loss: 0.4776\n",
      "Epoch 1150/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7554 - auc: 0.8344 - loss: 0.4927 - val_acc: 0.7627 - val_auc: 0.8454 - val_loss: 0.4745\n",
      "Epoch 1151/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7542 - auc: 0.8349 - loss: 0.4918 - val_acc: 0.7612 - val_auc: 0.8466 - val_loss: 0.4751\n",
      "Epoch 1152/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7543 - auc: 0.8352 - loss: 0.4914 - val_acc: 0.7647 - val_auc: 0.8477 - val_loss: 0.4721\n",
      "Epoch 1153/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7559 - auc: 0.8347 - loss: 0.4925 - val_acc: 0.7643 - val_auc: 0.8460 - val_loss: 0.4745\n",
      "Epoch 1154/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7560 - auc: 0.8365 - loss: 0.4902 - val_acc: 0.7637 - val_auc: 0.8459 - val_loss: 0.4744\n",
      "Epoch 1155/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7562 - auc: 0.8347 - loss: 0.4935 - val_acc: 0.7645 - val_auc: 0.8468 - val_loss: 0.4730\n",
      "Epoch 1156/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7560 - auc: 0.8355 - loss: 0.4924 - val_acc: 0.7648 - val_auc: 0.8471 - val_loss: 0.4746\n",
      "Epoch 1157/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7557 - auc: 0.8337 - loss: 0.4943 - val_acc: 0.7647 - val_auc: 0.8470 - val_loss: 0.4738\n",
      "Epoch 1158/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7550 - auc: 0.8348 - loss: 0.4924 - val_acc: 0.7621 - val_auc: 0.8449 - val_loss: 0.4770\n",
      "Epoch 1159/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7575 - auc: 0.8372 - loss: 0.4899 - val_acc: 0.7623 - val_auc: 0.8447 - val_loss: 0.4783\n",
      "Epoch 1160/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7568 - auc: 0.8363 - loss: 0.4908 - val_acc: 0.7648 - val_auc: 0.8464 - val_loss: 0.4747\n",
      "Epoch 1161/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7570 - auc: 0.8364 - loss: 0.4916 - val_acc: 0.7646 - val_auc: 0.8469 - val_loss: 0.4746\n",
      "Epoch 1162/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7562 - auc: 0.8338 - loss: 0.4943 - val_acc: 0.7646 - val_auc: 0.8464 - val_loss: 0.4738\n",
      "Epoch 1163/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7550 - auc: 0.8355 - loss: 0.4923 - val_acc: 0.7638 - val_auc: 0.8481 - val_loss: 0.4723\n",
      "Epoch 1164/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7551 - auc: 0.8349 - loss: 0.4933 - val_acc: 0.7640 - val_auc: 0.8465 - val_loss: 0.4739\n",
      "Epoch 1165/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7576 - auc: 0.8361 - loss: 0.4912 - val_acc: 0.7650 - val_auc: 0.8463 - val_loss: 0.4737\n",
      "Epoch 1166/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7554 - auc: 0.8357 - loss: 0.4908 - val_acc: 0.7624 - val_auc: 0.8456 - val_loss: 0.4768\n",
      "Epoch 1167/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7571 - auc: 0.8362 - loss: 0.4919 - val_acc: 0.7655 - val_auc: 0.8476 - val_loss: 0.4743\n",
      "Epoch 1168/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7564 - auc: 0.8370 - loss: 0.4894 - val_acc: 0.7615 - val_auc: 0.8444 - val_loss: 0.4768\n",
      "Epoch 1169/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7579 - auc: 0.8359 - loss: 0.4910 - val_acc: 0.7652 - val_auc: 0.8475 - val_loss: 0.4724\n",
      "Epoch 1170/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7565 - auc: 0.8368 - loss: 0.4898 - val_acc: 0.7632 - val_auc: 0.8461 - val_loss: 0.4739\n",
      "Epoch 1171/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7549 - auc: 0.8338 - loss: 0.4942 - val_acc: 0.7634 - val_auc: 0.8457 - val_loss: 0.4748\n",
      "Epoch 1172/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7538 - auc: 0.8345 - loss: 0.4933 - val_acc: 0.7664 - val_auc: 0.8466 - val_loss: 0.4745\n",
      "Epoch 1173/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7567 - auc: 0.8366 - loss: 0.4910 - val_acc: 0.7648 - val_auc: 0.8477 - val_loss: 0.4728\n",
      "Epoch 1174/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7573 - auc: 0.8360 - loss: 0.4905 - val_acc: 0.7649 - val_auc: 0.8460 - val_loss: 0.4744\n",
      "Epoch 1175/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7566 - auc: 0.8355 - loss: 0.4921 - val_acc: 0.7640 - val_auc: 0.8453 - val_loss: 0.4754\n",
      "Epoch 1176/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7550 - auc: 0.8349 - loss: 0.4930 - val_acc: 0.7637 - val_auc: 0.8460 - val_loss: 0.4744\n",
      "Epoch 1177/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7571 - auc: 0.8358 - loss: 0.4923 - val_acc: 0.7629 - val_auc: 0.8464 - val_loss: 0.4735\n",
      "Epoch 1178/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7562 - auc: 0.8350 - loss: 0.4934 - val_acc: 0.7644 - val_auc: 0.8476 - val_loss: 0.4731\n",
      "Epoch 1179/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7555 - auc: 0.8354 - loss: 0.4926 - val_acc: 0.7622 - val_auc: 0.8476 - val_loss: 0.4733\n",
      "Epoch 1180/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7545 - auc: 0.8345 - loss: 0.4929 - val_acc: 0.7670 - val_auc: 0.8487 - val_loss: 0.4720\n",
      "Epoch 1181/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7572 - auc: 0.8360 - loss: 0.4919 - val_acc: 0.7613 - val_auc: 0.8450 - val_loss: 0.4780\n",
      "Epoch 1182/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7555 - auc: 0.8348 - loss: 0.4932 - val_acc: 0.7631 - val_auc: 0.8488 - val_loss: 0.4724\n",
      "Epoch 1183/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7532 - auc: 0.8351 - loss: 0.4925 - val_acc: 0.7648 - val_auc: 0.8452 - val_loss: 0.4754\n",
      "Epoch 1184/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7570 - auc: 0.8372 - loss: 0.4903 - val_acc: 0.7638 - val_auc: 0.8474 - val_loss: 0.4730\n",
      "Epoch 1185/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7529 - auc: 0.8341 - loss: 0.4931 - val_acc: 0.7619 - val_auc: 0.8455 - val_loss: 0.4749\n",
      "Epoch 1186/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7561 - auc: 0.8356 - loss: 0.4919 - val_acc: 0.7650 - val_auc: 0.8470 - val_loss: 0.4752\n",
      "Epoch 1187/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7552 - auc: 0.8365 - loss: 0.4906 - val_acc: 0.7621 - val_auc: 0.8459 - val_loss: 0.4745\n",
      "Epoch 1188/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7591 - auc: 0.8358 - loss: 0.4918 - val_acc: 0.7636 - val_auc: 0.8479 - val_loss: 0.4734\n",
      "Epoch 1189/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7563 - auc: 0.8355 - loss: 0.4917 - val_acc: 0.7646 - val_auc: 0.8483 - val_loss: 0.4720\n",
      "Epoch 1190/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7550 - auc: 0.8352 - loss: 0.4927 - val_acc: 0.7645 - val_auc: 0.8474 - val_loss: 0.4735\n",
      "Epoch 1191/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7554 - auc: 0.8364 - loss: 0.4918 - val_acc: 0.7619 - val_auc: 0.8457 - val_loss: 0.4748\n",
      "Epoch 1192/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7576 - auc: 0.8373 - loss: 0.4898 - val_acc: 0.7638 - val_auc: 0.8468 - val_loss: 0.4743\n",
      "Epoch 1193/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7595 - auc: 0.8367 - loss: 0.4894 - val_acc: 0.7649 - val_auc: 0.8464 - val_loss: 0.4758\n",
      "Epoch 1194/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7573 - auc: 0.8364 - loss: 0.4910 - val_acc: 0.7648 - val_auc: 0.8480 - val_loss: 0.4719\n",
      "Epoch 1195/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7544 - auc: 0.8336 - loss: 0.4944 - val_acc: 0.7632 - val_auc: 0.8461 - val_loss: 0.4745\n",
      "Epoch 1196/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7551 - auc: 0.8349 - loss: 0.4931 - val_acc: 0.7634 - val_auc: 0.8457 - val_loss: 0.4769\n",
      "Epoch 1197/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7587 - auc: 0.8370 - loss: 0.4897 - val_acc: 0.7635 - val_auc: 0.8474 - val_loss: 0.4727\n",
      "Epoch 1198/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7555 - auc: 0.8357 - loss: 0.4906 - val_acc: 0.7666 - val_auc: 0.8463 - val_loss: 0.4741\n",
      "Epoch 1199/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7571 - auc: 0.8359 - loss: 0.4917 - val_acc: 0.7633 - val_auc: 0.8461 - val_loss: 0.4743\n",
      "Epoch 1200/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7572 - auc: 0.8358 - loss: 0.4921 - val_acc: 0.7631 - val_auc: 0.8458 - val_loss: 0.4746\n",
      "Epoch 1201/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7559 - auc: 0.8368 - loss: 0.4901 - val_acc: 0.7642 - val_auc: 0.8457 - val_loss: 0.4761\n",
      "Epoch 1202/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7546 - auc: 0.8337 - loss: 0.4935 - val_acc: 0.7670 - val_auc: 0.8477 - val_loss: 0.4744\n",
      "Epoch 1203/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7582 - auc: 0.8365 - loss: 0.4909 - val_acc: 0.7650 - val_auc: 0.8474 - val_loss: 0.4724\n",
      "Epoch 1204/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7556 - auc: 0.8353 - loss: 0.4905 - val_acc: 0.7679 - val_auc: 0.8480 - val_loss: 0.4716\n",
      "Epoch 1205/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7555 - auc: 0.8359 - loss: 0.4904 - val_acc: 0.7646 - val_auc: 0.8480 - val_loss: 0.4716\n",
      "Epoch 1206/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7586 - auc: 0.8376 - loss: 0.4892 - val_acc: 0.7633 - val_auc: 0.8459 - val_loss: 0.4745\n",
      "Epoch 1207/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7549 - auc: 0.8355 - loss: 0.4913 - val_acc: 0.7644 - val_auc: 0.8463 - val_loss: 0.4752\n",
      "Epoch 1208/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7572 - auc: 0.8359 - loss: 0.4913 - val_acc: 0.7639 - val_auc: 0.8460 - val_loss: 0.4760\n",
      "Epoch 1209/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7571 - auc: 0.8361 - loss: 0.4895 - val_acc: 0.7638 - val_auc: 0.8465 - val_loss: 0.4743\n",
      "Epoch 1210/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7550 - auc: 0.8344 - loss: 0.4934 - val_acc: 0.7630 - val_auc: 0.8473 - val_loss: 0.4726\n",
      "Epoch 1211/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7570 - auc: 0.8358 - loss: 0.4916 - val_acc: 0.7653 - val_auc: 0.8483 - val_loss: 0.4715\n",
      "Epoch 1212/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7574 - auc: 0.8369 - loss: 0.4910 - val_acc: 0.7663 - val_auc: 0.8462 - val_loss: 0.4746\n",
      "Epoch 1213/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7574 - auc: 0.8370 - loss: 0.4898 - val_acc: 0.7629 - val_auc: 0.8458 - val_loss: 0.4762\n",
      "Epoch 1214/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7576 - auc: 0.8363 - loss: 0.4918 - val_acc: 0.7617 - val_auc: 0.8458 - val_loss: 0.4746\n",
      "Epoch 1215/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7574 - auc: 0.8372 - loss: 0.4892 - val_acc: 0.7623 - val_auc: 0.8455 - val_loss: 0.4761\n",
      "Epoch 1216/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7569 - auc: 0.8360 - loss: 0.4917 - val_acc: 0.7651 - val_auc: 0.8460 - val_loss: 0.4752\n",
      "Epoch 1217/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7566 - auc: 0.8367 - loss: 0.4911 - val_acc: 0.7646 - val_auc: 0.8485 - val_loss: 0.4712\n",
      "Epoch 1218/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7559 - auc: 0.8353 - loss: 0.4927 - val_acc: 0.7662 - val_auc: 0.8468 - val_loss: 0.4754\n",
      "Epoch 1219/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7563 - auc: 0.8352 - loss: 0.4925 - val_acc: 0.7632 - val_auc: 0.8483 - val_loss: 0.4731\n",
      "Epoch 1220/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7570 - auc: 0.8355 - loss: 0.4920 - val_acc: 0.7649 - val_auc: 0.8475 - val_loss: 0.4723\n",
      "Epoch 1221/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7562 - auc: 0.8371 - loss: 0.4903 - val_acc: 0.7630 - val_auc: 0.8472 - val_loss: 0.4732\n",
      "Epoch 1222/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7562 - auc: 0.8359 - loss: 0.4908 - val_acc: 0.7647 - val_auc: 0.8472 - val_loss: 0.4737\n",
      "Epoch 1223/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7571 - auc: 0.8367 - loss: 0.4903 - val_acc: 0.7634 - val_auc: 0.8464 - val_loss: 0.4739\n",
      "Epoch 1224/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7558 - auc: 0.8368 - loss: 0.4900 - val_acc: 0.7667 - val_auc: 0.8485 - val_loss: 0.4719\n",
      "Epoch 1225/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7573 - auc: 0.8359 - loss: 0.4920 - val_acc: 0.7642 - val_auc: 0.8476 - val_loss: 0.4735\n",
      "Epoch 1226/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7573 - auc: 0.8369 - loss: 0.4902 - val_acc: 0.7679 - val_auc: 0.8491 - val_loss: 0.4710\n",
      "Epoch 1227/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7581 - auc: 0.8374 - loss: 0.4900 - val_acc: 0.7643 - val_auc: 0.8477 - val_loss: 0.4733\n",
      "Epoch 1228/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7589 - auc: 0.8373 - loss: 0.4908 - val_acc: 0.7666 - val_auc: 0.8484 - val_loss: 0.4708\n",
      "Epoch 1229/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7554 - auc: 0.8365 - loss: 0.4903 - val_acc: 0.7606 - val_auc: 0.8452 - val_loss: 0.4763\n",
      "Epoch 1230/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7559 - auc: 0.8356 - loss: 0.4922 - val_acc: 0.7671 - val_auc: 0.8490 - val_loss: 0.4712\n",
      "Epoch 1231/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7566 - auc: 0.8362 - loss: 0.4907 - val_acc: 0.7658 - val_auc: 0.8479 - val_loss: 0.4733\n",
      "Epoch 1232/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7573 - auc: 0.8368 - loss: 0.4909 - val_acc: 0.7666 - val_auc: 0.8474 - val_loss: 0.4726\n",
      "Epoch 1233/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7580 - auc: 0.8370 - loss: 0.4900 - val_acc: 0.7667 - val_auc: 0.8473 - val_loss: 0.4729\n",
      "Epoch 1234/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7568 - auc: 0.8365 - loss: 0.4909 - val_acc: 0.7686 - val_auc: 0.8485 - val_loss: 0.4722\n",
      "Epoch 1235/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7575 - auc: 0.8373 - loss: 0.4897 - val_acc: 0.7681 - val_auc: 0.8474 - val_loss: 0.4731\n",
      "Epoch 1236/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7548 - auc: 0.8350 - loss: 0.4923 - val_acc: 0.7655 - val_auc: 0.8471 - val_loss: 0.4743\n",
      "Epoch 1237/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7576 - auc: 0.8362 - loss: 0.4908 - val_acc: 0.7669 - val_auc: 0.8487 - val_loss: 0.4727\n",
      "Epoch 1238/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7580 - auc: 0.8370 - loss: 0.4891 - val_acc: 0.7670 - val_auc: 0.8487 - val_loss: 0.4711\n",
      "Epoch 1239/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7585 - auc: 0.8368 - loss: 0.4902 - val_acc: 0.7636 - val_auc: 0.8483 - val_loss: 0.4719\n",
      "Epoch 1240/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7582 - auc: 0.8370 - loss: 0.4903 - val_acc: 0.7670 - val_auc: 0.8489 - val_loss: 0.4712\n",
      "Epoch 1241/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7578 - auc: 0.8367 - loss: 0.4902 - val_acc: 0.7655 - val_auc: 0.8468 - val_loss: 0.4743\n",
      "Epoch 1242/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7573 - auc: 0.8362 - loss: 0.4898 - val_acc: 0.7640 - val_auc: 0.8461 - val_loss: 0.4748\n",
      "Epoch 1243/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7577 - auc: 0.8370 - loss: 0.4896 - val_acc: 0.7668 - val_auc: 0.8472 - val_loss: 0.4734\n",
      "Epoch 1244/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7566 - auc: 0.8363 - loss: 0.4907 - val_acc: 0.7680 - val_auc: 0.8496 - val_loss: 0.4703\n",
      "Epoch 1245/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7561 - auc: 0.8363 - loss: 0.4903 - val_acc: 0.7667 - val_auc: 0.8479 - val_loss: 0.4735\n",
      "Epoch 1246/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7564 - auc: 0.8362 - loss: 0.4910 - val_acc: 0.7662 - val_auc: 0.8483 - val_loss: 0.4719\n",
      "Epoch 1247/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7566 - auc: 0.8360 - loss: 0.4913 - val_acc: 0.7662 - val_auc: 0.8474 - val_loss: 0.4732\n",
      "Epoch 1248/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7568 - auc: 0.8357 - loss: 0.4915 - val_acc: 0.7675 - val_auc: 0.8477 - val_loss: 0.4726\n",
      "Epoch 1249/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7580 - auc: 0.8373 - loss: 0.4892 - val_acc: 0.7635 - val_auc: 0.8472 - val_loss: 0.4742\n",
      "Epoch 1250/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7568 - auc: 0.8357 - loss: 0.4913 - val_acc: 0.7664 - val_auc: 0.8484 - val_loss: 0.4715\n",
      "Epoch 1251/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7577 - auc: 0.8359 - loss: 0.4908 - val_acc: 0.7671 - val_auc: 0.8471 - val_loss: 0.4731\n",
      "Epoch 1252/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7573 - auc: 0.8365 - loss: 0.4901 - val_acc: 0.7680 - val_auc: 0.8479 - val_loss: 0.4718\n",
      "Epoch 1253/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7565 - auc: 0.8369 - loss: 0.4897 - val_acc: 0.7643 - val_auc: 0.8470 - val_loss: 0.4734\n",
      "Epoch 1254/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7562 - auc: 0.8362 - loss: 0.4913 - val_acc: 0.7642 - val_auc: 0.8478 - val_loss: 0.4728\n",
      "Epoch 1255/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7560 - auc: 0.8365 - loss: 0.4914 - val_acc: 0.7658 - val_auc: 0.8476 - val_loss: 0.4742\n",
      "Epoch 1256/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7567 - auc: 0.8377 - loss: 0.4887 - val_acc: 0.7668 - val_auc: 0.8496 - val_loss: 0.4703\n",
      "Epoch 1257/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7547 - auc: 0.8358 - loss: 0.4917 - val_acc: 0.7648 - val_auc: 0.8475 - val_loss: 0.4722\n",
      "Epoch 1258/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7577 - auc: 0.8370 - loss: 0.4902 - val_acc: 0.7662 - val_auc: 0.8482 - val_loss: 0.4715\n",
      "Epoch 1259/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7588 - auc: 0.8376 - loss: 0.4882 - val_acc: 0.7675 - val_auc: 0.8487 - val_loss: 0.4724\n",
      "Epoch 1260/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7584 - auc: 0.8379 - loss: 0.4882 - val_acc: 0.7657 - val_auc: 0.8475 - val_loss: 0.4713\n",
      "Epoch 1261/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7565 - auc: 0.8361 - loss: 0.4908 - val_acc: 0.7650 - val_auc: 0.8466 - val_loss: 0.4730\n",
      "Epoch 1262/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7582 - auc: 0.8375 - loss: 0.4892 - val_acc: 0.7642 - val_auc: 0.8476 - val_loss: 0.4741\n",
      "Epoch 1263/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7584 - auc: 0.8359 - loss: 0.4910 - val_acc: 0.7630 - val_auc: 0.8468 - val_loss: 0.4758\n",
      "Epoch 1264/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7576 - auc: 0.8382 - loss: 0.4885 - val_acc: 0.7657 - val_auc: 0.8483 - val_loss: 0.4713\n",
      "Epoch 1265/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7583 - auc: 0.8377 - loss: 0.4889 - val_acc: 0.7669 - val_auc: 0.8474 - val_loss: 0.4726\n",
      "Epoch 1266/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7589 - auc: 0.8383 - loss: 0.4885 - val_acc: 0.7651 - val_auc: 0.8477 - val_loss: 0.4721\n",
      "Epoch 1267/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7574 - auc: 0.8373 - loss: 0.4901 - val_acc: 0.7664 - val_auc: 0.8481 - val_loss: 0.4722\n",
      "Epoch 1268/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7564 - auc: 0.8357 - loss: 0.4916 - val_acc: 0.7661 - val_auc: 0.8482 - val_loss: 0.4717\n",
      "Epoch 1269/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7586 - auc: 0.8388 - loss: 0.4881 - val_acc: 0.7646 - val_auc: 0.8468 - val_loss: 0.4744\n",
      "Epoch 1270/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7583 - auc: 0.8383 - loss: 0.4877 - val_acc: 0.7677 - val_auc: 0.8485 - val_loss: 0.4706\n",
      "Epoch 1271/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7582 - auc: 0.8366 - loss: 0.4906 - val_acc: 0.7632 - val_auc: 0.8472 - val_loss: 0.4736\n",
      "Epoch 1272/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7572 - auc: 0.8368 - loss: 0.4894 - val_acc: 0.7684 - val_auc: 0.8474 - val_loss: 0.4738\n",
      "Epoch 1273/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7594 - auc: 0.8385 - loss: 0.4890 - val_acc: 0.7690 - val_auc: 0.8498 - val_loss: 0.4695\n",
      "Epoch 1274/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7575 - auc: 0.8367 - loss: 0.4899 - val_acc: 0.7656 - val_auc: 0.8481 - val_loss: 0.4717\n",
      "Epoch 1275/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7575 - auc: 0.8365 - loss: 0.4900 - val_acc: 0.7668 - val_auc: 0.8479 - val_loss: 0.4720\n",
      "Epoch 1276/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7564 - auc: 0.8373 - loss: 0.4894 - val_acc: 0.7688 - val_auc: 0.8482 - val_loss: 0.4720\n",
      "Epoch 1277/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7569 - auc: 0.8367 - loss: 0.4900 - val_acc: 0.7661 - val_auc: 0.8473 - val_loss: 0.4725\n",
      "Epoch 1278/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7575 - auc: 0.8378 - loss: 0.4890 - val_acc: 0.7670 - val_auc: 0.8492 - val_loss: 0.4707\n",
      "Epoch 1279/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7584 - auc: 0.8383 - loss: 0.4888 - val_acc: 0.7669 - val_auc: 0.8491 - val_loss: 0.4705\n",
      "Epoch 1280/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7576 - auc: 0.8366 - loss: 0.4902 - val_acc: 0.7678 - val_auc: 0.8480 - val_loss: 0.4735\n",
      "Epoch 1281/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7592 - auc: 0.8391 - loss: 0.4880 - val_acc: 0.7641 - val_auc: 0.8487 - val_loss: 0.4709\n",
      "Epoch 1282/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7561 - auc: 0.8363 - loss: 0.4913 - val_acc: 0.7669 - val_auc: 0.8466 - val_loss: 0.4744\n",
      "Epoch 1283/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7593 - auc: 0.8387 - loss: 0.4881 - val_acc: 0.7688 - val_auc: 0.8499 - val_loss: 0.4706\n",
      "Epoch 1284/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7564 - auc: 0.8368 - loss: 0.4896 - val_acc: 0.7674 - val_auc: 0.8497 - val_loss: 0.4697\n",
      "Epoch 1285/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7565 - auc: 0.8359 - loss: 0.4912 - val_acc: 0.7665 - val_auc: 0.8481 - val_loss: 0.4715\n",
      "Epoch 1286/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7577 - auc: 0.8364 - loss: 0.4907 - val_acc: 0.7654 - val_auc: 0.8484 - val_loss: 0.4721\n",
      "Epoch 1287/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7589 - auc: 0.8384 - loss: 0.4874 - val_acc: 0.7659 - val_auc: 0.8487 - val_loss: 0.4708\n",
      "Epoch 1288/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7589 - auc: 0.8371 - loss: 0.4899 - val_acc: 0.7674 - val_auc: 0.8472 - val_loss: 0.4724\n",
      "Epoch 1289/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7571 - auc: 0.8388 - loss: 0.4862 - val_acc: 0.7696 - val_auc: 0.8483 - val_loss: 0.4714\n",
      "Epoch 1290/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7584 - auc: 0.8369 - loss: 0.4903 - val_acc: 0.7664 - val_auc: 0.8476 - val_loss: 0.4736\n",
      "Epoch 1291/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7577 - auc: 0.8374 - loss: 0.4900 - val_acc: 0.7667 - val_auc: 0.8480 - val_loss: 0.4734\n",
      "Epoch 1292/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7571 - auc: 0.8363 - loss: 0.4903 - val_acc: 0.7654 - val_auc: 0.8469 - val_loss: 0.4729\n",
      "Epoch 1293/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7590 - auc: 0.8382 - loss: 0.4882 - val_acc: 0.7684 - val_auc: 0.8484 - val_loss: 0.4711\n",
      "Epoch 1294/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7589 - auc: 0.8377 - loss: 0.4883 - val_acc: 0.7663 - val_auc: 0.8479 - val_loss: 0.4719\n",
      "Epoch 1295/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7590 - auc: 0.8378 - loss: 0.4895 - val_acc: 0.7697 - val_auc: 0.8477 - val_loss: 0.4715\n",
      "Epoch 1296/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7562 - auc: 0.8364 - loss: 0.4907 - val_acc: 0.7675 - val_auc: 0.8478 - val_loss: 0.4742\n",
      "Epoch 1297/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7582 - auc: 0.8374 - loss: 0.4893 - val_acc: 0.7659 - val_auc: 0.8476 - val_loss: 0.4737\n",
      "Epoch 1298/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7571 - auc: 0.8366 - loss: 0.4904 - val_acc: 0.7633 - val_auc: 0.8474 - val_loss: 0.4732\n",
      "Epoch 1299/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7575 - auc: 0.8375 - loss: 0.4894 - val_acc: 0.7671 - val_auc: 0.8492 - val_loss: 0.4690\n",
      "Epoch 1300/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7578 - auc: 0.8391 - loss: 0.4864 - val_acc: 0.7632 - val_auc: 0.8475 - val_loss: 0.4709\n",
      "Epoch 1301/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7583 - auc: 0.8387 - loss: 0.4868 - val_acc: 0.7681 - val_auc: 0.8486 - val_loss: 0.4711\n",
      "Epoch 1302/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7577 - auc: 0.8375 - loss: 0.4886 - val_acc: 0.7679 - val_auc: 0.8506 - val_loss: 0.4693\n",
      "Epoch 1303/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7582 - auc: 0.8383 - loss: 0.4881 - val_acc: 0.7645 - val_auc: 0.8482 - val_loss: 0.4726\n",
      "Epoch 1304/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7567 - auc: 0.8379 - loss: 0.4876 - val_acc: 0.7661 - val_auc: 0.8487 - val_loss: 0.4703\n",
      "Epoch 1305/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7585 - auc: 0.8389 - loss: 0.4875 - val_acc: 0.7698 - val_auc: 0.8504 - val_loss: 0.4689\n",
      "Epoch 1306/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7587 - auc: 0.8372 - loss: 0.4898 - val_acc: 0.7690 - val_auc: 0.8503 - val_loss: 0.4686\n",
      "Epoch 1307/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7582 - auc: 0.8372 - loss: 0.4890 - val_acc: 0.7671 - val_auc: 0.8488 - val_loss: 0.4722\n",
      "Epoch 1308/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7569 - auc: 0.8375 - loss: 0.4887 - val_acc: 0.7659 - val_auc: 0.8477 - val_loss: 0.4742\n",
      "Epoch 1309/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7593 - auc: 0.8377 - loss: 0.4880 - val_acc: 0.7641 - val_auc: 0.8490 - val_loss: 0.4704\n",
      "Epoch 1310/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7583 - auc: 0.8383 - loss: 0.4876 - val_acc: 0.7666 - val_auc: 0.8484 - val_loss: 0.4710\n",
      "Epoch 1311/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7585 - auc: 0.8367 - loss: 0.4900 - val_acc: 0.7636 - val_auc: 0.8463 - val_loss: 0.4750\n",
      "Epoch 1312/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7566 - auc: 0.8366 - loss: 0.4899 - val_acc: 0.7672 - val_auc: 0.8495 - val_loss: 0.4712\n",
      "Epoch 1313/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7568 - auc: 0.8379 - loss: 0.4888 - val_acc: 0.7679 - val_auc: 0.8491 - val_loss: 0.4714\n",
      "Epoch 1314/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7596 - auc: 0.8381 - loss: 0.4888 - val_acc: 0.7696 - val_auc: 0.8499 - val_loss: 0.4692\n",
      "Epoch 1315/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7594 - auc: 0.8390 - loss: 0.4874 - val_acc: 0.7674 - val_auc: 0.8497 - val_loss: 0.4700\n",
      "Epoch 1316/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7572 - auc: 0.8372 - loss: 0.4895 - val_acc: 0.7676 - val_auc: 0.8487 - val_loss: 0.4708\n",
      "Epoch 1317/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7595 - auc: 0.8391 - loss: 0.4874 - val_acc: 0.7711 - val_auc: 0.8493 - val_loss: 0.4698\n",
      "Epoch 1318/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7584 - auc: 0.8372 - loss: 0.4900 - val_acc: 0.7665 - val_auc: 0.8492 - val_loss: 0.4704\n",
      "Epoch 1319/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7579 - auc: 0.8368 - loss: 0.4906 - val_acc: 0.7678 - val_auc: 0.8496 - val_loss: 0.4707\n",
      "Epoch 1320/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7561 - auc: 0.8371 - loss: 0.4891 - val_acc: 0.7689 - val_auc: 0.8505 - val_loss: 0.4703\n",
      "Epoch 1321/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7593 - auc: 0.8384 - loss: 0.4884 - val_acc: 0.7671 - val_auc: 0.8504 - val_loss: 0.4693\n",
      "Epoch 1322/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7579 - auc: 0.8394 - loss: 0.4870 - val_acc: 0.7677 - val_auc: 0.8494 - val_loss: 0.4701\n",
      "Epoch 1323/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7580 - auc: 0.8378 - loss: 0.4898 - val_acc: 0.7674 - val_auc: 0.8501 - val_loss: 0.4685\n",
      "Epoch 1324/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7584 - auc: 0.8379 - loss: 0.4890 - val_acc: 0.7696 - val_auc: 0.8492 - val_loss: 0.4702\n",
      "Epoch 1325/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7583 - auc: 0.8378 - loss: 0.4893 - val_acc: 0.7640 - val_auc: 0.8480 - val_loss: 0.4728\n",
      "Epoch 1326/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7610 - auc: 0.8389 - loss: 0.4870 - val_acc: 0.7670 - val_auc: 0.8492 - val_loss: 0.4696\n",
      "Epoch 1327/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7576 - auc: 0.8376 - loss: 0.4886 - val_acc: 0.7679 - val_auc: 0.8503 - val_loss: 0.4675\n",
      "Epoch 1328/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7560 - auc: 0.8375 - loss: 0.4881 - val_acc: 0.7671 - val_auc: 0.8499 - val_loss: 0.4696\n",
      "Epoch 1329/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7588 - auc: 0.8384 - loss: 0.4885 - val_acc: 0.7681 - val_auc: 0.8502 - val_loss: 0.4682\n",
      "Epoch 1330/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7602 - auc: 0.8385 - loss: 0.4888 - val_acc: 0.7680 - val_auc: 0.8502 - val_loss: 0.4713\n",
      "Epoch 1331/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7578 - auc: 0.8360 - loss: 0.4908 - val_acc: 0.7670 - val_auc: 0.8497 - val_loss: 0.4703\n",
      "Epoch 1332/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7573 - auc: 0.8374 - loss: 0.4900 - val_acc: 0.7686 - val_auc: 0.8501 - val_loss: 0.4691\n",
      "Epoch 1333/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7607 - auc: 0.8387 - loss: 0.4874 - val_acc: 0.7676 - val_auc: 0.8504 - val_loss: 0.4688\n",
      "Epoch 1334/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7583 - auc: 0.8382 - loss: 0.4885 - val_acc: 0.7671 - val_auc: 0.8488 - val_loss: 0.4706\n",
      "Epoch 1335/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7573 - auc: 0.8363 - loss: 0.4908 - val_acc: 0.7655 - val_auc: 0.8485 - val_loss: 0.4719\n",
      "Epoch 1336/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7570 - auc: 0.8380 - loss: 0.4885 - val_acc: 0.7669 - val_auc: 0.8496 - val_loss: 0.4704\n",
      "Epoch 1337/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7601 - auc: 0.8385 - loss: 0.4878 - val_acc: 0.7695 - val_auc: 0.8497 - val_loss: 0.4703\n",
      "Epoch 1338/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7588 - auc: 0.8380 - loss: 0.4887 - val_acc: 0.7665 - val_auc: 0.8480 - val_loss: 0.4713\n",
      "Epoch 1339/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7581 - auc: 0.8381 - loss: 0.4878 - val_acc: 0.7675 - val_auc: 0.8490 - val_loss: 0.4716\n",
      "Epoch 1340/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7587 - auc: 0.8368 - loss: 0.4901 - val_acc: 0.7664 - val_auc: 0.8486 - val_loss: 0.4706\n",
      "Epoch 1341/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7619 - auc: 0.8408 - loss: 0.4849 - val_acc: 0.7682 - val_auc: 0.8507 - val_loss: 0.4675\n",
      "Epoch 1342/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7574 - auc: 0.8374 - loss: 0.4891 - val_acc: 0.7679 - val_auc: 0.8503 - val_loss: 0.4688\n",
      "Epoch 1343/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7608 - auc: 0.8396 - loss: 0.4867 - val_acc: 0.7686 - val_auc: 0.8526 - val_loss: 0.4652\n",
      "Epoch 1344/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7595 - auc: 0.8379 - loss: 0.4885 - val_acc: 0.7682 - val_auc: 0.8486 - val_loss: 0.4713\n",
      "Epoch 1345/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7588 - auc: 0.8384 - loss: 0.4879 - val_acc: 0.7678 - val_auc: 0.8484 - val_loss: 0.4724\n",
      "Epoch 1346/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7594 - auc: 0.8401 - loss: 0.4857 - val_acc: 0.7710 - val_auc: 0.8496 - val_loss: 0.4692\n",
      "Epoch 1347/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7607 - auc: 0.8390 - loss: 0.4880 - val_acc: 0.7689 - val_auc: 0.8499 - val_loss: 0.4700\n",
      "Epoch 1348/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7609 - auc: 0.8403 - loss: 0.4855 - val_acc: 0.7677 - val_auc: 0.8492 - val_loss: 0.4714\n",
      "Epoch 1349/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7582 - auc: 0.8382 - loss: 0.4883 - val_acc: 0.7661 - val_auc: 0.8485 - val_loss: 0.4724\n",
      "Epoch 1350/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7591 - auc: 0.8376 - loss: 0.4888 - val_acc: 0.7681 - val_auc: 0.8492 - val_loss: 0.4716\n",
      "Epoch 1351/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7585 - auc: 0.8384 - loss: 0.4874 - val_acc: 0.7663 - val_auc: 0.8485 - val_loss: 0.4710\n",
      "Epoch 1352/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7577 - auc: 0.8396 - loss: 0.4855 - val_acc: 0.7674 - val_auc: 0.8493 - val_loss: 0.4701\n",
      "Epoch 1353/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7584 - auc: 0.8388 - loss: 0.4876 - val_acc: 0.7657 - val_auc: 0.8474 - val_loss: 0.4732\n",
      "Epoch 1354/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7597 - auc: 0.8395 - loss: 0.4867 - val_acc: 0.7680 - val_auc: 0.8492 - val_loss: 0.4705\n",
      "Epoch 1355/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7584 - auc: 0.8383 - loss: 0.4881 - val_acc: 0.7667 - val_auc: 0.8504 - val_loss: 0.4691\n",
      "Epoch 1356/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7583 - auc: 0.8383 - loss: 0.4876 - val_acc: 0.7651 - val_auc: 0.8485 - val_loss: 0.4721\n",
      "Epoch 1357/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7589 - auc: 0.8382 - loss: 0.4882 - val_acc: 0.7674 - val_auc: 0.8496 - val_loss: 0.4699\n",
      "Epoch 1358/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7577 - auc: 0.8382 - loss: 0.4882 - val_acc: 0.7667 - val_auc: 0.8502 - val_loss: 0.4704\n",
      "Epoch 1359/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7575 - auc: 0.8374 - loss: 0.4896 - val_acc: 0.7655 - val_auc: 0.8470 - val_loss: 0.4718\n",
      "Epoch 1360/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7591 - auc: 0.8392 - loss: 0.4872 - val_acc: 0.7689 - val_auc: 0.8511 - val_loss: 0.4683\n",
      "Epoch 1361/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7594 - auc: 0.8391 - loss: 0.4863 - val_acc: 0.7698 - val_auc: 0.8513 - val_loss: 0.4675\n",
      "Epoch 1362/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7589 - auc: 0.8393 - loss: 0.4866 - val_acc: 0.7710 - val_auc: 0.8491 - val_loss: 0.4705\n",
      "Epoch 1363/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7595 - auc: 0.8391 - loss: 0.4875 - val_acc: 0.7676 - val_auc: 0.8505 - val_loss: 0.4680\n",
      "Epoch 1364/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7590 - auc: 0.8394 - loss: 0.4867 - val_acc: 0.7690 - val_auc: 0.8488 - val_loss: 0.4709\n",
      "Epoch 1365/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7594 - auc: 0.8378 - loss: 0.4900 - val_acc: 0.7666 - val_auc: 0.8498 - val_loss: 0.4695\n",
      "Epoch 1366/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7585 - auc: 0.8383 - loss: 0.4892 - val_acc: 0.7663 - val_auc: 0.8488 - val_loss: 0.4707\n",
      "Epoch 1367/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7585 - auc: 0.8384 - loss: 0.4880 - val_acc: 0.7668 - val_auc: 0.8493 - val_loss: 0.4720\n",
      "Epoch 1368/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7597 - auc: 0.8385 - loss: 0.4883 - val_acc: 0.7678 - val_auc: 0.8495 - val_loss: 0.4695\n",
      "Epoch 1369/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7576 - auc: 0.8379 - loss: 0.4884 - val_acc: 0.7663 - val_auc: 0.8486 - val_loss: 0.4724\n",
      "Epoch 1370/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7602 - auc: 0.8387 - loss: 0.4878 - val_acc: 0.7687 - val_auc: 0.8510 - val_loss: 0.4691\n",
      "Epoch 1371/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7572 - auc: 0.8385 - loss: 0.4876 - val_acc: 0.7672 - val_auc: 0.8489 - val_loss: 0.4711\n",
      "Epoch 1372/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7576 - auc: 0.8382 - loss: 0.4881 - val_acc: 0.7685 - val_auc: 0.8504 - val_loss: 0.4678\n",
      "Epoch 1373/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7601 - auc: 0.8392 - loss: 0.4871 - val_acc: 0.7653 - val_auc: 0.8492 - val_loss: 0.4723\n",
      "Epoch 1374/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7602 - auc: 0.8394 - loss: 0.4878 - val_acc: 0.7704 - val_auc: 0.8502 - val_loss: 0.4693\n",
      "Epoch 1375/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7579 - auc: 0.8378 - loss: 0.4888 - val_acc: 0.7701 - val_auc: 0.8512 - val_loss: 0.4688\n",
      "Epoch 1376/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7592 - auc: 0.8395 - loss: 0.4861 - val_acc: 0.7698 - val_auc: 0.8501 - val_loss: 0.4678\n",
      "Epoch 1377/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7579 - auc: 0.8388 - loss: 0.4872 - val_acc: 0.7704 - val_auc: 0.8501 - val_loss: 0.4687\n",
      "Epoch 1378/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7592 - auc: 0.8382 - loss: 0.4878 - val_acc: 0.7692 - val_auc: 0.8511 - val_loss: 0.4682\n",
      "Epoch 1379/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7591 - auc: 0.8385 - loss: 0.4878 - val_acc: 0.7680 - val_auc: 0.8502 - val_loss: 0.4684\n",
      "Epoch 1380/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7608 - auc: 0.8391 - loss: 0.4867 - val_acc: 0.7645 - val_auc: 0.8474 - val_loss: 0.4728\n",
      "Epoch 1381/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7602 - auc: 0.8387 - loss: 0.4885 - val_acc: 0.7678 - val_auc: 0.8503 - val_loss: 0.4687\n",
      "Epoch 1382/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7562 - auc: 0.8364 - loss: 0.4910 - val_acc: 0.7679 - val_auc: 0.8490 - val_loss: 0.4726\n",
      "Epoch 1383/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7594 - auc: 0.8387 - loss: 0.4881 - val_acc: 0.7678 - val_auc: 0.8474 - val_loss: 0.4715\n",
      "Epoch 1384/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7587 - auc: 0.8387 - loss: 0.4884 - val_acc: 0.7675 - val_auc: 0.8491 - val_loss: 0.4715\n",
      "Epoch 1385/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7593 - auc: 0.8387 - loss: 0.4879 - val_acc: 0.7658 - val_auc: 0.8468 - val_loss: 0.4739\n",
      "Epoch 1386/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7584 - auc: 0.8380 - loss: 0.4886 - val_acc: 0.7674 - val_auc: 0.8501 - val_loss: 0.4690\n",
      "Epoch 1387/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7589 - auc: 0.8378 - loss: 0.4890 - val_acc: 0.7695 - val_auc: 0.8503 - val_loss: 0.4685\n",
      "Epoch 1388/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7602 - auc: 0.8405 - loss: 0.4850 - val_acc: 0.7674 - val_auc: 0.8498 - val_loss: 0.4687\n",
      "Epoch 1389/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7608 - auc: 0.8402 - loss: 0.4863 - val_acc: 0.7690 - val_auc: 0.8495 - val_loss: 0.4698\n",
      "Epoch 1390/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7580 - auc: 0.8383 - loss: 0.4887 - val_acc: 0.7664 - val_auc: 0.8488 - val_loss: 0.4724\n",
      "Epoch 1391/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7592 - auc: 0.8392 - loss: 0.4873 - val_acc: 0.7699 - val_auc: 0.8499 - val_loss: 0.4693\n",
      "Epoch 1392/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7601 - auc: 0.8382 - loss: 0.4891 - val_acc: 0.7712 - val_auc: 0.8515 - val_loss: 0.4681\n",
      "Epoch 1393/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7579 - auc: 0.8385 - loss: 0.4877 - val_acc: 0.7704 - val_auc: 0.8500 - val_loss: 0.4699\n",
      "Epoch 1394/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7578 - auc: 0.8394 - loss: 0.4863 - val_acc: 0.7693 - val_auc: 0.8502 - val_loss: 0.4692\n",
      "Epoch 1395/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7603 - auc: 0.8400 - loss: 0.4857 - val_acc: 0.7692 - val_auc: 0.8503 - val_loss: 0.4686\n",
      "Epoch 1396/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7613 - auc: 0.8389 - loss: 0.4879 - val_acc: 0.7687 - val_auc: 0.8498 - val_loss: 0.4692\n",
      "Epoch 1397/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7601 - auc: 0.8391 - loss: 0.4871 - val_acc: 0.7677 - val_auc: 0.8494 - val_loss: 0.4703\n",
      "Epoch 1398/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7625 - auc: 0.8405 - loss: 0.4856 - val_acc: 0.7687 - val_auc: 0.8485 - val_loss: 0.4700\n",
      "Epoch 1399/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7578 - auc: 0.8384 - loss: 0.4879 - val_acc: 0.7671 - val_auc: 0.8495 - val_loss: 0.4695\n",
      "Epoch 1400/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7598 - auc: 0.8397 - loss: 0.4865 - val_acc: 0.7686 - val_auc: 0.8507 - val_loss: 0.4683\n",
      "Epoch 1401/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7587 - auc: 0.8381 - loss: 0.4885 - val_acc: 0.7691 - val_auc: 0.8496 - val_loss: 0.4692\n",
      "Epoch 1402/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7604 - auc: 0.8399 - loss: 0.4856 - val_acc: 0.7685 - val_auc: 0.8503 - val_loss: 0.4694\n",
      "Epoch 1403/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7595 - auc: 0.8395 - loss: 0.4862 - val_acc: 0.7695 - val_auc: 0.8507 - val_loss: 0.4688\n",
      "Epoch 1404/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7587 - auc: 0.8377 - loss: 0.4898 - val_acc: 0.7699 - val_auc: 0.8501 - val_loss: 0.4691\n",
      "Epoch 1405/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7602 - auc: 0.8404 - loss: 0.4862 - val_acc: 0.7712 - val_auc: 0.8500 - val_loss: 0.4677\n",
      "Epoch 1406/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7611 - auc: 0.8398 - loss: 0.4871 - val_acc: 0.7681 - val_auc: 0.8491 - val_loss: 0.4697\n",
      "Epoch 1407/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7600 - auc: 0.8391 - loss: 0.4872 - val_acc: 0.7663 - val_auc: 0.8479 - val_loss: 0.4751\n",
      "Epoch 1408/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7615 - auc: 0.8396 - loss: 0.4865 - val_acc: 0.7692 - val_auc: 0.8501 - val_loss: 0.4685\n",
      "Epoch 1409/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7589 - auc: 0.8395 - loss: 0.4870 - val_acc: 0.7704 - val_auc: 0.8502 - val_loss: 0.4694\n",
      "Epoch 1410/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7587 - auc: 0.8394 - loss: 0.4874 - val_acc: 0.7694 - val_auc: 0.8504 - val_loss: 0.4679\n",
      "Epoch 1411/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7604 - auc: 0.8400 - loss: 0.4868 - val_acc: 0.7706 - val_auc: 0.8505 - val_loss: 0.4683\n",
      "Epoch 1412/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7603 - auc: 0.8406 - loss: 0.4847 - val_acc: 0.7699 - val_auc: 0.8496 - val_loss: 0.4703\n",
      "Epoch 1413/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7624 - auc: 0.8401 - loss: 0.4866 - val_acc: 0.7677 - val_auc: 0.8494 - val_loss: 0.4705\n",
      "Epoch 1414/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7607 - auc: 0.8395 - loss: 0.4871 - val_acc: 0.7708 - val_auc: 0.8507 - val_loss: 0.4672\n",
      "Epoch 1415/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7597 - auc: 0.8390 - loss: 0.4876 - val_acc: 0.7708 - val_auc: 0.8521 - val_loss: 0.4657\n",
      "Epoch 1416/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7615 - auc: 0.8399 - loss: 0.4866 - val_acc: 0.7702 - val_auc: 0.8511 - val_loss: 0.4681\n",
      "Epoch 1417/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7578 - auc: 0.8393 - loss: 0.4860 - val_acc: 0.7684 - val_auc: 0.8514 - val_loss: 0.4693\n",
      "Epoch 1418/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7589 - auc: 0.8408 - loss: 0.4852 - val_acc: 0.7695 - val_auc: 0.8512 - val_loss: 0.4691\n",
      "Epoch 1419/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7583 - auc: 0.8394 - loss: 0.4870 - val_acc: 0.7686 - val_auc: 0.8487 - val_loss: 0.4702\n",
      "Epoch 1420/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7600 - auc: 0.8392 - loss: 0.4864 - val_acc: 0.7725 - val_auc: 0.8523 - val_loss: 0.4665\n",
      "Epoch 1421/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7601 - auc: 0.8394 - loss: 0.4872 - val_acc: 0.7695 - val_auc: 0.8503 - val_loss: 0.4697\n",
      "Epoch 1422/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7607 - auc: 0.8398 - loss: 0.4868 - val_acc: 0.7703 - val_auc: 0.8510 - val_loss: 0.4675\n",
      "Epoch 1423/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7594 - auc: 0.8393 - loss: 0.4870 - val_acc: 0.7694 - val_auc: 0.8507 - val_loss: 0.4688\n",
      "Epoch 1424/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7590 - auc: 0.8380 - loss: 0.4894 - val_acc: 0.7704 - val_auc: 0.8507 - val_loss: 0.4690\n",
      "Epoch 1425/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7605 - auc: 0.8392 - loss: 0.4866 - val_acc: 0.7707 - val_auc: 0.8515 - val_loss: 0.4674\n",
      "Epoch 1426/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7576 - auc: 0.8389 - loss: 0.4871 - val_acc: 0.7698 - val_auc: 0.8509 - val_loss: 0.4687\n",
      "Epoch 1427/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7594 - auc: 0.8404 - loss: 0.4848 - val_acc: 0.7703 - val_auc: 0.8510 - val_loss: 0.4667\n",
      "Epoch 1428/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7597 - auc: 0.8383 - loss: 0.4886 - val_acc: 0.7698 - val_auc: 0.8500 - val_loss: 0.4689\n",
      "Epoch 1429/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7591 - auc: 0.8401 - loss: 0.4862 - val_acc: 0.7742 - val_auc: 0.8517 - val_loss: 0.4676\n",
      "Epoch 1430/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7589 - auc: 0.8397 - loss: 0.4869 - val_acc: 0.7715 - val_auc: 0.8509 - val_loss: 0.4688\n",
      "Epoch 1431/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7583 - auc: 0.8398 - loss: 0.4854 - val_acc: 0.7692 - val_auc: 0.8504 - val_loss: 0.4681\n",
      "Epoch 1432/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7591 - auc: 0.8394 - loss: 0.4873 - val_acc: 0.7699 - val_auc: 0.8510 - val_loss: 0.4696\n",
      "Epoch 1433/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7606 - auc: 0.8398 - loss: 0.4869 - val_acc: 0.7702 - val_auc: 0.8511 - val_loss: 0.4689\n",
      "Epoch 1434/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7604 - auc: 0.8395 - loss: 0.4862 - val_acc: 0.7689 - val_auc: 0.8498 - val_loss: 0.4688\n",
      "Epoch 1435/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7608 - auc: 0.8394 - loss: 0.4872 - val_acc: 0.7716 - val_auc: 0.8520 - val_loss: 0.4661\n",
      "Epoch 1436/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7592 - auc: 0.8387 - loss: 0.4880 - val_acc: 0.7735 - val_auc: 0.8530 - val_loss: 0.4657\n",
      "Epoch 1437/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7589 - auc: 0.8396 - loss: 0.4868 - val_acc: 0.7721 - val_auc: 0.8514 - val_loss: 0.4680\n",
      "Epoch 1438/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7603 - auc: 0.8407 - loss: 0.4841 - val_acc: 0.7722 - val_auc: 0.8512 - val_loss: 0.4669\n",
      "Epoch 1439/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7608 - auc: 0.8402 - loss: 0.4849 - val_acc: 0.7693 - val_auc: 0.8506 - val_loss: 0.4697\n",
      "Epoch 1440/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7593 - auc: 0.8397 - loss: 0.4869 - val_acc: 0.7691 - val_auc: 0.8506 - val_loss: 0.4695\n",
      "Epoch 1441/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7594 - auc: 0.8392 - loss: 0.4879 - val_acc: 0.7725 - val_auc: 0.8518 - val_loss: 0.4666\n",
      "Epoch 1442/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7596 - auc: 0.8398 - loss: 0.4860 - val_acc: 0.7717 - val_auc: 0.8520 - val_loss: 0.4659\n",
      "Epoch 1443/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7596 - auc: 0.8396 - loss: 0.4869 - val_acc: 0.7719 - val_auc: 0.8509 - val_loss: 0.4681\n",
      "Epoch 1444/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7612 - auc: 0.8410 - loss: 0.4842 - val_acc: 0.7688 - val_auc: 0.8524 - val_loss: 0.4662\n",
      "Epoch 1445/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7607 - auc: 0.8396 - loss: 0.4867 - val_acc: 0.7719 - val_auc: 0.8526 - val_loss: 0.4660\n",
      "Epoch 1446/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7598 - auc: 0.8395 - loss: 0.4858 - val_acc: 0.7703 - val_auc: 0.8517 - val_loss: 0.4674\n",
      "Epoch 1447/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7614 - auc: 0.8409 - loss: 0.4859 - val_acc: 0.7720 - val_auc: 0.8513 - val_loss: 0.4660\n",
      "Epoch 1448/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7588 - auc: 0.8382 - loss: 0.4885 - val_acc: 0.7740 - val_auc: 0.8516 - val_loss: 0.4675\n",
      "Epoch 1449/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7595 - auc: 0.8401 - loss: 0.4854 - val_acc: 0.7685 - val_auc: 0.8498 - val_loss: 0.4708\n",
      "Epoch 1450/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7609 - auc: 0.8397 - loss: 0.4865 - val_acc: 0.7725 - val_auc: 0.8529 - val_loss: 0.4664\n",
      "Epoch 1451/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7625 - auc: 0.8418 - loss: 0.4839 - val_acc: 0.7688 - val_auc: 0.8505 - val_loss: 0.4692\n",
      "Epoch 1452/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7575 - auc: 0.8392 - loss: 0.4872 - val_acc: 0.7676 - val_auc: 0.8482 - val_loss: 0.4731\n",
      "Epoch 1453/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7616 - auc: 0.8417 - loss: 0.4841 - val_acc: 0.7698 - val_auc: 0.8515 - val_loss: 0.4686\n",
      "Epoch 1454/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7597 - auc: 0.8391 - loss: 0.4874 - val_acc: 0.7730 - val_auc: 0.8519 - val_loss: 0.4674\n",
      "Epoch 1455/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7604 - auc: 0.8398 - loss: 0.4858 - val_acc: 0.7686 - val_auc: 0.8517 - val_loss: 0.4673\n",
      "Epoch 1456/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7591 - auc: 0.8392 - loss: 0.4871 - val_acc: 0.7734 - val_auc: 0.8518 - val_loss: 0.4654\n",
      "Epoch 1457/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7570 - auc: 0.8379 - loss: 0.4886 - val_acc: 0.7699 - val_auc: 0.8520 - val_loss: 0.4685\n",
      "Epoch 1458/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7598 - auc: 0.8400 - loss: 0.4868 - val_acc: 0.7715 - val_auc: 0.8518 - val_loss: 0.4675\n",
      "Epoch 1459/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7603 - auc: 0.8403 - loss: 0.4851 - val_acc: 0.7711 - val_auc: 0.8525 - val_loss: 0.4693\n",
      "Epoch 1460/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7617 - auc: 0.8402 - loss: 0.4851 - val_acc: 0.7701 - val_auc: 0.8511 - val_loss: 0.4681\n",
      "Epoch 1461/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7599 - auc: 0.8398 - loss: 0.4864 - val_acc: 0.7681 - val_auc: 0.8530 - val_loss: 0.4653\n",
      "Epoch 1462/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7613 - auc: 0.8392 - loss: 0.4867 - val_acc: 0.7713 - val_auc: 0.8520 - val_loss: 0.4671\n",
      "Epoch 1463/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7594 - auc: 0.8395 - loss: 0.4865 - val_acc: 0.7715 - val_auc: 0.8514 - val_loss: 0.4663\n",
      "Epoch 1464/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7611 - auc: 0.8405 - loss: 0.4847 - val_acc: 0.7707 - val_auc: 0.8518 - val_loss: 0.4674\n",
      "Epoch 1465/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7616 - auc: 0.8414 - loss: 0.4840 - val_acc: 0.7690 - val_auc: 0.8519 - val_loss: 0.4666\n",
      "Epoch 1466/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7608 - auc: 0.8403 - loss: 0.4863 - val_acc: 0.7688 - val_auc: 0.8510 - val_loss: 0.4678\n",
      "Epoch 1467/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7579 - auc: 0.8385 - loss: 0.4867 - val_acc: 0.7695 - val_auc: 0.8511 - val_loss: 0.4685\n",
      "Epoch 1468/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7600 - auc: 0.8399 - loss: 0.4863 - val_acc: 0.7679 - val_auc: 0.8518 - val_loss: 0.4674\n",
      "Epoch 1469/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7604 - auc: 0.8406 - loss: 0.4856 - val_acc: 0.7728 - val_auc: 0.8516 - val_loss: 0.4668\n",
      "Epoch 1470/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7597 - auc: 0.8407 - loss: 0.4846 - val_acc: 0.7704 - val_auc: 0.8501 - val_loss: 0.4688\n",
      "Epoch 1471/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7609 - auc: 0.8406 - loss: 0.4859 - val_acc: 0.7704 - val_auc: 0.8510 - val_loss: 0.4684\n",
      "Epoch 1472/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7601 - auc: 0.8404 - loss: 0.4852 - val_acc: 0.7697 - val_auc: 0.8520 - val_loss: 0.4660\n",
      "Epoch 1473/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7609 - auc: 0.8410 - loss: 0.4849 - val_acc: 0.7710 - val_auc: 0.8518 - val_loss: 0.4658\n",
      "Epoch 1474/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7612 - auc: 0.8407 - loss: 0.4851 - val_acc: 0.7699 - val_auc: 0.8530 - val_loss: 0.4660\n",
      "Epoch 1475/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7586 - auc: 0.8387 - loss: 0.4885 - val_acc: 0.7702 - val_auc: 0.8512 - val_loss: 0.4670\n",
      "Epoch 1476/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7617 - auc: 0.8406 - loss: 0.4852 - val_acc: 0.7676 - val_auc: 0.8512 - val_loss: 0.4690\n",
      "Epoch 1477/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7611 - auc: 0.8397 - loss: 0.4868 - val_acc: 0.7675 - val_auc: 0.8504 - val_loss: 0.4712\n",
      "Epoch 1478/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7601 - auc: 0.8404 - loss: 0.4856 - val_acc: 0.7694 - val_auc: 0.8517 - val_loss: 0.4686\n",
      "Epoch 1479/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7610 - auc: 0.8403 - loss: 0.4853 - val_acc: 0.7713 - val_auc: 0.8515 - val_loss: 0.4672\n",
      "Epoch 1480/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7587 - auc: 0.8404 - loss: 0.4851 - val_acc: 0.7668 - val_auc: 0.8494 - val_loss: 0.4695\n",
      "Epoch 1481/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7596 - auc: 0.8405 - loss: 0.4848 - val_acc: 0.7684 - val_auc: 0.8499 - val_loss: 0.4697\n",
      "Epoch 1482/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7603 - auc: 0.8396 - loss: 0.4867 - val_acc: 0.7694 - val_auc: 0.8518 - val_loss: 0.4684\n",
      "Epoch 1483/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7607 - auc: 0.8409 - loss: 0.4848 - val_acc: 0.7693 - val_auc: 0.8517 - val_loss: 0.4670\n",
      "Epoch 1484/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7616 - auc: 0.8407 - loss: 0.4852 - val_acc: 0.7708 - val_auc: 0.8520 - val_loss: 0.4672\n",
      "Epoch 1485/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7614 - auc: 0.8409 - loss: 0.4852 - val_acc: 0.7712 - val_auc: 0.8530 - val_loss: 0.4653\n",
      "Epoch 1486/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7601 - auc: 0.8408 - loss: 0.4850 - val_acc: 0.7712 - val_auc: 0.8512 - val_loss: 0.4679\n",
      "Epoch 1487/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7588 - auc: 0.8387 - loss: 0.4884 - val_acc: 0.7715 - val_auc: 0.8538 - val_loss: 0.4633\n",
      "Epoch 1488/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7599 - auc: 0.8392 - loss: 0.4866 - val_acc: 0.7680 - val_auc: 0.8507 - val_loss: 0.4692\n",
      "Epoch 1489/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7606 - auc: 0.8398 - loss: 0.4866 - val_acc: 0.7692 - val_auc: 0.8487 - val_loss: 0.4700\n",
      "Epoch 1490/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7607 - auc: 0.8395 - loss: 0.4865 - val_acc: 0.7689 - val_auc: 0.8497 - val_loss: 0.4689\n",
      "Epoch 1491/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7608 - auc: 0.8403 - loss: 0.4848 - val_acc: 0.7717 - val_auc: 0.8518 - val_loss: 0.4666\n",
      "Epoch 1492/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7592 - auc: 0.8403 - loss: 0.4843 - val_acc: 0.7736 - val_auc: 0.8529 - val_loss: 0.4655\n",
      "Epoch 1493/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7588 - auc: 0.8391 - loss: 0.4868 - val_acc: 0.7719 - val_auc: 0.8522 - val_loss: 0.4660\n",
      "Epoch 1494/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7592 - auc: 0.8400 - loss: 0.4867 - val_acc: 0.7708 - val_auc: 0.8515 - val_loss: 0.4670\n",
      "Epoch 1495/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7598 - auc: 0.8400 - loss: 0.4864 - val_acc: 0.7711 - val_auc: 0.8510 - val_loss: 0.4670\n",
      "Epoch 1496/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7599 - auc: 0.8401 - loss: 0.4850 - val_acc: 0.7712 - val_auc: 0.8517 - val_loss: 0.4673\n",
      "Epoch 1497/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7590 - auc: 0.8397 - loss: 0.4869 - val_acc: 0.7688 - val_auc: 0.8507 - val_loss: 0.4683\n",
      "Epoch 1498/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7589 - auc: 0.8408 - loss: 0.4844 - val_acc: 0.7708 - val_auc: 0.8520 - val_loss: 0.4667\n",
      "Epoch 1499/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7616 - auc: 0.8413 - loss: 0.4843 - val_acc: 0.7710 - val_auc: 0.8513 - val_loss: 0.4674\n",
      "Epoch 1500/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7630 - auc: 0.8418 - loss: 0.4828 - val_acc: 0.7704 - val_auc: 0.8524 - val_loss: 0.4651\n",
      "Epoch 1501/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7613 - auc: 0.8404 - loss: 0.4852 - val_acc: 0.7712 - val_auc: 0.8521 - val_loss: 0.4659\n",
      "Epoch 1502/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7612 - auc: 0.8417 - loss: 0.4835 - val_acc: 0.7715 - val_auc: 0.8534 - val_loss: 0.4641\n",
      "Epoch 1503/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7609 - auc: 0.8414 - loss: 0.4841 - val_acc: 0.7734 - val_auc: 0.8536 - val_loss: 0.4641\n",
      "Epoch 1504/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7615 - auc: 0.8407 - loss: 0.4859 - val_acc: 0.7706 - val_auc: 0.8508 - val_loss: 0.4692\n",
      "Epoch 1505/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7598 - auc: 0.8393 - loss: 0.4862 - val_acc: 0.7712 - val_auc: 0.8533 - val_loss: 0.4643\n",
      "Epoch 1506/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7616 - auc: 0.8404 - loss: 0.4863 - val_acc: 0.7702 - val_auc: 0.8523 - val_loss: 0.4661\n",
      "Epoch 1507/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7611 - auc: 0.8411 - loss: 0.4847 - val_acc: 0.7692 - val_auc: 0.8513 - val_loss: 0.4685\n",
      "Epoch 1508/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7606 - auc: 0.8408 - loss: 0.4860 - val_acc: 0.7727 - val_auc: 0.8524 - val_loss: 0.4657\n",
      "Epoch 1509/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7610 - auc: 0.8397 - loss: 0.4871 - val_acc: 0.7721 - val_auc: 0.8538 - val_loss: 0.4640\n",
      "Epoch 1510/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7601 - auc: 0.8403 - loss: 0.4847 - val_acc: 0.7722 - val_auc: 0.8537 - val_loss: 0.4645\n",
      "Epoch 1511/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7620 - auc: 0.8410 - loss: 0.4850 - val_acc: 0.7684 - val_auc: 0.8514 - val_loss: 0.4687\n",
      "Epoch 1512/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7603 - auc: 0.8415 - loss: 0.4837 - val_acc: 0.7723 - val_auc: 0.8520 - val_loss: 0.4659\n",
      "Epoch 1513/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7591 - auc: 0.8399 - loss: 0.4859 - val_acc: 0.7696 - val_auc: 0.8514 - val_loss: 0.4678\n",
      "Epoch 1514/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7610 - auc: 0.8413 - loss: 0.4845 - val_acc: 0.7719 - val_auc: 0.8530 - val_loss: 0.4656\n",
      "Epoch 1515/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7607 - auc: 0.8392 - loss: 0.4868 - val_acc: 0.7711 - val_auc: 0.8524 - val_loss: 0.4656\n",
      "Epoch 1516/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7613 - auc: 0.8408 - loss: 0.4856 - val_acc: 0.7696 - val_auc: 0.8504 - val_loss: 0.4682\n",
      "Epoch 1517/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7608 - auc: 0.8410 - loss: 0.4839 - val_acc: 0.7719 - val_auc: 0.8517 - val_loss: 0.4661\n",
      "Epoch 1518/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7623 - auc: 0.8415 - loss: 0.4838 - val_acc: 0.7720 - val_auc: 0.8525 - val_loss: 0.4661\n",
      "Epoch 1519/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7611 - auc: 0.8409 - loss: 0.4849 - val_acc: 0.7710 - val_auc: 0.8510 - val_loss: 0.4688\n",
      "Epoch 1520/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7611 - auc: 0.8397 - loss: 0.4866 - val_acc: 0.7725 - val_auc: 0.8530 - val_loss: 0.4642\n",
      "Epoch 1521/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7605 - auc: 0.8395 - loss: 0.4860 - val_acc: 0.7672 - val_auc: 0.8498 - val_loss: 0.4704\n",
      "Epoch 1522/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7610 - auc: 0.8409 - loss: 0.4849 - val_acc: 0.7725 - val_auc: 0.8530 - val_loss: 0.4652\n",
      "Epoch 1523/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7601 - auc: 0.8409 - loss: 0.4849 - val_acc: 0.7695 - val_auc: 0.8509 - val_loss: 0.4681\n",
      "Epoch 1524/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7625 - auc: 0.8421 - loss: 0.4834 - val_acc: 0.7711 - val_auc: 0.8526 - val_loss: 0.4655\n",
      "Epoch 1525/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7613 - auc: 0.8407 - loss: 0.4844 - val_acc: 0.7735 - val_auc: 0.8527 - val_loss: 0.4654\n",
      "Epoch 1526/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7619 - auc: 0.8415 - loss: 0.4842 - val_acc: 0.7690 - val_auc: 0.8504 - val_loss: 0.4693\n",
      "Epoch 1527/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7600 - auc: 0.8393 - loss: 0.4865 - val_acc: 0.7693 - val_auc: 0.8497 - val_loss: 0.4694\n",
      "Epoch 1528/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7625 - auc: 0.8415 - loss: 0.4838 - val_acc: 0.7683 - val_auc: 0.8516 - val_loss: 0.4678\n",
      "Epoch 1529/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7614 - auc: 0.8407 - loss: 0.4840 - val_acc: 0.7706 - val_auc: 0.8519 - val_loss: 0.4662\n",
      "Epoch 1530/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7610 - auc: 0.8405 - loss: 0.4850 - val_acc: 0.7710 - val_auc: 0.8520 - val_loss: 0.4677\n",
      "Epoch 1531/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7620 - auc: 0.8426 - loss: 0.4821 - val_acc: 0.7734 - val_auc: 0.8544 - val_loss: 0.4628\n",
      "Epoch 1532/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7598 - auc: 0.8406 - loss: 0.4862 - val_acc: 0.7713 - val_auc: 0.8523 - val_loss: 0.4660\n",
      "Epoch 1533/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7595 - auc: 0.8400 - loss: 0.4863 - val_acc: 0.7708 - val_auc: 0.8526 - val_loss: 0.4661\n",
      "Epoch 1534/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7623 - auc: 0.8405 - loss: 0.4859 - val_acc: 0.7705 - val_auc: 0.8507 - val_loss: 0.4677\n",
      "Epoch 1535/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7592 - auc: 0.8403 - loss: 0.4858 - val_acc: 0.7685 - val_auc: 0.8522 - val_loss: 0.4675\n",
      "Epoch 1536/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7604 - auc: 0.8404 - loss: 0.4843 - val_acc: 0.7722 - val_auc: 0.8523 - val_loss: 0.4667\n",
      "Epoch 1537/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7607 - auc: 0.8409 - loss: 0.4843 - val_acc: 0.7687 - val_auc: 0.8521 - val_loss: 0.4666\n",
      "Epoch 1538/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7619 - auc: 0.8409 - loss: 0.4845 - val_acc: 0.7723 - val_auc: 0.8526 - val_loss: 0.4660\n",
      "Epoch 1539/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7610 - auc: 0.8413 - loss: 0.4829 - val_acc: 0.7710 - val_auc: 0.8522 - val_loss: 0.4658\n",
      "Epoch 1540/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7603 - auc: 0.8418 - loss: 0.4829 - val_acc: 0.7704 - val_auc: 0.8523 - val_loss: 0.4676\n",
      "Epoch 1541/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7623 - auc: 0.8419 - loss: 0.4829 - val_acc: 0.7705 - val_auc: 0.8527 - val_loss: 0.4664\n",
      "Epoch 1542/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7606 - auc: 0.8408 - loss: 0.4851 - val_acc: 0.7694 - val_auc: 0.8523 - val_loss: 0.4667\n",
      "Epoch 1543/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7609 - auc: 0.8410 - loss: 0.4843 - val_acc: 0.7709 - val_auc: 0.8522 - val_loss: 0.4671\n",
      "Epoch 1544/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7627 - auc: 0.8429 - loss: 0.4817 - val_acc: 0.7689 - val_auc: 0.8517 - val_loss: 0.4662\n",
      "Epoch 1545/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7614 - auc: 0.8406 - loss: 0.4860 - val_acc: 0.7732 - val_auc: 0.8525 - val_loss: 0.4646\n",
      "Epoch 1546/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7590 - auc: 0.8409 - loss: 0.4847 - val_acc: 0.7712 - val_auc: 0.8529 - val_loss: 0.4669\n",
      "Epoch 1547/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7625 - auc: 0.8414 - loss: 0.4844 - val_acc: 0.7706 - val_auc: 0.8522 - val_loss: 0.4669\n",
      "Epoch 1548/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7607 - auc: 0.8415 - loss: 0.4840 - val_acc: 0.7696 - val_auc: 0.8521 - val_loss: 0.4672\n",
      "Epoch 1549/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7625 - auc: 0.8419 - loss: 0.4825 - val_acc: 0.7713 - val_auc: 0.8523 - val_loss: 0.4664\n",
      "Epoch 1550/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7618 - auc: 0.8407 - loss: 0.4846 - val_acc: 0.7712 - val_auc: 0.8524 - val_loss: 0.4649\n",
      "Epoch 1551/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7603 - auc: 0.8410 - loss: 0.4845 - val_acc: 0.7711 - val_auc: 0.8525 - val_loss: 0.4652\n",
      "Epoch 1552/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7611 - auc: 0.8410 - loss: 0.4847 - val_acc: 0.7708 - val_auc: 0.8529 - val_loss: 0.4663\n",
      "Epoch 1553/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7600 - auc: 0.8397 - loss: 0.4868 - val_acc: 0.7672 - val_auc: 0.8503 - val_loss: 0.4684\n",
      "Epoch 1554/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7614 - auc: 0.8412 - loss: 0.4835 - val_acc: 0.7658 - val_auc: 0.8487 - val_loss: 0.4730\n",
      "Epoch 1555/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7618 - auc: 0.8422 - loss: 0.4833 - val_acc: 0.7742 - val_auc: 0.8524 - val_loss: 0.4666\n",
      "Epoch 1556/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7608 - auc: 0.8410 - loss: 0.4845 - val_acc: 0.7688 - val_auc: 0.8518 - val_loss: 0.4663\n",
      "Epoch 1557/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7618 - auc: 0.8412 - loss: 0.4843 - val_acc: 0.7712 - val_auc: 0.8526 - val_loss: 0.4655\n",
      "Epoch 1558/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7611 - auc: 0.8413 - loss: 0.4836 - val_acc: 0.7686 - val_auc: 0.8506 - val_loss: 0.4694\n",
      "Epoch 1559/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7628 - auc: 0.8419 - loss: 0.4845 - val_acc: 0.7730 - val_auc: 0.8530 - val_loss: 0.4655\n",
      "Epoch 1560/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7604 - auc: 0.8399 - loss: 0.4855 - val_acc: 0.7700 - val_auc: 0.8517 - val_loss: 0.4663\n",
      "Epoch 1561/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7608 - auc: 0.8404 - loss: 0.4860 - val_acc: 0.7706 - val_auc: 0.8523 - val_loss: 0.4671\n",
      "Epoch 1562/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7616 - auc: 0.8406 - loss: 0.4846 - val_acc: 0.7726 - val_auc: 0.8514 - val_loss: 0.4672\n",
      "Epoch 1563/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7617 - auc: 0.8410 - loss: 0.4848 - val_acc: 0.7729 - val_auc: 0.8551 - val_loss: 0.4632\n",
      "Epoch 1564/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7621 - auc: 0.8416 - loss: 0.4832 - val_acc: 0.7706 - val_auc: 0.8526 - val_loss: 0.4670\n",
      "Epoch 1565/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7610 - auc: 0.8410 - loss: 0.4839 - val_acc: 0.7711 - val_auc: 0.8526 - val_loss: 0.4654\n",
      "Epoch 1566/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7627 - auc: 0.8424 - loss: 0.4842 - val_acc: 0.7690 - val_auc: 0.8486 - val_loss: 0.4708\n",
      "Epoch 1567/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7624 - auc: 0.8415 - loss: 0.4842 - val_acc: 0.7709 - val_auc: 0.8530 - val_loss: 0.4651\n",
      "Epoch 1568/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7612 - auc: 0.8402 - loss: 0.4855 - val_acc: 0.7704 - val_auc: 0.8530 - val_loss: 0.4651\n",
      "Epoch 1569/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7628 - auc: 0.8425 - loss: 0.4818 - val_acc: 0.7717 - val_auc: 0.8532 - val_loss: 0.4647\n",
      "Epoch 1570/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7608 - auc: 0.8406 - loss: 0.4844 - val_acc: 0.7729 - val_auc: 0.8529 - val_loss: 0.4653\n",
      "Epoch 1571/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7621 - auc: 0.8404 - loss: 0.4862 - val_acc: 0.7707 - val_auc: 0.8518 - val_loss: 0.4673\n",
      "Epoch 1572/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7628 - auc: 0.8409 - loss: 0.4845 - val_acc: 0.7724 - val_auc: 0.8526 - val_loss: 0.4657\n",
      "Epoch 1573/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7621 - auc: 0.8410 - loss: 0.4848 - val_acc: 0.7763 - val_auc: 0.8545 - val_loss: 0.4633\n",
      "Epoch 1574/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7617 - auc: 0.8423 - loss: 0.4825 - val_acc: 0.7712 - val_auc: 0.8536 - val_loss: 0.4639\n",
      "Epoch 1575/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7620 - auc: 0.8411 - loss: 0.4835 - val_acc: 0.7708 - val_auc: 0.8522 - val_loss: 0.4663\n",
      "Epoch 1576/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7587 - auc: 0.8399 - loss: 0.4856 - val_acc: 0.7727 - val_auc: 0.8532 - val_loss: 0.4656\n",
      "Epoch 1577/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7615 - auc: 0.8417 - loss: 0.4842 - val_acc: 0.7739 - val_auc: 0.8529 - val_loss: 0.4652\n",
      "Epoch 1578/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7629 - auc: 0.8420 - loss: 0.4823 - val_acc: 0.7712 - val_auc: 0.8524 - val_loss: 0.4648\n",
      "Epoch 1579/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7601 - auc: 0.8401 - loss: 0.4852 - val_acc: 0.7726 - val_auc: 0.8530 - val_loss: 0.4656\n",
      "Epoch 1580/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7630 - auc: 0.8433 - loss: 0.4816 - val_acc: 0.7730 - val_auc: 0.8535 - val_loss: 0.4648\n",
      "Epoch 1581/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7604 - auc: 0.8403 - loss: 0.4849 - val_acc: 0.7717 - val_auc: 0.8531 - val_loss: 0.4677\n",
      "Epoch 1582/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7610 - auc: 0.8407 - loss: 0.4847 - val_acc: 0.7705 - val_auc: 0.8520 - val_loss: 0.4668\n",
      "Epoch 1583/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7592 - auc: 0.8406 - loss: 0.4843 - val_acc: 0.7743 - val_auc: 0.8542 - val_loss: 0.4640\n",
      "Epoch 1584/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7602 - auc: 0.8406 - loss: 0.4854 - val_acc: 0.7694 - val_auc: 0.8528 - val_loss: 0.4648\n",
      "Epoch 1585/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7617 - auc: 0.8410 - loss: 0.4840 - val_acc: 0.7746 - val_auc: 0.8530 - val_loss: 0.4660\n",
      "Epoch 1586/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7626 - auc: 0.8414 - loss: 0.4833 - val_acc: 0.7719 - val_auc: 0.8527 - val_loss: 0.4658\n",
      "Epoch 1587/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7625 - auc: 0.8407 - loss: 0.4848 - val_acc: 0.7703 - val_auc: 0.8527 - val_loss: 0.4672\n",
      "Epoch 1588/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7609 - auc: 0.8408 - loss: 0.4847 - val_acc: 0.7704 - val_auc: 0.8528 - val_loss: 0.4645\n",
      "Epoch 1589/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7608 - auc: 0.8412 - loss: 0.4845 - val_acc: 0.7721 - val_auc: 0.8538 - val_loss: 0.4642\n",
      "Epoch 1590/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7593 - auc: 0.8420 - loss: 0.4838 - val_acc: 0.7719 - val_auc: 0.8529 - val_loss: 0.4660\n",
      "Epoch 1591/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7623 - auc: 0.8415 - loss: 0.4848 - val_acc: 0.7734 - val_auc: 0.8532 - val_loss: 0.4658\n",
      "Epoch 1592/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7612 - auc: 0.8405 - loss: 0.4856 - val_acc: 0.7734 - val_auc: 0.8541 - val_loss: 0.4646\n",
      "Epoch 1593/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7622 - auc: 0.8414 - loss: 0.4839 - val_acc: 0.7713 - val_auc: 0.8526 - val_loss: 0.4655\n",
      "Epoch 1594/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7619 - auc: 0.8418 - loss: 0.4837 - val_acc: 0.7729 - val_auc: 0.8529 - val_loss: 0.4646\n",
      "Epoch 1595/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7631 - auc: 0.8427 - loss: 0.4825 - val_acc: 0.7719 - val_auc: 0.8537 - val_loss: 0.4645\n",
      "Epoch 1596/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7624 - auc: 0.8416 - loss: 0.4827 - val_acc: 0.7721 - val_auc: 0.8517 - val_loss: 0.4674\n",
      "Epoch 1597/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7620 - auc: 0.8430 - loss: 0.4816 - val_acc: 0.7719 - val_auc: 0.8525 - val_loss: 0.4645\n",
      "Epoch 1598/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7618 - auc: 0.8415 - loss: 0.4835 - val_acc: 0.7711 - val_auc: 0.8521 - val_loss: 0.4660\n",
      "Epoch 1599/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7616 - auc: 0.8413 - loss: 0.4846 - val_acc: 0.7699 - val_auc: 0.8524 - val_loss: 0.4671\n",
      "Epoch 1600/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7625 - auc: 0.8415 - loss: 0.4835 - val_acc: 0.7722 - val_auc: 0.8524 - val_loss: 0.4653\n",
      "Epoch 1601/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7632 - auc: 0.8425 - loss: 0.4831 - val_acc: 0.7731 - val_auc: 0.8524 - val_loss: 0.4656\n",
      "Epoch 1602/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7626 - auc: 0.8423 - loss: 0.4822 - val_acc: 0.7716 - val_auc: 0.8513 - val_loss: 0.4676\n",
      "Epoch 1603/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7641 - auc: 0.8426 - loss: 0.4828 - val_acc: 0.7743 - val_auc: 0.8539 - val_loss: 0.4635\n",
      "Epoch 1604/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7625 - auc: 0.8423 - loss: 0.4830 - val_acc: 0.7714 - val_auc: 0.8529 - val_loss: 0.4660\n",
      "Epoch 1605/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7614 - auc: 0.8417 - loss: 0.4838 - val_acc: 0.7737 - val_auc: 0.8534 - val_loss: 0.4654\n",
      "Epoch 1606/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7616 - auc: 0.8415 - loss: 0.4844 - val_acc: 0.7746 - val_auc: 0.8539 - val_loss: 0.4645\n",
      "Epoch 1607/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7647 - auc: 0.8433 - loss: 0.4811 - val_acc: 0.7747 - val_auc: 0.8543 - val_loss: 0.4642\n",
      "Epoch 1608/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7624 - auc: 0.8429 - loss: 0.4819 - val_acc: 0.7694 - val_auc: 0.8515 - val_loss: 0.4666\n",
      "Epoch 1609/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7618 - auc: 0.8414 - loss: 0.4834 - val_acc: 0.7754 - val_auc: 0.8553 - val_loss: 0.4624\n",
      "Epoch 1610/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7639 - auc: 0.8433 - loss: 0.4822 - val_acc: 0.7728 - val_auc: 0.8527 - val_loss: 0.4655\n",
      "Epoch 1611/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7620 - auc: 0.8414 - loss: 0.4831 - val_acc: 0.7724 - val_auc: 0.8527 - val_loss: 0.4660\n",
      "Epoch 1612/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7632 - auc: 0.8418 - loss: 0.4834 - val_acc: 0.7718 - val_auc: 0.8514 - val_loss: 0.4684\n",
      "Epoch 1613/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7635 - auc: 0.8431 - loss: 0.4813 - val_acc: 0.7718 - val_auc: 0.8526 - val_loss: 0.4645\n",
      "Epoch 1614/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7625 - auc: 0.8430 - loss: 0.4816 - val_acc: 0.7708 - val_auc: 0.8524 - val_loss: 0.4657\n",
      "Epoch 1615/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7608 - auc: 0.8412 - loss: 0.4838 - val_acc: 0.7725 - val_auc: 0.8531 - val_loss: 0.4657\n",
      "Epoch 1616/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7601 - auc: 0.8411 - loss: 0.4843 - val_acc: 0.7731 - val_auc: 0.8530 - val_loss: 0.4643\n",
      "Epoch 1617/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7623 - auc: 0.8412 - loss: 0.4839 - val_acc: 0.7718 - val_auc: 0.8528 - val_loss: 0.4647\n",
      "Epoch 1618/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7613 - auc: 0.8416 - loss: 0.4837 - val_acc: 0.7731 - val_auc: 0.8530 - val_loss: 0.4644\n",
      "Epoch 1619/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7621 - auc: 0.8417 - loss: 0.4851 - val_acc: 0.7734 - val_auc: 0.8529 - val_loss: 0.4645\n",
      "Epoch 1620/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7649 - auc: 0.8428 - loss: 0.4816 - val_acc: 0.7731 - val_auc: 0.8538 - val_loss: 0.4645\n",
      "Epoch 1621/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7633 - auc: 0.8437 - loss: 0.4813 - val_acc: 0.7693 - val_auc: 0.8529 - val_loss: 0.4645\n",
      "Epoch 1622/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7609 - auc: 0.8419 - loss: 0.4835 - val_acc: 0.7699 - val_auc: 0.8535 - val_loss: 0.4649\n",
      "Epoch 1623/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7634 - auc: 0.8421 - loss: 0.4833 - val_acc: 0.7729 - val_auc: 0.8530 - val_loss: 0.4651\n",
      "Epoch 1624/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7633 - auc: 0.8418 - loss: 0.4840 - val_acc: 0.7736 - val_auc: 0.8537 - val_loss: 0.4640\n",
      "Epoch 1625/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7625 - auc: 0.8411 - loss: 0.4841 - val_acc: 0.7762 - val_auc: 0.8545 - val_loss: 0.4638\n",
      "Epoch 1626/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7624 - auc: 0.8415 - loss: 0.4838 - val_acc: 0.7718 - val_auc: 0.8529 - val_loss: 0.4652\n",
      "Epoch 1627/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7624 - auc: 0.8435 - loss: 0.4821 - val_acc: 0.7695 - val_auc: 0.8521 - val_loss: 0.4672\n",
      "Epoch 1628/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7612 - auc: 0.8412 - loss: 0.4830 - val_acc: 0.7712 - val_auc: 0.8524 - val_loss: 0.4647\n",
      "Epoch 1629/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7639 - auc: 0.8430 - loss: 0.4820 - val_acc: 0.7744 - val_auc: 0.8548 - val_loss: 0.4621\n",
      "Epoch 1630/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7648 - auc: 0.8432 - loss: 0.4812 - val_acc: 0.7751 - val_auc: 0.8536 - val_loss: 0.4642\n",
      "Epoch 1631/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7620 - auc: 0.8428 - loss: 0.4813 - val_acc: 0.7740 - val_auc: 0.8530 - val_loss: 0.4637\n",
      "Epoch 1632/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7625 - auc: 0.8429 - loss: 0.4814 - val_acc: 0.7724 - val_auc: 0.8546 - val_loss: 0.4632\n",
      "Epoch 1633/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7616 - auc: 0.8416 - loss: 0.4830 - val_acc: 0.7774 - val_auc: 0.8541 - val_loss: 0.4623\n",
      "Epoch 1634/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7591 - auc: 0.8417 - loss: 0.4835 - val_acc: 0.7747 - val_auc: 0.8531 - val_loss: 0.4629\n",
      "Epoch 1635/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7644 - auc: 0.8434 - loss: 0.4820 - val_acc: 0.7746 - val_auc: 0.8543 - val_loss: 0.4629\n",
      "Epoch 1636/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7626 - auc: 0.8428 - loss: 0.4832 - val_acc: 0.7771 - val_auc: 0.8533 - val_loss: 0.4641\n",
      "Epoch 1637/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7614 - auc: 0.8415 - loss: 0.4843 - val_acc: 0.7723 - val_auc: 0.8538 - val_loss: 0.4630\n",
      "Epoch 1638/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7618 - auc: 0.8412 - loss: 0.4845 - val_acc: 0.7728 - val_auc: 0.8528 - val_loss: 0.4649\n",
      "Epoch 1639/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7640 - auc: 0.8440 - loss: 0.4802 - val_acc: 0.7762 - val_auc: 0.8541 - val_loss: 0.4631\n",
      "Epoch 1640/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7596 - auc: 0.8399 - loss: 0.4851 - val_acc: 0.7729 - val_auc: 0.8533 - val_loss: 0.4650\n",
      "Epoch 1641/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7629 - auc: 0.8423 - loss: 0.4821 - val_acc: 0.7713 - val_auc: 0.8540 - val_loss: 0.4628\n",
      "Epoch 1642/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7612 - auc: 0.8422 - loss: 0.4832 - val_acc: 0.7711 - val_auc: 0.8546 - val_loss: 0.4624\n",
      "Epoch 1643/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7604 - auc: 0.8414 - loss: 0.4842 - val_acc: 0.7737 - val_auc: 0.8541 - val_loss: 0.4630\n",
      "Epoch 1644/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7622 - auc: 0.8410 - loss: 0.4856 - val_acc: 0.7715 - val_auc: 0.8533 - val_loss: 0.4649\n",
      "Epoch 1645/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7629 - auc: 0.8428 - loss: 0.4821 - val_acc: 0.7725 - val_auc: 0.8530 - val_loss: 0.4653\n",
      "Epoch 1646/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7639 - auc: 0.8429 - loss: 0.4816 - val_acc: 0.7725 - val_auc: 0.8532 - val_loss: 0.4655\n",
      "Epoch 1647/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7610 - auc: 0.8422 - loss: 0.4830 - val_acc: 0.7707 - val_auc: 0.8526 - val_loss: 0.4659\n",
      "Epoch 1648/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7639 - auc: 0.8432 - loss: 0.4815 - val_acc: 0.7696 - val_auc: 0.8529 - val_loss: 0.4655\n",
      "Epoch 1649/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7622 - auc: 0.8430 - loss: 0.4819 - val_acc: 0.7720 - val_auc: 0.8530 - val_loss: 0.4667\n",
      "Epoch 1650/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7631 - auc: 0.8426 - loss: 0.4832 - val_acc: 0.7728 - val_auc: 0.8532 - val_loss: 0.4650\n",
      "Epoch 1651/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7612 - auc: 0.8407 - loss: 0.4858 - val_acc: 0.7747 - val_auc: 0.8542 - val_loss: 0.4630\n",
      "Epoch 1652/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7628 - auc: 0.8425 - loss: 0.4831 - val_acc: 0.7726 - val_auc: 0.8530 - val_loss: 0.4645\n",
      "Epoch 1653/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7647 - auc: 0.8426 - loss: 0.4831 - val_acc: 0.7709 - val_auc: 0.8534 - val_loss: 0.4645\n",
      "Epoch 1654/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7620 - auc: 0.8411 - loss: 0.4846 - val_acc: 0.7723 - val_auc: 0.8547 - val_loss: 0.4632\n",
      "Epoch 1655/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7610 - auc: 0.8430 - loss: 0.4823 - val_acc: 0.7703 - val_auc: 0.8530 - val_loss: 0.4652\n",
      "Epoch 1656/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7611 - auc: 0.8420 - loss: 0.4827 - val_acc: 0.7713 - val_auc: 0.8532 - val_loss: 0.4634\n",
      "Epoch 1657/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7616 - auc: 0.8423 - loss: 0.4824 - val_acc: 0.7744 - val_auc: 0.8540 - val_loss: 0.4633\n",
      "Epoch 1658/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7628 - auc: 0.8429 - loss: 0.4815 - val_acc: 0.7717 - val_auc: 0.8538 - val_loss: 0.4640\n",
      "Epoch 1659/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7632 - auc: 0.8440 - loss: 0.4807 - val_acc: 0.7706 - val_auc: 0.8526 - val_loss: 0.4652\n",
      "Epoch 1660/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7633 - auc: 0.8433 - loss: 0.4817 - val_acc: 0.7734 - val_auc: 0.8532 - val_loss: 0.4659\n",
      "Epoch 1661/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7630 - auc: 0.8422 - loss: 0.4830 - val_acc: 0.7715 - val_auc: 0.8529 - val_loss: 0.4664\n",
      "Epoch 1662/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7627 - auc: 0.8431 - loss: 0.4823 - val_acc: 0.7729 - val_auc: 0.8541 - val_loss: 0.4641\n",
      "Epoch 1663/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7627 - auc: 0.8423 - loss: 0.4821 - val_acc: 0.7727 - val_auc: 0.8535 - val_loss: 0.4651\n",
      "Epoch 1664/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7617 - auc: 0.8424 - loss: 0.4829 - val_acc: 0.7710 - val_auc: 0.8531 - val_loss: 0.4638\n",
      "Epoch 1665/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7613 - auc: 0.8408 - loss: 0.4848 - val_acc: 0.7707 - val_auc: 0.8527 - val_loss: 0.4648\n",
      "Epoch 1666/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7631 - auc: 0.8426 - loss: 0.4831 - val_acc: 0.7731 - val_auc: 0.8545 - val_loss: 0.4645\n",
      "Epoch 1667/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7631 - auc: 0.8413 - loss: 0.4845 - val_acc: 0.7731 - val_auc: 0.8533 - val_loss: 0.4662\n",
      "Epoch 1668/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7616 - auc: 0.8414 - loss: 0.4845 - val_acc: 0.7728 - val_auc: 0.8540 - val_loss: 0.4631\n",
      "Epoch 1669/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7605 - auc: 0.8404 - loss: 0.4853 - val_acc: 0.7704 - val_auc: 0.8524 - val_loss: 0.4662\n",
      "Epoch 1670/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7649 - auc: 0.8431 - loss: 0.4809 - val_acc: 0.7729 - val_auc: 0.8538 - val_loss: 0.4641\n",
      "Epoch 1671/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7633 - auc: 0.8416 - loss: 0.4837 - val_acc: 0.7731 - val_auc: 0.8540 - val_loss: 0.4642\n",
      "Epoch 1672/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7640 - auc: 0.8434 - loss: 0.4816 - val_acc: 0.7728 - val_auc: 0.8541 - val_loss: 0.4631\n",
      "Epoch 1673/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7644 - auc: 0.8438 - loss: 0.4810 - val_acc: 0.7690 - val_auc: 0.8524 - val_loss: 0.4665\n",
      "Epoch 1674/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7606 - auc: 0.8405 - loss: 0.4849 - val_acc: 0.7689 - val_auc: 0.8522 - val_loss: 0.4688\n",
      "Epoch 1675/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7618 - auc: 0.8423 - loss: 0.4838 - val_acc: 0.7743 - val_auc: 0.8551 - val_loss: 0.4630\n",
      "Epoch 1676/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7637 - auc: 0.8436 - loss: 0.4805 - val_acc: 0.7722 - val_auc: 0.8526 - val_loss: 0.4648\n",
      "Epoch 1677/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7625 - auc: 0.8424 - loss: 0.4822 - val_acc: 0.7737 - val_auc: 0.8541 - val_loss: 0.4644\n",
      "Epoch 1678/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7633 - auc: 0.8422 - loss: 0.4822 - val_acc: 0.7719 - val_auc: 0.8533 - val_loss: 0.4639\n",
      "Epoch 1679/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7631 - auc: 0.8427 - loss: 0.4818 - val_acc: 0.7731 - val_auc: 0.8546 - val_loss: 0.4632\n",
      "Epoch 1680/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7626 - auc: 0.8428 - loss: 0.4818 - val_acc: 0.7705 - val_auc: 0.8522 - val_loss: 0.4670\n",
      "Epoch 1681/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7624 - auc: 0.8416 - loss: 0.4843 - val_acc: 0.7735 - val_auc: 0.8536 - val_loss: 0.4643\n",
      "Epoch 1682/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7636 - auc: 0.8434 - loss: 0.4810 - val_acc: 0.7766 - val_auc: 0.8544 - val_loss: 0.4634\n",
      "Epoch 1683/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7630 - auc: 0.8433 - loss: 0.4823 - val_acc: 0.7737 - val_auc: 0.8550 - val_loss: 0.4636\n",
      "Epoch 1684/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7627 - auc: 0.8423 - loss: 0.4814 - val_acc: 0.7711 - val_auc: 0.8536 - val_loss: 0.4650\n",
      "Epoch 1685/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7617 - auc: 0.8417 - loss: 0.4826 - val_acc: 0.7716 - val_auc: 0.8526 - val_loss: 0.4651\n",
      "Epoch 1686/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7633 - auc: 0.8420 - loss: 0.4833 - val_acc: 0.7735 - val_auc: 0.8550 - val_loss: 0.4639\n",
      "Epoch 1687/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7637 - auc: 0.8435 - loss: 0.4814 - val_acc: 0.7719 - val_auc: 0.8530 - val_loss: 0.4661\n",
      "Epoch 1688/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7622 - auc: 0.8424 - loss: 0.4830 - val_acc: 0.7751 - val_auc: 0.8564 - val_loss: 0.4613\n",
      "Epoch 1689/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7599 - auc: 0.8421 - loss: 0.4833 - val_acc: 0.7717 - val_auc: 0.8519 - val_loss: 0.4656\n",
      "Epoch 1690/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7618 - auc: 0.8429 - loss: 0.4823 - val_acc: 0.7746 - val_auc: 0.8553 - val_loss: 0.4622\n",
      "Epoch 1691/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7635 - auc: 0.8437 - loss: 0.4805 - val_acc: 0.7748 - val_auc: 0.8542 - val_loss: 0.4638\n",
      "Epoch 1692/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7653 - auc: 0.8450 - loss: 0.4797 - val_acc: 0.7733 - val_auc: 0.8544 - val_loss: 0.4622\n",
      "Epoch 1693/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7612 - auc: 0.8421 - loss: 0.4836 - val_acc: 0.7733 - val_auc: 0.8540 - val_loss: 0.4641\n",
      "Epoch 1694/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7636 - auc: 0.8432 - loss: 0.4812 - val_acc: 0.7741 - val_auc: 0.8555 - val_loss: 0.4614\n",
      "Epoch 1695/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7620 - auc: 0.8413 - loss: 0.4836 - val_acc: 0.7749 - val_auc: 0.8552 - val_loss: 0.4644\n",
      "Epoch 1696/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7637 - auc: 0.8430 - loss: 0.4825 - val_acc: 0.7729 - val_auc: 0.8541 - val_loss: 0.4629\n",
      "Epoch 1697/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7631 - auc: 0.8420 - loss: 0.4822 - val_acc: 0.7733 - val_auc: 0.8537 - val_loss: 0.4641\n",
      "Epoch 1698/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7631 - auc: 0.8429 - loss: 0.4828 - val_acc: 0.7729 - val_auc: 0.8539 - val_loss: 0.4640\n",
      "Epoch 1699/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7647 - auc: 0.8431 - loss: 0.4814 - val_acc: 0.7743 - val_auc: 0.8549 - val_loss: 0.4634\n",
      "Epoch 1700/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7617 - auc: 0.8423 - loss: 0.4834 - val_acc: 0.7713 - val_auc: 0.8537 - val_loss: 0.4638\n",
      "Epoch 1701/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7635 - auc: 0.8427 - loss: 0.4814 - val_acc: 0.7741 - val_auc: 0.8547 - val_loss: 0.4632\n",
      "Epoch 1702/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7629 - auc: 0.8413 - loss: 0.4836 - val_acc: 0.7746 - val_auc: 0.8539 - val_loss: 0.4638\n",
      "Epoch 1703/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7644 - auc: 0.8432 - loss: 0.4820 - val_acc: 0.7694 - val_auc: 0.8538 - val_loss: 0.4645\n",
      "Epoch 1704/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7634 - auc: 0.8432 - loss: 0.4804 - val_acc: 0.7738 - val_auc: 0.8553 - val_loss: 0.4620\n",
      "Epoch 1705/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7631 - auc: 0.8420 - loss: 0.4828 - val_acc: 0.7718 - val_auc: 0.8533 - val_loss: 0.4643\n",
      "Epoch 1706/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7628 - auc: 0.8427 - loss: 0.4823 - val_acc: 0.7747 - val_auc: 0.8557 - val_loss: 0.4619\n",
      "Epoch 1707/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7630 - auc: 0.8430 - loss: 0.4817 - val_acc: 0.7744 - val_auc: 0.8540 - val_loss: 0.4625\n",
      "Epoch 1708/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7643 - auc: 0.8442 - loss: 0.4806 - val_acc: 0.7719 - val_auc: 0.8535 - val_loss: 0.4634\n",
      "Epoch 1709/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7609 - auc: 0.8408 - loss: 0.4852 - val_acc: 0.7731 - val_auc: 0.8548 - val_loss: 0.4634\n",
      "Epoch 1710/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7640 - auc: 0.8428 - loss: 0.4820 - val_acc: 0.7717 - val_auc: 0.8538 - val_loss: 0.4634\n",
      "Epoch 1711/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7627 - auc: 0.8419 - loss: 0.4837 - val_acc: 0.7766 - val_auc: 0.8555 - val_loss: 0.4638\n",
      "Epoch 1712/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7623 - auc: 0.8431 - loss: 0.4809 - val_acc: 0.7728 - val_auc: 0.8547 - val_loss: 0.4644\n",
      "Epoch 1713/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7620 - auc: 0.8434 - loss: 0.4813 - val_acc: 0.7733 - val_auc: 0.8541 - val_loss: 0.4648\n",
      "Epoch 1714/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7626 - auc: 0.8430 - loss: 0.4820 - val_acc: 0.7741 - val_auc: 0.8552 - val_loss: 0.4623\n",
      "Epoch 1715/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7607 - auc: 0.8417 - loss: 0.4829 - val_acc: 0.7717 - val_auc: 0.8526 - val_loss: 0.4664\n",
      "Epoch 1716/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7633 - auc: 0.8426 - loss: 0.4828 - val_acc: 0.7723 - val_auc: 0.8533 - val_loss: 0.4653\n",
      "Epoch 1717/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7642 - auc: 0.8443 - loss: 0.4805 - val_acc: 0.7748 - val_auc: 0.8536 - val_loss: 0.4641\n",
      "Epoch 1718/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7616 - auc: 0.8429 - loss: 0.4827 - val_acc: 0.7764 - val_auc: 0.8548 - val_loss: 0.4624\n",
      "Epoch 1719/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7629 - auc: 0.8441 - loss: 0.4805 - val_acc: 0.7768 - val_auc: 0.8561 - val_loss: 0.4619\n",
      "Epoch 1720/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7636 - auc: 0.8432 - loss: 0.4818 - val_acc: 0.7776 - val_auc: 0.8556 - val_loss: 0.4614\n",
      "Epoch 1721/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7632 - auc: 0.8424 - loss: 0.4830 - val_acc: 0.7723 - val_auc: 0.8534 - val_loss: 0.4643\n",
      "Epoch 1722/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7627 - auc: 0.8436 - loss: 0.4807 - val_acc: 0.7771 - val_auc: 0.8576 - val_loss: 0.4595\n",
      "Epoch 1723/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7627 - auc: 0.8420 - loss: 0.4822 - val_acc: 0.7755 - val_auc: 0.8557 - val_loss: 0.4606\n",
      "Epoch 1724/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7620 - auc: 0.8441 - loss: 0.4807 - val_acc: 0.7729 - val_auc: 0.8540 - val_loss: 0.4652\n",
      "Epoch 1725/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7644 - auc: 0.8435 - loss: 0.4800 - val_acc: 0.7756 - val_auc: 0.8552 - val_loss: 0.4620\n",
      "Epoch 1726/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7630 - auc: 0.8439 - loss: 0.4807 - val_acc: 0.7713 - val_auc: 0.8541 - val_loss: 0.4644\n",
      "Epoch 1727/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7636 - auc: 0.8427 - loss: 0.4838 - val_acc: 0.7757 - val_auc: 0.8556 - val_loss: 0.4623\n",
      "Epoch 1728/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7629 - auc: 0.8434 - loss: 0.4821 - val_acc: 0.7761 - val_auc: 0.8553 - val_loss: 0.4629\n",
      "Epoch 1729/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7644 - auc: 0.8432 - loss: 0.4819 - val_acc: 0.7747 - val_auc: 0.8548 - val_loss: 0.4635\n",
      "Epoch 1730/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7609 - auc: 0.8421 - loss: 0.4827 - val_acc: 0.7729 - val_auc: 0.8550 - val_loss: 0.4641\n",
      "Epoch 1731/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7634 - auc: 0.8430 - loss: 0.4818 - val_acc: 0.7724 - val_auc: 0.8541 - val_loss: 0.4633\n",
      "Epoch 1732/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7626 - auc: 0.8423 - loss: 0.4841 - val_acc: 0.7716 - val_auc: 0.8542 - val_loss: 0.4630\n",
      "Epoch 1733/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7648 - auc: 0.8421 - loss: 0.4830 - val_acc: 0.7727 - val_auc: 0.8556 - val_loss: 0.4620\n",
      "Epoch 1734/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7623 - auc: 0.8432 - loss: 0.4811 - val_acc: 0.7728 - val_auc: 0.8540 - val_loss: 0.4625\n",
      "Epoch 1735/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7622 - auc: 0.8425 - loss: 0.4830 - val_acc: 0.7742 - val_auc: 0.8544 - val_loss: 0.4632\n",
      "Epoch 1736/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7637 - auc: 0.8428 - loss: 0.4824 - val_acc: 0.7738 - val_auc: 0.8550 - val_loss: 0.4625\n",
      "Epoch 1737/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7650 - auc: 0.8437 - loss: 0.4817 - val_acc: 0.7742 - val_auc: 0.8553 - val_loss: 0.4616\n",
      "Epoch 1738/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7634 - auc: 0.8427 - loss: 0.4836 - val_acc: 0.7732 - val_auc: 0.8557 - val_loss: 0.4626\n",
      "Epoch 1739/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7629 - auc: 0.8426 - loss: 0.4812 - val_acc: 0.7727 - val_auc: 0.8549 - val_loss: 0.4631\n",
      "Epoch 1740/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7648 - auc: 0.8442 - loss: 0.4809 - val_acc: 0.7754 - val_auc: 0.8553 - val_loss: 0.4616\n",
      "Epoch 1741/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7648 - auc: 0.8432 - loss: 0.4815 - val_acc: 0.7749 - val_auc: 0.8544 - val_loss: 0.4623\n",
      "Epoch 1742/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7627 - auc: 0.8421 - loss: 0.4836 - val_acc: 0.7708 - val_auc: 0.8539 - val_loss: 0.4659\n",
      "Epoch 1743/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7616 - auc: 0.8414 - loss: 0.4828 - val_acc: 0.7745 - val_auc: 0.8552 - val_loss: 0.4629\n",
      "Epoch 1744/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7626 - auc: 0.8428 - loss: 0.4814 - val_acc: 0.7761 - val_auc: 0.8562 - val_loss: 0.4620\n",
      "Epoch 1745/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7639 - auc: 0.8440 - loss: 0.4808 - val_acc: 0.7713 - val_auc: 0.8540 - val_loss: 0.4624\n",
      "Epoch 1746/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7651 - auc: 0.8436 - loss: 0.4816 - val_acc: 0.7758 - val_auc: 0.8552 - val_loss: 0.4608\n",
      "Epoch 1747/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7627 - auc: 0.8423 - loss: 0.4829 - val_acc: 0.7732 - val_auc: 0.8543 - val_loss: 0.4645\n",
      "Epoch 1748/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7643 - auc: 0.8429 - loss: 0.4825 - val_acc: 0.7731 - val_auc: 0.8548 - val_loss: 0.4624\n",
      "Epoch 1749/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7626 - auc: 0.8419 - loss: 0.4830 - val_acc: 0.7760 - val_auc: 0.8561 - val_loss: 0.4612\n",
      "Epoch 1750/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7630 - auc: 0.8427 - loss: 0.4820 - val_acc: 0.7742 - val_auc: 0.8551 - val_loss: 0.4633\n",
      "Epoch 1751/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7622 - auc: 0.8429 - loss: 0.4830 - val_acc: 0.7753 - val_auc: 0.8542 - val_loss: 0.4625\n",
      "Epoch 1752/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7658 - auc: 0.8456 - loss: 0.4785 - val_acc: 0.7733 - val_auc: 0.8536 - val_loss: 0.4651\n",
      "Epoch 1753/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7642 - auc: 0.8436 - loss: 0.4802 - val_acc: 0.7724 - val_auc: 0.8543 - val_loss: 0.4656\n",
      "Epoch 1754/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7620 - auc: 0.8418 - loss: 0.4821 - val_acc: 0.7757 - val_auc: 0.8571 - val_loss: 0.4602\n",
      "Epoch 1755/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7623 - auc: 0.8422 - loss: 0.4822 - val_acc: 0.7745 - val_auc: 0.8546 - val_loss: 0.4619\n",
      "Epoch 1756/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7629 - auc: 0.8442 - loss: 0.4806 - val_acc: 0.7743 - val_auc: 0.8554 - val_loss: 0.4630\n",
      "Epoch 1757/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7627 - auc: 0.8435 - loss: 0.4814 - val_acc: 0.7728 - val_auc: 0.8554 - val_loss: 0.4619\n",
      "Epoch 1758/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7626 - auc: 0.8431 - loss: 0.4814 - val_acc: 0.7741 - val_auc: 0.8538 - val_loss: 0.4632\n",
      "Epoch 1759/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7606 - auc: 0.8428 - loss: 0.4822 - val_acc: 0.7715 - val_auc: 0.8535 - val_loss: 0.4632\n",
      "Epoch 1760/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7633 - auc: 0.8432 - loss: 0.4811 - val_acc: 0.7764 - val_auc: 0.8561 - val_loss: 0.4614\n",
      "Epoch 1761/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7629 - auc: 0.8422 - loss: 0.4834 - val_acc: 0.7760 - val_auc: 0.8564 - val_loss: 0.4606\n",
      "Epoch 1762/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7645 - auc: 0.8441 - loss: 0.4805 - val_acc: 0.7722 - val_auc: 0.8552 - val_loss: 0.4645\n",
      "Epoch 1763/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7636 - auc: 0.8450 - loss: 0.4788 - val_acc: 0.7733 - val_auc: 0.8555 - val_loss: 0.4611\n",
      "Epoch 1764/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7631 - auc: 0.8427 - loss: 0.4822 - val_acc: 0.7743 - val_auc: 0.8539 - val_loss: 0.4655\n",
      "Epoch 1765/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7652 - auc: 0.8438 - loss: 0.4811 - val_acc: 0.7753 - val_auc: 0.8557 - val_loss: 0.4620\n",
      "Epoch 1766/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7649 - auc: 0.8441 - loss: 0.4808 - val_acc: 0.7732 - val_auc: 0.8547 - val_loss: 0.4640\n",
      "Epoch 1767/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7616 - auc: 0.8415 - loss: 0.4834 - val_acc: 0.7729 - val_auc: 0.8547 - val_loss: 0.4633\n",
      "Epoch 1768/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7636 - auc: 0.8430 - loss: 0.4810 - val_acc: 0.7747 - val_auc: 0.8536 - val_loss: 0.4648\n",
      "Epoch 1769/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7628 - auc: 0.8426 - loss: 0.4820 - val_acc: 0.7756 - val_auc: 0.8559 - val_loss: 0.4610\n",
      "Epoch 1770/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7640 - auc: 0.8423 - loss: 0.4816 - val_acc: 0.7741 - val_auc: 0.8560 - val_loss: 0.4605\n",
      "Epoch 1771/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7628 - auc: 0.8435 - loss: 0.4807 - val_acc: 0.7755 - val_auc: 0.8550 - val_loss: 0.4637\n",
      "Epoch 1772/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7642 - auc: 0.8437 - loss: 0.4806 - val_acc: 0.7724 - val_auc: 0.8551 - val_loss: 0.4633\n",
      "Epoch 1773/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7642 - auc: 0.8432 - loss: 0.4812 - val_acc: 0.7725 - val_auc: 0.8539 - val_loss: 0.4634\n",
      "Epoch 1774/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7651 - auc: 0.8453 - loss: 0.4795 - val_acc: 0.7693 - val_auc: 0.8519 - val_loss: 0.4675\n",
      "Epoch 1775/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7663 - auc: 0.8444 - loss: 0.4803 - val_acc: 0.7767 - val_auc: 0.8551 - val_loss: 0.4617\n",
      "Epoch 1776/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7647 - auc: 0.8424 - loss: 0.4834 - val_acc: 0.7745 - val_auc: 0.8551 - val_loss: 0.4633\n",
      "Epoch 1777/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7631 - auc: 0.8428 - loss: 0.4828 - val_acc: 0.7759 - val_auc: 0.8560 - val_loss: 0.4609\n",
      "Epoch 1778/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7630 - auc: 0.8435 - loss: 0.4805 - val_acc: 0.7754 - val_auc: 0.8560 - val_loss: 0.4602\n",
      "Epoch 1779/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7649 - auc: 0.8434 - loss: 0.4810 - val_acc: 0.7738 - val_auc: 0.8561 - val_loss: 0.4631\n",
      "Epoch 1780/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7651 - auc: 0.8455 - loss: 0.4795 - val_acc: 0.7746 - val_auc: 0.8534 - val_loss: 0.4631\n",
      "Epoch 1781/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7634 - auc: 0.8442 - loss: 0.4794 - val_acc: 0.7740 - val_auc: 0.8548 - val_loss: 0.4644\n",
      "Epoch 1782/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7663 - auc: 0.8445 - loss: 0.4797 - val_acc: 0.7753 - val_auc: 0.8564 - val_loss: 0.4614\n",
      "Epoch 1783/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7638 - auc: 0.8427 - loss: 0.4811 - val_acc: 0.7741 - val_auc: 0.8560 - val_loss: 0.4606\n",
      "Epoch 1784/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7626 - auc: 0.8434 - loss: 0.4819 - val_acc: 0.7740 - val_auc: 0.8544 - val_loss: 0.4639\n",
      "Epoch 1785/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7612 - auc: 0.8417 - loss: 0.4827 - val_acc: 0.7737 - val_auc: 0.8537 - val_loss: 0.4645\n",
      "Epoch 1786/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7634 - auc: 0.8434 - loss: 0.4816 - val_acc: 0.7722 - val_auc: 0.8547 - val_loss: 0.4626\n",
      "Epoch 1787/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7645 - auc: 0.8436 - loss: 0.4807 - val_acc: 0.7761 - val_auc: 0.8540 - val_loss: 0.4643\n",
      "Epoch 1788/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7632 - auc: 0.8438 - loss: 0.4812 - val_acc: 0.7734 - val_auc: 0.8554 - val_loss: 0.4618\n",
      "Epoch 1789/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7633 - auc: 0.8422 - loss: 0.4829 - val_acc: 0.7727 - val_auc: 0.8552 - val_loss: 0.4633\n",
      "Epoch 1790/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7633 - auc: 0.8430 - loss: 0.4822 - val_acc: 0.7713 - val_auc: 0.8544 - val_loss: 0.4627\n",
      "Epoch 1791/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7621 - auc: 0.8431 - loss: 0.4817 - val_acc: 0.7754 - val_auc: 0.8543 - val_loss: 0.4638\n",
      "Epoch 1792/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7652 - auc: 0.8444 - loss: 0.4807 - val_acc: 0.7759 - val_auc: 0.8550 - val_loss: 0.4616\n",
      "Epoch 1793/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7646 - auc: 0.8441 - loss: 0.4806 - val_acc: 0.7735 - val_auc: 0.8535 - val_loss: 0.4638\n",
      "Epoch 1794/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7632 - auc: 0.8440 - loss: 0.4797 - val_acc: 0.7751 - val_auc: 0.8552 - val_loss: 0.4617\n",
      "Epoch 1795/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7646 - auc: 0.8437 - loss: 0.4814 - val_acc: 0.7748 - val_auc: 0.8547 - val_loss: 0.4620\n",
      "Epoch 1796/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7634 - auc: 0.8447 - loss: 0.4799 - val_acc: 0.7735 - val_auc: 0.8549 - val_loss: 0.4634\n",
      "Epoch 1797/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7637 - auc: 0.8434 - loss: 0.4817 - val_acc: 0.7756 - val_auc: 0.8558 - val_loss: 0.4604\n",
      "Epoch 1798/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7636 - auc: 0.8446 - loss: 0.4794 - val_acc: 0.7755 - val_auc: 0.8564 - val_loss: 0.4611\n",
      "Epoch 1799/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7634 - auc: 0.8442 - loss: 0.4798 - val_acc: 0.7747 - val_auc: 0.8556 - val_loss: 0.4617\n",
      "Epoch 1800/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7634 - auc: 0.8445 - loss: 0.4795 - val_acc: 0.7754 - val_auc: 0.8546 - val_loss: 0.4618\n",
      "Epoch 1801/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7638 - auc: 0.8441 - loss: 0.4794 - val_acc: 0.7757 - val_auc: 0.8553 - val_loss: 0.4624\n",
      "Epoch 1802/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7628 - auc: 0.8438 - loss: 0.4809 - val_acc: 0.7750 - val_auc: 0.8559 - val_loss: 0.4618\n",
      "Epoch 1803/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7656 - auc: 0.8436 - loss: 0.4812 - val_acc: 0.7734 - val_auc: 0.8551 - val_loss: 0.4632\n",
      "Epoch 1804/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7646 - auc: 0.8444 - loss: 0.4805 - val_acc: 0.7740 - val_auc: 0.8543 - val_loss: 0.4635\n",
      "Epoch 1805/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7653 - auc: 0.8437 - loss: 0.4808 - val_acc: 0.7732 - val_auc: 0.8561 - val_loss: 0.4616\n",
      "Epoch 1806/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7635 - auc: 0.8434 - loss: 0.4806 - val_acc: 0.7764 - val_auc: 0.8555 - val_loss: 0.4622\n",
      "Epoch 1807/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7642 - auc: 0.8420 - loss: 0.4836 - val_acc: 0.7759 - val_auc: 0.8568 - val_loss: 0.4615\n",
      "Epoch 1808/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7627 - auc: 0.8415 - loss: 0.4829 - val_acc: 0.7752 - val_auc: 0.8553 - val_loss: 0.4622\n",
      "Epoch 1809/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7664 - auc: 0.8448 - loss: 0.4792 - val_acc: 0.7747 - val_auc: 0.8547 - val_loss: 0.4624\n",
      "Epoch 1810/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7638 - auc: 0.8428 - loss: 0.4823 - val_acc: 0.7731 - val_auc: 0.8538 - val_loss: 0.4629\n",
      "Epoch 1811/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7650 - auc: 0.8432 - loss: 0.4809 - val_acc: 0.7761 - val_auc: 0.8562 - val_loss: 0.4605\n",
      "Epoch 1812/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7623 - auc: 0.8428 - loss: 0.4823 - val_acc: 0.7751 - val_auc: 0.8558 - val_loss: 0.4610\n",
      "Epoch 1813/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7642 - auc: 0.8434 - loss: 0.4822 - val_acc: 0.7772 - val_auc: 0.8557 - val_loss: 0.4618\n",
      "Epoch 1814/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7632 - auc: 0.8431 - loss: 0.4818 - val_acc: 0.7748 - val_auc: 0.8534 - val_loss: 0.4651\n",
      "Epoch 1815/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7631 - auc: 0.8429 - loss: 0.4824 - val_acc: 0.7714 - val_auc: 0.8541 - val_loss: 0.4647\n",
      "Epoch 1816/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7641 - auc: 0.8430 - loss: 0.4808 - val_acc: 0.7748 - val_auc: 0.8551 - val_loss: 0.4611\n",
      "Epoch 1817/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7651 - auc: 0.8434 - loss: 0.4820 - val_acc: 0.7751 - val_auc: 0.8560 - val_loss: 0.4610\n",
      "Epoch 1818/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7646 - auc: 0.8453 - loss: 0.4783 - val_acc: 0.7743 - val_auc: 0.8557 - val_loss: 0.4631\n",
      "Epoch 1819/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7630 - auc: 0.8434 - loss: 0.4814 - val_acc: 0.7768 - val_auc: 0.8558 - val_loss: 0.4619\n",
      "Epoch 1820/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7651 - auc: 0.8441 - loss: 0.4802 - val_acc: 0.7761 - val_auc: 0.8571 - val_loss: 0.4595\n",
      "Epoch 1821/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7663 - auc: 0.8447 - loss: 0.4798 - val_acc: 0.7738 - val_auc: 0.8547 - val_loss: 0.4633\n",
      "Epoch 1822/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7646 - auc: 0.8438 - loss: 0.4802 - val_acc: 0.7756 - val_auc: 0.8552 - val_loss: 0.4614\n",
      "Epoch 1823/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7632 - auc: 0.8433 - loss: 0.4815 - val_acc: 0.7755 - val_auc: 0.8564 - val_loss: 0.4605\n",
      "Epoch 1824/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7631 - auc: 0.8433 - loss: 0.4806 - val_acc: 0.7754 - val_auc: 0.8566 - val_loss: 0.4599\n",
      "Epoch 1825/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7639 - auc: 0.8432 - loss: 0.4817 - val_acc: 0.7760 - val_auc: 0.8546 - val_loss: 0.4627\n",
      "Epoch 1826/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7636 - auc: 0.8423 - loss: 0.4831 - val_acc: 0.7769 - val_auc: 0.8570 - val_loss: 0.4598\n",
      "Epoch 1827/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7648 - auc: 0.8443 - loss: 0.4803 - val_acc: 0.7772 - val_auc: 0.8554 - val_loss: 0.4624\n",
      "Epoch 1828/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7629 - auc: 0.8437 - loss: 0.4812 - val_acc: 0.7757 - val_auc: 0.8561 - val_loss: 0.4611\n",
      "Epoch 1829/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7659 - auc: 0.8451 - loss: 0.4786 - val_acc: 0.7745 - val_auc: 0.8554 - val_loss: 0.4618\n",
      "Epoch 1830/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7638 - auc: 0.8437 - loss: 0.4809 - val_acc: 0.7723 - val_auc: 0.8548 - val_loss: 0.4630\n",
      "Epoch 1831/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7645 - auc: 0.8441 - loss: 0.4808 - val_acc: 0.7760 - val_auc: 0.8556 - val_loss: 0.4607\n",
      "Epoch 1832/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7633 - auc: 0.8439 - loss: 0.4807 - val_acc: 0.7749 - val_auc: 0.8564 - val_loss: 0.4601\n",
      "Epoch 1833/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7626 - auc: 0.8436 - loss: 0.4812 - val_acc: 0.7738 - val_auc: 0.8554 - val_loss: 0.4621\n",
      "Epoch 1834/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7650 - auc: 0.8441 - loss: 0.4799 - val_acc: 0.7767 - val_auc: 0.8555 - val_loss: 0.4612\n",
      "Epoch 1835/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7653 - auc: 0.8451 - loss: 0.4795 - val_acc: 0.7768 - val_auc: 0.8577 - val_loss: 0.4589\n",
      "Epoch 1836/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7632 - auc: 0.8432 - loss: 0.4814 - val_acc: 0.7725 - val_auc: 0.8556 - val_loss: 0.4625\n",
      "Epoch 1837/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7630 - auc: 0.8433 - loss: 0.4808 - val_acc: 0.7759 - val_auc: 0.8560 - val_loss: 0.4617\n",
      "Epoch 1838/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7664 - auc: 0.8447 - loss: 0.4805 - val_acc: 0.7766 - val_auc: 0.8554 - val_loss: 0.4615\n",
      "Epoch 1839/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7649 - auc: 0.8438 - loss: 0.4816 - val_acc: 0.7724 - val_auc: 0.8556 - val_loss: 0.4630\n",
      "Epoch 1840/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7655 - auc: 0.8435 - loss: 0.4818 - val_acc: 0.7760 - val_auc: 0.8555 - val_loss: 0.4620\n",
      "Epoch 1841/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7657 - auc: 0.8449 - loss: 0.4793 - val_acc: 0.7747 - val_auc: 0.8551 - val_loss: 0.4625\n",
      "Epoch 1842/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7627 - auc: 0.8427 - loss: 0.4822 - val_acc: 0.7758 - val_auc: 0.8568 - val_loss: 0.4614\n",
      "Epoch 1843/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7633 - auc: 0.8437 - loss: 0.4807 - val_acc: 0.7738 - val_auc: 0.8560 - val_loss: 0.4609\n",
      "Epoch 1844/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7663 - auc: 0.8448 - loss: 0.4788 - val_acc: 0.7761 - val_auc: 0.8549 - val_loss: 0.4621\n",
      "Epoch 1845/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7626 - auc: 0.8436 - loss: 0.4809 - val_acc: 0.7746 - val_auc: 0.8559 - val_loss: 0.4631\n",
      "Epoch 1846/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7633 - auc: 0.8441 - loss: 0.4806 - val_acc: 0.7716 - val_auc: 0.8541 - val_loss: 0.4639\n",
      "Epoch 1847/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7647 - auc: 0.8445 - loss: 0.4803 - val_acc: 0.7750 - val_auc: 0.8558 - val_loss: 0.4621\n",
      "Epoch 1848/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7630 - auc: 0.8434 - loss: 0.4810 - val_acc: 0.7733 - val_auc: 0.8565 - val_loss: 0.4622\n",
      "Epoch 1849/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7650 - auc: 0.8441 - loss: 0.4813 - val_acc: 0.7761 - val_auc: 0.8564 - val_loss: 0.4604\n",
      "Epoch 1850/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7659 - auc: 0.8451 - loss: 0.4796 - val_acc: 0.7720 - val_auc: 0.8540 - val_loss: 0.4641\n",
      "Epoch 1851/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7661 - auc: 0.8449 - loss: 0.4784 - val_acc: 0.7758 - val_auc: 0.8553 - val_loss: 0.4617\n",
      "Epoch 1852/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7650 - auc: 0.8448 - loss: 0.4798 - val_acc: 0.7760 - val_auc: 0.8558 - val_loss: 0.4620\n",
      "Epoch 1853/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7647 - auc: 0.8450 - loss: 0.4806 - val_acc: 0.7754 - val_auc: 0.8574 - val_loss: 0.4603\n",
      "Epoch 1854/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7642 - auc: 0.8441 - loss: 0.4809 - val_acc: 0.7759 - val_auc: 0.8568 - val_loss: 0.4602\n",
      "Epoch 1855/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7646 - auc: 0.8440 - loss: 0.4811 - val_acc: 0.7760 - val_auc: 0.8559 - val_loss: 0.4625\n",
      "Epoch 1856/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7634 - auc: 0.8437 - loss: 0.4815 - val_acc: 0.7741 - val_auc: 0.8564 - val_loss: 0.4604\n",
      "Epoch 1857/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7635 - auc: 0.8442 - loss: 0.4807 - val_acc: 0.7741 - val_auc: 0.8553 - val_loss: 0.4610\n",
      "Epoch 1858/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7630 - auc: 0.8428 - loss: 0.4821 - val_acc: 0.7745 - val_auc: 0.8566 - val_loss: 0.4600\n",
      "Epoch 1859/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7634 - auc: 0.8437 - loss: 0.4806 - val_acc: 0.7780 - val_auc: 0.8568 - val_loss: 0.4612\n",
      "Epoch 1860/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7642 - auc: 0.8431 - loss: 0.4818 - val_acc: 0.7782 - val_auc: 0.8570 - val_loss: 0.4598\n",
      "Epoch 1861/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7655 - auc: 0.8442 - loss: 0.4814 - val_acc: 0.7750 - val_auc: 0.8553 - val_loss: 0.4617\n",
      "Epoch 1862/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7652 - auc: 0.8448 - loss: 0.4799 - val_acc: 0.7719 - val_auc: 0.8530 - val_loss: 0.4638\n",
      "Epoch 1863/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7638 - auc: 0.8436 - loss: 0.4818 - val_acc: 0.7735 - val_auc: 0.8543 - val_loss: 0.4625\n",
      "Epoch 1864/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7646 - auc: 0.8443 - loss: 0.4798 - val_acc: 0.7752 - val_auc: 0.8564 - val_loss: 0.4606\n",
      "Epoch 1865/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7648 - auc: 0.8441 - loss: 0.4800 - val_acc: 0.7790 - val_auc: 0.8585 - val_loss: 0.4573\n",
      "Epoch 1866/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7649 - auc: 0.8449 - loss: 0.4788 - val_acc: 0.7730 - val_auc: 0.8547 - val_loss: 0.4623\n",
      "Epoch 1867/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7643 - auc: 0.8453 - loss: 0.4791 - val_acc: 0.7768 - val_auc: 0.8558 - val_loss: 0.4618\n",
      "Epoch 1868/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7642 - auc: 0.8451 - loss: 0.4799 - val_acc: 0.7790 - val_auc: 0.8583 - val_loss: 0.4577\n",
      "Epoch 1869/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7654 - auc: 0.8448 - loss: 0.4802 - val_acc: 0.7745 - val_auc: 0.8559 - val_loss: 0.4619\n",
      "Epoch 1870/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7647 - auc: 0.8439 - loss: 0.4810 - val_acc: 0.7711 - val_auc: 0.8547 - val_loss: 0.4643\n",
      "Epoch 1871/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7656 - auc: 0.8449 - loss: 0.4794 - val_acc: 0.7723 - val_auc: 0.8540 - val_loss: 0.4653\n",
      "Epoch 1872/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7644 - auc: 0.8439 - loss: 0.4804 - val_acc: 0.7760 - val_auc: 0.8543 - val_loss: 0.4627\n",
      "Epoch 1873/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7640 - auc: 0.8447 - loss: 0.4789 - val_acc: 0.7758 - val_auc: 0.8560 - val_loss: 0.4616\n",
      "Epoch 1874/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7655 - auc: 0.8442 - loss: 0.4802 - val_acc: 0.7759 - val_auc: 0.8551 - val_loss: 0.4614\n",
      "Epoch 1875/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7653 - auc: 0.8445 - loss: 0.4802 - val_acc: 0.7735 - val_auc: 0.8555 - val_loss: 0.4613\n",
      "Epoch 1876/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7651 - auc: 0.8450 - loss: 0.4786 - val_acc: 0.7757 - val_auc: 0.8556 - val_loss: 0.4613\n",
      "Epoch 1877/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7662 - auc: 0.8461 - loss: 0.4787 - val_acc: 0.7738 - val_auc: 0.8564 - val_loss: 0.4616\n",
      "Epoch 1878/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7647 - auc: 0.8440 - loss: 0.4800 - val_acc: 0.7735 - val_auc: 0.8563 - val_loss: 0.4608\n",
      "Epoch 1879/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7650 - auc: 0.8438 - loss: 0.4804 - val_acc: 0.7751 - val_auc: 0.8560 - val_loss: 0.4598\n",
      "Epoch 1880/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7649 - auc: 0.8452 - loss: 0.4792 - val_acc: 0.7781 - val_auc: 0.8562 - val_loss: 0.4616\n",
      "Epoch 1881/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7624 - auc: 0.8435 - loss: 0.4813 - val_acc: 0.7790 - val_auc: 0.8567 - val_loss: 0.4597\n",
      "Epoch 1882/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7642 - auc: 0.8438 - loss: 0.4808 - val_acc: 0.7765 - val_auc: 0.8561 - val_loss: 0.4617\n",
      "Epoch 1883/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7643 - auc: 0.8450 - loss: 0.4800 - val_acc: 0.7726 - val_auc: 0.8546 - val_loss: 0.4649\n",
      "Epoch 1884/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7661 - auc: 0.8435 - loss: 0.4804 - val_acc: 0.7755 - val_auc: 0.8557 - val_loss: 0.4603\n",
      "Epoch 1885/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7644 - auc: 0.8451 - loss: 0.4797 - val_acc: 0.7741 - val_auc: 0.8559 - val_loss: 0.4618\n",
      "Epoch 1886/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7648 - auc: 0.8452 - loss: 0.4791 - val_acc: 0.7788 - val_auc: 0.8580 - val_loss: 0.4575\n",
      "Epoch 1887/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7649 - auc: 0.8448 - loss: 0.4791 - val_acc: 0.7752 - val_auc: 0.8554 - val_loss: 0.4622\n",
      "Epoch 1888/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7661 - auc: 0.8444 - loss: 0.4796 - val_acc: 0.7755 - val_auc: 0.8572 - val_loss: 0.4595\n",
      "Epoch 1889/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7627 - auc: 0.8422 - loss: 0.4828 - val_acc: 0.7782 - val_auc: 0.8581 - val_loss: 0.4590\n",
      "Epoch 1890/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7660 - auc: 0.8454 - loss: 0.4783 - val_acc: 0.7770 - val_auc: 0.8570 - val_loss: 0.4601\n",
      "Epoch 1891/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7637 - auc: 0.8442 - loss: 0.4799 - val_acc: 0.7744 - val_auc: 0.8547 - val_loss: 0.4631\n",
      "Epoch 1892/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7641 - auc: 0.8442 - loss: 0.4813 - val_acc: 0.7759 - val_auc: 0.8563 - val_loss: 0.4619\n",
      "Epoch 1893/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7636 - auc: 0.8446 - loss: 0.4787 - val_acc: 0.7792 - val_auc: 0.8578 - val_loss: 0.4586\n",
      "Epoch 1894/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7628 - auc: 0.8432 - loss: 0.4801 - val_acc: 0.7773 - val_auc: 0.8567 - val_loss: 0.4601\n",
      "Epoch 1895/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7633 - auc: 0.8442 - loss: 0.4797 - val_acc: 0.7697 - val_auc: 0.8543 - val_loss: 0.4621\n",
      "Epoch 1896/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7667 - auc: 0.8444 - loss: 0.4804 - val_acc: 0.7766 - val_auc: 0.8565 - val_loss: 0.4602\n",
      "Epoch 1897/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7656 - auc: 0.8459 - loss: 0.4788 - val_acc: 0.7735 - val_auc: 0.8564 - val_loss: 0.4604\n",
      "Epoch 1898/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7653 - auc: 0.8444 - loss: 0.4798 - val_acc: 0.7752 - val_auc: 0.8557 - val_loss: 0.4629\n",
      "Epoch 1899/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7655 - auc: 0.8461 - loss: 0.4774 - val_acc: 0.7754 - val_auc: 0.8572 - val_loss: 0.4601\n",
      "Epoch 1900/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7645 - auc: 0.8441 - loss: 0.4801 - val_acc: 0.7770 - val_auc: 0.8563 - val_loss: 0.4607\n",
      "Epoch 1901/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7674 - auc: 0.8460 - loss: 0.4767 - val_acc: 0.7744 - val_auc: 0.8560 - val_loss: 0.4603\n",
      "Epoch 1902/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7654 - auc: 0.8458 - loss: 0.4772 - val_acc: 0.7743 - val_auc: 0.8550 - val_loss: 0.4610\n",
      "Epoch 1903/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7651 - auc: 0.8439 - loss: 0.4811 - val_acc: 0.7778 - val_auc: 0.8581 - val_loss: 0.4599\n",
      "Epoch 1904/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7632 - auc: 0.8446 - loss: 0.4795 - val_acc: 0.7760 - val_auc: 0.8551 - val_loss: 0.4607\n",
      "Epoch 1905/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7653 - auc: 0.8453 - loss: 0.4790 - val_acc: 0.7774 - val_auc: 0.8562 - val_loss: 0.4610\n",
      "Epoch 1906/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7654 - auc: 0.8459 - loss: 0.4786 - val_acc: 0.7754 - val_auc: 0.8568 - val_loss: 0.4612\n",
      "Epoch 1907/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7662 - auc: 0.8447 - loss: 0.4796 - val_acc: 0.7742 - val_auc: 0.8566 - val_loss: 0.4621\n",
      "Epoch 1908/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7637 - auc: 0.8443 - loss: 0.4804 - val_acc: 0.7789 - val_auc: 0.8580 - val_loss: 0.4594\n",
      "Epoch 1909/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7653 - auc: 0.8451 - loss: 0.4789 - val_acc: 0.7767 - val_auc: 0.8572 - val_loss: 0.4594\n",
      "Epoch 1910/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7629 - auc: 0.8424 - loss: 0.4831 - val_acc: 0.7751 - val_auc: 0.8559 - val_loss: 0.4612\n",
      "Epoch 1911/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7662 - auc: 0.8447 - loss: 0.4792 - val_acc: 0.7749 - val_auc: 0.8544 - val_loss: 0.4630\n",
      "Epoch 1912/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7651 - auc: 0.8442 - loss: 0.4802 - val_acc: 0.7764 - val_auc: 0.8557 - val_loss: 0.4619\n",
      "Epoch 1913/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7633 - auc: 0.8454 - loss: 0.4777 - val_acc: 0.7761 - val_auc: 0.8575 - val_loss: 0.4597\n",
      "Epoch 1914/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7651 - auc: 0.8454 - loss: 0.4793 - val_acc: 0.7783 - val_auc: 0.8580 - val_loss: 0.4578\n",
      "Epoch 1915/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7666 - auc: 0.8459 - loss: 0.4781 - val_acc: 0.7748 - val_auc: 0.8540 - val_loss: 0.4639\n",
      "Epoch 1916/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7637 - auc: 0.8433 - loss: 0.4815 - val_acc: 0.7768 - val_auc: 0.8577 - val_loss: 0.4593\n",
      "Epoch 1917/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7644 - auc: 0.8456 - loss: 0.4779 - val_acc: 0.7755 - val_auc: 0.8573 - val_loss: 0.4602\n",
      "Epoch 1918/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7651 - auc: 0.8446 - loss: 0.4799 - val_acc: 0.7782 - val_auc: 0.8576 - val_loss: 0.4596\n",
      "Epoch 1919/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7674 - auc: 0.8464 - loss: 0.4772 - val_acc: 0.7802 - val_auc: 0.8571 - val_loss: 0.4587\n",
      "Epoch 1920/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7647 - auc: 0.8436 - loss: 0.4811 - val_acc: 0.7771 - val_auc: 0.8577 - val_loss: 0.4590\n",
      "Epoch 1921/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7675 - auc: 0.8457 - loss: 0.4783 - val_acc: 0.7772 - val_auc: 0.8564 - val_loss: 0.4611\n",
      "Epoch 1922/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7636 - auc: 0.8440 - loss: 0.4806 - val_acc: 0.7768 - val_auc: 0.8572 - val_loss: 0.4597\n",
      "Epoch 1923/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7648 - auc: 0.8450 - loss: 0.4785 - val_acc: 0.7763 - val_auc: 0.8560 - val_loss: 0.4609\n",
      "Epoch 1924/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7656 - auc: 0.8452 - loss: 0.4786 - val_acc: 0.7785 - val_auc: 0.8573 - val_loss: 0.4595\n",
      "Epoch 1925/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7657 - auc: 0.8445 - loss: 0.4802 - val_acc: 0.7783 - val_auc: 0.8567 - val_loss: 0.4593\n",
      "Epoch 1926/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7624 - auc: 0.8431 - loss: 0.4807 - val_acc: 0.7767 - val_auc: 0.8565 - val_loss: 0.4618\n",
      "Epoch 1927/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7633 - auc: 0.8443 - loss: 0.4796 - val_acc: 0.7794 - val_auc: 0.8572 - val_loss: 0.4589\n",
      "Epoch 1928/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7662 - auc: 0.8447 - loss: 0.4785 - val_acc: 0.7752 - val_auc: 0.8574 - val_loss: 0.4582\n",
      "Epoch 1929/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7656 - auc: 0.8458 - loss: 0.4783 - val_acc: 0.7755 - val_auc: 0.8572 - val_loss: 0.4610\n",
      "Epoch 1930/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7639 - auc: 0.8447 - loss: 0.4800 - val_acc: 0.7768 - val_auc: 0.8571 - val_loss: 0.4601\n",
      "Epoch 1931/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7677 - auc: 0.8454 - loss: 0.4786 - val_acc: 0.7772 - val_auc: 0.8568 - val_loss: 0.4609\n",
      "Epoch 1932/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7656 - auc: 0.8451 - loss: 0.4788 - val_acc: 0.7762 - val_auc: 0.8564 - val_loss: 0.4617\n",
      "Epoch 1933/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7656 - auc: 0.8459 - loss: 0.4776 - val_acc: 0.7747 - val_auc: 0.8571 - val_loss: 0.4603\n",
      "Epoch 1934/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7645 - auc: 0.8446 - loss: 0.4805 - val_acc: 0.7779 - val_auc: 0.8555 - val_loss: 0.4616\n",
      "Epoch 1935/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7646 - auc: 0.8450 - loss: 0.4779 - val_acc: 0.7741 - val_auc: 0.8562 - val_loss: 0.4614\n",
      "Epoch 1936/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7619 - auc: 0.8435 - loss: 0.4810 - val_acc: 0.7758 - val_auc: 0.8563 - val_loss: 0.4599\n",
      "Epoch 1937/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7656 - auc: 0.8459 - loss: 0.4788 - val_acc: 0.7772 - val_auc: 0.8566 - val_loss: 0.4597\n",
      "Epoch 1938/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7654 - auc: 0.8452 - loss: 0.4791 - val_acc: 0.7772 - val_auc: 0.8584 - val_loss: 0.4582\n",
      "Epoch 1939/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7676 - auc: 0.8457 - loss: 0.4783 - val_acc: 0.7754 - val_auc: 0.8571 - val_loss: 0.4596\n",
      "Epoch 1940/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7653 - auc: 0.8452 - loss: 0.4783 - val_acc: 0.7771 - val_auc: 0.8563 - val_loss: 0.4603\n",
      "Epoch 1941/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7645 - auc: 0.8445 - loss: 0.4795 - val_acc: 0.7774 - val_auc: 0.8585 - val_loss: 0.4599\n",
      "Epoch 1942/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7661 - auc: 0.8444 - loss: 0.4803 - val_acc: 0.7770 - val_auc: 0.8588 - val_loss: 0.4588\n",
      "Epoch 1943/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7641 - auc: 0.8445 - loss: 0.4797 - val_acc: 0.7758 - val_auc: 0.8567 - val_loss: 0.4597\n",
      "Epoch 1944/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7661 - auc: 0.8448 - loss: 0.4793 - val_acc: 0.7751 - val_auc: 0.8567 - val_loss: 0.4591\n",
      "Epoch 1945/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7661 - auc: 0.8454 - loss: 0.4787 - val_acc: 0.7788 - val_auc: 0.8592 - val_loss: 0.4573\n",
      "Epoch 1946/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7672 - auc: 0.8474 - loss: 0.4764 - val_acc: 0.7785 - val_auc: 0.8585 - val_loss: 0.4592\n",
      "Epoch 1947/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7663 - auc: 0.8454 - loss: 0.4792 - val_acc: 0.7745 - val_auc: 0.8557 - val_loss: 0.4614\n",
      "Epoch 1948/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7666 - auc: 0.8466 - loss: 0.4774 - val_acc: 0.7781 - val_auc: 0.8576 - val_loss: 0.4592\n",
      "Epoch 1949/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7668 - auc: 0.8457 - loss: 0.4789 - val_acc: 0.7735 - val_auc: 0.8560 - val_loss: 0.4627\n",
      "Epoch 1950/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7639 - auc: 0.8435 - loss: 0.4815 - val_acc: 0.7803 - val_auc: 0.8585 - val_loss: 0.4596\n",
      "Epoch 1951/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7642 - auc: 0.8451 - loss: 0.4781 - val_acc: 0.7779 - val_auc: 0.8574 - val_loss: 0.4605\n",
      "Epoch 1952/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7654 - auc: 0.8448 - loss: 0.4792 - val_acc: 0.7769 - val_auc: 0.8577 - val_loss: 0.4589\n",
      "Epoch 1953/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7657 - auc: 0.8446 - loss: 0.4796 - val_acc: 0.7770 - val_auc: 0.8568 - val_loss: 0.4620\n",
      "Epoch 1954/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7646 - auc: 0.8446 - loss: 0.4798 - val_acc: 0.7742 - val_auc: 0.8558 - val_loss: 0.4617\n",
      "Epoch 1955/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7654 - auc: 0.8455 - loss: 0.4780 - val_acc: 0.7812 - val_auc: 0.8583 - val_loss: 0.4584\n",
      "Epoch 1956/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7668 - auc: 0.8467 - loss: 0.4771 - val_acc: 0.7763 - val_auc: 0.8582 - val_loss: 0.4582\n",
      "Epoch 1957/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7675 - auc: 0.8462 - loss: 0.4778 - val_acc: 0.7794 - val_auc: 0.8584 - val_loss: 0.4584\n",
      "Epoch 1958/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7654 - auc: 0.8454 - loss: 0.4787 - val_acc: 0.7801 - val_auc: 0.8587 - val_loss: 0.4574\n",
      "Epoch 1959/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7651 - auc: 0.8441 - loss: 0.4807 - val_acc: 0.7784 - val_auc: 0.8579 - val_loss: 0.4596\n",
      "Epoch 1960/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7652 - auc: 0.8456 - loss: 0.4785 - val_acc: 0.7782 - val_auc: 0.8567 - val_loss: 0.4595\n",
      "Epoch 1961/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7640 - auc: 0.8450 - loss: 0.4794 - val_acc: 0.7737 - val_auc: 0.8555 - val_loss: 0.4611\n",
      "Epoch 1962/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7665 - auc: 0.8453 - loss: 0.4782 - val_acc: 0.7764 - val_auc: 0.8563 - val_loss: 0.4607\n",
      "Epoch 1963/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7649 - auc: 0.8449 - loss: 0.4799 - val_acc: 0.7755 - val_auc: 0.8562 - val_loss: 0.4599\n",
      "Epoch 1964/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7667 - auc: 0.8471 - loss: 0.4756 - val_acc: 0.7821 - val_auc: 0.8589 - val_loss: 0.4584\n",
      "Epoch 1965/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7654 - auc: 0.8448 - loss: 0.4798 - val_acc: 0.7813 - val_auc: 0.8586 - val_loss: 0.4576\n",
      "Epoch 1966/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7657 - auc: 0.8441 - loss: 0.4809 - val_acc: 0.7792 - val_auc: 0.8570 - val_loss: 0.4597\n",
      "Epoch 1967/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7668 - auc: 0.8451 - loss: 0.4791 - val_acc: 0.7788 - val_auc: 0.8580 - val_loss: 0.4602\n",
      "Epoch 1968/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7631 - auc: 0.8428 - loss: 0.4819 - val_acc: 0.7802 - val_auc: 0.8571 - val_loss: 0.4606\n",
      "Epoch 1969/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7661 - auc: 0.8473 - loss: 0.4754 - val_acc: 0.7776 - val_auc: 0.8558 - val_loss: 0.4606\n",
      "Epoch 1970/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7660 - auc: 0.8459 - loss: 0.4774 - val_acc: 0.7785 - val_auc: 0.8582 - val_loss: 0.4576\n",
      "Epoch 1971/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7660 - auc: 0.8455 - loss: 0.4783 - val_acc: 0.7795 - val_auc: 0.8583 - val_loss: 0.4581\n",
      "Epoch 1972/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7652 - auc: 0.8461 - loss: 0.4782 - val_acc: 0.7784 - val_auc: 0.8571 - val_loss: 0.4607\n",
      "Epoch 1973/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7653 - auc: 0.8458 - loss: 0.4779 - val_acc: 0.7778 - val_auc: 0.8574 - val_loss: 0.4596\n",
      "Epoch 1974/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7640 - auc: 0.8439 - loss: 0.4801 - val_acc: 0.7791 - val_auc: 0.8588 - val_loss: 0.4584\n",
      "Epoch 1975/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7663 - auc: 0.8469 - loss: 0.4762 - val_acc: 0.7767 - val_auc: 0.8589 - val_loss: 0.4577\n",
      "Epoch 1976/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7666 - auc: 0.8464 - loss: 0.4770 - val_acc: 0.7773 - val_auc: 0.8555 - val_loss: 0.4620\n",
      "Epoch 1977/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7668 - auc: 0.8475 - loss: 0.4760 - val_acc: 0.7781 - val_auc: 0.8572 - val_loss: 0.4580\n",
      "Epoch 1978/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7653 - auc: 0.8451 - loss: 0.4786 - val_acc: 0.7794 - val_auc: 0.8586 - val_loss: 0.4583\n",
      "Epoch 1979/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7646 - auc: 0.8433 - loss: 0.4818 - val_acc: 0.7791 - val_auc: 0.8581 - val_loss: 0.4586\n",
      "Epoch 1980/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7648 - auc: 0.8454 - loss: 0.4794 - val_acc: 0.7764 - val_auc: 0.8574 - val_loss: 0.4598\n",
      "Epoch 1981/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7653 - auc: 0.8453 - loss: 0.4793 - val_acc: 0.7781 - val_auc: 0.8573 - val_loss: 0.4597\n",
      "Epoch 1982/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7662 - auc: 0.8463 - loss: 0.4775 - val_acc: 0.7770 - val_auc: 0.8579 - val_loss: 0.4586\n",
      "Epoch 1983/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7677 - auc: 0.8454 - loss: 0.4782 - val_acc: 0.7759 - val_auc: 0.8577 - val_loss: 0.4588\n",
      "Epoch 1984/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7661 - auc: 0.8451 - loss: 0.4785 - val_acc: 0.7798 - val_auc: 0.8588 - val_loss: 0.4558\n",
      "Epoch 1985/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7679 - auc: 0.8467 - loss: 0.4772 - val_acc: 0.7789 - val_auc: 0.8576 - val_loss: 0.4588\n",
      "Epoch 1986/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7638 - auc: 0.8448 - loss: 0.4792 - val_acc: 0.7802 - val_auc: 0.8580 - val_loss: 0.4585\n",
      "Epoch 1987/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7642 - auc: 0.8443 - loss: 0.4809 - val_acc: 0.7781 - val_auc: 0.8579 - val_loss: 0.4585\n",
      "Epoch 1988/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7642 - auc: 0.8440 - loss: 0.4796 - val_acc: 0.7766 - val_auc: 0.8562 - val_loss: 0.4602\n",
      "Epoch 1989/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7663 - auc: 0.8461 - loss: 0.4773 - val_acc: 0.7828 - val_auc: 0.8578 - val_loss: 0.4598\n",
      "Epoch 1990/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7651 - auc: 0.8453 - loss: 0.4787 - val_acc: 0.7770 - val_auc: 0.8560 - val_loss: 0.4605\n",
      "Epoch 1991/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7652 - auc: 0.8464 - loss: 0.4759 - val_acc: 0.7764 - val_auc: 0.8568 - val_loss: 0.4598\n",
      "Epoch 1992/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7647 - auc: 0.8461 - loss: 0.4780 - val_acc: 0.7785 - val_auc: 0.8571 - val_loss: 0.4593\n",
      "Epoch 1993/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7648 - auc: 0.8456 - loss: 0.4777 - val_acc: 0.7794 - val_auc: 0.8588 - val_loss: 0.4587\n",
      "Epoch 1994/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7671 - auc: 0.8456 - loss: 0.4778 - val_acc: 0.7804 - val_auc: 0.8604 - val_loss: 0.4551\n",
      "Epoch 1995/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7646 - auc: 0.8449 - loss: 0.4787 - val_acc: 0.7795 - val_auc: 0.8572 - val_loss: 0.4588\n",
      "Epoch 1996/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7662 - auc: 0.8465 - loss: 0.4774 - val_acc: 0.7782 - val_auc: 0.8577 - val_loss: 0.4590\n",
      "Epoch 1997/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7654 - auc: 0.8454 - loss: 0.4785 - val_acc: 0.7756 - val_auc: 0.8564 - val_loss: 0.4603\n",
      "Epoch 1998/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7653 - auc: 0.8463 - loss: 0.4770 - val_acc: 0.7771 - val_auc: 0.8569 - val_loss: 0.4600\n",
      "Epoch 1999/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7661 - auc: 0.8464 - loss: 0.4777 - val_acc: 0.7748 - val_auc: 0.8563 - val_loss: 0.4601\n",
      "Epoch 2000/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7641 - auc: 0.8461 - loss: 0.4783 - val_acc: 0.7792 - val_auc: 0.8594 - val_loss: 0.4575\n",
      "Epoch 2001/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7660 - auc: 0.8446 - loss: 0.4804 - val_acc: 0.7791 - val_auc: 0.8588 - val_loss: 0.4572\n",
      "Epoch 2002/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7664 - auc: 0.8450 - loss: 0.4803 - val_acc: 0.7765 - val_auc: 0.8577 - val_loss: 0.4588\n",
      "Epoch 2003/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7647 - auc: 0.8448 - loss: 0.4798 - val_acc: 0.7752 - val_auc: 0.8572 - val_loss: 0.4600\n",
      "Epoch 2004/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7678 - auc: 0.8470 - loss: 0.4776 - val_acc: 0.7771 - val_auc: 0.8579 - val_loss: 0.4613\n",
      "Epoch 2005/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7643 - auc: 0.8445 - loss: 0.4800 - val_acc: 0.7758 - val_auc: 0.8561 - val_loss: 0.4599\n",
      "Epoch 2006/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7668 - auc: 0.8454 - loss: 0.4788 - val_acc: 0.7771 - val_auc: 0.8580 - val_loss: 0.4588\n",
      "Epoch 2007/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7664 - auc: 0.8462 - loss: 0.4770 - val_acc: 0.7739 - val_auc: 0.8552 - val_loss: 0.4617\n",
      "Epoch 2008/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7671 - auc: 0.8468 - loss: 0.4766 - val_acc: 0.7785 - val_auc: 0.8579 - val_loss: 0.4593\n",
      "Epoch 2009/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7650 - auc: 0.8449 - loss: 0.4786 - val_acc: 0.7771 - val_auc: 0.8575 - val_loss: 0.4577\n",
      "Epoch 2010/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7656 - auc: 0.8447 - loss: 0.4797 - val_acc: 0.7741 - val_auc: 0.8572 - val_loss: 0.4604\n",
      "Epoch 2011/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7652 - auc: 0.8451 - loss: 0.4787 - val_acc: 0.7796 - val_auc: 0.8584 - val_loss: 0.4582\n",
      "Epoch 2012/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7650 - auc: 0.8440 - loss: 0.4795 - val_acc: 0.7747 - val_auc: 0.8574 - val_loss: 0.4604\n",
      "Epoch 2013/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7673 - auc: 0.8463 - loss: 0.4768 - val_acc: 0.7766 - val_auc: 0.8572 - val_loss: 0.4592\n",
      "Epoch 2014/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7674 - auc: 0.8461 - loss: 0.4771 - val_acc: 0.7788 - val_auc: 0.8590 - val_loss: 0.4563\n",
      "Epoch 2015/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7666 - auc: 0.8464 - loss: 0.4769 - val_acc: 0.7776 - val_auc: 0.8583 - val_loss: 0.4581\n",
      "Epoch 2016/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7666 - auc: 0.8466 - loss: 0.4766 - val_acc: 0.7759 - val_auc: 0.8573 - val_loss: 0.4609\n",
      "Epoch 2017/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7655 - auc: 0.8452 - loss: 0.4789 - val_acc: 0.7765 - val_auc: 0.8580 - val_loss: 0.4589\n",
      "Epoch 2018/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7670 - auc: 0.8483 - loss: 0.4753 - val_acc: 0.7766 - val_auc: 0.8584 - val_loss: 0.4581\n",
      "Epoch 2019/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7633 - auc: 0.8448 - loss: 0.4797 - val_acc: 0.7778 - val_auc: 0.8586 - val_loss: 0.4575\n",
      "Epoch 2020/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7658 - auc: 0.8462 - loss: 0.4773 - val_acc: 0.7792 - val_auc: 0.8587 - val_loss: 0.4576\n",
      "Epoch 2021/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7653 - auc: 0.8452 - loss: 0.4795 - val_acc: 0.7790 - val_auc: 0.8593 - val_loss: 0.4576\n",
      "Epoch 2022/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7651 - auc: 0.8462 - loss: 0.4767 - val_acc: 0.7780 - val_auc: 0.8583 - val_loss: 0.4572\n",
      "Epoch 2023/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7654 - auc: 0.8463 - loss: 0.4768 - val_acc: 0.7761 - val_auc: 0.8583 - val_loss: 0.4572\n",
      "Epoch 2024/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7682 - auc: 0.8466 - loss: 0.4772 - val_acc: 0.7799 - val_auc: 0.8571 - val_loss: 0.4592\n",
      "Epoch 2025/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7644 - auc: 0.8444 - loss: 0.4800 - val_acc: 0.7767 - val_auc: 0.8566 - val_loss: 0.4607\n",
      "Epoch 2026/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7647 - auc: 0.8464 - loss: 0.4764 - val_acc: 0.7774 - val_auc: 0.8575 - val_loss: 0.4588\n",
      "Epoch 2027/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7648 - auc: 0.8464 - loss: 0.4764 - val_acc: 0.7766 - val_auc: 0.8591 - val_loss: 0.4583\n",
      "Epoch 2028/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7681 - auc: 0.8464 - loss: 0.4769 - val_acc: 0.7784 - val_auc: 0.8588 - val_loss: 0.4580\n",
      "Epoch 2029/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7654 - auc: 0.8446 - loss: 0.4804 - val_acc: 0.7808 - val_auc: 0.8583 - val_loss: 0.4569\n",
      "Epoch 2030/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7664 - auc: 0.8450 - loss: 0.4795 - val_acc: 0.7796 - val_auc: 0.8595 - val_loss: 0.4587\n",
      "Epoch 2031/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7645 - auc: 0.8452 - loss: 0.4791 - val_acc: 0.7766 - val_auc: 0.8568 - val_loss: 0.4602\n",
      "Epoch 2032/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7660 - auc: 0.8471 - loss: 0.4768 - val_acc: 0.7759 - val_auc: 0.8582 - val_loss: 0.4584\n",
      "Epoch 2033/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7672 - auc: 0.8466 - loss: 0.4761 - val_acc: 0.7782 - val_auc: 0.8575 - val_loss: 0.4586\n",
      "Epoch 2034/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7663 - auc: 0.8456 - loss: 0.4784 - val_acc: 0.7783 - val_auc: 0.8574 - val_loss: 0.4603\n",
      "Epoch 2035/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7660 - auc: 0.8444 - loss: 0.4800 - val_acc: 0.7779 - val_auc: 0.8575 - val_loss: 0.4597\n",
      "Epoch 2036/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7633 - auc: 0.8430 - loss: 0.4810 - val_acc: 0.7767 - val_auc: 0.8583 - val_loss: 0.4595\n",
      "Epoch 2037/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7667 - auc: 0.8456 - loss: 0.4786 - val_acc: 0.7778 - val_auc: 0.8581 - val_loss: 0.4591\n",
      "Epoch 2038/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7689 - auc: 0.8474 - loss: 0.4757 - val_acc: 0.7772 - val_auc: 0.8575 - val_loss: 0.4584\n",
      "Epoch 2039/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7653 - auc: 0.8445 - loss: 0.4808 - val_acc: 0.7740 - val_auc: 0.8563 - val_loss: 0.4618\n",
      "Epoch 2040/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7668 - auc: 0.8457 - loss: 0.4786 - val_acc: 0.7790 - val_auc: 0.8592 - val_loss: 0.4572\n",
      "Epoch 2041/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7661 - auc: 0.8450 - loss: 0.4797 - val_acc: 0.7779 - val_auc: 0.8586 - val_loss: 0.4572\n",
      "Epoch 2042/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7654 - auc: 0.8462 - loss: 0.4778 - val_acc: 0.7778 - val_auc: 0.8581 - val_loss: 0.4596\n",
      "Epoch 2043/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7655 - auc: 0.8461 - loss: 0.4774 - val_acc: 0.7780 - val_auc: 0.8577 - val_loss: 0.4598\n",
      "Epoch 2044/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7687 - auc: 0.8462 - loss: 0.4774 - val_acc: 0.7775 - val_auc: 0.8587 - val_loss: 0.4588\n",
      "Epoch 2045/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7641 - auc: 0.8453 - loss: 0.4796 - val_acc: 0.7776 - val_auc: 0.8590 - val_loss: 0.4588\n",
      "Epoch 2046/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7676 - auc: 0.8467 - loss: 0.4764 - val_acc: 0.7763 - val_auc: 0.8571 - val_loss: 0.4592\n",
      "Epoch 2047/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7669 - auc: 0.8464 - loss: 0.4773 - val_acc: 0.7776 - val_auc: 0.8571 - val_loss: 0.4610\n",
      "Epoch 2048/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7667 - auc: 0.8466 - loss: 0.4762 - val_acc: 0.7783 - val_auc: 0.8579 - val_loss: 0.4590\n",
      "Epoch 2049/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7657 - auc: 0.8460 - loss: 0.4786 - val_acc: 0.7800 - val_auc: 0.8582 - val_loss: 0.4585\n",
      "Epoch 2050/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7653 - auc: 0.8463 - loss: 0.4782 - val_acc: 0.7777 - val_auc: 0.8575 - val_loss: 0.4580\n",
      "Epoch 2051/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7651 - auc: 0.8448 - loss: 0.4801 - val_acc: 0.7791 - val_auc: 0.8582 - val_loss: 0.4583\n",
      "Epoch 2052/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7654 - auc: 0.8446 - loss: 0.4796 - val_acc: 0.7806 - val_auc: 0.8589 - val_loss: 0.4583\n",
      "Epoch 2053/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7649 - auc: 0.8445 - loss: 0.4794 - val_acc: 0.7782 - val_auc: 0.8585 - val_loss: 0.4596\n",
      "Epoch 2054/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7650 - auc: 0.8452 - loss: 0.4793 - val_acc: 0.7767 - val_auc: 0.8586 - val_loss: 0.4577\n",
      "Epoch 2055/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7666 - auc: 0.8466 - loss: 0.4776 - val_acc: 0.7791 - val_auc: 0.8582 - val_loss: 0.4593\n",
      "Epoch 2056/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7673 - auc: 0.8468 - loss: 0.4777 - val_acc: 0.7803 - val_auc: 0.8595 - val_loss: 0.4560\n",
      "Epoch 2057/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7688 - auc: 0.8477 - loss: 0.4772 - val_acc: 0.7816 - val_auc: 0.8590 - val_loss: 0.4564\n",
      "Epoch 2058/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7666 - auc: 0.8463 - loss: 0.4772 - val_acc: 0.7777 - val_auc: 0.8582 - val_loss: 0.4585\n",
      "Epoch 2059/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7666 - auc: 0.8464 - loss: 0.4774 - val_acc: 0.7779 - val_auc: 0.8590 - val_loss: 0.4576\n",
      "Epoch 2060/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7675 - auc: 0.8481 - loss: 0.4752 - val_acc: 0.7801 - val_auc: 0.8595 - val_loss: 0.4571\n",
      "Epoch 2061/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7671 - auc: 0.8453 - loss: 0.4788 - val_acc: 0.7808 - val_auc: 0.8590 - val_loss: 0.4574\n",
      "Epoch 2062/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7668 - auc: 0.8460 - loss: 0.4771 - val_acc: 0.7786 - val_auc: 0.8576 - val_loss: 0.4596\n",
      "Epoch 2063/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7661 - auc: 0.8454 - loss: 0.4783 - val_acc: 0.7767 - val_auc: 0.8580 - val_loss: 0.4590\n",
      "Epoch 2064/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7643 - auc: 0.8452 - loss: 0.4791 - val_acc: 0.7764 - val_auc: 0.8564 - val_loss: 0.4610\n",
      "Epoch 2065/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7689 - auc: 0.8479 - loss: 0.4753 - val_acc: 0.7766 - val_auc: 0.8581 - val_loss: 0.4577\n",
      "Epoch 2066/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7648 - auc: 0.8448 - loss: 0.4802 - val_acc: 0.7782 - val_auc: 0.8583 - val_loss: 0.4572\n",
      "Epoch 2067/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7661 - auc: 0.8471 - loss: 0.4761 - val_acc: 0.7752 - val_auc: 0.8560 - val_loss: 0.4616\n",
      "Epoch 2068/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7649 - auc: 0.8451 - loss: 0.4794 - val_acc: 0.7781 - val_auc: 0.8588 - val_loss: 0.4592\n",
      "Epoch 2069/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7648 - auc: 0.8448 - loss: 0.4784 - val_acc: 0.7792 - val_auc: 0.8578 - val_loss: 0.4584\n",
      "Epoch 2070/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7665 - auc: 0.8466 - loss: 0.4777 - val_acc: 0.7762 - val_auc: 0.8569 - val_loss: 0.4596\n",
      "Epoch 2071/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7645 - auc: 0.8452 - loss: 0.4791 - val_acc: 0.7782 - val_auc: 0.8577 - val_loss: 0.4575\n",
      "Epoch 2072/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7670 - auc: 0.8459 - loss: 0.4787 - val_acc: 0.7767 - val_auc: 0.8576 - val_loss: 0.4591\n",
      "Epoch 2073/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7644 - auc: 0.8451 - loss: 0.4800 - val_acc: 0.7759 - val_auc: 0.8576 - val_loss: 0.4600\n",
      "Epoch 2074/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7650 - auc: 0.8465 - loss: 0.4771 - val_acc: 0.7790 - val_auc: 0.8577 - val_loss: 0.4579\n",
      "Epoch 2075/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7653 - auc: 0.8456 - loss: 0.4785 - val_acc: 0.7791 - val_auc: 0.8596 - val_loss: 0.4579\n",
      "Epoch 2076/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7661 - auc: 0.8464 - loss: 0.4775 - val_acc: 0.7784 - val_auc: 0.8576 - val_loss: 0.4587\n",
      "Epoch 2077/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7680 - auc: 0.8481 - loss: 0.4751 - val_acc: 0.7754 - val_auc: 0.8568 - val_loss: 0.4597\n",
      "Epoch 2078/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7670 - auc: 0.8470 - loss: 0.4769 - val_acc: 0.7811 - val_auc: 0.8594 - val_loss: 0.4578\n",
      "Epoch 2079/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7651 - auc: 0.8462 - loss: 0.4778 - val_acc: 0.7809 - val_auc: 0.8586 - val_loss: 0.4579\n",
      "Epoch 2080/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7658 - auc: 0.8464 - loss: 0.4773 - val_acc: 0.7810 - val_auc: 0.8594 - val_loss: 0.4563\n",
      "Epoch 2081/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7678 - auc: 0.8474 - loss: 0.4761 - val_acc: 0.7815 - val_auc: 0.8602 - val_loss: 0.4541\n",
      "Epoch 2082/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7650 - auc: 0.8451 - loss: 0.4787 - val_acc: 0.7811 - val_auc: 0.8588 - val_loss: 0.4574\n",
      "Epoch 2083/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7636 - auc: 0.8444 - loss: 0.4798 - val_acc: 0.7781 - val_auc: 0.8594 - val_loss: 0.4577\n",
      "Epoch 2084/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7652 - auc: 0.8462 - loss: 0.4772 - val_acc: 0.7782 - val_auc: 0.8587 - val_loss: 0.4579\n",
      "Epoch 2085/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7653 - auc: 0.8461 - loss: 0.4776 - val_acc: 0.7754 - val_auc: 0.8582 - val_loss: 0.4578\n",
      "Epoch 2086/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7648 - auc: 0.8446 - loss: 0.4792 - val_acc: 0.7755 - val_auc: 0.8574 - val_loss: 0.4599\n",
      "Epoch 2087/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7661 - auc: 0.8455 - loss: 0.4779 - val_acc: 0.7776 - val_auc: 0.8589 - val_loss: 0.4569\n",
      "Epoch 2088/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7663 - auc: 0.8467 - loss: 0.4774 - val_acc: 0.7786 - val_auc: 0.8573 - val_loss: 0.4604\n",
      "Epoch 2089/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7657 - auc: 0.8468 - loss: 0.4767 - val_acc: 0.7806 - val_auc: 0.8599 - val_loss: 0.4550\n",
      "Epoch 2090/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7646 - auc: 0.8464 - loss: 0.4776 - val_acc: 0.7792 - val_auc: 0.8585 - val_loss: 0.4571\n",
      "Epoch 2091/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7653 - auc: 0.8462 - loss: 0.4769 - val_acc: 0.7776 - val_auc: 0.8573 - val_loss: 0.4589\n",
      "Epoch 2092/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7649 - auc: 0.8456 - loss: 0.4782 - val_acc: 0.7810 - val_auc: 0.8593 - val_loss: 0.4567\n",
      "Epoch 2093/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7655 - auc: 0.8452 - loss: 0.4782 - val_acc: 0.7775 - val_auc: 0.8565 - val_loss: 0.4592\n",
      "Epoch 2094/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7667 - auc: 0.8463 - loss: 0.4775 - val_acc: 0.7790 - val_auc: 0.8586 - val_loss: 0.4584\n",
      "Epoch 2095/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7689 - auc: 0.8484 - loss: 0.4744 - val_acc: 0.7775 - val_auc: 0.8590 - val_loss: 0.4583\n",
      "Epoch 2096/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7673 - auc: 0.8469 - loss: 0.4759 - val_acc: 0.7757 - val_auc: 0.8577 - val_loss: 0.4587\n",
      "Epoch 2097/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7678 - auc: 0.8470 - loss: 0.4767 - val_acc: 0.7797 - val_auc: 0.8587 - val_loss: 0.4567\n",
      "Epoch 2098/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7656 - auc: 0.8456 - loss: 0.4786 - val_acc: 0.7788 - val_auc: 0.8594 - val_loss: 0.4576\n",
      "Epoch 2099/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7662 - auc: 0.8459 - loss: 0.4780 - val_acc: 0.7797 - val_auc: 0.8583 - val_loss: 0.4581\n",
      "Epoch 2100/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7663 - auc: 0.8464 - loss: 0.4776 - val_acc: 0.7805 - val_auc: 0.8570 - val_loss: 0.4590\n",
      "Epoch 2101/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7655 - auc: 0.8447 - loss: 0.4788 - val_acc: 0.7796 - val_auc: 0.8586 - val_loss: 0.4577\n",
      "Epoch 2102/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7671 - auc: 0.8464 - loss: 0.4775 - val_acc: 0.7766 - val_auc: 0.8581 - val_loss: 0.4594\n",
      "Epoch 2103/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7680 - auc: 0.8477 - loss: 0.4764 - val_acc: 0.7775 - val_auc: 0.8590 - val_loss: 0.4574\n",
      "Epoch 2104/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7657 - auc: 0.8453 - loss: 0.4783 - val_acc: 0.7804 - val_auc: 0.8596 - val_loss: 0.4563\n",
      "Epoch 2105/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7626 - auc: 0.8445 - loss: 0.4796 - val_acc: 0.7774 - val_auc: 0.8582 - val_loss: 0.4584\n",
      "Epoch 2106/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7673 - auc: 0.8469 - loss: 0.4757 - val_acc: 0.7786 - val_auc: 0.8589 - val_loss: 0.4584\n",
      "Epoch 2107/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7682 - auc: 0.8478 - loss: 0.4750 - val_acc: 0.7802 - val_auc: 0.8590 - val_loss: 0.4565\n",
      "Epoch 2108/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7657 - auc: 0.8446 - loss: 0.4800 - val_acc: 0.7790 - val_auc: 0.8593 - val_loss: 0.4585\n",
      "Epoch 2109/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7682 - auc: 0.8469 - loss: 0.4773 - val_acc: 0.7766 - val_auc: 0.8579 - val_loss: 0.4593\n",
      "Epoch 2110/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7681 - auc: 0.8477 - loss: 0.4764 - val_acc: 0.7778 - val_auc: 0.8582 - val_loss: 0.4587\n",
      "Epoch 2111/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7659 - auc: 0.8457 - loss: 0.4780 - val_acc: 0.7784 - val_auc: 0.8582 - val_loss: 0.4588\n",
      "Epoch 2112/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7657 - auc: 0.8457 - loss: 0.4774 - val_acc: 0.7834 - val_auc: 0.8599 - val_loss: 0.4547\n",
      "Epoch 2113/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7651 - auc: 0.8455 - loss: 0.4777 - val_acc: 0.7793 - val_auc: 0.8595 - val_loss: 0.4567\n",
      "Epoch 2114/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7673 - auc: 0.8470 - loss: 0.4761 - val_acc: 0.7764 - val_auc: 0.8576 - val_loss: 0.4580\n",
      "Epoch 2115/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7681 - auc: 0.8466 - loss: 0.4766 - val_acc: 0.7785 - val_auc: 0.8580 - val_loss: 0.4582\n",
      "Epoch 2116/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7671 - auc: 0.8457 - loss: 0.4791 - val_acc: 0.7760 - val_auc: 0.8582 - val_loss: 0.4576\n",
      "Epoch 2117/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7678 - auc: 0.8472 - loss: 0.4761 - val_acc: 0.7779 - val_auc: 0.8591 - val_loss: 0.4580\n",
      "Epoch 2118/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7658 - auc: 0.8453 - loss: 0.4787 - val_acc: 0.7776 - val_auc: 0.8586 - val_loss: 0.4574\n",
      "Epoch 2119/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7685 - auc: 0.8471 - loss: 0.4763 - val_acc: 0.7786 - val_auc: 0.8583 - val_loss: 0.4571\n",
      "Epoch 2120/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7668 - auc: 0.8460 - loss: 0.4779 - val_acc: 0.7786 - val_auc: 0.8598 - val_loss: 0.4559\n",
      "Epoch 2121/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7656 - auc: 0.8465 - loss: 0.4778 - val_acc: 0.7803 - val_auc: 0.8601 - val_loss: 0.4559\n",
      "Epoch 2122/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7658 - auc: 0.8451 - loss: 0.4796 - val_acc: 0.7784 - val_auc: 0.8590 - val_loss: 0.4578\n",
      "Epoch 2123/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7682 - auc: 0.8463 - loss: 0.4776 - val_acc: 0.7761 - val_auc: 0.8574 - val_loss: 0.4592\n",
      "Epoch 2124/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7681 - auc: 0.8474 - loss: 0.4757 - val_acc: 0.7792 - val_auc: 0.8578 - val_loss: 0.4584\n",
      "Epoch 2125/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7685 - auc: 0.8481 - loss: 0.4752 - val_acc: 0.7773 - val_auc: 0.8569 - val_loss: 0.4600\n",
      "Epoch 2126/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7695 - auc: 0.8486 - loss: 0.4742 - val_acc: 0.7819 - val_auc: 0.8593 - val_loss: 0.4575\n",
      "Epoch 2127/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7649 - auc: 0.8467 - loss: 0.4762 - val_acc: 0.7768 - val_auc: 0.8582 - val_loss: 0.4598\n",
      "Epoch 2128/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7650 - auc: 0.8449 - loss: 0.4796 - val_acc: 0.7799 - val_auc: 0.8588 - val_loss: 0.4575\n",
      "Epoch 2129/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7689 - auc: 0.8466 - loss: 0.4766 - val_acc: 0.7820 - val_auc: 0.8605 - val_loss: 0.4555\n",
      "Epoch 2130/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7688 - auc: 0.8475 - loss: 0.4751 - val_acc: 0.7808 - val_auc: 0.8593 - val_loss: 0.4568\n",
      "Epoch 2131/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7678 - auc: 0.8467 - loss: 0.4764 - val_acc: 0.7780 - val_auc: 0.8595 - val_loss: 0.4576\n",
      "Epoch 2132/7000\n",
      "106/106 - 2s - 15ms/step - acc: 0.7690 - auc: 0.8467 - loss: 0.4770 - val_acc: 0.7791 - val_auc: 0.8587 - val_loss: 0.4580\n",
      "Epoch 2133/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7671 - auc: 0.8460 - loss: 0.4784 - val_acc: 0.7800 - val_auc: 0.8579 - val_loss: 0.4596\n",
      "Epoch 2134/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7641 - auc: 0.8459 - loss: 0.4774 - val_acc: 0.7793 - val_auc: 0.8583 - val_loss: 0.4578\n",
      "Epoch 2135/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7662 - auc: 0.8455 - loss: 0.4785 - val_acc: 0.7784 - val_auc: 0.8590 - val_loss: 0.4575\n",
      "Epoch 2136/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7691 - auc: 0.8483 - loss: 0.4744 - val_acc: 0.7791 - val_auc: 0.8597 - val_loss: 0.4565\n",
      "Epoch 2137/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7666 - auc: 0.8461 - loss: 0.4776 - val_acc: 0.7803 - val_auc: 0.8602 - val_loss: 0.4553\n",
      "Epoch 2138/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7668 - auc: 0.8467 - loss: 0.4776 - val_acc: 0.7787 - val_auc: 0.8582 - val_loss: 0.4572\n",
      "Epoch 2139/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7663 - auc: 0.8473 - loss: 0.4756 - val_acc: 0.7776 - val_auc: 0.8582 - val_loss: 0.4584\n",
      "Epoch 2140/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7674 - auc: 0.8469 - loss: 0.4762 - val_acc: 0.7781 - val_auc: 0.8584 - val_loss: 0.4580\n",
      "Epoch 2141/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7668 - auc: 0.8468 - loss: 0.4769 - val_acc: 0.7782 - val_auc: 0.8596 - val_loss: 0.4586\n",
      "Epoch 2142/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7683 - auc: 0.8486 - loss: 0.4752 - val_acc: 0.7774 - val_auc: 0.8583 - val_loss: 0.4577\n",
      "Epoch 2143/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7647 - auc: 0.8444 - loss: 0.4794 - val_acc: 0.7780 - val_auc: 0.8592 - val_loss: 0.4590\n",
      "Epoch 2144/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7662 - auc: 0.8469 - loss: 0.4757 - val_acc: 0.7786 - val_auc: 0.8595 - val_loss: 0.4573\n",
      "Epoch 2145/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7676 - auc: 0.8460 - loss: 0.4781 - val_acc: 0.7788 - val_auc: 0.8575 - val_loss: 0.4581\n",
      "Epoch 2146/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7667 - auc: 0.8464 - loss: 0.4770 - val_acc: 0.7756 - val_auc: 0.8559 - val_loss: 0.4633\n",
      "Epoch 2147/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7680 - auc: 0.8469 - loss: 0.4776 - val_acc: 0.7806 - val_auc: 0.8583 - val_loss: 0.4575\n",
      "Epoch 2148/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7652 - auc: 0.8461 - loss: 0.4773 - val_acc: 0.7792 - val_auc: 0.8579 - val_loss: 0.4576\n",
      "Epoch 2149/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7661 - auc: 0.8446 - loss: 0.4805 - val_acc: 0.7783 - val_auc: 0.8582 - val_loss: 0.4588\n",
      "Epoch 2150/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7687 - auc: 0.8474 - loss: 0.4757 - val_acc: 0.7766 - val_auc: 0.8574 - val_loss: 0.4599\n",
      "Epoch 2151/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7651 - auc: 0.8455 - loss: 0.4780 - val_acc: 0.7770 - val_auc: 0.8579 - val_loss: 0.4600\n",
      "Epoch 2152/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7672 - auc: 0.8475 - loss: 0.4748 - val_acc: 0.7805 - val_auc: 0.8596 - val_loss: 0.4568\n",
      "Epoch 2153/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7673 - auc: 0.8477 - loss: 0.4750 - val_acc: 0.7830 - val_auc: 0.8593 - val_loss: 0.4565\n",
      "Epoch 2154/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7685 - auc: 0.8486 - loss: 0.4747 - val_acc: 0.7790 - val_auc: 0.8590 - val_loss: 0.4574\n",
      "Epoch 2155/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7675 - auc: 0.8474 - loss: 0.4755 - val_acc: 0.7786 - val_auc: 0.8591 - val_loss: 0.4575\n",
      "Epoch 2156/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7669 - auc: 0.8490 - loss: 0.4737 - val_acc: 0.7807 - val_auc: 0.8590 - val_loss: 0.4554\n",
      "Epoch 2157/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7677 - auc: 0.8470 - loss: 0.4766 - val_acc: 0.7784 - val_auc: 0.8583 - val_loss: 0.4573\n",
      "Epoch 2158/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7675 - auc: 0.8474 - loss: 0.4769 - val_acc: 0.7799 - val_auc: 0.8600 - val_loss: 0.4568\n",
      "Epoch 2159/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7680 - auc: 0.8471 - loss: 0.4773 - val_acc: 0.7784 - val_auc: 0.8580 - val_loss: 0.4587\n",
      "Epoch 2160/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7669 - auc: 0.8474 - loss: 0.4757 - val_acc: 0.7792 - val_auc: 0.8585 - val_loss: 0.4566\n",
      "Epoch 2161/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7667 - auc: 0.8468 - loss: 0.4759 - val_acc: 0.7791 - val_auc: 0.8604 - val_loss: 0.4567\n",
      "Epoch 2162/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7678 - auc: 0.8479 - loss: 0.4753 - val_acc: 0.7791 - val_auc: 0.8597 - val_loss: 0.4564\n",
      "Epoch 2163/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7682 - auc: 0.8466 - loss: 0.4775 - val_acc: 0.7800 - val_auc: 0.8595 - val_loss: 0.4555\n",
      "Epoch 2164/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7680 - auc: 0.8489 - loss: 0.4740 - val_acc: 0.7806 - val_auc: 0.8592 - val_loss: 0.4569\n",
      "Epoch 2165/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7671 - auc: 0.8474 - loss: 0.4763 - val_acc: 0.7821 - val_auc: 0.8608 - val_loss: 0.4544\n",
      "Epoch 2166/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7655 - auc: 0.8461 - loss: 0.4775 - val_acc: 0.7777 - val_auc: 0.8589 - val_loss: 0.4584\n",
      "Epoch 2167/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7674 - auc: 0.8477 - loss: 0.4760 - val_acc: 0.7779 - val_auc: 0.8562 - val_loss: 0.4615\n",
      "Epoch 2168/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7663 - auc: 0.8461 - loss: 0.4778 - val_acc: 0.7765 - val_auc: 0.8584 - val_loss: 0.4591\n",
      "Epoch 2169/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7678 - auc: 0.8476 - loss: 0.4755 - val_acc: 0.7810 - val_auc: 0.8610 - val_loss: 0.4546\n",
      "Epoch 2170/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7683 - auc: 0.8480 - loss: 0.4747 - val_acc: 0.7835 - val_auc: 0.8612 - val_loss: 0.4545\n",
      "Epoch 2171/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7672 - auc: 0.8471 - loss: 0.4758 - val_acc: 0.7807 - val_auc: 0.8597 - val_loss: 0.4553\n",
      "Epoch 2172/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7673 - auc: 0.8467 - loss: 0.4765 - val_acc: 0.7816 - val_auc: 0.8600 - val_loss: 0.4558\n",
      "Epoch 2173/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7646 - auc: 0.8462 - loss: 0.4770 - val_acc: 0.7789 - val_auc: 0.8592 - val_loss: 0.4575\n",
      "Epoch 2174/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7660 - auc: 0.8467 - loss: 0.4770 - val_acc: 0.7816 - val_auc: 0.8593 - val_loss: 0.4572\n",
      "Epoch 2175/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7688 - auc: 0.8476 - loss: 0.4759 - val_acc: 0.7785 - val_auc: 0.8590 - val_loss: 0.4578\n",
      "Epoch 2176/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7643 - auc: 0.8458 - loss: 0.4789 - val_acc: 0.7801 - val_auc: 0.8598 - val_loss: 0.4562\n",
      "Epoch 2177/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7670 - auc: 0.8460 - loss: 0.4771 - val_acc: 0.7777 - val_auc: 0.8585 - val_loss: 0.4597\n",
      "Epoch 2178/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7686 - auc: 0.8480 - loss: 0.4751 - val_acc: 0.7807 - val_auc: 0.8595 - val_loss: 0.4579\n",
      "Epoch 2179/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7667 - auc: 0.8469 - loss: 0.4775 - val_acc: 0.7804 - val_auc: 0.8579 - val_loss: 0.4589\n",
      "Epoch 2180/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7665 - auc: 0.8456 - loss: 0.4790 - val_acc: 0.7809 - val_auc: 0.8594 - val_loss: 0.4569\n",
      "Epoch 2181/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7689 - auc: 0.8471 - loss: 0.4774 - val_acc: 0.7788 - val_auc: 0.8594 - val_loss: 0.4570\n",
      "Epoch 2182/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7663 - auc: 0.8469 - loss: 0.4759 - val_acc: 0.7811 - val_auc: 0.8599 - val_loss: 0.4559\n",
      "Epoch 2183/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7691 - auc: 0.8485 - loss: 0.4745 - val_acc: 0.7819 - val_auc: 0.8598 - val_loss: 0.4553\n",
      "Epoch 2184/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7676 - auc: 0.8464 - loss: 0.4768 - val_acc: 0.7794 - val_auc: 0.8593 - val_loss: 0.4576\n",
      "Epoch 2185/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7651 - auc: 0.8455 - loss: 0.4778 - val_acc: 0.7825 - val_auc: 0.8607 - val_loss: 0.4551\n",
      "Epoch 2186/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7676 - auc: 0.8471 - loss: 0.4753 - val_acc: 0.7814 - val_auc: 0.8607 - val_loss: 0.4545\n",
      "Epoch 2187/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7673 - auc: 0.8473 - loss: 0.4761 - val_acc: 0.7776 - val_auc: 0.8581 - val_loss: 0.4585\n",
      "Epoch 2188/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7674 - auc: 0.8467 - loss: 0.4773 - val_acc: 0.7781 - val_auc: 0.8584 - val_loss: 0.4584\n",
      "Epoch 2189/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7671 - auc: 0.8484 - loss: 0.4739 - val_acc: 0.7786 - val_auc: 0.8598 - val_loss: 0.4566\n",
      "Epoch 2190/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7660 - auc: 0.8464 - loss: 0.4780 - val_acc: 0.7797 - val_auc: 0.8606 - val_loss: 0.4565\n",
      "Epoch 2191/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7644 - auc: 0.8460 - loss: 0.4775 - val_acc: 0.7801 - val_auc: 0.8585 - val_loss: 0.4578\n",
      "Epoch 2192/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7668 - auc: 0.8469 - loss: 0.4769 - val_acc: 0.7787 - val_auc: 0.8594 - val_loss: 0.4568\n",
      "Epoch 2193/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7667 - auc: 0.8465 - loss: 0.4776 - val_acc: 0.7803 - val_auc: 0.8584 - val_loss: 0.4580\n",
      "Epoch 2194/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7676 - auc: 0.8473 - loss: 0.4765 - val_acc: 0.7779 - val_auc: 0.8601 - val_loss: 0.4582\n",
      "Epoch 2195/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7655 - auc: 0.8456 - loss: 0.4774 - val_acc: 0.7811 - val_auc: 0.8593 - val_loss: 0.4562\n",
      "Epoch 2196/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7673 - auc: 0.8465 - loss: 0.4768 - val_acc: 0.7798 - val_auc: 0.8595 - val_loss: 0.4564\n",
      "Epoch 2197/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7698 - auc: 0.8484 - loss: 0.4738 - val_acc: 0.7814 - val_auc: 0.8587 - val_loss: 0.4587\n",
      "Epoch 2198/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7677 - auc: 0.8473 - loss: 0.4748 - val_acc: 0.7804 - val_auc: 0.8600 - val_loss: 0.4572\n",
      "Epoch 2199/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7671 - auc: 0.8471 - loss: 0.4761 - val_acc: 0.7780 - val_auc: 0.8588 - val_loss: 0.4595\n",
      "Epoch 2200/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7664 - auc: 0.8469 - loss: 0.4768 - val_acc: 0.7787 - val_auc: 0.8603 - val_loss: 0.4586\n",
      "Epoch 2201/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7684 - auc: 0.8485 - loss: 0.4741 - val_acc: 0.7786 - val_auc: 0.8591 - val_loss: 0.4573\n",
      "Epoch 2202/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7675 - auc: 0.8479 - loss: 0.4754 - val_acc: 0.7830 - val_auc: 0.8595 - val_loss: 0.4575\n",
      "Epoch 2203/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7678 - auc: 0.8479 - loss: 0.4762 - val_acc: 0.7806 - val_auc: 0.8602 - val_loss: 0.4565\n",
      "Epoch 2204/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7674 - auc: 0.8473 - loss: 0.4765 - val_acc: 0.7811 - val_auc: 0.8610 - val_loss: 0.4550\n",
      "Epoch 2205/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7661 - auc: 0.8460 - loss: 0.4780 - val_acc: 0.7788 - val_auc: 0.8591 - val_loss: 0.4577\n",
      "Epoch 2206/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7672 - auc: 0.8473 - loss: 0.4760 - val_acc: 0.7814 - val_auc: 0.8593 - val_loss: 0.4562\n",
      "Epoch 2207/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7688 - auc: 0.8489 - loss: 0.4742 - val_acc: 0.7766 - val_auc: 0.8582 - val_loss: 0.4597\n",
      "Epoch 2208/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7687 - auc: 0.8479 - loss: 0.4749 - val_acc: 0.7805 - val_auc: 0.8610 - val_loss: 0.4548\n",
      "Epoch 2209/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7685 - auc: 0.8470 - loss: 0.4758 - val_acc: 0.7823 - val_auc: 0.8610 - val_loss: 0.4552\n",
      "Epoch 2210/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7680 - auc: 0.8475 - loss: 0.4763 - val_acc: 0.7804 - val_auc: 0.8601 - val_loss: 0.4548\n",
      "Epoch 2211/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7692 - auc: 0.8487 - loss: 0.4744 - val_acc: 0.7806 - val_auc: 0.8599 - val_loss: 0.4571\n",
      "Epoch 2212/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7673 - auc: 0.8469 - loss: 0.4769 - val_acc: 0.7812 - val_auc: 0.8590 - val_loss: 0.4578\n",
      "Epoch 2213/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7691 - auc: 0.8479 - loss: 0.4740 - val_acc: 0.7807 - val_auc: 0.8601 - val_loss: 0.4565\n",
      "Epoch 2214/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7705 - auc: 0.8488 - loss: 0.4740 - val_acc: 0.7797 - val_auc: 0.8608 - val_loss: 0.4564\n",
      "Epoch 2215/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7684 - auc: 0.8479 - loss: 0.4746 - val_acc: 0.7791 - val_auc: 0.8588 - val_loss: 0.4585\n",
      "Epoch 2216/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7666 - auc: 0.8463 - loss: 0.4776 - val_acc: 0.7783 - val_auc: 0.8583 - val_loss: 0.4587\n",
      "Epoch 2217/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7663 - auc: 0.8472 - loss: 0.4754 - val_acc: 0.7792 - val_auc: 0.8582 - val_loss: 0.4572\n",
      "Epoch 2218/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7662 - auc: 0.8478 - loss: 0.4762 - val_acc: 0.7809 - val_auc: 0.8597 - val_loss: 0.4563\n",
      "Epoch 2219/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7681 - auc: 0.8480 - loss: 0.4751 - val_acc: 0.7776 - val_auc: 0.8595 - val_loss: 0.4572\n",
      "Epoch 2220/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7684 - auc: 0.8477 - loss: 0.4766 - val_acc: 0.7806 - val_auc: 0.8601 - val_loss: 0.4556\n",
      "Epoch 2221/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7690 - auc: 0.8479 - loss: 0.4763 - val_acc: 0.7814 - val_auc: 0.8602 - val_loss: 0.4560\n",
      "Epoch 2222/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7674 - auc: 0.8492 - loss: 0.4742 - val_acc: 0.7809 - val_auc: 0.8601 - val_loss: 0.4554\n",
      "Epoch 2223/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7676 - auc: 0.8476 - loss: 0.4766 - val_acc: 0.7827 - val_auc: 0.8602 - val_loss: 0.4554\n",
      "Epoch 2224/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7654 - auc: 0.8468 - loss: 0.4770 - val_acc: 0.7812 - val_auc: 0.8585 - val_loss: 0.4571\n",
      "Epoch 2225/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7659 - auc: 0.8463 - loss: 0.4782 - val_acc: 0.7802 - val_auc: 0.8593 - val_loss: 0.4559\n",
      "Epoch 2226/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7684 - auc: 0.8475 - loss: 0.4760 - val_acc: 0.7834 - val_auc: 0.8600 - val_loss: 0.4558\n",
      "Epoch 2227/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7676 - auc: 0.8475 - loss: 0.4761 - val_acc: 0.7801 - val_auc: 0.8597 - val_loss: 0.4566\n",
      "Epoch 2228/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7675 - auc: 0.8470 - loss: 0.4767 - val_acc: 0.7803 - val_auc: 0.8607 - val_loss: 0.4568\n",
      "Epoch 2229/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7658 - auc: 0.8470 - loss: 0.4765 - val_acc: 0.7801 - val_auc: 0.8588 - val_loss: 0.4573\n",
      "Epoch 2230/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7672 - auc: 0.8471 - loss: 0.4762 - val_acc: 0.7796 - val_auc: 0.8601 - val_loss: 0.4568\n",
      "Epoch 2231/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7665 - auc: 0.8466 - loss: 0.4765 - val_acc: 0.7801 - val_auc: 0.8590 - val_loss: 0.4562\n",
      "Epoch 2232/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7674 - auc: 0.8492 - loss: 0.4731 - val_acc: 0.7828 - val_auc: 0.8603 - val_loss: 0.4551\n",
      "Epoch 2233/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7672 - auc: 0.8482 - loss: 0.4743 - val_acc: 0.7808 - val_auc: 0.8596 - val_loss: 0.4549\n",
      "Epoch 2234/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7672 - auc: 0.8473 - loss: 0.4759 - val_acc: 0.7812 - val_auc: 0.8585 - val_loss: 0.4581\n",
      "Epoch 2235/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7688 - auc: 0.8468 - loss: 0.4772 - val_acc: 0.7785 - val_auc: 0.8588 - val_loss: 0.4583\n",
      "Epoch 2236/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7694 - auc: 0.8483 - loss: 0.4749 - val_acc: 0.7813 - val_auc: 0.8595 - val_loss: 0.4556\n",
      "Epoch 2237/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7674 - auc: 0.8476 - loss: 0.4757 - val_acc: 0.7813 - val_auc: 0.8601 - val_loss: 0.4548\n",
      "Epoch 2238/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7684 - auc: 0.8480 - loss: 0.4751 - val_acc: 0.7793 - val_auc: 0.8586 - val_loss: 0.4584\n",
      "Epoch 2239/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7672 - auc: 0.8474 - loss: 0.4754 - val_acc: 0.7749 - val_auc: 0.8583 - val_loss: 0.4567\n",
      "Epoch 2240/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7693 - auc: 0.8490 - loss: 0.4735 - val_acc: 0.7788 - val_auc: 0.8596 - val_loss: 0.4562\n",
      "Epoch 2241/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7681 - auc: 0.8477 - loss: 0.4753 - val_acc: 0.7789 - val_auc: 0.8593 - val_loss: 0.4555\n",
      "Epoch 2242/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7681 - auc: 0.8475 - loss: 0.4763 - val_acc: 0.7803 - val_auc: 0.8600 - val_loss: 0.4551\n",
      "Epoch 2243/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7664 - auc: 0.8460 - loss: 0.4779 - val_acc: 0.7770 - val_auc: 0.8577 - val_loss: 0.4587\n",
      "Epoch 2244/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7666 - auc: 0.8468 - loss: 0.4765 - val_acc: 0.7785 - val_auc: 0.8582 - val_loss: 0.4573\n",
      "Epoch 2245/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7676 - auc: 0.8482 - loss: 0.4757 - val_acc: 0.7810 - val_auc: 0.8595 - val_loss: 0.4575\n",
      "Epoch 2246/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7685 - auc: 0.8474 - loss: 0.4769 - val_acc: 0.7818 - val_auc: 0.8591 - val_loss: 0.4567\n",
      "Epoch 2247/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7675 - auc: 0.8479 - loss: 0.4757 - val_acc: 0.7761 - val_auc: 0.8577 - val_loss: 0.4610\n",
      "Epoch 2248/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7677 - auc: 0.8476 - loss: 0.4747 - val_acc: 0.7823 - val_auc: 0.8606 - val_loss: 0.4543\n",
      "Epoch 2249/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7690 - auc: 0.8476 - loss: 0.4757 - val_acc: 0.7807 - val_auc: 0.8593 - val_loss: 0.4581\n",
      "Epoch 2250/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7677 - auc: 0.8469 - loss: 0.4765 - val_acc: 0.7789 - val_auc: 0.8601 - val_loss: 0.4571\n",
      "Epoch 2251/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7678 - auc: 0.8475 - loss: 0.4772 - val_acc: 0.7802 - val_auc: 0.8605 - val_loss: 0.4568\n",
      "Epoch 2252/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7656 - auc: 0.8476 - loss: 0.4753 - val_acc: 0.7807 - val_auc: 0.8603 - val_loss: 0.4556\n",
      "Epoch 2253/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7692 - auc: 0.8487 - loss: 0.4744 - val_acc: 0.7825 - val_auc: 0.8600 - val_loss: 0.4551\n",
      "Epoch 2254/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7678 - auc: 0.8483 - loss: 0.4747 - val_acc: 0.7796 - val_auc: 0.8595 - val_loss: 0.4567\n",
      "Epoch 2255/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7686 - auc: 0.8488 - loss: 0.4740 - val_acc: 0.7816 - val_auc: 0.8596 - val_loss: 0.4559\n",
      "Epoch 2256/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7694 - auc: 0.8494 - loss: 0.4739 - val_acc: 0.7787 - val_auc: 0.8597 - val_loss: 0.4596\n",
      "Epoch 2257/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7665 - auc: 0.8467 - loss: 0.4762 - val_acc: 0.7799 - val_auc: 0.8601 - val_loss: 0.4560\n",
      "Epoch 2258/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7659 - auc: 0.8474 - loss: 0.4772 - val_acc: 0.7836 - val_auc: 0.8601 - val_loss: 0.4553\n",
      "Epoch 2259/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7688 - auc: 0.8484 - loss: 0.4742 - val_acc: 0.7807 - val_auc: 0.8592 - val_loss: 0.4570\n",
      "Epoch 2260/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7695 - auc: 0.8480 - loss: 0.4751 - val_acc: 0.7800 - val_auc: 0.8592 - val_loss: 0.4560\n",
      "Epoch 2261/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7701 - auc: 0.8479 - loss: 0.4765 - val_acc: 0.7791 - val_auc: 0.8597 - val_loss: 0.4562\n",
      "Epoch 2262/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7673 - auc: 0.8473 - loss: 0.4757 - val_acc: 0.7803 - val_auc: 0.8591 - val_loss: 0.4585\n",
      "Epoch 2263/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7683 - auc: 0.8479 - loss: 0.4762 - val_acc: 0.7822 - val_auc: 0.8603 - val_loss: 0.4568\n",
      "Epoch 2264/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7682 - auc: 0.8470 - loss: 0.4764 - val_acc: 0.7824 - val_auc: 0.8599 - val_loss: 0.4567\n",
      "Epoch 2265/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7689 - auc: 0.8483 - loss: 0.4751 - val_acc: 0.7802 - val_auc: 0.8596 - val_loss: 0.4567\n",
      "Epoch 2266/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7701 - auc: 0.8485 - loss: 0.4745 - val_acc: 0.7809 - val_auc: 0.8603 - val_loss: 0.4551\n",
      "Epoch 2267/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7690 - auc: 0.8473 - loss: 0.4761 - val_acc: 0.7811 - val_auc: 0.8608 - val_loss: 0.4549\n",
      "Epoch 2268/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7666 - auc: 0.8473 - loss: 0.4757 - val_acc: 0.7797 - val_auc: 0.8606 - val_loss: 0.4554\n",
      "Epoch 2269/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7652 - auc: 0.8457 - loss: 0.4786 - val_acc: 0.7785 - val_auc: 0.8591 - val_loss: 0.4567\n",
      "Epoch 2270/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7686 - auc: 0.8478 - loss: 0.4749 - val_acc: 0.7791 - val_auc: 0.8583 - val_loss: 0.4582\n",
      "Epoch 2271/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7687 - auc: 0.8479 - loss: 0.4757 - val_acc: 0.7792 - val_auc: 0.8599 - val_loss: 0.4578\n",
      "Epoch 2272/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7684 - auc: 0.8472 - loss: 0.4757 - val_acc: 0.7809 - val_auc: 0.8597 - val_loss: 0.4553\n",
      "Epoch 2273/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7694 - auc: 0.8483 - loss: 0.4749 - val_acc: 0.7817 - val_auc: 0.8606 - val_loss: 0.4543\n",
      "Epoch 2274/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7683 - auc: 0.8471 - loss: 0.4763 - val_acc: 0.7820 - val_auc: 0.8602 - val_loss: 0.4552\n",
      "Epoch 2275/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7700 - auc: 0.8496 - loss: 0.4732 - val_acc: 0.7794 - val_auc: 0.8587 - val_loss: 0.4581\n",
      "Epoch 2276/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7691 - auc: 0.8491 - loss: 0.4744 - val_acc: 0.7767 - val_auc: 0.8591 - val_loss: 0.4567\n",
      "Epoch 2277/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7683 - auc: 0.8472 - loss: 0.4756 - val_acc: 0.7822 - val_auc: 0.8606 - val_loss: 0.4539\n",
      "Epoch 2278/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7669 - auc: 0.8469 - loss: 0.4763 - val_acc: 0.7784 - val_auc: 0.8588 - val_loss: 0.4565\n",
      "Epoch 2279/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7674 - auc: 0.8480 - loss: 0.4750 - val_acc: 0.7797 - val_auc: 0.8594 - val_loss: 0.4577\n",
      "Epoch 2280/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7686 - auc: 0.8472 - loss: 0.4760 - val_acc: 0.7804 - val_auc: 0.8596 - val_loss: 0.4567\n",
      "Epoch 2281/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7704 - auc: 0.8489 - loss: 0.4741 - val_acc: 0.7791 - val_auc: 0.8574 - val_loss: 0.4592\n",
      "Epoch 2282/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7674 - auc: 0.8482 - loss: 0.4751 - val_acc: 0.7825 - val_auc: 0.8600 - val_loss: 0.4550\n",
      "Epoch 2283/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7677 - auc: 0.8484 - loss: 0.4740 - val_acc: 0.7831 - val_auc: 0.8601 - val_loss: 0.4557\n",
      "Epoch 2284/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7666 - auc: 0.8460 - loss: 0.4770 - val_acc: 0.7773 - val_auc: 0.8581 - val_loss: 0.4580\n",
      "Epoch 2285/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7674 - auc: 0.8468 - loss: 0.4778 - val_acc: 0.7794 - val_auc: 0.8594 - val_loss: 0.4579\n",
      "Epoch 2286/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7681 - auc: 0.8474 - loss: 0.4766 - val_acc: 0.7827 - val_auc: 0.8604 - val_loss: 0.4570\n",
      "Epoch 2287/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7674 - auc: 0.8481 - loss: 0.4752 - val_acc: 0.7789 - val_auc: 0.8582 - val_loss: 0.4584\n",
      "Epoch 2288/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7693 - auc: 0.8480 - loss: 0.4753 - val_acc: 0.7844 - val_auc: 0.8613 - val_loss: 0.4533\n",
      "Epoch 2289/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7675 - auc: 0.8479 - loss: 0.4760 - val_acc: 0.7770 - val_auc: 0.8596 - val_loss: 0.4562\n",
      "Epoch 2290/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7704 - auc: 0.8483 - loss: 0.4756 - val_acc: 0.7792 - val_auc: 0.8589 - val_loss: 0.4576\n",
      "Epoch 2291/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7695 - auc: 0.8486 - loss: 0.4742 - val_acc: 0.7831 - val_auc: 0.8613 - val_loss: 0.4545\n",
      "Epoch 2292/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7676 - auc: 0.8476 - loss: 0.4746 - val_acc: 0.7799 - val_auc: 0.8602 - val_loss: 0.4551\n",
      "Epoch 2293/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7671 - auc: 0.8480 - loss: 0.4753 - val_acc: 0.7798 - val_auc: 0.8594 - val_loss: 0.4563\n",
      "Epoch 2294/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7687 - auc: 0.8490 - loss: 0.4736 - val_acc: 0.7841 - val_auc: 0.8607 - val_loss: 0.4546\n",
      "Epoch 2295/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7674 - auc: 0.8480 - loss: 0.4741 - val_acc: 0.7832 - val_auc: 0.8602 - val_loss: 0.4552\n",
      "Epoch 2296/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7688 - auc: 0.8469 - loss: 0.4775 - val_acc: 0.7802 - val_auc: 0.8599 - val_loss: 0.4560\n",
      "Epoch 2297/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7674 - auc: 0.8476 - loss: 0.4755 - val_acc: 0.7779 - val_auc: 0.8582 - val_loss: 0.4582\n",
      "Epoch 2298/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7685 - auc: 0.8475 - loss: 0.4758 - val_acc: 0.7832 - val_auc: 0.8608 - val_loss: 0.4542\n",
      "Epoch 2299/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7690 - auc: 0.8478 - loss: 0.4761 - val_acc: 0.7812 - val_auc: 0.8602 - val_loss: 0.4563\n",
      "Epoch 2300/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7686 - auc: 0.8477 - loss: 0.4759 - val_acc: 0.7791 - val_auc: 0.8586 - val_loss: 0.4579\n",
      "Epoch 2301/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7688 - auc: 0.8487 - loss: 0.4739 - val_acc: 0.7807 - val_auc: 0.8602 - val_loss: 0.4578\n",
      "Epoch 2302/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7663 - auc: 0.8464 - loss: 0.4760 - val_acc: 0.7803 - val_auc: 0.8602 - val_loss: 0.4577\n",
      "Epoch 2303/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7661 - auc: 0.8462 - loss: 0.4777 - val_acc: 0.7812 - val_auc: 0.8603 - val_loss: 0.4550\n",
      "Epoch 2304/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7692 - auc: 0.8496 - loss: 0.4735 - val_acc: 0.7766 - val_auc: 0.8571 - val_loss: 0.4614\n",
      "Epoch 2305/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7682 - auc: 0.8484 - loss: 0.4747 - val_acc: 0.7818 - val_auc: 0.8603 - val_loss: 0.4554\n",
      "Epoch 2306/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7660 - auc: 0.8475 - loss: 0.4754 - val_acc: 0.7818 - val_auc: 0.8605 - val_loss: 0.4560\n",
      "Epoch 2307/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7662 - auc: 0.8472 - loss: 0.4763 - val_acc: 0.7823 - val_auc: 0.8592 - val_loss: 0.4575\n",
      "Epoch 2308/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7668 - auc: 0.8469 - loss: 0.4768 - val_acc: 0.7801 - val_auc: 0.8594 - val_loss: 0.4577\n",
      "Epoch 2309/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7662 - auc: 0.8466 - loss: 0.4775 - val_acc: 0.7803 - val_auc: 0.8604 - val_loss: 0.4550\n",
      "Epoch 2310/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7655 - auc: 0.8472 - loss: 0.4760 - val_acc: 0.7811 - val_auc: 0.8602 - val_loss: 0.4568\n",
      "Epoch 2311/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7688 - auc: 0.8485 - loss: 0.4735 - val_acc: 0.7803 - val_auc: 0.8592 - val_loss: 0.4555\n",
      "Epoch 2312/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7689 - auc: 0.8498 - loss: 0.4725 - val_acc: 0.7811 - val_auc: 0.8597 - val_loss: 0.4567\n",
      "Epoch 2313/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7686 - auc: 0.8471 - loss: 0.4763 - val_acc: 0.7840 - val_auc: 0.8620 - val_loss: 0.4536\n",
      "Epoch 2314/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7685 - auc: 0.8477 - loss: 0.4755 - val_acc: 0.7837 - val_auc: 0.8615 - val_loss: 0.4555\n",
      "Epoch 2315/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7663 - auc: 0.8476 - loss: 0.4749 - val_acc: 0.7817 - val_auc: 0.8599 - val_loss: 0.4562\n",
      "Epoch 2316/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7678 - auc: 0.8481 - loss: 0.4754 - val_acc: 0.7842 - val_auc: 0.8616 - val_loss: 0.4555\n",
      "Epoch 2317/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7671 - auc: 0.8482 - loss: 0.4749 - val_acc: 0.7784 - val_auc: 0.8600 - val_loss: 0.4589\n",
      "Epoch 2318/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7680 - auc: 0.8478 - loss: 0.4756 - val_acc: 0.7836 - val_auc: 0.8611 - val_loss: 0.4535\n",
      "Epoch 2319/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7690 - auc: 0.8488 - loss: 0.4739 - val_acc: 0.7793 - val_auc: 0.8586 - val_loss: 0.4585\n",
      "Epoch 2320/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7678 - auc: 0.8481 - loss: 0.4756 - val_acc: 0.7814 - val_auc: 0.8594 - val_loss: 0.4566\n",
      "Epoch 2321/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7685 - auc: 0.8489 - loss: 0.4744 - val_acc: 0.7832 - val_auc: 0.8603 - val_loss: 0.4562\n",
      "Epoch 2322/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7688 - auc: 0.8480 - loss: 0.4751 - val_acc: 0.7826 - val_auc: 0.8607 - val_loss: 0.4549\n",
      "Epoch 2323/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7699 - auc: 0.8497 - loss: 0.4735 - val_acc: 0.7835 - val_auc: 0.8608 - val_loss: 0.4550\n",
      "Epoch 2324/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7696 - auc: 0.8480 - loss: 0.4753 - val_acc: 0.7774 - val_auc: 0.8600 - val_loss: 0.4575\n",
      "Epoch 2325/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7692 - auc: 0.8486 - loss: 0.4746 - val_acc: 0.7814 - val_auc: 0.8600 - val_loss: 0.4563\n",
      "Epoch 2326/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7684 - auc: 0.8475 - loss: 0.4758 - val_acc: 0.7837 - val_auc: 0.8617 - val_loss: 0.4529\n",
      "Epoch 2327/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7673 - auc: 0.8471 - loss: 0.4768 - val_acc: 0.7815 - val_auc: 0.8607 - val_loss: 0.4545\n",
      "Epoch 2328/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7678 - auc: 0.8485 - loss: 0.4735 - val_acc: 0.7828 - val_auc: 0.8617 - val_loss: 0.4535\n",
      "Epoch 2329/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7687 - auc: 0.8489 - loss: 0.4738 - val_acc: 0.7792 - val_auc: 0.8593 - val_loss: 0.4574\n",
      "Epoch 2330/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7673 - auc: 0.8472 - loss: 0.4761 - val_acc: 0.7805 - val_auc: 0.8594 - val_loss: 0.4565\n",
      "Epoch 2331/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7703 - auc: 0.8494 - loss: 0.4731 - val_acc: 0.7820 - val_auc: 0.8599 - val_loss: 0.4552\n",
      "Epoch 2332/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7684 - auc: 0.8479 - loss: 0.4762 - val_acc: 0.7818 - val_auc: 0.8594 - val_loss: 0.4566\n",
      "Epoch 2333/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7692 - auc: 0.8482 - loss: 0.4741 - val_acc: 0.7810 - val_auc: 0.8601 - val_loss: 0.4570\n",
      "Epoch 2334/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7695 - auc: 0.8482 - loss: 0.4749 - val_acc: 0.7800 - val_auc: 0.8602 - val_loss: 0.4563\n",
      "Epoch 2335/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7682 - auc: 0.8488 - loss: 0.4740 - val_acc: 0.7789 - val_auc: 0.8590 - val_loss: 0.4575\n",
      "Epoch 2336/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7666 - auc: 0.8469 - loss: 0.4762 - val_acc: 0.7793 - val_auc: 0.8590 - val_loss: 0.4577\n",
      "Epoch 2337/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7689 - auc: 0.8497 - loss: 0.4731 - val_acc: 0.7821 - val_auc: 0.8608 - val_loss: 0.4540\n",
      "Epoch 2338/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7680 - auc: 0.8481 - loss: 0.4756 - val_acc: 0.7822 - val_auc: 0.8593 - val_loss: 0.4564\n",
      "Epoch 2339/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7709 - auc: 0.8483 - loss: 0.4732 - val_acc: 0.7814 - val_auc: 0.8601 - val_loss: 0.4565\n",
      "Epoch 2340/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7684 - auc: 0.8485 - loss: 0.4738 - val_acc: 0.7813 - val_auc: 0.8619 - val_loss: 0.4552\n",
      "Epoch 2341/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7657 - auc: 0.8476 - loss: 0.4763 - val_acc: 0.7811 - val_auc: 0.8620 - val_loss: 0.4553\n",
      "Epoch 2342/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7702 - auc: 0.8491 - loss: 0.4730 - val_acc: 0.7840 - val_auc: 0.8618 - val_loss: 0.4528\n",
      "Epoch 2343/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7685 - auc: 0.8479 - loss: 0.4744 - val_acc: 0.7800 - val_auc: 0.8590 - val_loss: 0.4574\n",
      "Epoch 2344/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7684 - auc: 0.8481 - loss: 0.4753 - val_acc: 0.7827 - val_auc: 0.8604 - val_loss: 0.4552\n",
      "Epoch 2345/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7691 - auc: 0.8500 - loss: 0.4728 - val_acc: 0.7798 - val_auc: 0.8583 - val_loss: 0.4580\n",
      "Epoch 2346/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7675 - auc: 0.8480 - loss: 0.4754 - val_acc: 0.7774 - val_auc: 0.8580 - val_loss: 0.4591\n",
      "Epoch 2347/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7683 - auc: 0.8488 - loss: 0.4726 - val_acc: 0.7816 - val_auc: 0.8594 - val_loss: 0.4572\n",
      "Epoch 2348/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7668 - auc: 0.8465 - loss: 0.4770 - val_acc: 0.7844 - val_auc: 0.8610 - val_loss: 0.4545\n",
      "Epoch 2349/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7687 - auc: 0.8482 - loss: 0.4736 - val_acc: 0.7801 - val_auc: 0.8594 - val_loss: 0.4572\n",
      "Epoch 2350/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7677 - auc: 0.8478 - loss: 0.4751 - val_acc: 0.7789 - val_auc: 0.8597 - val_loss: 0.4569\n",
      "Epoch 2351/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7695 - auc: 0.8490 - loss: 0.4733 - val_acc: 0.7813 - val_auc: 0.8589 - val_loss: 0.4564\n",
      "Epoch 2352/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7699 - auc: 0.8481 - loss: 0.4754 - val_acc: 0.7811 - val_auc: 0.8613 - val_loss: 0.4545\n",
      "Epoch 2353/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7690 - auc: 0.8480 - loss: 0.4748 - val_acc: 0.7788 - val_auc: 0.8590 - val_loss: 0.4574\n",
      "Epoch 2354/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7682 - auc: 0.8480 - loss: 0.4754 - val_acc: 0.7835 - val_auc: 0.8606 - val_loss: 0.4558\n",
      "Epoch 2355/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7713 - auc: 0.8497 - loss: 0.4735 - val_acc: 0.7829 - val_auc: 0.8600 - val_loss: 0.4564\n",
      "Epoch 2356/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7685 - auc: 0.8484 - loss: 0.4735 - val_acc: 0.7815 - val_auc: 0.8593 - val_loss: 0.4556\n",
      "Epoch 2357/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7681 - auc: 0.8478 - loss: 0.4758 - val_acc: 0.7782 - val_auc: 0.8590 - val_loss: 0.4579\n",
      "Epoch 2358/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7686 - auc: 0.8482 - loss: 0.4745 - val_acc: 0.7816 - val_auc: 0.8602 - val_loss: 0.4547\n",
      "Epoch 2359/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7683 - auc: 0.8474 - loss: 0.4767 - val_acc: 0.7823 - val_auc: 0.8609 - val_loss: 0.4536\n",
      "Epoch 2360/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7705 - auc: 0.8484 - loss: 0.4743 - val_acc: 0.7800 - val_auc: 0.8608 - val_loss: 0.4550\n",
      "Epoch 2361/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7665 - auc: 0.8468 - loss: 0.4767 - val_acc: 0.7799 - val_auc: 0.8609 - val_loss: 0.4553\n",
      "Epoch 2362/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7687 - auc: 0.8485 - loss: 0.4755 - val_acc: 0.7806 - val_auc: 0.8606 - val_loss: 0.4548\n",
      "Epoch 2363/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7692 - auc: 0.8478 - loss: 0.4751 - val_acc: 0.7810 - val_auc: 0.8612 - val_loss: 0.4537\n",
      "Epoch 2364/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7695 - auc: 0.8493 - loss: 0.4734 - val_acc: 0.7766 - val_auc: 0.8587 - val_loss: 0.4569\n",
      "Epoch 2365/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7689 - auc: 0.8494 - loss: 0.4729 - val_acc: 0.7814 - val_auc: 0.8591 - val_loss: 0.4558\n",
      "Epoch 2366/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7691 - auc: 0.8485 - loss: 0.4752 - val_acc: 0.7805 - val_auc: 0.8590 - val_loss: 0.4590\n",
      "Epoch 2367/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7703 - auc: 0.8481 - loss: 0.4741 - val_acc: 0.7799 - val_auc: 0.8596 - val_loss: 0.4574\n",
      "Epoch 2368/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7667 - auc: 0.8483 - loss: 0.4752 - val_acc: 0.7826 - val_auc: 0.8602 - val_loss: 0.4549\n",
      "Epoch 2369/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7672 - auc: 0.8477 - loss: 0.4756 - val_acc: 0.7818 - val_auc: 0.8601 - val_loss: 0.4554\n",
      "Epoch 2370/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7689 - auc: 0.8471 - loss: 0.4756 - val_acc: 0.7809 - val_auc: 0.8596 - val_loss: 0.4554\n",
      "Epoch 2371/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7671 - auc: 0.8467 - loss: 0.4761 - val_acc: 0.7812 - val_auc: 0.8603 - val_loss: 0.4546\n",
      "Epoch 2372/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7685 - auc: 0.8488 - loss: 0.4737 - val_acc: 0.7794 - val_auc: 0.8593 - val_loss: 0.4579\n",
      "Epoch 2373/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7680 - auc: 0.8473 - loss: 0.4765 - val_acc: 0.7837 - val_auc: 0.8617 - val_loss: 0.4533\n",
      "Epoch 2374/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7687 - auc: 0.8486 - loss: 0.4741 - val_acc: 0.7779 - val_auc: 0.8596 - val_loss: 0.4581\n",
      "Epoch 2375/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7704 - auc: 0.8486 - loss: 0.4749 - val_acc: 0.7820 - val_auc: 0.8610 - val_loss: 0.4544\n",
      "Epoch 2376/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7704 - auc: 0.8491 - loss: 0.4743 - val_acc: 0.7814 - val_auc: 0.8599 - val_loss: 0.4562\n",
      "Epoch 2377/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7679 - auc: 0.8462 - loss: 0.4776 - val_acc: 0.7825 - val_auc: 0.8596 - val_loss: 0.4569\n",
      "Epoch 2378/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7690 - auc: 0.8476 - loss: 0.4752 - val_acc: 0.7819 - val_auc: 0.8617 - val_loss: 0.4525\n",
      "Epoch 2379/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7663 - auc: 0.8483 - loss: 0.4757 - val_acc: 0.7820 - val_auc: 0.8607 - val_loss: 0.4543\n",
      "Epoch 2380/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7681 - auc: 0.8475 - loss: 0.4753 - val_acc: 0.7778 - val_auc: 0.8589 - val_loss: 0.4564\n",
      "Epoch 2381/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7683 - auc: 0.8472 - loss: 0.4774 - val_acc: 0.7775 - val_auc: 0.8601 - val_loss: 0.4571\n",
      "Epoch 2382/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7662 - auc: 0.8476 - loss: 0.4761 - val_acc: 0.7782 - val_auc: 0.8582 - val_loss: 0.4579\n",
      "Epoch 2383/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7702 - auc: 0.8480 - loss: 0.4754 - val_acc: 0.7836 - val_auc: 0.8617 - val_loss: 0.4529\n",
      "Epoch 2384/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7677 - auc: 0.8485 - loss: 0.4748 - val_acc: 0.7825 - val_auc: 0.8602 - val_loss: 0.4559\n",
      "Epoch 2385/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7684 - auc: 0.8470 - loss: 0.4771 - val_acc: 0.7801 - val_auc: 0.8595 - val_loss: 0.4579\n",
      "Epoch 2386/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7685 - auc: 0.8475 - loss: 0.4767 - val_acc: 0.7809 - val_auc: 0.8595 - val_loss: 0.4561\n",
      "Epoch 2387/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7673 - auc: 0.8469 - loss: 0.4770 - val_acc: 0.7800 - val_auc: 0.8603 - val_loss: 0.4562\n",
      "Epoch 2388/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7698 - auc: 0.8481 - loss: 0.4747 - val_acc: 0.7816 - val_auc: 0.8601 - val_loss: 0.4544\n",
      "Epoch 2389/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7696 - auc: 0.8498 - loss: 0.4724 - val_acc: 0.7812 - val_auc: 0.8595 - val_loss: 0.4563\n",
      "Epoch 2390/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7681 - auc: 0.8470 - loss: 0.4757 - val_acc: 0.7779 - val_auc: 0.8599 - val_loss: 0.4567\n",
      "Epoch 2391/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7670 - auc: 0.8480 - loss: 0.4763 - val_acc: 0.7800 - val_auc: 0.8595 - val_loss: 0.4567\n",
      "Epoch 2392/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7662 - auc: 0.8480 - loss: 0.4757 - val_acc: 0.7806 - val_auc: 0.8607 - val_loss: 0.4559\n",
      "Epoch 2393/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7718 - auc: 0.8500 - loss: 0.4728 - val_acc: 0.7806 - val_auc: 0.8602 - val_loss: 0.4558\n",
      "Epoch 2394/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7701 - auc: 0.8492 - loss: 0.4730 - val_acc: 0.7801 - val_auc: 0.8598 - val_loss: 0.4562\n",
      "Epoch 2395/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7685 - auc: 0.8474 - loss: 0.4757 - val_acc: 0.7834 - val_auc: 0.8617 - val_loss: 0.4534\n",
      "Epoch 2396/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7680 - auc: 0.8489 - loss: 0.4741 - val_acc: 0.7808 - val_auc: 0.8594 - val_loss: 0.4566\n",
      "Epoch 2397/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7698 - auc: 0.8483 - loss: 0.4757 - val_acc: 0.7805 - val_auc: 0.8610 - val_loss: 0.4547\n",
      "Epoch 2398/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7692 - auc: 0.8497 - loss: 0.4731 - val_acc: 0.7812 - val_auc: 0.8603 - val_loss: 0.4550\n",
      "Epoch 2399/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7673 - auc: 0.8476 - loss: 0.4749 - val_acc: 0.7802 - val_auc: 0.8615 - val_loss: 0.4546\n",
      "Epoch 2400/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7666 - auc: 0.8483 - loss: 0.4739 - val_acc: 0.7779 - val_auc: 0.8592 - val_loss: 0.4573\n",
      "Epoch 2401/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7669 - auc: 0.8471 - loss: 0.4763 - val_acc: 0.7831 - val_auc: 0.8623 - val_loss: 0.4525\n",
      "Epoch 2402/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7687 - auc: 0.8487 - loss: 0.4734 - val_acc: 0.7840 - val_auc: 0.8609 - val_loss: 0.4547\n",
      "Epoch 2403/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7683 - auc: 0.8497 - loss: 0.4734 - val_acc: 0.7778 - val_auc: 0.8599 - val_loss: 0.4562\n",
      "Epoch 2404/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7681 - auc: 0.8485 - loss: 0.4751 - val_acc: 0.7837 - val_auc: 0.8621 - val_loss: 0.4536\n",
      "Epoch 2405/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7686 - auc: 0.8483 - loss: 0.4749 - val_acc: 0.7833 - val_auc: 0.8602 - val_loss: 0.4555\n",
      "Epoch 2406/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7690 - auc: 0.8486 - loss: 0.4743 - val_acc: 0.7808 - val_auc: 0.8616 - val_loss: 0.4530\n",
      "Epoch 2407/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7667 - auc: 0.8489 - loss: 0.4732 - val_acc: 0.7804 - val_auc: 0.8592 - val_loss: 0.4581\n",
      "Epoch 2408/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7697 - auc: 0.8481 - loss: 0.4742 - val_acc: 0.7833 - val_auc: 0.8607 - val_loss: 0.4549\n",
      "Epoch 2409/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7696 - auc: 0.8497 - loss: 0.4723 - val_acc: 0.7780 - val_auc: 0.8590 - val_loss: 0.4581\n",
      "Epoch 2410/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7692 - auc: 0.8491 - loss: 0.4737 - val_acc: 0.7797 - val_auc: 0.8590 - val_loss: 0.4561\n",
      "Epoch 2411/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7657 - auc: 0.8478 - loss: 0.4743 - val_acc: 0.7799 - val_auc: 0.8596 - val_loss: 0.4581\n",
      "Epoch 2412/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7692 - auc: 0.8492 - loss: 0.4728 - val_acc: 0.7809 - val_auc: 0.8601 - val_loss: 0.4567\n",
      "Epoch 2413/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7681 - auc: 0.8484 - loss: 0.4746 - val_acc: 0.7814 - val_auc: 0.8602 - val_loss: 0.4553\n",
      "Epoch 2414/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7685 - auc: 0.8471 - loss: 0.4760 - val_acc: 0.7816 - val_auc: 0.8595 - val_loss: 0.4567\n",
      "Epoch 2415/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7689 - auc: 0.8475 - loss: 0.4759 - val_acc: 0.7814 - val_auc: 0.8610 - val_loss: 0.4545\n",
      "Epoch 2416/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7683 - auc: 0.8482 - loss: 0.4751 - val_acc: 0.7790 - val_auc: 0.8602 - val_loss: 0.4565\n",
      "Epoch 2417/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7675 - auc: 0.8479 - loss: 0.4757 - val_acc: 0.7797 - val_auc: 0.8612 - val_loss: 0.4543\n",
      "Epoch 2418/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7680 - auc: 0.8470 - loss: 0.4766 - val_acc: 0.7824 - val_auc: 0.8617 - val_loss: 0.4531\n",
      "Epoch 2419/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7701 - auc: 0.8491 - loss: 0.4728 - val_acc: 0.7806 - val_auc: 0.8603 - val_loss: 0.4549\n",
      "Epoch 2420/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7698 - auc: 0.8488 - loss: 0.4746 - val_acc: 0.7816 - val_auc: 0.8597 - val_loss: 0.4554\n",
      "Epoch 2421/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7678 - auc: 0.8478 - loss: 0.4756 - val_acc: 0.7820 - val_auc: 0.8611 - val_loss: 0.4540\n",
      "Epoch 2422/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7699 - auc: 0.8482 - loss: 0.4756 - val_acc: 0.7814 - val_auc: 0.8610 - val_loss: 0.4557\n",
      "Epoch 2423/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7694 - auc: 0.8471 - loss: 0.4768 - val_acc: 0.7817 - val_auc: 0.8621 - val_loss: 0.4547\n",
      "Epoch 2424/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7689 - auc: 0.8476 - loss: 0.4750 - val_acc: 0.7817 - val_auc: 0.8609 - val_loss: 0.4547\n",
      "Epoch 2425/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7684 - auc: 0.8483 - loss: 0.4749 - val_acc: 0.7837 - val_auc: 0.8618 - val_loss: 0.4537\n",
      "Epoch 2426/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7675 - auc: 0.8500 - loss: 0.4727 - val_acc: 0.7791 - val_auc: 0.8610 - val_loss: 0.4559\n",
      "Epoch 2427/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7675 - auc: 0.8478 - loss: 0.4748 - val_acc: 0.7815 - val_auc: 0.8605 - val_loss: 0.4553\n",
      "Epoch 2428/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7699 - auc: 0.8500 - loss: 0.4736 - val_acc: 0.7807 - val_auc: 0.8598 - val_loss: 0.4561\n",
      "Epoch 2429/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7673 - auc: 0.8480 - loss: 0.4743 - val_acc: 0.7806 - val_auc: 0.8610 - val_loss: 0.4547\n",
      "Epoch 2430/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7687 - auc: 0.8497 - loss: 0.4728 - val_acc: 0.7792 - val_auc: 0.8610 - val_loss: 0.4556\n",
      "Epoch 2431/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7679 - auc: 0.8467 - loss: 0.4766 - val_acc: 0.7807 - val_auc: 0.8605 - val_loss: 0.4552\n",
      "Epoch 2432/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7673 - auc: 0.8478 - loss: 0.4746 - val_acc: 0.7820 - val_auc: 0.8616 - val_loss: 0.4554\n",
      "Epoch 2433/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7686 - auc: 0.8497 - loss: 0.4729 - val_acc: 0.7816 - val_auc: 0.8617 - val_loss: 0.4536\n",
      "Epoch 2434/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7698 - auc: 0.8497 - loss: 0.4728 - val_acc: 0.7800 - val_auc: 0.8616 - val_loss: 0.4537\n",
      "Epoch 2435/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7725 - auc: 0.8511 - loss: 0.4713 - val_acc: 0.7823 - val_auc: 0.8611 - val_loss: 0.4543\n",
      "Epoch 2436/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7684 - auc: 0.8487 - loss: 0.4737 - val_acc: 0.7838 - val_auc: 0.8607 - val_loss: 0.4549\n",
      "Epoch 2437/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7725 - auc: 0.8492 - loss: 0.4734 - val_acc: 0.7842 - val_auc: 0.8611 - val_loss: 0.4539\n",
      "Epoch 2438/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7682 - auc: 0.8474 - loss: 0.4764 - val_acc: 0.7802 - val_auc: 0.8600 - val_loss: 0.4552\n",
      "Epoch 2439/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7692 - auc: 0.8488 - loss: 0.4738 - val_acc: 0.7837 - val_auc: 0.8609 - val_loss: 0.4545\n",
      "Epoch 2440/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7684 - auc: 0.8480 - loss: 0.4754 - val_acc: 0.7821 - val_auc: 0.8603 - val_loss: 0.4550\n",
      "Epoch 2441/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7680 - auc: 0.8497 - loss: 0.4723 - val_acc: 0.7817 - val_auc: 0.8601 - val_loss: 0.4549\n",
      "Epoch 2442/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7676 - auc: 0.8486 - loss: 0.4735 - val_acc: 0.7840 - val_auc: 0.8620 - val_loss: 0.4545\n",
      "Epoch 2443/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7698 - auc: 0.8493 - loss: 0.4737 - val_acc: 0.7821 - val_auc: 0.8612 - val_loss: 0.4557\n",
      "Epoch 2444/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7686 - auc: 0.8487 - loss: 0.4740 - val_acc: 0.7824 - val_auc: 0.8619 - val_loss: 0.4533\n",
      "Epoch 2445/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7673 - auc: 0.8483 - loss: 0.4740 - val_acc: 0.7798 - val_auc: 0.8607 - val_loss: 0.4558\n",
      "Epoch 2446/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7697 - auc: 0.8494 - loss: 0.4730 - val_acc: 0.7821 - val_auc: 0.8615 - val_loss: 0.4536\n",
      "Epoch 2447/7000\n",
      "106/106 - 2s - 23ms/step - acc: 0.7680 - auc: 0.8482 - loss: 0.4749 - val_acc: 0.7818 - val_auc: 0.8605 - val_loss: 0.4542\n",
      "Epoch 2448/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7703 - auc: 0.8493 - loss: 0.4730 - val_acc: 0.7811 - val_auc: 0.8609 - val_loss: 0.4550\n",
      "Epoch 2449/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7688 - auc: 0.8488 - loss: 0.4735 - val_acc: 0.7799 - val_auc: 0.8586 - val_loss: 0.4569\n",
      "Epoch 2450/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7692 - auc: 0.8485 - loss: 0.4751 - val_acc: 0.7820 - val_auc: 0.8605 - val_loss: 0.4557\n",
      "Epoch 2451/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7682 - auc: 0.8480 - loss: 0.4747 - val_acc: 0.7806 - val_auc: 0.8610 - val_loss: 0.4539\n",
      "Epoch 2452/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7700 - auc: 0.8506 - loss: 0.4716 - val_acc: 0.7803 - val_auc: 0.8607 - val_loss: 0.4559\n",
      "Epoch 2453/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7703 - auc: 0.8507 - loss: 0.4721 - val_acc: 0.7816 - val_auc: 0.8610 - val_loss: 0.4549\n",
      "Epoch 2454/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7684 - auc: 0.8493 - loss: 0.4729 - val_acc: 0.7821 - val_auc: 0.8602 - val_loss: 0.4560\n",
      "Epoch 2455/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7693 - auc: 0.8482 - loss: 0.4754 - val_acc: 0.7807 - val_auc: 0.8620 - val_loss: 0.4533\n",
      "Epoch 2456/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7698 - auc: 0.8493 - loss: 0.4727 - val_acc: 0.7804 - val_auc: 0.8596 - val_loss: 0.4562\n",
      "Epoch 2457/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7686 - auc: 0.8475 - loss: 0.4764 - val_acc: 0.7817 - val_auc: 0.8602 - val_loss: 0.4560\n",
      "Epoch 2458/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7660 - auc: 0.8479 - loss: 0.4746 - val_acc: 0.7825 - val_auc: 0.8614 - val_loss: 0.4564\n",
      "Epoch 2459/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7693 - auc: 0.8499 - loss: 0.4732 - val_acc: 0.7806 - val_auc: 0.8606 - val_loss: 0.4549\n",
      "Epoch 2460/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7673 - auc: 0.8492 - loss: 0.4729 - val_acc: 0.7835 - val_auc: 0.8619 - val_loss: 0.4533\n",
      "Epoch 2461/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7692 - auc: 0.8489 - loss: 0.4736 - val_acc: 0.7846 - val_auc: 0.8624 - val_loss: 0.4540\n",
      "Epoch 2462/7000\n",
      "106/106 - 2s - 22ms/step - acc: 0.7697 - auc: 0.8499 - loss: 0.4731 - val_acc: 0.7835 - val_auc: 0.8618 - val_loss: 0.4541\n",
      "Epoch 2463/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7674 - auc: 0.8485 - loss: 0.4752 - val_acc: 0.7811 - val_auc: 0.8614 - val_loss: 0.4557\n",
      "Epoch 2464/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7690 - auc: 0.8502 - loss: 0.4725 - val_acc: 0.7830 - val_auc: 0.8608 - val_loss: 0.4553\n",
      "Epoch 2465/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7668 - auc: 0.8478 - loss: 0.4755 - val_acc: 0.7790 - val_auc: 0.8619 - val_loss: 0.4557\n",
      "Epoch 2466/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7704 - auc: 0.8492 - loss: 0.4736 - val_acc: 0.7824 - val_auc: 0.8611 - val_loss: 0.4552\n",
      "Epoch 2467/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7694 - auc: 0.8501 - loss: 0.4725 - val_acc: 0.7781 - val_auc: 0.8612 - val_loss: 0.4564\n",
      "Epoch 2468/7000\n",
      "106/106 - 2s - 16ms/step - acc: 0.7662 - auc: 0.8485 - loss: 0.4746 - val_acc: 0.7845 - val_auc: 0.8611 - val_loss: 0.4542\n",
      "Epoch 2469/7000\n",
      "106/106 - 2s - 15ms/step - acc: 0.7695 - auc: 0.8484 - loss: 0.4744 - val_acc: 0.7813 - val_auc: 0.8609 - val_loss: 0.4557\n",
      "Epoch 2470/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7692 - auc: 0.8494 - loss: 0.4733 - val_acc: 0.7841 - val_auc: 0.8617 - val_loss: 0.4538\n",
      "Epoch 2471/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7678 - auc: 0.8476 - loss: 0.4756 - val_acc: 0.7789 - val_auc: 0.8604 - val_loss: 0.4568\n",
      "Epoch 2472/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7670 - auc: 0.8479 - loss: 0.4748 - val_acc: 0.7818 - val_auc: 0.8615 - val_loss: 0.4547\n",
      "Epoch 2473/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7704 - auc: 0.8490 - loss: 0.4728 - val_acc: 0.7822 - val_auc: 0.8624 - val_loss: 0.4530\n",
      "Epoch 2474/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7696 - auc: 0.8482 - loss: 0.4743 - val_acc: 0.7809 - val_auc: 0.8614 - val_loss: 0.4558\n",
      "Epoch 2475/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7702 - auc: 0.8502 - loss: 0.4721 - val_acc: 0.7828 - val_auc: 0.8619 - val_loss: 0.4541\n",
      "Epoch 2476/7000\n",
      "106/106 - 2s - 14ms/step - acc: 0.7706 - auc: 0.8498 - loss: 0.4725 - val_acc: 0.7808 - val_auc: 0.8630 - val_loss: 0.4533\n",
      "Epoch 2477/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7694 - auc: 0.8489 - loss: 0.4733 - val_acc: 0.7827 - val_auc: 0.8607 - val_loss: 0.4554\n",
      "Epoch 2478/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7688 - auc: 0.8487 - loss: 0.4742 - val_acc: 0.7816 - val_auc: 0.8607 - val_loss: 0.4548\n",
      "Epoch 2479/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7693 - auc: 0.8484 - loss: 0.4749 - val_acc: 0.7817 - val_auc: 0.8611 - val_loss: 0.4540\n",
      "Epoch 2480/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7681 - auc: 0.8494 - loss: 0.4727 - val_acc: 0.7819 - val_auc: 0.8625 - val_loss: 0.4536\n",
      "Epoch 2481/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7677 - auc: 0.8485 - loss: 0.4750 - val_acc: 0.7819 - val_auc: 0.8623 - val_loss: 0.4544\n",
      "Epoch 2482/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7694 - auc: 0.8489 - loss: 0.4735 - val_acc: 0.7830 - val_auc: 0.8632 - val_loss: 0.4523\n",
      "Epoch 2483/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7693 - auc: 0.8496 - loss: 0.4739 - val_acc: 0.7818 - val_auc: 0.8611 - val_loss: 0.4577\n",
      "Epoch 2484/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7700 - auc: 0.8500 - loss: 0.4719 - val_acc: 0.7812 - val_auc: 0.8606 - val_loss: 0.4549\n",
      "Epoch 2485/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7681 - auc: 0.8493 - loss: 0.4726 - val_acc: 0.7818 - val_auc: 0.8619 - val_loss: 0.4535\n",
      "Epoch 2486/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7689 - auc: 0.8479 - loss: 0.4739 - val_acc: 0.7805 - val_auc: 0.8623 - val_loss: 0.4538\n",
      "Epoch 2487/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7702 - auc: 0.8497 - loss: 0.4739 - val_acc: 0.7806 - val_auc: 0.8608 - val_loss: 0.4550\n",
      "Epoch 2488/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7679 - auc: 0.8488 - loss: 0.4726 - val_acc: 0.7817 - val_auc: 0.8607 - val_loss: 0.4539\n",
      "Epoch 2489/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7687 - auc: 0.8498 - loss: 0.4727 - val_acc: 0.7840 - val_auc: 0.8616 - val_loss: 0.4534\n",
      "Epoch 2490/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7683 - auc: 0.8482 - loss: 0.4743 - val_acc: 0.7827 - val_auc: 0.8610 - val_loss: 0.4550\n",
      "Epoch 2491/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7703 - auc: 0.8504 - loss: 0.4721 - val_acc: 0.7836 - val_auc: 0.8617 - val_loss: 0.4541\n",
      "Epoch 2492/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7696 - auc: 0.8490 - loss: 0.4742 - val_acc: 0.7837 - val_auc: 0.8601 - val_loss: 0.4572\n",
      "Epoch 2493/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7683 - auc: 0.8489 - loss: 0.4741 - val_acc: 0.7812 - val_auc: 0.8610 - val_loss: 0.4563\n",
      "Epoch 2494/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7715 - auc: 0.8498 - loss: 0.4725 - val_acc: 0.7792 - val_auc: 0.8596 - val_loss: 0.4558\n",
      "Epoch 2495/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7702 - auc: 0.8501 - loss: 0.4732 - val_acc: 0.7829 - val_auc: 0.8620 - val_loss: 0.4529\n",
      "Epoch 2496/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7680 - auc: 0.8465 - loss: 0.4766 - val_acc: 0.7798 - val_auc: 0.8589 - val_loss: 0.4575\n",
      "Epoch 2497/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7678 - auc: 0.8474 - loss: 0.4756 - val_acc: 0.7800 - val_auc: 0.8613 - val_loss: 0.4550\n",
      "Epoch 2498/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7695 - auc: 0.8494 - loss: 0.4730 - val_acc: 0.7820 - val_auc: 0.8606 - val_loss: 0.4560\n",
      "Epoch 2499/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7695 - auc: 0.8486 - loss: 0.4738 - val_acc: 0.7782 - val_auc: 0.8593 - val_loss: 0.4573\n",
      "Epoch 2500/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7709 - auc: 0.8495 - loss: 0.4737 - val_acc: 0.7814 - val_auc: 0.8618 - val_loss: 0.4540\n",
      "Epoch 2501/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7676 - auc: 0.8479 - loss: 0.4744 - val_acc: 0.7801 - val_auc: 0.8616 - val_loss: 0.4530\n",
      "Epoch 2502/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7670 - auc: 0.8483 - loss: 0.4750 - val_acc: 0.7843 - val_auc: 0.8621 - val_loss: 0.4546\n",
      "Epoch 2503/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7689 - auc: 0.8481 - loss: 0.4751 - val_acc: 0.7842 - val_auc: 0.8622 - val_loss: 0.4528\n",
      "Epoch 2504/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7680 - auc: 0.8488 - loss: 0.4737 - val_acc: 0.7791 - val_auc: 0.8609 - val_loss: 0.4548\n",
      "Epoch 2505/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7684 - auc: 0.8481 - loss: 0.4755 - val_acc: 0.7825 - val_auc: 0.8604 - val_loss: 0.4552\n",
      "Epoch 2506/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7676 - auc: 0.8478 - loss: 0.4757 - val_acc: 0.7814 - val_auc: 0.8594 - val_loss: 0.4567\n",
      "Epoch 2507/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7705 - auc: 0.8491 - loss: 0.4729 - val_acc: 0.7827 - val_auc: 0.8621 - val_loss: 0.4530\n",
      "Epoch 2508/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7692 - auc: 0.8477 - loss: 0.4750 - val_acc: 0.7830 - val_auc: 0.8616 - val_loss: 0.4544\n",
      "Epoch 2509/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7695 - auc: 0.8504 - loss: 0.4722 - val_acc: 0.7829 - val_auc: 0.8617 - val_loss: 0.4545\n",
      "Epoch 2510/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7679 - auc: 0.8502 - loss: 0.4719 - val_acc: 0.7846 - val_auc: 0.8612 - val_loss: 0.4533\n",
      "Epoch 2511/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7705 - auc: 0.8491 - loss: 0.4735 - val_acc: 0.7865 - val_auc: 0.8618 - val_loss: 0.4531\n",
      "Epoch 2512/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7695 - auc: 0.8487 - loss: 0.4737 - val_acc: 0.7824 - val_auc: 0.8606 - val_loss: 0.4562\n",
      "Epoch 2513/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7675 - auc: 0.8481 - loss: 0.4747 - val_acc: 0.7840 - val_auc: 0.8611 - val_loss: 0.4533\n",
      "Epoch 2514/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7693 - auc: 0.8487 - loss: 0.4741 - val_acc: 0.7818 - val_auc: 0.8623 - val_loss: 0.4529\n",
      "Epoch 2515/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7676 - auc: 0.8486 - loss: 0.4745 - val_acc: 0.7796 - val_auc: 0.8606 - val_loss: 0.4551\n",
      "Epoch 2516/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7707 - auc: 0.8500 - loss: 0.4722 - val_acc: 0.7816 - val_auc: 0.8601 - val_loss: 0.4556\n",
      "Epoch 2517/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7681 - auc: 0.8489 - loss: 0.4735 - val_acc: 0.7803 - val_auc: 0.8596 - val_loss: 0.4556\n",
      "Epoch 2518/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7685 - auc: 0.8491 - loss: 0.4738 - val_acc: 0.7818 - val_auc: 0.8615 - val_loss: 0.4542\n",
      "Epoch 2519/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7688 - auc: 0.8503 - loss: 0.4724 - val_acc: 0.7836 - val_auc: 0.8605 - val_loss: 0.4557\n",
      "Epoch 2520/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7689 - auc: 0.8488 - loss: 0.4731 - val_acc: 0.7794 - val_auc: 0.8592 - val_loss: 0.4574\n",
      "Epoch 2521/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7683 - auc: 0.8482 - loss: 0.4762 - val_acc: 0.7815 - val_auc: 0.8621 - val_loss: 0.4538\n",
      "Epoch 2522/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7697 - auc: 0.8493 - loss: 0.4734 - val_acc: 0.7828 - val_auc: 0.8610 - val_loss: 0.4548\n",
      "Epoch 2523/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7699 - auc: 0.8491 - loss: 0.4737 - val_acc: 0.7850 - val_auc: 0.8614 - val_loss: 0.4526\n",
      "Epoch 2524/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7704 - auc: 0.8493 - loss: 0.4731 - val_acc: 0.7846 - val_auc: 0.8628 - val_loss: 0.4516\n",
      "Epoch 2525/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7683 - auc: 0.8489 - loss: 0.4731 - val_acc: 0.7823 - val_auc: 0.8611 - val_loss: 0.4556\n",
      "Epoch 2526/7000\n",
      "106/106 - 2s - 21ms/step - acc: 0.7694 - auc: 0.8501 - loss: 0.4717 - val_acc: 0.7838 - val_auc: 0.8608 - val_loss: 0.4542\n",
      "Epoch 2527/7000\n",
      "106/106 - 2s - 19ms/step - acc: 0.7669 - auc: 0.8487 - loss: 0.4746 - val_acc: 0.7789 - val_auc: 0.8610 - val_loss: 0.4558\n",
      "Epoch 2528/7000\n",
      "106/106 - 2s - 15ms/step - acc: 0.7682 - auc: 0.8489 - loss: 0.4738 - val_acc: 0.7828 - val_auc: 0.8623 - val_loss: 0.4522\n",
      "Epoch 2529/7000\n",
      "106/106 - 2s - 14ms/step - acc: 0.7696 - auc: 0.8478 - loss: 0.4757 - val_acc: 0.7815 - val_auc: 0.8610 - val_loss: 0.4564\n",
      "Epoch 2530/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7686 - auc: 0.8482 - loss: 0.4738 - val_acc: 0.7802 - val_auc: 0.8602 - val_loss: 0.4567\n",
      "Epoch 2531/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7691 - auc: 0.8481 - loss: 0.4757 - val_acc: 0.7783 - val_auc: 0.8599 - val_loss: 0.4543\n",
      "Epoch 2532/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7699 - auc: 0.8500 - loss: 0.4718 - val_acc: 0.7811 - val_auc: 0.8609 - val_loss: 0.4543\n",
      "Epoch 2533/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7698 - auc: 0.8499 - loss: 0.4725 - val_acc: 0.7818 - val_auc: 0.8616 - val_loss: 0.4538\n",
      "Epoch 2534/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7702 - auc: 0.8496 - loss: 0.4736 - val_acc: 0.7824 - val_auc: 0.8623 - val_loss: 0.4526\n",
      "Epoch 2535/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7693 - auc: 0.8492 - loss: 0.4730 - val_acc: 0.7816 - val_auc: 0.8601 - val_loss: 0.4558\n",
      "Epoch 2536/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7697 - auc: 0.8500 - loss: 0.4725 - val_acc: 0.7824 - val_auc: 0.8610 - val_loss: 0.4550\n",
      "Epoch 2537/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7676 - auc: 0.8477 - loss: 0.4753 - val_acc: 0.7808 - val_auc: 0.8583 - val_loss: 0.4587\n",
      "Epoch 2538/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7686 - auc: 0.8490 - loss: 0.4743 - val_acc: 0.7793 - val_auc: 0.8605 - val_loss: 0.4561\n",
      "Epoch 2539/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7685 - auc: 0.8485 - loss: 0.4741 - val_acc: 0.7833 - val_auc: 0.8617 - val_loss: 0.4529\n",
      "Epoch 2540/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7708 - auc: 0.8500 - loss: 0.4730 - val_acc: 0.7803 - val_auc: 0.8603 - val_loss: 0.4551\n",
      "Epoch 2541/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7715 - auc: 0.8507 - loss: 0.4720 - val_acc: 0.7816 - val_auc: 0.8604 - val_loss: 0.4570\n",
      "Epoch 2542/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7702 - auc: 0.8505 - loss: 0.4720 - val_acc: 0.7838 - val_auc: 0.8616 - val_loss: 0.4536\n",
      "Epoch 2543/7000\n",
      "106/106 - 2s - 18ms/step - acc: 0.7683 - auc: 0.8489 - loss: 0.4739 - val_acc: 0.7840 - val_auc: 0.8618 - val_loss: 0.4538\n",
      "Epoch 2544/7000\n",
      "106/106 - 2s - 18ms/step - acc: 0.7698 - auc: 0.8484 - loss: 0.4740 - val_acc: 0.7791 - val_auc: 0.8589 - val_loss: 0.4599\n",
      "Epoch 2545/7000\n",
      "106/106 - 2s - 15ms/step - acc: 0.7683 - auc: 0.8488 - loss: 0.4744 - val_acc: 0.7795 - val_auc: 0.8608 - val_loss: 0.4554\n",
      "Epoch 2546/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7710 - auc: 0.8506 - loss: 0.4721 - val_acc: 0.7821 - val_auc: 0.8611 - val_loss: 0.4532\n",
      "Epoch 2547/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7693 - auc: 0.8489 - loss: 0.4742 - val_acc: 0.7821 - val_auc: 0.8616 - val_loss: 0.4537\n",
      "Epoch 2548/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7688 - auc: 0.8481 - loss: 0.4747 - val_acc: 0.7836 - val_auc: 0.8629 - val_loss: 0.4525\n",
      "Epoch 2549/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7720 - auc: 0.8512 - loss: 0.4718 - val_acc: 0.7822 - val_auc: 0.8613 - val_loss: 0.4548\n",
      "Epoch 2550/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7698 - auc: 0.8501 - loss: 0.4718 - val_acc: 0.7812 - val_auc: 0.8610 - val_loss: 0.4558\n",
      "Epoch 2551/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7685 - auc: 0.8482 - loss: 0.4745 - val_acc: 0.7819 - val_auc: 0.8590 - val_loss: 0.4556\n",
      "Epoch 2552/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7714 - auc: 0.8507 - loss: 0.4713 - val_acc: 0.7812 - val_auc: 0.8606 - val_loss: 0.4550\n",
      "Epoch 2553/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7689 - auc: 0.8481 - loss: 0.4755 - val_acc: 0.7796 - val_auc: 0.8602 - val_loss: 0.4578\n",
      "Epoch 2554/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7695 - auc: 0.8492 - loss: 0.4742 - val_acc: 0.7856 - val_auc: 0.8632 - val_loss: 0.4524\n",
      "Epoch 2555/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7701 - auc: 0.8497 - loss: 0.4721 - val_acc: 0.7803 - val_auc: 0.8604 - val_loss: 0.4541\n",
      "Epoch 2556/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7702 - auc: 0.8503 - loss: 0.4720 - val_acc: 0.7822 - val_auc: 0.8615 - val_loss: 0.4543\n",
      "Epoch 2557/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7702 - auc: 0.8494 - loss: 0.4729 - val_acc: 0.7817 - val_auc: 0.8605 - val_loss: 0.4549\n",
      "Epoch 2558/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7672 - auc: 0.8486 - loss: 0.4733 - val_acc: 0.7803 - val_auc: 0.8590 - val_loss: 0.4577\n",
      "Epoch 2559/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7706 - auc: 0.8487 - loss: 0.4741 - val_acc: 0.7840 - val_auc: 0.8627 - val_loss: 0.4522\n",
      "Epoch 2560/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7712 - auc: 0.8506 - loss: 0.4721 - val_acc: 0.7816 - val_auc: 0.8612 - val_loss: 0.4552\n",
      "Epoch 2561/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7697 - auc: 0.8493 - loss: 0.4733 - val_acc: 0.7831 - val_auc: 0.8623 - val_loss: 0.4528\n",
      "Epoch 2562/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7708 - auc: 0.8503 - loss: 0.4718 - val_acc: 0.7851 - val_auc: 0.8618 - val_loss: 0.4530\n",
      "Epoch 2563/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7690 - auc: 0.8497 - loss: 0.4725 - val_acc: 0.7828 - val_auc: 0.8609 - val_loss: 0.4535\n",
      "Epoch 2564/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7710 - auc: 0.8505 - loss: 0.4716 - val_acc: 0.7800 - val_auc: 0.8613 - val_loss: 0.4525\n",
      "Epoch 2565/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7685 - auc: 0.8479 - loss: 0.4754 - val_acc: 0.7803 - val_auc: 0.8593 - val_loss: 0.4577\n",
      "Epoch 2566/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7699 - auc: 0.8495 - loss: 0.4729 - val_acc: 0.7837 - val_auc: 0.8623 - val_loss: 0.4528\n",
      "Epoch 2567/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7710 - auc: 0.8505 - loss: 0.4723 - val_acc: 0.7801 - val_auc: 0.8612 - val_loss: 0.4543\n",
      "Epoch 2568/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7668 - auc: 0.8468 - loss: 0.4775 - val_acc: 0.7827 - val_auc: 0.8633 - val_loss: 0.4540\n",
      "Epoch 2569/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7687 - auc: 0.8491 - loss: 0.4739 - val_acc: 0.7825 - val_auc: 0.8626 - val_loss: 0.4519\n",
      "Epoch 2570/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7690 - auc: 0.8489 - loss: 0.4740 - val_acc: 0.7824 - val_auc: 0.8606 - val_loss: 0.4551\n",
      "Epoch 2571/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7706 - auc: 0.8495 - loss: 0.4733 - val_acc: 0.7806 - val_auc: 0.8605 - val_loss: 0.4542\n",
      "Epoch 2572/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7686 - auc: 0.8491 - loss: 0.4731 - val_acc: 0.7805 - val_auc: 0.8613 - val_loss: 0.4540\n",
      "Epoch 2573/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7709 - auc: 0.8503 - loss: 0.4714 - val_acc: 0.7850 - val_auc: 0.8616 - val_loss: 0.4530\n",
      "Epoch 2574/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7671 - auc: 0.8466 - loss: 0.4778 - val_acc: 0.7813 - val_auc: 0.8607 - val_loss: 0.4567\n",
      "Epoch 2575/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7713 - auc: 0.8505 - loss: 0.4724 - val_acc: 0.7772 - val_auc: 0.8597 - val_loss: 0.4562\n",
      "Epoch 2576/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7693 - auc: 0.8503 - loss: 0.4715 - val_acc: 0.7832 - val_auc: 0.8618 - val_loss: 0.4542\n",
      "Epoch 2577/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7693 - auc: 0.8490 - loss: 0.4741 - val_acc: 0.7818 - val_auc: 0.8613 - val_loss: 0.4547\n",
      "Epoch 2578/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7703 - auc: 0.8517 - loss: 0.4700 - val_acc: 0.7825 - val_auc: 0.8604 - val_loss: 0.4542\n",
      "Epoch 2579/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7700 - auc: 0.8502 - loss: 0.4731 - val_acc: 0.7840 - val_auc: 0.8617 - val_loss: 0.4540\n",
      "Epoch 2580/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7716 - auc: 0.8493 - loss: 0.4737 - val_acc: 0.7838 - val_auc: 0.8630 - val_loss: 0.4523\n",
      "Epoch 2581/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7715 - auc: 0.8505 - loss: 0.4725 - val_acc: 0.7805 - val_auc: 0.8612 - val_loss: 0.4547\n",
      "Epoch 2582/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7680 - auc: 0.8482 - loss: 0.4743 - val_acc: 0.7785 - val_auc: 0.8605 - val_loss: 0.4567\n",
      "Epoch 2583/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7699 - auc: 0.8498 - loss: 0.4729 - val_acc: 0.7811 - val_auc: 0.8618 - val_loss: 0.4540\n",
      "Epoch 2584/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7698 - auc: 0.8491 - loss: 0.4733 - val_acc: 0.7807 - val_auc: 0.8602 - val_loss: 0.4567\n",
      "Epoch 2585/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7662 - auc: 0.8473 - loss: 0.4761 - val_acc: 0.7813 - val_auc: 0.8615 - val_loss: 0.4536\n",
      "Epoch 2586/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7688 - auc: 0.8496 - loss: 0.4724 - val_acc: 0.7803 - val_auc: 0.8609 - val_loss: 0.4552\n",
      "Epoch 2587/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7701 - auc: 0.8508 - loss: 0.4717 - val_acc: 0.7808 - val_auc: 0.8615 - val_loss: 0.4532\n",
      "Epoch 2588/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7680 - auc: 0.8497 - loss: 0.4737 - val_acc: 0.7840 - val_auc: 0.8622 - val_loss: 0.4523\n",
      "Epoch 2589/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7702 - auc: 0.8501 - loss: 0.4717 - val_acc: 0.7811 - val_auc: 0.8617 - val_loss: 0.4541\n",
      "Epoch 2590/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7695 - auc: 0.8494 - loss: 0.4725 - val_acc: 0.7808 - val_auc: 0.8614 - val_loss: 0.4537\n",
      "Epoch 2591/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7705 - auc: 0.8490 - loss: 0.4732 - val_acc: 0.7796 - val_auc: 0.8604 - val_loss: 0.4537\n",
      "Epoch 2592/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7681 - auc: 0.8475 - loss: 0.4764 - val_acc: 0.7840 - val_auc: 0.8613 - val_loss: 0.4529\n",
      "Epoch 2593/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7706 - auc: 0.8496 - loss: 0.4730 - val_acc: 0.7826 - val_auc: 0.8623 - val_loss: 0.4525\n",
      "Epoch 2594/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7708 - auc: 0.8508 - loss: 0.4713 - val_acc: 0.7802 - val_auc: 0.8619 - val_loss: 0.4549\n",
      "Epoch 2595/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7688 - auc: 0.8493 - loss: 0.4740 - val_acc: 0.7825 - val_auc: 0.8611 - val_loss: 0.4556\n",
      "Epoch 2596/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7699 - auc: 0.8499 - loss: 0.4719 - val_acc: 0.7867 - val_auc: 0.8634 - val_loss: 0.4517\n",
      "Epoch 2597/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7692 - auc: 0.8504 - loss: 0.4714 - val_acc: 0.7866 - val_auc: 0.8616 - val_loss: 0.4533\n",
      "Epoch 2598/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7703 - auc: 0.8494 - loss: 0.4730 - val_acc: 0.7808 - val_auc: 0.8611 - val_loss: 0.4542\n",
      "Epoch 2599/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7680 - auc: 0.8484 - loss: 0.4750 - val_acc: 0.7818 - val_auc: 0.8621 - val_loss: 0.4543\n",
      "Epoch 2600/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7712 - auc: 0.8501 - loss: 0.4718 - val_acc: 0.7816 - val_auc: 0.8610 - val_loss: 0.4549\n",
      "Epoch 2601/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7700 - auc: 0.8501 - loss: 0.4727 - val_acc: 0.7844 - val_auc: 0.8622 - val_loss: 0.4535\n",
      "Epoch 2602/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7686 - auc: 0.8493 - loss: 0.4736 - val_acc: 0.7827 - val_auc: 0.8620 - val_loss: 0.4529\n",
      "Epoch 2603/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7701 - auc: 0.8495 - loss: 0.4736 - val_acc: 0.7816 - val_auc: 0.8604 - val_loss: 0.4549\n",
      "Epoch 2604/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7678 - auc: 0.8483 - loss: 0.4753 - val_acc: 0.7808 - val_auc: 0.8606 - val_loss: 0.4553\n",
      "Epoch 2605/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7701 - auc: 0.8482 - loss: 0.4747 - val_acc: 0.7806 - val_auc: 0.8630 - val_loss: 0.4523\n",
      "Epoch 2606/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7712 - auc: 0.8517 - loss: 0.4706 - val_acc: 0.7824 - val_auc: 0.8602 - val_loss: 0.4547\n",
      "Epoch 2607/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7706 - auc: 0.8500 - loss: 0.4726 - val_acc: 0.7823 - val_auc: 0.8617 - val_loss: 0.4544\n",
      "Epoch 2608/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7684 - auc: 0.8483 - loss: 0.4748 - val_acc: 0.7782 - val_auc: 0.8607 - val_loss: 0.4568\n",
      "Epoch 2609/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7699 - auc: 0.8489 - loss: 0.4728 - val_acc: 0.7867 - val_auc: 0.8617 - val_loss: 0.4522\n",
      "Epoch 2610/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7698 - auc: 0.8496 - loss: 0.4727 - val_acc: 0.7838 - val_auc: 0.8611 - val_loss: 0.4544\n",
      "Epoch 2611/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7676 - auc: 0.8491 - loss: 0.4738 - val_acc: 0.7841 - val_auc: 0.8632 - val_loss: 0.4513\n",
      "Epoch 2612/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7698 - auc: 0.8488 - loss: 0.4741 - val_acc: 0.7817 - val_auc: 0.8620 - val_loss: 0.4525\n",
      "Epoch 2613/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7698 - auc: 0.8494 - loss: 0.4728 - val_acc: 0.7840 - val_auc: 0.8616 - val_loss: 0.4533\n",
      "Epoch 2614/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7704 - auc: 0.8486 - loss: 0.4739 - val_acc: 0.7804 - val_auc: 0.8607 - val_loss: 0.4558\n",
      "Epoch 2615/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7700 - auc: 0.8497 - loss: 0.4721 - val_acc: 0.7828 - val_auc: 0.8620 - val_loss: 0.4529\n",
      "Epoch 2616/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7717 - auc: 0.8513 - loss: 0.4708 - val_acc: 0.7818 - val_auc: 0.8625 - val_loss: 0.4532\n",
      "Epoch 2617/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7694 - auc: 0.8475 - loss: 0.4759 - val_acc: 0.7816 - val_auc: 0.8623 - val_loss: 0.4520\n",
      "Epoch 2618/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7703 - auc: 0.8493 - loss: 0.4737 - val_acc: 0.7841 - val_auc: 0.8630 - val_loss: 0.4512\n",
      "Epoch 2619/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7680 - auc: 0.8487 - loss: 0.4746 - val_acc: 0.7830 - val_auc: 0.8622 - val_loss: 0.4531\n",
      "Epoch 2620/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7692 - auc: 0.8489 - loss: 0.4735 - val_acc: 0.7810 - val_auc: 0.8617 - val_loss: 0.4537\n",
      "Epoch 2621/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7701 - auc: 0.8495 - loss: 0.4727 - val_acc: 0.7833 - val_auc: 0.8631 - val_loss: 0.4520\n",
      "Epoch 2622/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7694 - auc: 0.8507 - loss: 0.4706 - val_acc: 0.7816 - val_auc: 0.8626 - val_loss: 0.4523\n",
      "Epoch 2623/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7694 - auc: 0.8506 - loss: 0.4723 - val_acc: 0.7830 - val_auc: 0.8611 - val_loss: 0.4538\n",
      "Epoch 2624/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7704 - auc: 0.8490 - loss: 0.4740 - val_acc: 0.7813 - val_auc: 0.8622 - val_loss: 0.4540\n",
      "Epoch 2625/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7686 - auc: 0.8486 - loss: 0.4741 - val_acc: 0.7833 - val_auc: 0.8621 - val_loss: 0.4547\n",
      "Epoch 2626/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7718 - auc: 0.8509 - loss: 0.4713 - val_acc: 0.7806 - val_auc: 0.8586 - val_loss: 0.4587\n",
      "Epoch 2627/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7704 - auc: 0.8502 - loss: 0.4701 - val_acc: 0.7821 - val_auc: 0.8619 - val_loss: 0.4521\n",
      "Epoch 2628/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7693 - auc: 0.8496 - loss: 0.4743 - val_acc: 0.7840 - val_auc: 0.8630 - val_loss: 0.4516\n",
      "Epoch 2629/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7709 - auc: 0.8502 - loss: 0.4725 - val_acc: 0.7808 - val_auc: 0.8615 - val_loss: 0.4537\n",
      "Epoch 2630/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7681 - auc: 0.8496 - loss: 0.4729 - val_acc: 0.7852 - val_auc: 0.8626 - val_loss: 0.4520\n",
      "Epoch 2631/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7703 - auc: 0.8502 - loss: 0.4716 - val_acc: 0.7795 - val_auc: 0.8608 - val_loss: 0.4549\n",
      "Epoch 2632/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7701 - auc: 0.8496 - loss: 0.4736 - val_acc: 0.7835 - val_auc: 0.8630 - val_loss: 0.4521\n",
      "Epoch 2633/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7701 - auc: 0.8505 - loss: 0.4714 - val_acc: 0.7826 - val_auc: 0.8621 - val_loss: 0.4513\n",
      "Epoch 2634/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7681 - auc: 0.8492 - loss: 0.4736 - val_acc: 0.7824 - val_auc: 0.8621 - val_loss: 0.4540\n",
      "Epoch 2635/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7704 - auc: 0.8499 - loss: 0.4735 - val_acc: 0.7818 - val_auc: 0.8614 - val_loss: 0.4549\n",
      "Epoch 2636/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7695 - auc: 0.8491 - loss: 0.4741 - val_acc: 0.7803 - val_auc: 0.8609 - val_loss: 0.4536\n",
      "Epoch 2637/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7702 - auc: 0.8491 - loss: 0.4736 - val_acc: 0.7790 - val_auc: 0.8595 - val_loss: 0.4565\n",
      "Epoch 2638/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7717 - auc: 0.8510 - loss: 0.4714 - val_acc: 0.7828 - val_auc: 0.8632 - val_loss: 0.4514\n",
      "Epoch 2639/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7700 - auc: 0.8508 - loss: 0.4713 - val_acc: 0.7834 - val_auc: 0.8636 - val_loss: 0.4510\n",
      "Epoch 2640/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7701 - auc: 0.8505 - loss: 0.4714 - val_acc: 0.7838 - val_auc: 0.8622 - val_loss: 0.4528\n",
      "Epoch 2641/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7696 - auc: 0.8498 - loss: 0.4714 - val_acc: 0.7837 - val_auc: 0.8625 - val_loss: 0.4529\n",
      "Epoch 2642/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7686 - auc: 0.8492 - loss: 0.4738 - val_acc: 0.7836 - val_auc: 0.8628 - val_loss: 0.4525\n",
      "Epoch 2643/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7698 - auc: 0.8498 - loss: 0.4725 - val_acc: 0.7833 - val_auc: 0.8619 - val_loss: 0.4548\n",
      "Epoch 2644/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7681 - auc: 0.8481 - loss: 0.4751 - val_acc: 0.7816 - val_auc: 0.8631 - val_loss: 0.4512\n",
      "Epoch 2645/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7710 - auc: 0.8498 - loss: 0.4735 - val_acc: 0.7811 - val_auc: 0.8622 - val_loss: 0.4531\n",
      "Epoch 2646/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7705 - auc: 0.8497 - loss: 0.4726 - val_acc: 0.7824 - val_auc: 0.8618 - val_loss: 0.4537\n",
      "Epoch 2647/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7703 - auc: 0.8502 - loss: 0.4719 - val_acc: 0.7799 - val_auc: 0.8616 - val_loss: 0.4545\n",
      "Epoch 2648/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7696 - auc: 0.8489 - loss: 0.4737 - val_acc: 0.7836 - val_auc: 0.8618 - val_loss: 0.4533\n",
      "Epoch 2649/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7701 - auc: 0.8502 - loss: 0.4735 - val_acc: 0.7838 - val_auc: 0.8626 - val_loss: 0.4530\n",
      "Epoch 2650/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7717 - auc: 0.8507 - loss: 0.4718 - val_acc: 0.7828 - val_auc: 0.8637 - val_loss: 0.4521\n",
      "Epoch 2651/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7715 - auc: 0.8502 - loss: 0.4721 - val_acc: 0.7824 - val_auc: 0.8622 - val_loss: 0.4526\n",
      "Epoch 2652/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7712 - auc: 0.8497 - loss: 0.4723 - val_acc: 0.7846 - val_auc: 0.8625 - val_loss: 0.4521\n",
      "Epoch 2653/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7703 - auc: 0.8497 - loss: 0.4730 - val_acc: 0.7796 - val_auc: 0.8605 - val_loss: 0.4563\n",
      "Epoch 2654/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7707 - auc: 0.8506 - loss: 0.4723 - val_acc: 0.7829 - val_auc: 0.8630 - val_loss: 0.4524\n",
      "Epoch 2655/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7700 - auc: 0.8507 - loss: 0.4713 - val_acc: 0.7842 - val_auc: 0.8629 - val_loss: 0.4517\n",
      "Epoch 2656/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7686 - auc: 0.8499 - loss: 0.4727 - val_acc: 0.7808 - val_auc: 0.8624 - val_loss: 0.4542\n",
      "Epoch 2657/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7685 - auc: 0.8493 - loss: 0.4732 - val_acc: 0.7830 - val_auc: 0.8623 - val_loss: 0.4529\n",
      "Epoch 2658/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7703 - auc: 0.8504 - loss: 0.4715 - val_acc: 0.7828 - val_auc: 0.8610 - val_loss: 0.4538\n",
      "Epoch 2659/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7697 - auc: 0.8494 - loss: 0.4733 - val_acc: 0.7815 - val_auc: 0.8616 - val_loss: 0.4528\n",
      "Epoch 2660/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7699 - auc: 0.8498 - loss: 0.4724 - val_acc: 0.7803 - val_auc: 0.8601 - val_loss: 0.4540\n",
      "Epoch 2661/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7694 - auc: 0.8489 - loss: 0.4738 - val_acc: 0.7810 - val_auc: 0.8609 - val_loss: 0.4556\n",
      "Epoch 2662/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7706 - auc: 0.8508 - loss: 0.4713 - val_acc: 0.7817 - val_auc: 0.8619 - val_loss: 0.4528\n",
      "Epoch 2663/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7711 - auc: 0.8503 - loss: 0.4735 - val_acc: 0.7857 - val_auc: 0.8625 - val_loss: 0.4534\n",
      "Epoch 2664/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7683 - auc: 0.8494 - loss: 0.4739 - val_acc: 0.7821 - val_auc: 0.8619 - val_loss: 0.4533\n",
      "Epoch 2665/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7708 - auc: 0.8497 - loss: 0.4734 - val_acc: 0.7789 - val_auc: 0.8616 - val_loss: 0.4541\n",
      "Epoch 2666/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7718 - auc: 0.8517 - loss: 0.4694 - val_acc: 0.7828 - val_auc: 0.8607 - val_loss: 0.4543\n",
      "Epoch 2667/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7705 - auc: 0.8490 - loss: 0.4735 - val_acc: 0.7834 - val_auc: 0.8632 - val_loss: 0.4523\n",
      "Epoch 2668/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7676 - auc: 0.8482 - loss: 0.4755 - val_acc: 0.7853 - val_auc: 0.8630 - val_loss: 0.4522\n",
      "Epoch 2669/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7700 - auc: 0.8501 - loss: 0.4723 - val_acc: 0.7826 - val_auc: 0.8604 - val_loss: 0.4546\n",
      "Epoch 2670/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7688 - auc: 0.8500 - loss: 0.4729 - val_acc: 0.7831 - val_auc: 0.8610 - val_loss: 0.4542\n",
      "Epoch 2671/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7688 - auc: 0.8496 - loss: 0.4734 - val_acc: 0.7837 - val_auc: 0.8625 - val_loss: 0.4521\n",
      "Epoch 2672/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7728 - auc: 0.8514 - loss: 0.4702 - val_acc: 0.7801 - val_auc: 0.8629 - val_loss: 0.4531\n",
      "Epoch 2673/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7704 - auc: 0.8502 - loss: 0.4721 - val_acc: 0.7832 - val_auc: 0.8630 - val_loss: 0.4522\n",
      "Epoch 2674/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7696 - auc: 0.8483 - loss: 0.4749 - val_acc: 0.7805 - val_auc: 0.8614 - val_loss: 0.4541\n",
      "Epoch 2675/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7719 - auc: 0.8507 - loss: 0.4706 - val_acc: 0.7839 - val_auc: 0.8630 - val_loss: 0.4525\n",
      "Epoch 2676/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7713 - auc: 0.8500 - loss: 0.4725 - val_acc: 0.7829 - val_auc: 0.8632 - val_loss: 0.4513\n",
      "Epoch 2677/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7717 - auc: 0.8510 - loss: 0.4710 - val_acc: 0.7844 - val_auc: 0.8639 - val_loss: 0.4504\n",
      "Epoch 2678/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7696 - auc: 0.8507 - loss: 0.4715 - val_acc: 0.7811 - val_auc: 0.8623 - val_loss: 0.4540\n",
      "Epoch 2679/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7710 - auc: 0.8514 - loss: 0.4708 - val_acc: 0.7836 - val_auc: 0.8622 - val_loss: 0.4515\n",
      "Epoch 2680/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7730 - auc: 0.8515 - loss: 0.4703 - val_acc: 0.7856 - val_auc: 0.8623 - val_loss: 0.4519\n",
      "Epoch 2681/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7700 - auc: 0.8496 - loss: 0.4723 - val_acc: 0.7828 - val_auc: 0.8624 - val_loss: 0.4527\n",
      "Epoch 2682/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7697 - auc: 0.8501 - loss: 0.4721 - val_acc: 0.7843 - val_auc: 0.8639 - val_loss: 0.4506\n",
      "Epoch 2683/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7692 - auc: 0.8490 - loss: 0.4729 - val_acc: 0.7822 - val_auc: 0.8619 - val_loss: 0.4535\n",
      "Epoch 2684/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7689 - auc: 0.8491 - loss: 0.4733 - val_acc: 0.7834 - val_auc: 0.8617 - val_loss: 0.4534\n",
      "Epoch 2685/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7695 - auc: 0.8490 - loss: 0.4732 - val_acc: 0.7829 - val_auc: 0.8626 - val_loss: 0.4515\n",
      "Epoch 2686/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7718 - auc: 0.8507 - loss: 0.4722 - val_acc: 0.7826 - val_auc: 0.8629 - val_loss: 0.4527\n",
      "Epoch 2687/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7711 - auc: 0.8501 - loss: 0.4730 - val_acc: 0.7865 - val_auc: 0.8629 - val_loss: 0.4518\n",
      "Epoch 2688/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7699 - auc: 0.8501 - loss: 0.4723 - val_acc: 0.7815 - val_auc: 0.8614 - val_loss: 0.4541\n",
      "Epoch 2689/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7701 - auc: 0.8502 - loss: 0.4727 - val_acc: 0.7842 - val_auc: 0.8622 - val_loss: 0.4543\n",
      "Epoch 2690/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7687 - auc: 0.8492 - loss: 0.4746 - val_acc: 0.7824 - val_auc: 0.8627 - val_loss: 0.4534\n",
      "Epoch 2691/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7712 - auc: 0.8505 - loss: 0.4725 - val_acc: 0.7870 - val_auc: 0.8632 - val_loss: 0.4519\n",
      "Epoch 2692/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7709 - auc: 0.8496 - loss: 0.4725 - val_acc: 0.7845 - val_auc: 0.8621 - val_loss: 0.4538\n",
      "Epoch 2693/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7686 - auc: 0.8486 - loss: 0.4736 - val_acc: 0.7846 - val_auc: 0.8627 - val_loss: 0.4518\n",
      "Epoch 2694/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7703 - auc: 0.8491 - loss: 0.4737 - val_acc: 0.7870 - val_auc: 0.8637 - val_loss: 0.4508\n",
      "Epoch 2695/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7703 - auc: 0.8513 - loss: 0.4710 - val_acc: 0.7808 - val_auc: 0.8613 - val_loss: 0.4536\n",
      "Epoch 2696/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7691 - auc: 0.8500 - loss: 0.4738 - val_acc: 0.7830 - val_auc: 0.8634 - val_loss: 0.4510\n",
      "Epoch 2697/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7701 - auc: 0.8502 - loss: 0.4708 - val_acc: 0.7811 - val_auc: 0.8616 - val_loss: 0.4530\n",
      "Epoch 2698/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7699 - auc: 0.8495 - loss: 0.4732 - val_acc: 0.7828 - val_auc: 0.8625 - val_loss: 0.4512\n",
      "Epoch 2699/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7717 - auc: 0.8519 - loss: 0.4703 - val_acc: 0.7831 - val_auc: 0.8623 - val_loss: 0.4524\n",
      "Epoch 2700/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7697 - auc: 0.8504 - loss: 0.4718 - val_acc: 0.7834 - val_auc: 0.8631 - val_loss: 0.4510\n",
      "Epoch 2701/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7700 - auc: 0.8497 - loss: 0.4731 - val_acc: 0.7805 - val_auc: 0.8614 - val_loss: 0.4539\n",
      "Epoch 2702/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7715 - auc: 0.8511 - loss: 0.4706 - val_acc: 0.7844 - val_auc: 0.8635 - val_loss: 0.4500\n",
      "Epoch 2703/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7703 - auc: 0.8497 - loss: 0.4715 - val_acc: 0.7840 - val_auc: 0.8624 - val_loss: 0.4529\n",
      "Epoch 2704/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7698 - auc: 0.8495 - loss: 0.4736 - val_acc: 0.7827 - val_auc: 0.8618 - val_loss: 0.4522\n",
      "Epoch 2705/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7694 - auc: 0.8492 - loss: 0.4739 - val_acc: 0.7848 - val_auc: 0.8638 - val_loss: 0.4501\n",
      "Epoch 2706/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7703 - auc: 0.8513 - loss: 0.4694 - val_acc: 0.7813 - val_auc: 0.8630 - val_loss: 0.4512\n",
      "Epoch 2707/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7705 - auc: 0.8508 - loss: 0.4703 - val_acc: 0.7827 - val_auc: 0.8638 - val_loss: 0.4508\n",
      "Epoch 2708/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7708 - auc: 0.8510 - loss: 0.4704 - val_acc: 0.7836 - val_auc: 0.8627 - val_loss: 0.4518\n",
      "Epoch 2709/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7695 - auc: 0.8489 - loss: 0.4736 - val_acc: 0.7821 - val_auc: 0.8617 - val_loss: 0.4548\n",
      "Epoch 2710/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7715 - auc: 0.8505 - loss: 0.4726 - val_acc: 0.7834 - val_auc: 0.8622 - val_loss: 0.4544\n",
      "Epoch 2711/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7716 - auc: 0.8501 - loss: 0.4716 - val_acc: 0.7811 - val_auc: 0.8615 - val_loss: 0.4535\n",
      "Epoch 2712/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7678 - auc: 0.8477 - loss: 0.4756 - val_acc: 0.7841 - val_auc: 0.8643 - val_loss: 0.4502\n",
      "Epoch 2713/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7717 - auc: 0.8498 - loss: 0.4723 - val_acc: 0.7833 - val_auc: 0.8632 - val_loss: 0.4508\n",
      "Epoch 2714/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7703 - auc: 0.8501 - loss: 0.4724 - val_acc: 0.7856 - val_auc: 0.8629 - val_loss: 0.4518\n",
      "Epoch 2715/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7718 - auc: 0.8509 - loss: 0.4711 - val_acc: 0.7814 - val_auc: 0.8619 - val_loss: 0.4541\n",
      "Epoch 2716/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7695 - auc: 0.8506 - loss: 0.4710 - val_acc: 0.7828 - val_auc: 0.8622 - val_loss: 0.4518\n",
      "Epoch 2717/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7710 - auc: 0.8503 - loss: 0.4713 - val_acc: 0.7810 - val_auc: 0.8624 - val_loss: 0.4535\n",
      "Epoch 2718/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7689 - auc: 0.8485 - loss: 0.4744 - val_acc: 0.7826 - val_auc: 0.8610 - val_loss: 0.4543\n",
      "Epoch 2719/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7701 - auc: 0.8497 - loss: 0.4724 - val_acc: 0.7837 - val_auc: 0.8624 - val_loss: 0.4521\n",
      "Epoch 2720/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7705 - auc: 0.8489 - loss: 0.4729 - val_acc: 0.7831 - val_auc: 0.8630 - val_loss: 0.4531\n",
      "Epoch 2721/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7714 - auc: 0.8512 - loss: 0.4700 - val_acc: 0.7836 - val_auc: 0.8634 - val_loss: 0.4503\n",
      "Epoch 2722/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7705 - auc: 0.8504 - loss: 0.4728 - val_acc: 0.7822 - val_auc: 0.8629 - val_loss: 0.4522\n",
      "Epoch 2723/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7716 - auc: 0.8517 - loss: 0.4696 - val_acc: 0.7827 - val_auc: 0.8611 - val_loss: 0.4554\n",
      "Epoch 2724/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7728 - auc: 0.8520 - loss: 0.4697 - val_acc: 0.7844 - val_auc: 0.8623 - val_loss: 0.4526\n",
      "Epoch 2725/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7695 - auc: 0.8504 - loss: 0.4719 - val_acc: 0.7836 - val_auc: 0.8635 - val_loss: 0.4512\n",
      "Epoch 2726/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7718 - auc: 0.8510 - loss: 0.4710 - val_acc: 0.7862 - val_auc: 0.8636 - val_loss: 0.4527\n",
      "Epoch 2727/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7688 - auc: 0.8495 - loss: 0.4739 - val_acc: 0.7845 - val_auc: 0.8633 - val_loss: 0.4509\n",
      "Epoch 2728/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7708 - auc: 0.8506 - loss: 0.4718 - val_acc: 0.7830 - val_auc: 0.8637 - val_loss: 0.4517\n",
      "Epoch 2729/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7697 - auc: 0.8496 - loss: 0.4724 - val_acc: 0.7831 - val_auc: 0.8624 - val_loss: 0.4527\n",
      "Epoch 2730/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7709 - auc: 0.8510 - loss: 0.4708 - val_acc: 0.7849 - val_auc: 0.8631 - val_loss: 0.4505\n",
      "Epoch 2731/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7719 - auc: 0.8510 - loss: 0.4709 - val_acc: 0.7835 - val_auc: 0.8626 - val_loss: 0.4516\n",
      "Epoch 2732/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7716 - auc: 0.8509 - loss: 0.4716 - val_acc: 0.7818 - val_auc: 0.8620 - val_loss: 0.4522\n",
      "Epoch 2733/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7716 - auc: 0.8511 - loss: 0.4712 - val_acc: 0.7830 - val_auc: 0.8634 - val_loss: 0.4514\n",
      "Epoch 2734/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7707 - auc: 0.8497 - loss: 0.4729 - val_acc: 0.7854 - val_auc: 0.8644 - val_loss: 0.4504\n",
      "Epoch 2735/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7718 - auc: 0.8515 - loss: 0.4701 - val_acc: 0.7837 - val_auc: 0.8631 - val_loss: 0.4511\n",
      "Epoch 2736/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7708 - auc: 0.8510 - loss: 0.4708 - val_acc: 0.7837 - val_auc: 0.8630 - val_loss: 0.4512\n",
      "Epoch 2737/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7717 - auc: 0.8518 - loss: 0.4697 - val_acc: 0.7830 - val_auc: 0.8631 - val_loss: 0.4516\n",
      "Epoch 2738/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7717 - auc: 0.8499 - loss: 0.4719 - val_acc: 0.7812 - val_auc: 0.8613 - val_loss: 0.4552\n",
      "Epoch 2739/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7694 - auc: 0.8491 - loss: 0.4731 - val_acc: 0.7834 - val_auc: 0.8619 - val_loss: 0.4533\n",
      "Epoch 2740/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7741 - auc: 0.8521 - loss: 0.4693 - val_acc: 0.7833 - val_auc: 0.8623 - val_loss: 0.4519\n",
      "Epoch 2741/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7706 - auc: 0.8499 - loss: 0.4733 - val_acc: 0.7826 - val_auc: 0.8619 - val_loss: 0.4531\n",
      "Epoch 2742/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7722 - auc: 0.8513 - loss: 0.4712 - val_acc: 0.7842 - val_auc: 0.8630 - val_loss: 0.4514\n",
      "Epoch 2743/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7695 - auc: 0.8502 - loss: 0.4721 - val_acc: 0.7817 - val_auc: 0.8628 - val_loss: 0.4517\n",
      "Epoch 2744/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7705 - auc: 0.8501 - loss: 0.4722 - val_acc: 0.7837 - val_auc: 0.8630 - val_loss: 0.4515\n",
      "Epoch 2745/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7697 - auc: 0.8496 - loss: 0.4735 - val_acc: 0.7815 - val_auc: 0.8621 - val_loss: 0.4532\n",
      "Epoch 2746/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7720 - auc: 0.8514 - loss: 0.4706 - val_acc: 0.7826 - val_auc: 0.8621 - val_loss: 0.4512\n",
      "Epoch 2747/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7707 - auc: 0.8505 - loss: 0.4724 - val_acc: 0.7798 - val_auc: 0.8611 - val_loss: 0.4537\n",
      "Epoch 2748/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7726 - auc: 0.8513 - loss: 0.4697 - val_acc: 0.7841 - val_auc: 0.8627 - val_loss: 0.4524\n",
      "Epoch 2749/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7706 - auc: 0.8492 - loss: 0.4735 - val_acc: 0.7865 - val_auc: 0.8639 - val_loss: 0.4509\n",
      "Epoch 2750/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7712 - auc: 0.8511 - loss: 0.4718 - val_acc: 0.7845 - val_auc: 0.8637 - val_loss: 0.4526\n",
      "Epoch 2751/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7714 - auc: 0.8497 - loss: 0.4724 - val_acc: 0.7807 - val_auc: 0.8620 - val_loss: 0.4536\n",
      "Epoch 2752/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7707 - auc: 0.8496 - loss: 0.4734 - val_acc: 0.7853 - val_auc: 0.8636 - val_loss: 0.4511\n",
      "Epoch 2753/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7715 - auc: 0.8500 - loss: 0.4722 - val_acc: 0.7813 - val_auc: 0.8622 - val_loss: 0.4541\n",
      "Epoch 2754/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7698 - auc: 0.8490 - loss: 0.4729 - val_acc: 0.7811 - val_auc: 0.8622 - val_loss: 0.4516\n",
      "Epoch 2755/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7713 - auc: 0.8511 - loss: 0.4717 - val_acc: 0.7865 - val_auc: 0.8634 - val_loss: 0.4508\n",
      "Epoch 2756/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7722 - auc: 0.8514 - loss: 0.4705 - val_acc: 0.7853 - val_auc: 0.8634 - val_loss: 0.4518\n",
      "Epoch 2757/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7686 - auc: 0.8495 - loss: 0.4733 - val_acc: 0.7843 - val_auc: 0.8634 - val_loss: 0.4516\n",
      "Epoch 2758/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7713 - auc: 0.8518 - loss: 0.4699 - val_acc: 0.7807 - val_auc: 0.8610 - val_loss: 0.4544\n",
      "Epoch 2759/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7715 - auc: 0.8512 - loss: 0.4706 - val_acc: 0.7845 - val_auc: 0.8621 - val_loss: 0.4523\n",
      "Epoch 2760/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7732 - auc: 0.8520 - loss: 0.4688 - val_acc: 0.7840 - val_auc: 0.8624 - val_loss: 0.4528\n",
      "Epoch 2761/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7694 - auc: 0.8490 - loss: 0.4735 - val_acc: 0.7856 - val_auc: 0.8634 - val_loss: 0.4523\n",
      "Epoch 2762/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7701 - auc: 0.8488 - loss: 0.4728 - val_acc: 0.7844 - val_auc: 0.8624 - val_loss: 0.4525\n",
      "Epoch 2763/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7723 - auc: 0.8507 - loss: 0.4715 - val_acc: 0.7843 - val_auc: 0.8643 - val_loss: 0.4508\n",
      "Epoch 2764/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7728 - auc: 0.8516 - loss: 0.4708 - val_acc: 0.7812 - val_auc: 0.8613 - val_loss: 0.4553\n",
      "Epoch 2765/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7703 - auc: 0.8522 - loss: 0.4691 - val_acc: 0.7845 - val_auc: 0.8646 - val_loss: 0.4489\n",
      "Epoch 2766/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7733 - auc: 0.8512 - loss: 0.4713 - val_acc: 0.7828 - val_auc: 0.8637 - val_loss: 0.4514\n",
      "Epoch 2767/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7703 - auc: 0.8503 - loss: 0.4725 - val_acc: 0.7843 - val_auc: 0.8626 - val_loss: 0.4525\n",
      "Epoch 2768/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7712 - auc: 0.8514 - loss: 0.4714 - val_acc: 0.7839 - val_auc: 0.8625 - val_loss: 0.4534\n",
      "Epoch 2769/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7711 - auc: 0.8512 - loss: 0.4704 - val_acc: 0.7813 - val_auc: 0.8612 - val_loss: 0.4532\n",
      "Epoch 2770/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7725 - auc: 0.8513 - loss: 0.4717 - val_acc: 0.7826 - val_auc: 0.8623 - val_loss: 0.4526\n",
      "Epoch 2771/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7715 - auc: 0.8506 - loss: 0.4717 - val_acc: 0.7845 - val_auc: 0.8633 - val_loss: 0.4506\n",
      "Epoch 2772/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7716 - auc: 0.8512 - loss: 0.4708 - val_acc: 0.7840 - val_auc: 0.8635 - val_loss: 0.4514\n",
      "Epoch 2773/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7707 - auc: 0.8511 - loss: 0.4708 - val_acc: 0.7827 - val_auc: 0.8627 - val_loss: 0.4522\n",
      "Epoch 2774/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7714 - auc: 0.8506 - loss: 0.4720 - val_acc: 0.7843 - val_auc: 0.8628 - val_loss: 0.4533\n",
      "Epoch 2775/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7697 - auc: 0.8501 - loss: 0.4717 - val_acc: 0.7867 - val_auc: 0.8647 - val_loss: 0.4498\n",
      "Epoch 2776/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7711 - auc: 0.8517 - loss: 0.4692 - val_acc: 0.7820 - val_auc: 0.8621 - val_loss: 0.4528\n",
      "Epoch 2777/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7724 - auc: 0.8516 - loss: 0.4704 - val_acc: 0.7816 - val_auc: 0.8635 - val_loss: 0.4517\n",
      "Epoch 2778/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7713 - auc: 0.8504 - loss: 0.4719 - val_acc: 0.7821 - val_auc: 0.8641 - val_loss: 0.4512\n",
      "Epoch 2779/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7729 - auc: 0.8517 - loss: 0.4710 - val_acc: 0.7840 - val_auc: 0.8635 - val_loss: 0.4510\n",
      "Epoch 2780/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7699 - auc: 0.8496 - loss: 0.4722 - val_acc: 0.7855 - val_auc: 0.8641 - val_loss: 0.4513\n",
      "Epoch 2781/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7721 - auc: 0.8525 - loss: 0.4693 - val_acc: 0.7847 - val_auc: 0.8626 - val_loss: 0.4521\n",
      "Epoch 2782/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7715 - auc: 0.8509 - loss: 0.4703 - val_acc: 0.7825 - val_auc: 0.8618 - val_loss: 0.4528\n",
      "Epoch 2783/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7712 - auc: 0.8510 - loss: 0.4713 - val_acc: 0.7865 - val_auc: 0.8640 - val_loss: 0.4502\n",
      "Epoch 2784/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7718 - auc: 0.8509 - loss: 0.4723 - val_acc: 0.7816 - val_auc: 0.8624 - val_loss: 0.4540\n",
      "Epoch 2785/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7703 - auc: 0.8498 - loss: 0.4725 - val_acc: 0.7849 - val_auc: 0.8645 - val_loss: 0.4503\n",
      "Epoch 2786/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7716 - auc: 0.8517 - loss: 0.4697 - val_acc: 0.7825 - val_auc: 0.8624 - val_loss: 0.4517\n",
      "Epoch 2787/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7698 - auc: 0.8509 - loss: 0.4718 - val_acc: 0.7839 - val_auc: 0.8632 - val_loss: 0.4531\n",
      "Epoch 2788/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7738 - auc: 0.8508 - loss: 0.4708 - val_acc: 0.7848 - val_auc: 0.8641 - val_loss: 0.4501\n",
      "Epoch 2789/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7706 - auc: 0.8518 - loss: 0.4697 - val_acc: 0.7835 - val_auc: 0.8641 - val_loss: 0.4520\n",
      "Epoch 2790/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7704 - auc: 0.8518 - loss: 0.4694 - val_acc: 0.7835 - val_auc: 0.8640 - val_loss: 0.4506\n",
      "Epoch 2791/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7699 - auc: 0.8511 - loss: 0.4702 - val_acc: 0.7836 - val_auc: 0.8644 - val_loss: 0.4519\n",
      "Epoch 2792/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7718 - auc: 0.8518 - loss: 0.4691 - val_acc: 0.7846 - val_auc: 0.8636 - val_loss: 0.4510\n",
      "Epoch 2793/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7719 - auc: 0.8511 - loss: 0.4707 - val_acc: 0.7830 - val_auc: 0.8634 - val_loss: 0.4507\n",
      "Epoch 2794/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7710 - auc: 0.8510 - loss: 0.4704 - val_acc: 0.7847 - val_auc: 0.8635 - val_loss: 0.4510\n",
      "Epoch 2795/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7702 - auc: 0.8500 - loss: 0.4725 - val_acc: 0.7865 - val_auc: 0.8644 - val_loss: 0.4510\n",
      "Epoch 2796/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7740 - auc: 0.8524 - loss: 0.4696 - val_acc: 0.7851 - val_auc: 0.8640 - val_loss: 0.4504\n",
      "Epoch 2797/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7713 - auc: 0.8503 - loss: 0.4722 - val_acc: 0.7851 - val_auc: 0.8635 - val_loss: 0.4502\n",
      "Epoch 2798/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7715 - auc: 0.8509 - loss: 0.4711 - val_acc: 0.7871 - val_auc: 0.8645 - val_loss: 0.4510\n",
      "Epoch 2799/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7708 - auc: 0.8511 - loss: 0.4706 - val_acc: 0.7851 - val_auc: 0.8638 - val_loss: 0.4505\n",
      "Epoch 2800/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7713 - auc: 0.8511 - loss: 0.4717 - val_acc: 0.7853 - val_auc: 0.8616 - val_loss: 0.4534\n",
      "Epoch 2801/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7704 - auc: 0.8512 - loss: 0.4716 - val_acc: 0.7864 - val_auc: 0.8636 - val_loss: 0.4508\n",
      "Epoch 2802/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7704 - auc: 0.8493 - loss: 0.4737 - val_acc: 0.7829 - val_auc: 0.8638 - val_loss: 0.4522\n",
      "Epoch 2803/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7735 - auc: 0.8526 - loss: 0.4692 - val_acc: 0.7828 - val_auc: 0.8628 - val_loss: 0.4512\n",
      "Epoch 2804/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7698 - auc: 0.8502 - loss: 0.4724 - val_acc: 0.7837 - val_auc: 0.8626 - val_loss: 0.4514\n",
      "Epoch 2805/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7730 - auc: 0.8512 - loss: 0.4706 - val_acc: 0.7866 - val_auc: 0.8652 - val_loss: 0.4502\n",
      "Epoch 2806/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7700 - auc: 0.8507 - loss: 0.4714 - val_acc: 0.7832 - val_auc: 0.8638 - val_loss: 0.4503\n",
      "Epoch 2807/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7699 - auc: 0.8502 - loss: 0.4731 - val_acc: 0.7852 - val_auc: 0.8638 - val_loss: 0.4500\n",
      "Epoch 2808/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7702 - auc: 0.8505 - loss: 0.4714 - val_acc: 0.7832 - val_auc: 0.8643 - val_loss: 0.4527\n",
      "Epoch 2809/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7702 - auc: 0.8507 - loss: 0.4704 - val_acc: 0.7855 - val_auc: 0.8641 - val_loss: 0.4494\n",
      "Epoch 2810/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7712 - auc: 0.8506 - loss: 0.4713 - val_acc: 0.7833 - val_auc: 0.8634 - val_loss: 0.4512\n",
      "Epoch 2811/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7707 - auc: 0.8500 - loss: 0.4722 - val_acc: 0.7837 - val_auc: 0.8633 - val_loss: 0.4522\n",
      "Epoch 2812/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7711 - auc: 0.8509 - loss: 0.4707 - val_acc: 0.7839 - val_auc: 0.8626 - val_loss: 0.4524\n",
      "Epoch 2813/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7725 - auc: 0.8519 - loss: 0.4700 - val_acc: 0.7837 - val_auc: 0.8639 - val_loss: 0.4516\n",
      "Epoch 2814/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7704 - auc: 0.8497 - loss: 0.4714 - val_acc: 0.7855 - val_auc: 0.8634 - val_loss: 0.4511\n",
      "Epoch 2815/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7737 - auc: 0.8512 - loss: 0.4706 - val_acc: 0.7832 - val_auc: 0.8621 - val_loss: 0.4530\n",
      "Epoch 2816/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7711 - auc: 0.8516 - loss: 0.4700 - val_acc: 0.7826 - val_auc: 0.8626 - val_loss: 0.4530\n",
      "Epoch 2817/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7677 - auc: 0.8494 - loss: 0.4723 - val_acc: 0.7858 - val_auc: 0.8644 - val_loss: 0.4499\n",
      "Epoch 2818/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7705 - auc: 0.8523 - loss: 0.4701 - val_acc: 0.7836 - val_auc: 0.8631 - val_loss: 0.4523\n",
      "Epoch 2819/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7717 - auc: 0.8510 - loss: 0.4715 - val_acc: 0.7877 - val_auc: 0.8638 - val_loss: 0.4502\n",
      "Epoch 2820/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7719 - auc: 0.8520 - loss: 0.4697 - val_acc: 0.7837 - val_auc: 0.8640 - val_loss: 0.4493\n",
      "Epoch 2821/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7709 - auc: 0.8508 - loss: 0.4723 - val_acc: 0.7839 - val_auc: 0.8631 - val_loss: 0.4523\n",
      "Epoch 2822/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7725 - auc: 0.8514 - loss: 0.4704 - val_acc: 0.7831 - val_auc: 0.8618 - val_loss: 0.4537\n",
      "Epoch 2823/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7715 - auc: 0.8513 - loss: 0.4717 - val_acc: 0.7851 - val_auc: 0.8643 - val_loss: 0.4499\n",
      "Epoch 2824/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7738 - auc: 0.8526 - loss: 0.4691 - val_acc: 0.7839 - val_auc: 0.8646 - val_loss: 0.4513\n",
      "Epoch 2825/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7718 - auc: 0.8513 - loss: 0.4708 - val_acc: 0.7838 - val_auc: 0.8634 - val_loss: 0.4493\n",
      "Epoch 2826/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7719 - auc: 0.8515 - loss: 0.4705 - val_acc: 0.7821 - val_auc: 0.8625 - val_loss: 0.4520\n",
      "Epoch 2827/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7740 - auc: 0.8526 - loss: 0.4682 - val_acc: 0.7849 - val_auc: 0.8637 - val_loss: 0.4511\n",
      "Epoch 2828/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7711 - auc: 0.8518 - loss: 0.4697 - val_acc: 0.7855 - val_auc: 0.8631 - val_loss: 0.4515\n",
      "Epoch 2829/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7698 - auc: 0.8497 - loss: 0.4730 - val_acc: 0.7843 - val_auc: 0.8632 - val_loss: 0.4522\n",
      "Epoch 2830/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7725 - auc: 0.8518 - loss: 0.4690 - val_acc: 0.7854 - val_auc: 0.8638 - val_loss: 0.4490\n",
      "Epoch 2831/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7727 - auc: 0.8515 - loss: 0.4711 - val_acc: 0.7816 - val_auc: 0.8622 - val_loss: 0.4511\n",
      "Epoch 2832/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7719 - auc: 0.8508 - loss: 0.4715 - val_acc: 0.7846 - val_auc: 0.8635 - val_loss: 0.4516\n",
      "Epoch 2833/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7687 - auc: 0.8488 - loss: 0.4739 - val_acc: 0.7828 - val_auc: 0.8627 - val_loss: 0.4540\n",
      "Epoch 2834/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7729 - auc: 0.8515 - loss: 0.4695 - val_acc: 0.7830 - val_auc: 0.8627 - val_loss: 0.4519\n",
      "Epoch 2835/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7696 - auc: 0.8511 - loss: 0.4710 - val_acc: 0.7839 - val_auc: 0.8638 - val_loss: 0.4502\n",
      "Epoch 2836/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7683 - auc: 0.8486 - loss: 0.4740 - val_acc: 0.7861 - val_auc: 0.8627 - val_loss: 0.4525\n",
      "Epoch 2837/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7702 - auc: 0.8499 - loss: 0.4731 - val_acc: 0.7847 - val_auc: 0.8629 - val_loss: 0.4520\n",
      "Epoch 2838/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7709 - auc: 0.8514 - loss: 0.4723 - val_acc: 0.7837 - val_auc: 0.8633 - val_loss: 0.4510\n",
      "Epoch 2839/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7708 - auc: 0.8501 - loss: 0.4722 - val_acc: 0.7874 - val_auc: 0.8651 - val_loss: 0.4491\n",
      "Epoch 2840/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7707 - auc: 0.8489 - loss: 0.4733 - val_acc: 0.7827 - val_auc: 0.8626 - val_loss: 0.4527\n",
      "Epoch 2841/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7706 - auc: 0.8510 - loss: 0.4718 - val_acc: 0.7837 - val_auc: 0.8636 - val_loss: 0.4525\n",
      "Epoch 2842/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7731 - auc: 0.8521 - loss: 0.4700 - val_acc: 0.7836 - val_auc: 0.8631 - val_loss: 0.4521\n",
      "Epoch 2843/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7716 - auc: 0.8508 - loss: 0.4701 - val_acc: 0.7827 - val_auc: 0.8638 - val_loss: 0.4510\n",
      "Epoch 2844/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7694 - auc: 0.8482 - loss: 0.4745 - val_acc: 0.7843 - val_auc: 0.8644 - val_loss: 0.4512\n",
      "Epoch 2845/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7732 - auc: 0.8532 - loss: 0.4684 - val_acc: 0.7842 - val_auc: 0.8633 - val_loss: 0.4520\n",
      "Epoch 2846/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7720 - auc: 0.8519 - loss: 0.4701 - val_acc: 0.7836 - val_auc: 0.8621 - val_loss: 0.4526\n",
      "Epoch 2847/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7734 - auc: 0.8530 - loss: 0.4684 - val_acc: 0.7859 - val_auc: 0.8649 - val_loss: 0.4489\n",
      "Epoch 2848/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7718 - auc: 0.8507 - loss: 0.4708 - val_acc: 0.7836 - val_auc: 0.8624 - val_loss: 0.4545\n",
      "Epoch 2849/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7709 - auc: 0.8510 - loss: 0.4710 - val_acc: 0.7830 - val_auc: 0.8624 - val_loss: 0.4520\n",
      "Epoch 2850/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7709 - auc: 0.8501 - loss: 0.4722 - val_acc: 0.7843 - val_auc: 0.8630 - val_loss: 0.4526\n",
      "Epoch 2851/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7722 - auc: 0.8507 - loss: 0.4720 - val_acc: 0.7847 - val_auc: 0.8642 - val_loss: 0.4507\n",
      "Epoch 2852/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7712 - auc: 0.8518 - loss: 0.4706 - val_acc: 0.7851 - val_auc: 0.8623 - val_loss: 0.4508\n",
      "Epoch 2853/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7729 - auc: 0.8528 - loss: 0.4682 - val_acc: 0.7835 - val_auc: 0.8637 - val_loss: 0.4502\n",
      "Epoch 2854/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7735 - auc: 0.8517 - loss: 0.4694 - val_acc: 0.7855 - val_auc: 0.8640 - val_loss: 0.4505\n",
      "Epoch 2855/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7701 - auc: 0.8505 - loss: 0.4712 - val_acc: 0.7863 - val_auc: 0.8641 - val_loss: 0.4512\n",
      "Epoch 2856/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7714 - auc: 0.8519 - loss: 0.4698 - val_acc: 0.7825 - val_auc: 0.8640 - val_loss: 0.4526\n",
      "Epoch 2857/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7717 - auc: 0.8513 - loss: 0.4704 - val_acc: 0.7846 - val_auc: 0.8642 - val_loss: 0.4502\n",
      "Epoch 2858/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7736 - auc: 0.8522 - loss: 0.4702 - val_acc: 0.7828 - val_auc: 0.8633 - val_loss: 0.4537\n",
      "Epoch 2859/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7731 - auc: 0.8526 - loss: 0.4698 - val_acc: 0.7875 - val_auc: 0.8653 - val_loss: 0.4514\n",
      "Epoch 2860/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7706 - auc: 0.8512 - loss: 0.4717 - val_acc: 0.7837 - val_auc: 0.8628 - val_loss: 0.4513\n",
      "Epoch 2861/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7733 - auc: 0.8517 - loss: 0.4691 - val_acc: 0.7831 - val_auc: 0.8638 - val_loss: 0.4497\n",
      "Epoch 2862/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7706 - auc: 0.8513 - loss: 0.4699 - val_acc: 0.7841 - val_auc: 0.8626 - val_loss: 0.4529\n",
      "Epoch 2863/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7717 - auc: 0.8517 - loss: 0.4701 - val_acc: 0.7841 - val_auc: 0.8632 - val_loss: 0.4508\n",
      "Epoch 2864/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7722 - auc: 0.8527 - loss: 0.4685 - val_acc: 0.7857 - val_auc: 0.8636 - val_loss: 0.4493\n",
      "Epoch 2865/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7727 - auc: 0.8528 - loss: 0.4692 - val_acc: 0.7846 - val_auc: 0.8623 - val_loss: 0.4527\n",
      "Epoch 2866/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7727 - auc: 0.8517 - loss: 0.4696 - val_acc: 0.7817 - val_auc: 0.8631 - val_loss: 0.4509\n",
      "Epoch 2867/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7729 - auc: 0.8508 - loss: 0.4716 - val_acc: 0.7868 - val_auc: 0.8634 - val_loss: 0.4508\n",
      "Epoch 2868/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7746 - auc: 0.8528 - loss: 0.4682 - val_acc: 0.7860 - val_auc: 0.8637 - val_loss: 0.4517\n",
      "Epoch 2869/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7720 - auc: 0.8507 - loss: 0.4702 - val_acc: 0.7856 - val_auc: 0.8641 - val_loss: 0.4505\n",
      "Epoch 2870/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7700 - auc: 0.8509 - loss: 0.4714 - val_acc: 0.7804 - val_auc: 0.8630 - val_loss: 0.4520\n",
      "Epoch 2871/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7717 - auc: 0.8514 - loss: 0.4703 - val_acc: 0.7833 - val_auc: 0.8643 - val_loss: 0.4511\n",
      "Epoch 2872/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7728 - auc: 0.8522 - loss: 0.4692 - val_acc: 0.7851 - val_auc: 0.8637 - val_loss: 0.4496\n",
      "Epoch 2873/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7719 - auc: 0.8515 - loss: 0.4698 - val_acc: 0.7866 - val_auc: 0.8647 - val_loss: 0.4501\n",
      "Epoch 2874/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7715 - auc: 0.8512 - loss: 0.4721 - val_acc: 0.7848 - val_auc: 0.8642 - val_loss: 0.4497\n",
      "Epoch 2875/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7731 - auc: 0.8519 - loss: 0.4702 - val_acc: 0.7853 - val_auc: 0.8643 - val_loss: 0.4505\n",
      "Epoch 2876/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7724 - auc: 0.8501 - loss: 0.4720 - val_acc: 0.7841 - val_auc: 0.8632 - val_loss: 0.4514\n",
      "Epoch 2877/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7701 - auc: 0.8506 - loss: 0.4719 - val_acc: 0.7869 - val_auc: 0.8649 - val_loss: 0.4508\n",
      "Epoch 2878/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7740 - auc: 0.8521 - loss: 0.4698 - val_acc: 0.7864 - val_auc: 0.8635 - val_loss: 0.4505\n",
      "Epoch 2879/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7708 - auc: 0.8512 - loss: 0.4705 - val_acc: 0.7877 - val_auc: 0.8641 - val_loss: 0.4501\n",
      "Epoch 2880/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7692 - auc: 0.8502 - loss: 0.4720 - val_acc: 0.7852 - val_auc: 0.8630 - val_loss: 0.4519\n",
      "Epoch 2881/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7753 - auc: 0.8541 - loss: 0.4674 - val_acc: 0.7861 - val_auc: 0.8645 - val_loss: 0.4496\n",
      "Epoch 2882/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7709 - auc: 0.8517 - loss: 0.4699 - val_acc: 0.7840 - val_auc: 0.8625 - val_loss: 0.4515\n",
      "Epoch 2883/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7708 - auc: 0.8508 - loss: 0.4714 - val_acc: 0.7844 - val_auc: 0.8629 - val_loss: 0.4507\n",
      "Epoch 2884/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7714 - auc: 0.8513 - loss: 0.4703 - val_acc: 0.7820 - val_auc: 0.8638 - val_loss: 0.4515\n",
      "Epoch 2885/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7720 - auc: 0.8523 - loss: 0.4686 - val_acc: 0.7854 - val_auc: 0.8644 - val_loss: 0.4496\n",
      "Epoch 2886/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7725 - auc: 0.8512 - loss: 0.4711 - val_acc: 0.7842 - val_auc: 0.8642 - val_loss: 0.4512\n",
      "Epoch 2887/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7720 - auc: 0.8517 - loss: 0.4703 - val_acc: 0.7848 - val_auc: 0.8644 - val_loss: 0.4508\n",
      "Epoch 2888/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7725 - auc: 0.8510 - loss: 0.4711 - val_acc: 0.7840 - val_auc: 0.8641 - val_loss: 0.4510\n",
      "Epoch 2889/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7709 - auc: 0.8508 - loss: 0.4711 - val_acc: 0.7856 - val_auc: 0.8646 - val_loss: 0.4508\n",
      "Epoch 2890/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7730 - auc: 0.8516 - loss: 0.4709 - val_acc: 0.7846 - val_auc: 0.8634 - val_loss: 0.4515\n",
      "Epoch 2891/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7704 - auc: 0.8495 - loss: 0.4726 - val_acc: 0.7866 - val_auc: 0.8646 - val_loss: 0.4512\n",
      "Epoch 2892/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7703 - auc: 0.8505 - loss: 0.4716 - val_acc: 0.7828 - val_auc: 0.8632 - val_loss: 0.4524\n",
      "Epoch 2893/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7717 - auc: 0.8504 - loss: 0.4725 - val_acc: 0.7842 - val_auc: 0.8643 - val_loss: 0.4510\n",
      "Epoch 2894/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7717 - auc: 0.8503 - loss: 0.4719 - val_acc: 0.7843 - val_auc: 0.8626 - val_loss: 0.4534\n",
      "Epoch 2895/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7720 - auc: 0.8519 - loss: 0.4698 - val_acc: 0.7831 - val_auc: 0.8644 - val_loss: 0.4509\n",
      "Epoch 2896/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7725 - auc: 0.8525 - loss: 0.4693 - val_acc: 0.7838 - val_auc: 0.8635 - val_loss: 0.4517\n",
      "Epoch 2897/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7720 - auc: 0.8514 - loss: 0.4715 - val_acc: 0.7841 - val_auc: 0.8644 - val_loss: 0.4502\n",
      "Epoch 2898/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7715 - auc: 0.8507 - loss: 0.4709 - val_acc: 0.7817 - val_auc: 0.8615 - val_loss: 0.4528\n",
      "Epoch 2899/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7724 - auc: 0.8521 - loss: 0.4699 - val_acc: 0.7854 - val_auc: 0.8631 - val_loss: 0.4514\n",
      "Epoch 2900/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7718 - auc: 0.8512 - loss: 0.4703 - val_acc: 0.7846 - val_auc: 0.8640 - val_loss: 0.4505\n",
      "Epoch 2901/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7718 - auc: 0.8516 - loss: 0.4703 - val_acc: 0.7850 - val_auc: 0.8634 - val_loss: 0.4499\n",
      "Epoch 2902/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7714 - auc: 0.8521 - loss: 0.4693 - val_acc: 0.7846 - val_auc: 0.8645 - val_loss: 0.4505\n",
      "Epoch 2903/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7707 - auc: 0.8511 - loss: 0.4704 - val_acc: 0.7835 - val_auc: 0.8636 - val_loss: 0.4511\n",
      "Epoch 2904/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7699 - auc: 0.8487 - loss: 0.4741 - val_acc: 0.7852 - val_auc: 0.8642 - val_loss: 0.4507\n",
      "Epoch 2905/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7723 - auc: 0.8514 - loss: 0.4697 - val_acc: 0.7867 - val_auc: 0.8654 - val_loss: 0.4482\n",
      "Epoch 2906/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7703 - auc: 0.8506 - loss: 0.4723 - val_acc: 0.7843 - val_auc: 0.8638 - val_loss: 0.4508\n",
      "Epoch 2907/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7727 - auc: 0.8515 - loss: 0.4698 - val_acc: 0.7856 - val_auc: 0.8639 - val_loss: 0.4506\n",
      "Epoch 2908/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7715 - auc: 0.8520 - loss: 0.4687 - val_acc: 0.7819 - val_auc: 0.8639 - val_loss: 0.4518\n",
      "Epoch 2909/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7728 - auc: 0.8526 - loss: 0.4690 - val_acc: 0.7860 - val_auc: 0.8643 - val_loss: 0.4511\n",
      "Epoch 2910/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7713 - auc: 0.8519 - loss: 0.4698 - val_acc: 0.7865 - val_auc: 0.8653 - val_loss: 0.4501\n",
      "Epoch 2911/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7706 - auc: 0.8491 - loss: 0.4734 - val_acc: 0.7853 - val_auc: 0.8641 - val_loss: 0.4503\n",
      "Epoch 2912/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7726 - auc: 0.8515 - loss: 0.4706 - val_acc: 0.7830 - val_auc: 0.8637 - val_loss: 0.4526\n",
      "Epoch 2913/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7714 - auc: 0.8505 - loss: 0.4719 - val_acc: 0.7858 - val_auc: 0.8639 - val_loss: 0.4516\n",
      "Epoch 2914/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7733 - auc: 0.8520 - loss: 0.4705 - val_acc: 0.7854 - val_auc: 0.8633 - val_loss: 0.4518\n",
      "Epoch 2915/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7713 - auc: 0.8511 - loss: 0.4704 - val_acc: 0.7857 - val_auc: 0.8642 - val_loss: 0.4505\n",
      "Epoch 2916/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7710 - auc: 0.8503 - loss: 0.4719 - val_acc: 0.7855 - val_auc: 0.8626 - val_loss: 0.4521\n",
      "Epoch 2917/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7712 - auc: 0.8514 - loss: 0.4707 - val_acc: 0.7850 - val_auc: 0.8626 - val_loss: 0.4513\n",
      "Epoch 2918/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7703 - auc: 0.8505 - loss: 0.4706 - val_acc: 0.7823 - val_auc: 0.8612 - val_loss: 0.4545\n",
      "Epoch 2919/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7725 - auc: 0.8515 - loss: 0.4693 - val_acc: 0.7853 - val_auc: 0.8643 - val_loss: 0.4516\n",
      "Epoch 2920/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7738 - auc: 0.8533 - loss: 0.4677 - val_acc: 0.7846 - val_auc: 0.8635 - val_loss: 0.4507\n",
      "Epoch 2921/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7696 - auc: 0.8501 - loss: 0.4727 - val_acc: 0.7835 - val_auc: 0.8628 - val_loss: 0.4528\n",
      "Epoch 2922/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7720 - auc: 0.8517 - loss: 0.4711 - val_acc: 0.7877 - val_auc: 0.8647 - val_loss: 0.4499\n",
      "Epoch 2923/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7693 - auc: 0.8501 - loss: 0.4719 - val_acc: 0.7862 - val_auc: 0.8638 - val_loss: 0.4517\n",
      "Epoch 2924/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7721 - auc: 0.8509 - loss: 0.4718 - val_acc: 0.7848 - val_auc: 0.8638 - val_loss: 0.4499\n",
      "Epoch 2925/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7699 - auc: 0.8514 - loss: 0.4701 - val_acc: 0.7878 - val_auc: 0.8642 - val_loss: 0.4505\n",
      "Epoch 2926/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7708 - auc: 0.8513 - loss: 0.4699 - val_acc: 0.7836 - val_auc: 0.8625 - val_loss: 0.4523\n",
      "Epoch 2927/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7712 - auc: 0.8517 - loss: 0.4708 - val_acc: 0.7833 - val_auc: 0.8638 - val_loss: 0.4513\n",
      "Epoch 2928/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7723 - auc: 0.8524 - loss: 0.4689 - val_acc: 0.7826 - val_auc: 0.8624 - val_loss: 0.4542\n",
      "Epoch 2929/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7718 - auc: 0.8513 - loss: 0.4706 - val_acc: 0.7849 - val_auc: 0.8637 - val_loss: 0.4517\n",
      "Epoch 2930/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7717 - auc: 0.8518 - loss: 0.4693 - val_acc: 0.7867 - val_auc: 0.8634 - val_loss: 0.4511\n",
      "Epoch 2931/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7701 - auc: 0.8504 - loss: 0.4714 - val_acc: 0.7867 - val_auc: 0.8647 - val_loss: 0.4494\n",
      "Epoch 2932/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7735 - auc: 0.8523 - loss: 0.4702 - val_acc: 0.7833 - val_auc: 0.8632 - val_loss: 0.4527\n",
      "Epoch 2933/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7722 - auc: 0.8520 - loss: 0.4689 - val_acc: 0.7848 - val_auc: 0.8650 - val_loss: 0.4504\n",
      "Epoch 2934/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7710 - auc: 0.8521 - loss: 0.4688 - val_acc: 0.7833 - val_auc: 0.8638 - val_loss: 0.4513\n",
      "Epoch 2935/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7716 - auc: 0.8521 - loss: 0.4693 - val_acc: 0.7834 - val_auc: 0.8635 - val_loss: 0.4508\n",
      "Epoch 2936/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7696 - auc: 0.8519 - loss: 0.4696 - val_acc: 0.7816 - val_auc: 0.8647 - val_loss: 0.4524\n",
      "Epoch 2937/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7717 - auc: 0.8518 - loss: 0.4700 - val_acc: 0.7816 - val_auc: 0.8630 - val_loss: 0.4518\n",
      "Epoch 2938/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7728 - auc: 0.8518 - loss: 0.4700 - val_acc: 0.7832 - val_auc: 0.8624 - val_loss: 0.4513\n",
      "Epoch 2939/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7716 - auc: 0.8498 - loss: 0.4719 - val_acc: 0.7838 - val_auc: 0.8638 - val_loss: 0.4519\n",
      "Epoch 2940/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7714 - auc: 0.8505 - loss: 0.4710 - val_acc: 0.7852 - val_auc: 0.8644 - val_loss: 0.4501\n",
      "Epoch 2941/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7685 - auc: 0.8508 - loss: 0.4715 - val_acc: 0.7847 - val_auc: 0.8650 - val_loss: 0.4505\n",
      "Epoch 2942/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7721 - auc: 0.8521 - loss: 0.4691 - val_acc: 0.7817 - val_auc: 0.8623 - val_loss: 0.4532\n",
      "Epoch 2943/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7702 - auc: 0.8505 - loss: 0.4719 - val_acc: 0.7857 - val_auc: 0.8650 - val_loss: 0.4498\n",
      "Epoch 2944/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7698 - auc: 0.8503 - loss: 0.4719 - val_acc: 0.7845 - val_auc: 0.8644 - val_loss: 0.4505\n",
      "Epoch 2945/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7740 - auc: 0.8527 - loss: 0.4691 - val_acc: 0.7843 - val_auc: 0.8642 - val_loss: 0.4513\n",
      "Epoch 2946/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7742 - auc: 0.8525 - loss: 0.4684 - val_acc: 0.7859 - val_auc: 0.8649 - val_loss: 0.4479\n",
      "Epoch 2947/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7696 - auc: 0.8509 - loss: 0.4714 - val_acc: 0.7859 - val_auc: 0.8634 - val_loss: 0.4511\n",
      "Epoch 2948/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7730 - auc: 0.8512 - loss: 0.4709 - val_acc: 0.7831 - val_auc: 0.8639 - val_loss: 0.4506\n",
      "Epoch 2949/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7721 - auc: 0.8527 - loss: 0.4676 - val_acc: 0.7883 - val_auc: 0.8659 - val_loss: 0.4488\n",
      "Epoch 2950/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7706 - auc: 0.8515 - loss: 0.4694 - val_acc: 0.7830 - val_auc: 0.8633 - val_loss: 0.4497\n",
      "Epoch 2951/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7713 - auc: 0.8506 - loss: 0.4720 - val_acc: 0.7818 - val_auc: 0.8621 - val_loss: 0.4537\n",
      "Epoch 2952/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7716 - auc: 0.8516 - loss: 0.4707 - val_acc: 0.7831 - val_auc: 0.8640 - val_loss: 0.4525\n",
      "Epoch 2953/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7729 - auc: 0.8523 - loss: 0.4683 - val_acc: 0.7845 - val_auc: 0.8643 - val_loss: 0.4500\n",
      "Epoch 2954/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7725 - auc: 0.8525 - loss: 0.4683 - val_acc: 0.7856 - val_auc: 0.8643 - val_loss: 0.4488\n",
      "Epoch 2955/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7718 - auc: 0.8513 - loss: 0.4700 - val_acc: 0.7830 - val_auc: 0.8641 - val_loss: 0.4513\n",
      "Epoch 2956/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7686 - auc: 0.8495 - loss: 0.4727 - val_acc: 0.7869 - val_auc: 0.8649 - val_loss: 0.4475\n",
      "Epoch 2957/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7707 - auc: 0.8508 - loss: 0.4724 - val_acc: 0.7869 - val_auc: 0.8650 - val_loss: 0.4490\n",
      "Epoch 2958/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7740 - auc: 0.8516 - loss: 0.4703 - val_acc: 0.7830 - val_auc: 0.8625 - val_loss: 0.4516\n",
      "Epoch 2959/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7712 - auc: 0.8527 - loss: 0.4694 - val_acc: 0.7836 - val_auc: 0.8637 - val_loss: 0.4508\n",
      "Epoch 2960/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7702 - auc: 0.8506 - loss: 0.4717 - val_acc: 0.7853 - val_auc: 0.8632 - val_loss: 0.4506\n",
      "Epoch 2961/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7732 - auc: 0.8512 - loss: 0.4708 - val_acc: 0.7828 - val_auc: 0.8631 - val_loss: 0.4524\n",
      "Epoch 2962/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7719 - auc: 0.8513 - loss: 0.4703 - val_acc: 0.7849 - val_auc: 0.8644 - val_loss: 0.4505\n",
      "Epoch 2963/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7730 - auc: 0.8513 - loss: 0.4709 - val_acc: 0.7845 - val_auc: 0.8631 - val_loss: 0.4509\n",
      "Epoch 2964/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7726 - auc: 0.8523 - loss: 0.4696 - val_acc: 0.7853 - val_auc: 0.8645 - val_loss: 0.4498\n",
      "Epoch 2965/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7725 - auc: 0.8511 - loss: 0.4705 - val_acc: 0.7844 - val_auc: 0.8634 - val_loss: 0.4518\n",
      "Epoch 2966/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7710 - auc: 0.8509 - loss: 0.4710 - val_acc: 0.7869 - val_auc: 0.8656 - val_loss: 0.4483\n",
      "Epoch 2967/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7710 - auc: 0.8504 - loss: 0.4724 - val_acc: 0.7846 - val_auc: 0.8644 - val_loss: 0.4507\n",
      "Epoch 2968/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7742 - auc: 0.8529 - loss: 0.4688 - val_acc: 0.7866 - val_auc: 0.8642 - val_loss: 0.4517\n",
      "Epoch 2969/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7740 - auc: 0.8523 - loss: 0.4682 - val_acc: 0.7841 - val_auc: 0.8645 - val_loss: 0.4497\n",
      "Epoch 2970/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7729 - auc: 0.8514 - loss: 0.4705 - val_acc: 0.7862 - val_auc: 0.8640 - val_loss: 0.4499\n",
      "Epoch 2971/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7716 - auc: 0.8516 - loss: 0.4690 - val_acc: 0.7863 - val_auc: 0.8661 - val_loss: 0.4484\n",
      "Epoch 2972/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7717 - auc: 0.8505 - loss: 0.4722 - val_acc: 0.7843 - val_auc: 0.8639 - val_loss: 0.4509\n",
      "Epoch 2973/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7709 - auc: 0.8520 - loss: 0.4695 - val_acc: 0.7872 - val_auc: 0.8661 - val_loss: 0.4480\n",
      "Epoch 2974/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7707 - auc: 0.8509 - loss: 0.4715 - val_acc: 0.7840 - val_auc: 0.8646 - val_loss: 0.4509\n",
      "Epoch 2975/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7710 - auc: 0.8516 - loss: 0.4701 - val_acc: 0.7821 - val_auc: 0.8623 - val_loss: 0.4539\n",
      "Epoch 2976/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7732 - auc: 0.8526 - loss: 0.4687 - val_acc: 0.7864 - val_auc: 0.8642 - val_loss: 0.4503\n",
      "Epoch 2977/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7724 - auc: 0.8523 - loss: 0.4698 - val_acc: 0.7853 - val_auc: 0.8651 - val_loss: 0.4514\n",
      "Epoch 2978/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7720 - auc: 0.8506 - loss: 0.4714 - val_acc: 0.7856 - val_auc: 0.8634 - val_loss: 0.4512\n",
      "Epoch 2979/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7725 - auc: 0.8516 - loss: 0.4706 - val_acc: 0.7827 - val_auc: 0.8639 - val_loss: 0.4482\n",
      "Epoch 2980/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7708 - auc: 0.8513 - loss: 0.4707 - val_acc: 0.7858 - val_auc: 0.8658 - val_loss: 0.4481\n",
      "Epoch 2981/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7703 - auc: 0.8517 - loss: 0.4690 - val_acc: 0.7865 - val_auc: 0.8636 - val_loss: 0.4503\n",
      "Epoch 2982/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7724 - auc: 0.8526 - loss: 0.4684 - val_acc: 0.7861 - val_auc: 0.8645 - val_loss: 0.4496\n",
      "Epoch 2983/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7713 - auc: 0.8511 - loss: 0.4707 - val_acc: 0.7829 - val_auc: 0.8633 - val_loss: 0.4501\n",
      "Epoch 2984/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7729 - auc: 0.8520 - loss: 0.4697 - val_acc: 0.7866 - val_auc: 0.8644 - val_loss: 0.4503\n",
      "Epoch 2985/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7706 - auc: 0.8503 - loss: 0.4711 - val_acc: 0.7862 - val_auc: 0.8655 - val_loss: 0.4473\n",
      "Epoch 2986/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7724 - auc: 0.8527 - loss: 0.4687 - val_acc: 0.7856 - val_auc: 0.8641 - val_loss: 0.4491\n",
      "Epoch 2987/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7687 - auc: 0.8491 - loss: 0.4735 - val_acc: 0.7840 - val_auc: 0.8635 - val_loss: 0.4524\n",
      "Epoch 2988/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7711 - auc: 0.8519 - loss: 0.4704 - val_acc: 0.7848 - val_auc: 0.8641 - val_loss: 0.4503\n",
      "Epoch 2989/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7714 - auc: 0.8514 - loss: 0.4700 - val_acc: 0.7871 - val_auc: 0.8643 - val_loss: 0.4494\n",
      "Epoch 2990/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7718 - auc: 0.8525 - loss: 0.4687 - val_acc: 0.7865 - val_auc: 0.8649 - val_loss: 0.4499\n",
      "Epoch 2991/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7712 - auc: 0.8494 - loss: 0.4728 - val_acc: 0.7856 - val_auc: 0.8646 - val_loss: 0.4496\n",
      "Epoch 2992/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7721 - auc: 0.8524 - loss: 0.4683 - val_acc: 0.7849 - val_auc: 0.8650 - val_loss: 0.4496\n",
      "Epoch 2993/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7725 - auc: 0.8519 - loss: 0.4691 - val_acc: 0.7840 - val_auc: 0.8632 - val_loss: 0.4506\n",
      "Epoch 2994/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7713 - auc: 0.8508 - loss: 0.4701 - val_acc: 0.7835 - val_auc: 0.8641 - val_loss: 0.4500\n",
      "Epoch 2995/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7703 - auc: 0.8503 - loss: 0.4718 - val_acc: 0.7873 - val_auc: 0.8636 - val_loss: 0.4503\n",
      "Epoch 2996/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7738 - auc: 0.8534 - loss: 0.4673 - val_acc: 0.7841 - val_auc: 0.8650 - val_loss: 0.4491\n",
      "Epoch 2997/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7706 - auc: 0.8516 - loss: 0.4708 - val_acc: 0.7834 - val_auc: 0.8656 - val_loss: 0.4492\n",
      "Epoch 2998/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7705 - auc: 0.8512 - loss: 0.4707 - val_acc: 0.7813 - val_auc: 0.8632 - val_loss: 0.4523\n",
      "Epoch 2999/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7715 - auc: 0.8511 - loss: 0.4710 - val_acc: 0.7882 - val_auc: 0.8658 - val_loss: 0.4487\n",
      "Epoch 3000/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7710 - auc: 0.8523 - loss: 0.4688 - val_acc: 0.7842 - val_auc: 0.8647 - val_loss: 0.4495\n",
      "Epoch 3001/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7720 - auc: 0.8516 - loss: 0.4698 - val_acc: 0.7850 - val_auc: 0.8656 - val_loss: 0.4489\n",
      "Epoch 3002/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7730 - auc: 0.8513 - loss: 0.4702 - val_acc: 0.7855 - val_auc: 0.8644 - val_loss: 0.4491\n",
      "Epoch 3003/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7722 - auc: 0.8510 - loss: 0.4701 - val_acc: 0.7856 - val_auc: 0.8640 - val_loss: 0.4511\n",
      "Epoch 3004/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7712 - auc: 0.8510 - loss: 0.4708 - val_acc: 0.7848 - val_auc: 0.8641 - val_loss: 0.4504\n",
      "Epoch 3005/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7738 - auc: 0.8524 - loss: 0.4692 - val_acc: 0.7880 - val_auc: 0.8648 - val_loss: 0.4490\n",
      "Epoch 3006/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7748 - auc: 0.8540 - loss: 0.4669 - val_acc: 0.7809 - val_auc: 0.8638 - val_loss: 0.4501\n",
      "Epoch 3007/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7717 - auc: 0.8516 - loss: 0.4694 - val_acc: 0.7854 - val_auc: 0.8645 - val_loss: 0.4512\n",
      "Epoch 3008/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7738 - auc: 0.8533 - loss: 0.4677 - val_acc: 0.7846 - val_auc: 0.8639 - val_loss: 0.4511\n",
      "Epoch 3009/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7719 - auc: 0.8529 - loss: 0.4679 - val_acc: 0.7843 - val_auc: 0.8645 - val_loss: 0.4491\n",
      "Epoch 3010/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7726 - auc: 0.8504 - loss: 0.4718 - val_acc: 0.7863 - val_auc: 0.8637 - val_loss: 0.4502\n",
      "Epoch 3011/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7720 - auc: 0.8519 - loss: 0.4702 - val_acc: 0.7884 - val_auc: 0.8647 - val_loss: 0.4494\n",
      "Epoch 3012/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7713 - auc: 0.8504 - loss: 0.4725 - val_acc: 0.7860 - val_auc: 0.8647 - val_loss: 0.4499\n",
      "Epoch 3013/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7736 - auc: 0.8540 - loss: 0.4670 - val_acc: 0.7841 - val_auc: 0.8632 - val_loss: 0.4509\n",
      "Epoch 3014/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7703 - auc: 0.8514 - loss: 0.4708 - val_acc: 0.7845 - val_auc: 0.8646 - val_loss: 0.4505\n",
      "Epoch 3015/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7718 - auc: 0.8519 - loss: 0.4698 - val_acc: 0.7864 - val_auc: 0.8652 - val_loss: 0.4485\n",
      "Epoch 3016/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7696 - auc: 0.8509 - loss: 0.4705 - val_acc: 0.7843 - val_auc: 0.8634 - val_loss: 0.4517\n",
      "Epoch 3017/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7729 - auc: 0.8513 - loss: 0.4706 - val_acc: 0.7818 - val_auc: 0.8630 - val_loss: 0.4528\n",
      "Epoch 3018/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7728 - auc: 0.8526 - loss: 0.4690 - val_acc: 0.7843 - val_auc: 0.8647 - val_loss: 0.4495\n",
      "Epoch 3019/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7728 - auc: 0.8531 - loss: 0.4677 - val_acc: 0.7857 - val_auc: 0.8631 - val_loss: 0.4509\n",
      "Epoch 3020/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7719 - auc: 0.8504 - loss: 0.4711 - val_acc: 0.7843 - val_auc: 0.8631 - val_loss: 0.4511\n",
      "Epoch 3021/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7714 - auc: 0.8521 - loss: 0.4696 - val_acc: 0.7820 - val_auc: 0.8640 - val_loss: 0.4517\n",
      "Epoch 3022/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7721 - auc: 0.8520 - loss: 0.4708 - val_acc: 0.7859 - val_auc: 0.8643 - val_loss: 0.4510\n",
      "Epoch 3023/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7744 - auc: 0.8530 - loss: 0.4684 - val_acc: 0.7869 - val_auc: 0.8645 - val_loss: 0.4497\n",
      "Epoch 3024/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7703 - auc: 0.8504 - loss: 0.4716 - val_acc: 0.7847 - val_auc: 0.8657 - val_loss: 0.4486\n",
      "Epoch 3025/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7723 - auc: 0.8526 - loss: 0.4691 - val_acc: 0.7853 - val_auc: 0.8639 - val_loss: 0.4489\n",
      "Epoch 3026/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7697 - auc: 0.8507 - loss: 0.4717 - val_acc: 0.7874 - val_auc: 0.8643 - val_loss: 0.4494\n",
      "Epoch 3027/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7713 - auc: 0.8504 - loss: 0.4721 - val_acc: 0.7862 - val_auc: 0.8650 - val_loss: 0.4498\n",
      "Epoch 3028/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7728 - auc: 0.8520 - loss: 0.4701 - val_acc: 0.7852 - val_auc: 0.8638 - val_loss: 0.4513\n",
      "Epoch 3029/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7723 - auc: 0.8524 - loss: 0.4686 - val_acc: 0.7845 - val_auc: 0.8632 - val_loss: 0.4501\n",
      "Epoch 3030/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7732 - auc: 0.8517 - loss: 0.4690 - val_acc: 0.7833 - val_auc: 0.8634 - val_loss: 0.4517\n",
      "Epoch 3031/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7718 - auc: 0.8522 - loss: 0.4692 - val_acc: 0.7836 - val_auc: 0.8635 - val_loss: 0.4508\n",
      "Epoch 3032/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7732 - auc: 0.8533 - loss: 0.4676 - val_acc: 0.7844 - val_auc: 0.8631 - val_loss: 0.4517\n",
      "Epoch 3033/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7737 - auc: 0.8532 - loss: 0.4686 - val_acc: 0.7852 - val_auc: 0.8650 - val_loss: 0.4506\n",
      "Epoch 3034/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7720 - auc: 0.8515 - loss: 0.4700 - val_acc: 0.7841 - val_auc: 0.8634 - val_loss: 0.4501\n",
      "Epoch 3035/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7740 - auc: 0.8524 - loss: 0.4695 - val_acc: 0.7820 - val_auc: 0.8628 - val_loss: 0.4522\n",
      "Epoch 3036/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7745 - auc: 0.8532 - loss: 0.4681 - val_acc: 0.7856 - val_auc: 0.8646 - val_loss: 0.4493\n",
      "Epoch 3037/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7725 - auc: 0.8518 - loss: 0.4700 - val_acc: 0.7848 - val_auc: 0.8651 - val_loss: 0.4503\n",
      "Epoch 3038/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7735 - auc: 0.8517 - loss: 0.4697 - val_acc: 0.7822 - val_auc: 0.8637 - val_loss: 0.4513\n",
      "Epoch 3039/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7707 - auc: 0.8507 - loss: 0.4706 - val_acc: 0.7866 - val_auc: 0.8652 - val_loss: 0.4500\n",
      "Epoch 3040/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7710 - auc: 0.8512 - loss: 0.4714 - val_acc: 0.7850 - val_auc: 0.8636 - val_loss: 0.4501\n",
      "Epoch 3041/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7731 - auc: 0.8522 - loss: 0.4692 - val_acc: 0.7846 - val_auc: 0.8660 - val_loss: 0.4485\n",
      "Epoch 3042/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7711 - auc: 0.8515 - loss: 0.4705 - val_acc: 0.7835 - val_auc: 0.8630 - val_loss: 0.4508\n",
      "Epoch 3043/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7712 - auc: 0.8511 - loss: 0.4705 - val_acc: 0.7864 - val_auc: 0.8658 - val_loss: 0.4489\n",
      "Epoch 3044/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7745 - auc: 0.8522 - loss: 0.4697 - val_acc: 0.7856 - val_auc: 0.8658 - val_loss: 0.4489\n",
      "Epoch 3045/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7719 - auc: 0.8515 - loss: 0.4708 - val_acc: 0.7858 - val_auc: 0.8655 - val_loss: 0.4504\n",
      "Epoch 3046/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7745 - auc: 0.8537 - loss: 0.4676 - val_acc: 0.7840 - val_auc: 0.8644 - val_loss: 0.4494\n",
      "Epoch 3047/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7723 - auc: 0.8518 - loss: 0.4695 - val_acc: 0.7871 - val_auc: 0.8645 - val_loss: 0.4502\n",
      "Epoch 3048/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7713 - auc: 0.8511 - loss: 0.4712 - val_acc: 0.7842 - val_auc: 0.8647 - val_loss: 0.4485\n",
      "Epoch 3049/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7708 - auc: 0.8514 - loss: 0.4699 - val_acc: 0.7829 - val_auc: 0.8633 - val_loss: 0.4528\n",
      "Epoch 3050/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7725 - auc: 0.8510 - loss: 0.4705 - val_acc: 0.7877 - val_auc: 0.8656 - val_loss: 0.4487\n",
      "Epoch 3051/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7724 - auc: 0.8529 - loss: 0.4677 - val_acc: 0.7865 - val_auc: 0.8649 - val_loss: 0.4492\n",
      "Epoch 3052/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7726 - auc: 0.8535 - loss: 0.4671 - val_acc: 0.7864 - val_auc: 0.8651 - val_loss: 0.4484\n",
      "Epoch 3053/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7726 - auc: 0.8515 - loss: 0.4708 - val_acc: 0.7845 - val_auc: 0.8635 - val_loss: 0.4527\n",
      "Epoch 3054/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7732 - auc: 0.8531 - loss: 0.4686 - val_acc: 0.7853 - val_auc: 0.8647 - val_loss: 0.4502\n",
      "Epoch 3055/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7721 - auc: 0.8521 - loss: 0.4693 - val_acc: 0.7886 - val_auc: 0.8667 - val_loss: 0.4473\n",
      "Epoch 3056/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7714 - auc: 0.8519 - loss: 0.4701 - val_acc: 0.7859 - val_auc: 0.8640 - val_loss: 0.4511\n",
      "Epoch 3057/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7727 - auc: 0.8522 - loss: 0.4674 - val_acc: 0.7847 - val_auc: 0.8644 - val_loss: 0.4491\n",
      "Epoch 3058/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7732 - auc: 0.8526 - loss: 0.4685 - val_acc: 0.7833 - val_auc: 0.8636 - val_loss: 0.4522\n",
      "Epoch 3059/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7752 - auc: 0.8535 - loss: 0.4667 - val_acc: 0.7841 - val_auc: 0.8649 - val_loss: 0.4495\n",
      "Epoch 3060/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7708 - auc: 0.8507 - loss: 0.4710 - val_acc: 0.7858 - val_auc: 0.8649 - val_loss: 0.4494\n",
      "Epoch 3061/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7712 - auc: 0.8505 - loss: 0.4704 - val_acc: 0.7862 - val_auc: 0.8657 - val_loss: 0.4492\n",
      "Epoch 3062/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7701 - auc: 0.8511 - loss: 0.4697 - val_acc: 0.7816 - val_auc: 0.8638 - val_loss: 0.4510\n",
      "Epoch 3063/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7751 - auc: 0.8531 - loss: 0.4683 - val_acc: 0.7842 - val_auc: 0.8651 - val_loss: 0.4486\n",
      "Epoch 3064/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7720 - auc: 0.8519 - loss: 0.4690 - val_acc: 0.7849 - val_auc: 0.8646 - val_loss: 0.4508\n",
      "Epoch 3065/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7691 - auc: 0.8506 - loss: 0.4722 - val_acc: 0.7856 - val_auc: 0.8663 - val_loss: 0.4477\n",
      "Epoch 3066/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7722 - auc: 0.8523 - loss: 0.4686 - val_acc: 0.7829 - val_auc: 0.8638 - val_loss: 0.4501\n",
      "Epoch 3067/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7726 - auc: 0.8519 - loss: 0.4698 - val_acc: 0.7851 - val_auc: 0.8637 - val_loss: 0.4513\n",
      "Epoch 3068/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7733 - auc: 0.8526 - loss: 0.4687 - val_acc: 0.7867 - val_auc: 0.8655 - val_loss: 0.4489\n",
      "Epoch 3069/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7726 - auc: 0.8530 - loss: 0.4683 - val_acc: 0.7847 - val_auc: 0.8630 - val_loss: 0.4520\n",
      "Epoch 3070/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7704 - auc: 0.8514 - loss: 0.4703 - val_acc: 0.7848 - val_auc: 0.8651 - val_loss: 0.4502\n",
      "Epoch 3071/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7725 - auc: 0.8527 - loss: 0.4678 - val_acc: 0.7829 - val_auc: 0.8648 - val_loss: 0.4505\n",
      "Epoch 3072/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7710 - auc: 0.8519 - loss: 0.4688 - val_acc: 0.7874 - val_auc: 0.8662 - val_loss: 0.4472\n",
      "Epoch 3073/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7717 - auc: 0.8518 - loss: 0.4717 - val_acc: 0.7839 - val_auc: 0.8645 - val_loss: 0.4521\n",
      "Epoch 3074/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7730 - auc: 0.8525 - loss: 0.4691 - val_acc: 0.7827 - val_auc: 0.8634 - val_loss: 0.4508\n",
      "Epoch 3075/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7735 - auc: 0.8530 - loss: 0.4684 - val_acc: 0.7874 - val_auc: 0.8651 - val_loss: 0.4493\n",
      "Epoch 3076/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7705 - auc: 0.8513 - loss: 0.4697 - val_acc: 0.7830 - val_auc: 0.8638 - val_loss: 0.4505\n",
      "Epoch 3077/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7723 - auc: 0.8523 - loss: 0.4697 - val_acc: 0.7846 - val_auc: 0.8657 - val_loss: 0.4481\n",
      "Epoch 3078/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7712 - auc: 0.8519 - loss: 0.4704 - val_acc: 0.7843 - val_auc: 0.8638 - val_loss: 0.4511\n",
      "Epoch 3079/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7706 - auc: 0.8514 - loss: 0.4703 - val_acc: 0.7853 - val_auc: 0.8652 - val_loss: 0.4494\n",
      "Epoch 3080/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7740 - auc: 0.8524 - loss: 0.4688 - val_acc: 0.7850 - val_auc: 0.8655 - val_loss: 0.4508\n",
      "Epoch 3081/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7744 - auc: 0.8535 - loss: 0.4680 - val_acc: 0.7850 - val_auc: 0.8647 - val_loss: 0.4496\n",
      "Epoch 3082/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7726 - auc: 0.8516 - loss: 0.4705 - val_acc: 0.7847 - val_auc: 0.8655 - val_loss: 0.4496\n",
      "Epoch 3083/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7716 - auc: 0.8525 - loss: 0.4686 - val_acc: 0.7851 - val_auc: 0.8656 - val_loss: 0.4496\n",
      "Epoch 3084/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7730 - auc: 0.8521 - loss: 0.4693 - val_acc: 0.7853 - val_auc: 0.8658 - val_loss: 0.4486\n",
      "Epoch 3085/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7721 - auc: 0.8520 - loss: 0.4691 - val_acc: 0.7861 - val_auc: 0.8640 - val_loss: 0.4517\n",
      "Epoch 3086/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7736 - auc: 0.8530 - loss: 0.4685 - val_acc: 0.7824 - val_auc: 0.8643 - val_loss: 0.4503\n",
      "Epoch 3087/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7719 - auc: 0.8513 - loss: 0.4711 - val_acc: 0.7854 - val_auc: 0.8645 - val_loss: 0.4509\n",
      "Epoch 3088/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7708 - auc: 0.8513 - loss: 0.4694 - val_acc: 0.7867 - val_auc: 0.8651 - val_loss: 0.4483\n",
      "Epoch 3089/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7743 - auc: 0.8520 - loss: 0.4703 - val_acc: 0.7844 - val_auc: 0.8647 - val_loss: 0.4487\n",
      "Epoch 3090/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7720 - auc: 0.8520 - loss: 0.4703 - val_acc: 0.7849 - val_auc: 0.8656 - val_loss: 0.4519\n",
      "Epoch 3091/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7715 - auc: 0.8508 - loss: 0.4713 - val_acc: 0.7828 - val_auc: 0.8641 - val_loss: 0.4520\n",
      "Epoch 3092/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7722 - auc: 0.8526 - loss: 0.4681 - val_acc: 0.7858 - val_auc: 0.8645 - val_loss: 0.4505\n",
      "Epoch 3093/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7735 - auc: 0.8515 - loss: 0.4700 - val_acc: 0.7842 - val_auc: 0.8651 - val_loss: 0.4500\n",
      "Epoch 3094/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7714 - auc: 0.8509 - loss: 0.4706 - val_acc: 0.7866 - val_auc: 0.8655 - val_loss: 0.4486\n",
      "Epoch 3095/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7721 - auc: 0.8522 - loss: 0.4707 - val_acc: 0.7880 - val_auc: 0.8662 - val_loss: 0.4498\n",
      "Epoch 3096/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7734 - auc: 0.8514 - loss: 0.4701 - val_acc: 0.7877 - val_auc: 0.8658 - val_loss: 0.4487\n",
      "Epoch 3097/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7713 - auc: 0.8515 - loss: 0.4695 - val_acc: 0.7879 - val_auc: 0.8668 - val_loss: 0.4487\n",
      "Epoch 3098/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7728 - auc: 0.8532 - loss: 0.4679 - val_acc: 0.7851 - val_auc: 0.8651 - val_loss: 0.4494\n",
      "Epoch 3099/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7704 - auc: 0.8512 - loss: 0.4702 - val_acc: 0.7857 - val_auc: 0.8650 - val_loss: 0.4504\n",
      "Epoch 3100/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7705 - auc: 0.8510 - loss: 0.4706 - val_acc: 0.7882 - val_auc: 0.8659 - val_loss: 0.4485\n",
      "Epoch 3101/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7721 - auc: 0.8515 - loss: 0.4702 - val_acc: 0.7877 - val_auc: 0.8650 - val_loss: 0.4479\n",
      "Epoch 3102/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7729 - auc: 0.8522 - loss: 0.4693 - val_acc: 0.7853 - val_auc: 0.8635 - val_loss: 0.4505\n",
      "Epoch 3103/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7735 - auc: 0.8526 - loss: 0.4689 - val_acc: 0.7863 - val_auc: 0.8655 - val_loss: 0.4479\n",
      "Epoch 3104/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7723 - auc: 0.8515 - loss: 0.4697 - val_acc: 0.7860 - val_auc: 0.8641 - val_loss: 0.4494\n",
      "Epoch 3105/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7732 - auc: 0.8524 - loss: 0.4687 - val_acc: 0.7853 - val_auc: 0.8649 - val_loss: 0.4501\n",
      "Epoch 3106/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7758 - auc: 0.8552 - loss: 0.4657 - val_acc: 0.7857 - val_auc: 0.8652 - val_loss: 0.4479\n",
      "Epoch 3107/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7725 - auc: 0.8531 - loss: 0.4685 - val_acc: 0.7872 - val_auc: 0.8663 - val_loss: 0.4471\n",
      "Epoch 3108/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7699 - auc: 0.8492 - loss: 0.4721 - val_acc: 0.7843 - val_auc: 0.8652 - val_loss: 0.4496\n",
      "Epoch 3109/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7725 - auc: 0.8513 - loss: 0.4702 - val_acc: 0.7894 - val_auc: 0.8668 - val_loss: 0.4482\n",
      "Epoch 3110/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7725 - auc: 0.8528 - loss: 0.4688 - val_acc: 0.7840 - val_auc: 0.8643 - val_loss: 0.4517\n",
      "Epoch 3111/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7725 - auc: 0.8535 - loss: 0.4674 - val_acc: 0.7868 - val_auc: 0.8645 - val_loss: 0.4505\n",
      "Epoch 3112/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7723 - auc: 0.8516 - loss: 0.4709 - val_acc: 0.7838 - val_auc: 0.8646 - val_loss: 0.4502\n",
      "Epoch 3113/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7725 - auc: 0.8521 - loss: 0.4691 - val_acc: 0.7872 - val_auc: 0.8657 - val_loss: 0.4478\n",
      "Epoch 3114/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7727 - auc: 0.8524 - loss: 0.4688 - val_acc: 0.7846 - val_auc: 0.8655 - val_loss: 0.4483\n",
      "Epoch 3115/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7716 - auc: 0.8509 - loss: 0.4709 - val_acc: 0.7840 - val_auc: 0.8636 - val_loss: 0.4500\n",
      "Epoch 3116/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7713 - auc: 0.8515 - loss: 0.4692 - val_acc: 0.7847 - val_auc: 0.8652 - val_loss: 0.4494\n",
      "Epoch 3117/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7718 - auc: 0.8515 - loss: 0.4705 - val_acc: 0.7812 - val_auc: 0.8629 - val_loss: 0.4533\n",
      "Epoch 3118/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7721 - auc: 0.8522 - loss: 0.4695 - val_acc: 0.7850 - val_auc: 0.8635 - val_loss: 0.4522\n",
      "Epoch 3119/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7730 - auc: 0.8533 - loss: 0.4678 - val_acc: 0.7845 - val_auc: 0.8645 - val_loss: 0.4492\n",
      "Epoch 3120/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7720 - auc: 0.8525 - loss: 0.4698 - val_acc: 0.7877 - val_auc: 0.8658 - val_loss: 0.4481\n",
      "Epoch 3121/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7704 - auc: 0.8508 - loss: 0.4704 - val_acc: 0.7844 - val_auc: 0.8640 - val_loss: 0.4498\n",
      "Epoch 3122/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7712 - auc: 0.8511 - loss: 0.4717 - val_acc: 0.7878 - val_auc: 0.8653 - val_loss: 0.4482\n",
      "Epoch 3123/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7710 - auc: 0.8521 - loss: 0.4703 - val_acc: 0.7866 - val_auc: 0.8663 - val_loss: 0.4497\n",
      "Epoch 3124/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7734 - auc: 0.8523 - loss: 0.4688 - val_acc: 0.7847 - val_auc: 0.8645 - val_loss: 0.4507\n",
      "Epoch 3125/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7712 - auc: 0.8520 - loss: 0.4699 - val_acc: 0.7857 - val_auc: 0.8653 - val_loss: 0.4482\n",
      "Epoch 3126/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7729 - auc: 0.8508 - loss: 0.4724 - val_acc: 0.7841 - val_auc: 0.8660 - val_loss: 0.4498\n",
      "Epoch 3127/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7726 - auc: 0.8523 - loss: 0.4677 - val_acc: 0.7843 - val_auc: 0.8651 - val_loss: 0.4499\n",
      "Epoch 3128/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7718 - auc: 0.8529 - loss: 0.4674 - val_acc: 0.7850 - val_auc: 0.8652 - val_loss: 0.4484\n",
      "Epoch 3129/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7738 - auc: 0.8521 - loss: 0.4695 - val_acc: 0.7850 - val_auc: 0.8641 - val_loss: 0.4510\n",
      "Epoch 3130/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7733 - auc: 0.8536 - loss: 0.4679 - val_acc: 0.7830 - val_auc: 0.8632 - val_loss: 0.4524\n",
      "Epoch 3131/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7709 - auc: 0.8500 - loss: 0.4722 - val_acc: 0.7868 - val_auc: 0.8655 - val_loss: 0.4499\n",
      "Epoch 3132/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7721 - auc: 0.8515 - loss: 0.4709 - val_acc: 0.7865 - val_auc: 0.8658 - val_loss: 0.4483\n",
      "Epoch 3133/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7748 - auc: 0.8529 - loss: 0.4689 - val_acc: 0.7872 - val_auc: 0.8655 - val_loss: 0.4486\n",
      "Epoch 3134/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7726 - auc: 0.8518 - loss: 0.4693 - val_acc: 0.7869 - val_auc: 0.8655 - val_loss: 0.4486\n",
      "Epoch 3135/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7715 - auc: 0.8515 - loss: 0.4697 - val_acc: 0.7875 - val_auc: 0.8667 - val_loss: 0.4486\n",
      "Epoch 3136/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7720 - auc: 0.8515 - loss: 0.4698 - val_acc: 0.7849 - val_auc: 0.8649 - val_loss: 0.4497\n",
      "Epoch 3137/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7738 - auc: 0.8527 - loss: 0.4695 - val_acc: 0.7846 - val_auc: 0.8658 - val_loss: 0.4495\n",
      "Epoch 3138/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7731 - auc: 0.8533 - loss: 0.4674 - val_acc: 0.7879 - val_auc: 0.8654 - val_loss: 0.4478\n",
      "Epoch 3139/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7711 - auc: 0.8524 - loss: 0.4683 - val_acc: 0.7871 - val_auc: 0.8656 - val_loss: 0.4490\n",
      "Epoch 3140/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7730 - auc: 0.8523 - loss: 0.4691 - val_acc: 0.7855 - val_auc: 0.8652 - val_loss: 0.4491\n",
      "Epoch 3141/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7735 - auc: 0.8539 - loss: 0.4672 - val_acc: 0.7867 - val_auc: 0.8650 - val_loss: 0.4496\n",
      "Epoch 3142/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7737 - auc: 0.8523 - loss: 0.4699 - val_acc: 0.7847 - val_auc: 0.8648 - val_loss: 0.4504\n",
      "Epoch 3143/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7725 - auc: 0.8527 - loss: 0.4690 - val_acc: 0.7873 - val_auc: 0.8664 - val_loss: 0.4474\n",
      "Epoch 3144/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7735 - auc: 0.8531 - loss: 0.4686 - val_acc: 0.7876 - val_auc: 0.8663 - val_loss: 0.4482\n",
      "Epoch 3145/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7732 - auc: 0.8526 - loss: 0.4686 - val_acc: 0.7863 - val_auc: 0.8658 - val_loss: 0.4477\n",
      "Epoch 3146/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7725 - auc: 0.8531 - loss: 0.4690 - val_acc: 0.7871 - val_auc: 0.8662 - val_loss: 0.4466\n",
      "Epoch 3147/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7737 - auc: 0.8523 - loss: 0.4690 - val_acc: 0.7886 - val_auc: 0.8650 - val_loss: 0.4488\n",
      "Epoch 3148/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7734 - auc: 0.8530 - loss: 0.4690 - val_acc: 0.7882 - val_auc: 0.8658 - val_loss: 0.4483\n",
      "Epoch 3149/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7718 - auc: 0.8521 - loss: 0.4687 - val_acc: 0.7869 - val_auc: 0.8645 - val_loss: 0.4496\n",
      "Epoch 3150/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7728 - auc: 0.8524 - loss: 0.4684 - val_acc: 0.7855 - val_auc: 0.8650 - val_loss: 0.4507\n",
      "Epoch 3151/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7712 - auc: 0.8516 - loss: 0.4706 - val_acc: 0.7863 - val_auc: 0.8654 - val_loss: 0.4482\n",
      "Epoch 3152/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7719 - auc: 0.8519 - loss: 0.4704 - val_acc: 0.7854 - val_auc: 0.8650 - val_loss: 0.4494\n",
      "Epoch 3153/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7745 - auc: 0.8536 - loss: 0.4673 - val_acc: 0.7886 - val_auc: 0.8660 - val_loss: 0.4473\n",
      "Epoch 3154/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7720 - auc: 0.8512 - loss: 0.4706 - val_acc: 0.7862 - val_auc: 0.8647 - val_loss: 0.4492\n",
      "Epoch 3155/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7735 - auc: 0.8521 - loss: 0.4694 - val_acc: 0.7831 - val_auc: 0.8638 - val_loss: 0.4508\n",
      "Epoch 3156/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7735 - auc: 0.8534 - loss: 0.4681 - val_acc: 0.7832 - val_auc: 0.8638 - val_loss: 0.4507\n",
      "Epoch 3157/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7722 - auc: 0.8512 - loss: 0.4715 - val_acc: 0.7852 - val_auc: 0.8651 - val_loss: 0.4504\n",
      "Epoch 3158/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7721 - auc: 0.8511 - loss: 0.4714 - val_acc: 0.7851 - val_auc: 0.8648 - val_loss: 0.4503\n",
      "Epoch 3159/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7715 - auc: 0.8519 - loss: 0.4697 - val_acc: 0.7852 - val_auc: 0.8652 - val_loss: 0.4483\n",
      "Epoch 3160/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7754 - auc: 0.8533 - loss: 0.4686 - val_acc: 0.7865 - val_auc: 0.8657 - val_loss: 0.4474\n",
      "Epoch 3161/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7725 - auc: 0.8516 - loss: 0.4708 - val_acc: 0.7853 - val_auc: 0.8646 - val_loss: 0.4502\n",
      "Epoch 3162/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7711 - auc: 0.8520 - loss: 0.4703 - val_acc: 0.7852 - val_auc: 0.8654 - val_loss: 0.4492\n",
      "Epoch 3163/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7735 - auc: 0.8530 - loss: 0.4683 - val_acc: 0.7853 - val_auc: 0.8647 - val_loss: 0.4491\n",
      "Epoch 3164/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7737 - auc: 0.8535 - loss: 0.4673 - val_acc: 0.7869 - val_auc: 0.8645 - val_loss: 0.4504\n",
      "Epoch 3165/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7708 - auc: 0.8525 - loss: 0.4687 - val_acc: 0.7841 - val_auc: 0.8655 - val_loss: 0.4505\n",
      "Epoch 3166/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7728 - auc: 0.8523 - loss: 0.4687 - val_acc: 0.7833 - val_auc: 0.8647 - val_loss: 0.4498\n",
      "Epoch 3167/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7699 - auc: 0.8506 - loss: 0.4719 - val_acc: 0.7862 - val_auc: 0.8668 - val_loss: 0.4490\n",
      "Epoch 3168/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7742 - auc: 0.8521 - loss: 0.4692 - val_acc: 0.7869 - val_auc: 0.8641 - val_loss: 0.4496\n",
      "Epoch 3169/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7699 - auc: 0.8522 - loss: 0.4694 - val_acc: 0.7854 - val_auc: 0.8646 - val_loss: 0.4504\n",
      "Epoch 3170/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7747 - auc: 0.8541 - loss: 0.4666 - val_acc: 0.7848 - val_auc: 0.8644 - val_loss: 0.4502\n",
      "Epoch 3171/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7740 - auc: 0.8537 - loss: 0.4671 - val_acc: 0.7834 - val_auc: 0.8649 - val_loss: 0.4484\n",
      "Epoch 3172/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7755 - auc: 0.8546 - loss: 0.4654 - val_acc: 0.7883 - val_auc: 0.8656 - val_loss: 0.4459\n",
      "Epoch 3173/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7728 - auc: 0.8518 - loss: 0.4689 - val_acc: 0.7815 - val_auc: 0.8643 - val_loss: 0.4519\n",
      "Epoch 3174/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7728 - auc: 0.8529 - loss: 0.4672 - val_acc: 0.7857 - val_auc: 0.8645 - val_loss: 0.4490\n",
      "Epoch 3175/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7740 - auc: 0.8526 - loss: 0.4676 - val_acc: 0.7865 - val_auc: 0.8659 - val_loss: 0.4489\n",
      "Epoch 3176/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7749 - auc: 0.8547 - loss: 0.4658 - val_acc: 0.7875 - val_auc: 0.8663 - val_loss: 0.4468\n",
      "Epoch 3177/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7720 - auc: 0.8520 - loss: 0.4704 - val_acc: 0.7855 - val_auc: 0.8651 - val_loss: 0.4494\n",
      "Epoch 3178/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7733 - auc: 0.8529 - loss: 0.4693 - val_acc: 0.7853 - val_auc: 0.8652 - val_loss: 0.4490\n",
      "Epoch 3179/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7740 - auc: 0.8530 - loss: 0.4684 - val_acc: 0.7865 - val_auc: 0.8648 - val_loss: 0.4503\n",
      "Epoch 3180/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7746 - auc: 0.8526 - loss: 0.4691 - val_acc: 0.7858 - val_auc: 0.8645 - val_loss: 0.4504\n",
      "Epoch 3181/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7716 - auc: 0.8511 - loss: 0.4709 - val_acc: 0.7840 - val_auc: 0.8651 - val_loss: 0.4502\n",
      "Epoch 3182/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7728 - auc: 0.8529 - loss: 0.4683 - val_acc: 0.7879 - val_auc: 0.8653 - val_loss: 0.4484\n",
      "Epoch 3183/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7760 - auc: 0.8544 - loss: 0.4666 - val_acc: 0.7859 - val_auc: 0.8647 - val_loss: 0.4492\n",
      "Epoch 3184/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7719 - auc: 0.8509 - loss: 0.4715 - val_acc: 0.7871 - val_auc: 0.8648 - val_loss: 0.4498\n",
      "Epoch 3185/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7739 - auc: 0.8522 - loss: 0.4683 - val_acc: 0.7858 - val_auc: 0.8649 - val_loss: 0.4487\n",
      "Epoch 3186/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7708 - auc: 0.8502 - loss: 0.4736 - val_acc: 0.7858 - val_auc: 0.8653 - val_loss: 0.4516\n",
      "Epoch 3187/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7743 - auc: 0.8534 - loss: 0.4676 - val_acc: 0.7849 - val_auc: 0.8653 - val_loss: 0.4495\n",
      "Epoch 3188/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7736 - auc: 0.8530 - loss: 0.4678 - val_acc: 0.7867 - val_auc: 0.8652 - val_loss: 0.4486\n",
      "Epoch 3189/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7735 - auc: 0.8533 - loss: 0.4679 - val_acc: 0.7886 - val_auc: 0.8657 - val_loss: 0.4485\n",
      "Epoch 3190/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7733 - auc: 0.8519 - loss: 0.4690 - val_acc: 0.7860 - val_auc: 0.8653 - val_loss: 0.4495\n",
      "Epoch 3191/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7743 - auc: 0.8534 - loss: 0.4684 - val_acc: 0.7872 - val_auc: 0.8658 - val_loss: 0.4486\n",
      "Epoch 3192/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7725 - auc: 0.8526 - loss: 0.4689 - val_acc: 0.7874 - val_auc: 0.8657 - val_loss: 0.4494\n",
      "Epoch 3193/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7725 - auc: 0.8515 - loss: 0.4692 - val_acc: 0.7843 - val_auc: 0.8657 - val_loss: 0.4487\n",
      "Epoch 3194/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7713 - auc: 0.8525 - loss: 0.4684 - val_acc: 0.7899 - val_auc: 0.8668 - val_loss: 0.4469\n",
      "Epoch 3195/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7742 - auc: 0.8534 - loss: 0.4672 - val_acc: 0.7856 - val_auc: 0.8649 - val_loss: 0.4495\n",
      "Epoch 3196/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7719 - auc: 0.8503 - loss: 0.4712 - val_acc: 0.7880 - val_auc: 0.8664 - val_loss: 0.4481\n",
      "Epoch 3197/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7747 - auc: 0.8537 - loss: 0.4673 - val_acc: 0.7869 - val_auc: 0.8649 - val_loss: 0.4488\n",
      "Epoch 3198/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7735 - auc: 0.8523 - loss: 0.4689 - val_acc: 0.7828 - val_auc: 0.8619 - val_loss: 0.4531\n",
      "Epoch 3199/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7739 - auc: 0.8528 - loss: 0.4685 - val_acc: 0.7882 - val_auc: 0.8669 - val_loss: 0.4472\n",
      "Epoch 3200/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7711 - auc: 0.8521 - loss: 0.4700 - val_acc: 0.7877 - val_auc: 0.8660 - val_loss: 0.4471\n",
      "Epoch 3201/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7741 - auc: 0.8533 - loss: 0.4683 - val_acc: 0.7879 - val_auc: 0.8656 - val_loss: 0.4492\n",
      "Epoch 3202/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7731 - auc: 0.8526 - loss: 0.4686 - val_acc: 0.7847 - val_auc: 0.8652 - val_loss: 0.4497\n",
      "Epoch 3203/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7712 - auc: 0.8505 - loss: 0.4709 - val_acc: 0.7868 - val_auc: 0.8646 - val_loss: 0.4488\n",
      "Epoch 3204/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7749 - auc: 0.8518 - loss: 0.4697 - val_acc: 0.7873 - val_auc: 0.8667 - val_loss: 0.4475\n",
      "Epoch 3205/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7728 - auc: 0.8533 - loss: 0.4674 - val_acc: 0.7856 - val_auc: 0.8661 - val_loss: 0.4481\n",
      "Epoch 3206/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7720 - auc: 0.8531 - loss: 0.4679 - val_acc: 0.7868 - val_auc: 0.8651 - val_loss: 0.4473\n",
      "Epoch 3207/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7735 - auc: 0.8519 - loss: 0.4699 - val_acc: 0.7877 - val_auc: 0.8661 - val_loss: 0.4486\n",
      "Epoch 3208/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7742 - auc: 0.8537 - loss: 0.4668 - val_acc: 0.7845 - val_auc: 0.8650 - val_loss: 0.4504\n",
      "Epoch 3209/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7734 - auc: 0.8536 - loss: 0.4686 - val_acc: 0.7859 - val_auc: 0.8661 - val_loss: 0.4481\n",
      "Epoch 3210/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7731 - auc: 0.8529 - loss: 0.4678 - val_acc: 0.7884 - val_auc: 0.8664 - val_loss: 0.4472\n",
      "Epoch 3211/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7744 - auc: 0.8530 - loss: 0.4689 - val_acc: 0.7878 - val_auc: 0.8649 - val_loss: 0.4492\n",
      "Epoch 3212/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7720 - auc: 0.8529 - loss: 0.4694 - val_acc: 0.7859 - val_auc: 0.8647 - val_loss: 0.4508\n",
      "Epoch 3213/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7727 - auc: 0.8525 - loss: 0.4683 - val_acc: 0.7865 - val_auc: 0.8633 - val_loss: 0.4512\n",
      "Epoch 3214/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7713 - auc: 0.8524 - loss: 0.4690 - val_acc: 0.7865 - val_auc: 0.8657 - val_loss: 0.4491\n",
      "Epoch 3215/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7735 - auc: 0.8532 - loss: 0.4679 - val_acc: 0.7889 - val_auc: 0.8659 - val_loss: 0.4478\n",
      "Epoch 3216/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7715 - auc: 0.8534 - loss: 0.4679 - val_acc: 0.7852 - val_auc: 0.8662 - val_loss: 0.4489\n",
      "Epoch 3217/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7731 - auc: 0.8526 - loss: 0.4696 - val_acc: 0.7867 - val_auc: 0.8658 - val_loss: 0.4485\n",
      "Epoch 3218/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7757 - auc: 0.8535 - loss: 0.4679 - val_acc: 0.7859 - val_auc: 0.8652 - val_loss: 0.4509\n",
      "Epoch 3219/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7722 - auc: 0.8534 - loss: 0.4669 - val_acc: 0.7858 - val_auc: 0.8665 - val_loss: 0.4456\n",
      "Epoch 3220/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7739 - auc: 0.8536 - loss: 0.4677 - val_acc: 0.7858 - val_auc: 0.8657 - val_loss: 0.4480\n",
      "Epoch 3221/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7731 - auc: 0.8531 - loss: 0.4678 - val_acc: 0.7902 - val_auc: 0.8648 - val_loss: 0.4491\n",
      "Epoch 3222/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7741 - auc: 0.8536 - loss: 0.4676 - val_acc: 0.7846 - val_auc: 0.8662 - val_loss: 0.4485\n",
      "Epoch 3223/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7737 - auc: 0.8533 - loss: 0.4679 - val_acc: 0.7894 - val_auc: 0.8674 - val_loss: 0.4465\n",
      "Epoch 3224/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7729 - auc: 0.8523 - loss: 0.4682 - val_acc: 0.7853 - val_auc: 0.8648 - val_loss: 0.4504\n",
      "Epoch 3225/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7730 - auc: 0.8532 - loss: 0.4689 - val_acc: 0.7837 - val_auc: 0.8640 - val_loss: 0.4502\n",
      "Epoch 3226/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7724 - auc: 0.8520 - loss: 0.4695 - val_acc: 0.7865 - val_auc: 0.8661 - val_loss: 0.4474\n",
      "Epoch 3227/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7717 - auc: 0.8528 - loss: 0.4685 - val_acc: 0.7862 - val_auc: 0.8642 - val_loss: 0.4485\n",
      "Epoch 3228/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7735 - auc: 0.8531 - loss: 0.4670 - val_acc: 0.7885 - val_auc: 0.8656 - val_loss: 0.4475\n",
      "Epoch 3229/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7737 - auc: 0.8531 - loss: 0.4690 - val_acc: 0.7854 - val_auc: 0.8651 - val_loss: 0.4506\n",
      "Epoch 3230/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7727 - auc: 0.8536 - loss: 0.4681 - val_acc: 0.7870 - val_auc: 0.8672 - val_loss: 0.4488\n",
      "Epoch 3231/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7725 - auc: 0.8523 - loss: 0.4693 - val_acc: 0.7852 - val_auc: 0.8652 - val_loss: 0.4499\n",
      "Epoch 3232/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7721 - auc: 0.8524 - loss: 0.4689 - val_acc: 0.7878 - val_auc: 0.8651 - val_loss: 0.4497\n",
      "Epoch 3233/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7724 - auc: 0.8531 - loss: 0.4687 - val_acc: 0.7873 - val_auc: 0.8663 - val_loss: 0.4479\n",
      "Epoch 3234/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7742 - auc: 0.8537 - loss: 0.4668 - val_acc: 0.7872 - val_auc: 0.8645 - val_loss: 0.4496\n",
      "Epoch 3235/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7738 - auc: 0.8528 - loss: 0.4685 - val_acc: 0.7900 - val_auc: 0.8671 - val_loss: 0.4465\n",
      "Epoch 3236/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7723 - auc: 0.8526 - loss: 0.4687 - val_acc: 0.7873 - val_auc: 0.8651 - val_loss: 0.4483\n",
      "Epoch 3237/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7728 - auc: 0.8521 - loss: 0.4691 - val_acc: 0.7890 - val_auc: 0.8661 - val_loss: 0.4469\n",
      "Epoch 3238/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7745 - auc: 0.8542 - loss: 0.4665 - val_acc: 0.7850 - val_auc: 0.8646 - val_loss: 0.4492\n",
      "Epoch 3239/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7749 - auc: 0.8544 - loss: 0.4673 - val_acc: 0.7865 - val_auc: 0.8647 - val_loss: 0.4502\n",
      "Epoch 3240/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7710 - auc: 0.8522 - loss: 0.4692 - val_acc: 0.7854 - val_auc: 0.8648 - val_loss: 0.4491\n",
      "Epoch 3241/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7725 - auc: 0.8530 - loss: 0.4697 - val_acc: 0.7842 - val_auc: 0.8647 - val_loss: 0.4501\n",
      "Epoch 3242/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7712 - auc: 0.8519 - loss: 0.4703 - val_acc: 0.7824 - val_auc: 0.8642 - val_loss: 0.4502\n",
      "Epoch 3243/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7725 - auc: 0.8537 - loss: 0.4678 - val_acc: 0.7877 - val_auc: 0.8665 - val_loss: 0.4498\n",
      "Epoch 3244/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7735 - auc: 0.8529 - loss: 0.4680 - val_acc: 0.7844 - val_auc: 0.8662 - val_loss: 0.4483\n",
      "Epoch 3245/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7711 - auc: 0.8513 - loss: 0.4700 - val_acc: 0.7871 - val_auc: 0.8663 - val_loss: 0.4487\n",
      "Epoch 3246/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7753 - auc: 0.8535 - loss: 0.4688 - val_acc: 0.7874 - val_auc: 0.8658 - val_loss: 0.4479\n",
      "Epoch 3247/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7717 - auc: 0.8520 - loss: 0.4694 - val_acc: 0.7858 - val_auc: 0.8647 - val_loss: 0.4490\n",
      "Epoch 3248/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7727 - auc: 0.8534 - loss: 0.4670 - val_acc: 0.7872 - val_auc: 0.8657 - val_loss: 0.4484\n",
      "Epoch 3249/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7731 - auc: 0.8527 - loss: 0.4689 - val_acc: 0.7849 - val_auc: 0.8639 - val_loss: 0.4518\n",
      "Epoch 3250/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7719 - auc: 0.8510 - loss: 0.4710 - val_acc: 0.7852 - val_auc: 0.8644 - val_loss: 0.4515\n",
      "Epoch 3251/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7735 - auc: 0.8516 - loss: 0.4696 - val_acc: 0.7865 - val_auc: 0.8660 - val_loss: 0.4490\n",
      "Epoch 3252/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7749 - auc: 0.8539 - loss: 0.4673 - val_acc: 0.7855 - val_auc: 0.8653 - val_loss: 0.4498\n",
      "Epoch 3253/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7742 - auc: 0.8528 - loss: 0.4682 - val_acc: 0.7877 - val_auc: 0.8664 - val_loss: 0.4473\n",
      "Epoch 3254/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7736 - auc: 0.8531 - loss: 0.4677 - val_acc: 0.7853 - val_auc: 0.8642 - val_loss: 0.4501\n",
      "Epoch 3255/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7736 - auc: 0.8523 - loss: 0.4682 - val_acc: 0.7878 - val_auc: 0.8662 - val_loss: 0.4460\n",
      "Epoch 3256/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7733 - auc: 0.8521 - loss: 0.4688 - val_acc: 0.7826 - val_auc: 0.8642 - val_loss: 0.4520\n",
      "Epoch 3257/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7713 - auc: 0.8521 - loss: 0.4697 - val_acc: 0.7848 - val_auc: 0.8647 - val_loss: 0.4520\n",
      "Epoch 3258/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7741 - auc: 0.8542 - loss: 0.4656 - val_acc: 0.7849 - val_auc: 0.8637 - val_loss: 0.4512\n",
      "Epoch 3259/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7725 - auc: 0.8518 - loss: 0.4703 - val_acc: 0.7866 - val_auc: 0.8652 - val_loss: 0.4488\n",
      "Epoch 3260/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7723 - auc: 0.8531 - loss: 0.4682 - val_acc: 0.7866 - val_auc: 0.8664 - val_loss: 0.4480\n",
      "Epoch 3261/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7744 - auc: 0.8532 - loss: 0.4680 - val_acc: 0.7868 - val_auc: 0.8648 - val_loss: 0.4489\n",
      "Epoch 3262/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7718 - auc: 0.8520 - loss: 0.4685 - val_acc: 0.7849 - val_auc: 0.8653 - val_loss: 0.4499\n",
      "Epoch 3263/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7739 - auc: 0.8523 - loss: 0.4705 - val_acc: 0.7889 - val_auc: 0.8666 - val_loss: 0.4471\n",
      "Epoch 3264/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7731 - auc: 0.8539 - loss: 0.4670 - val_acc: 0.7838 - val_auc: 0.8654 - val_loss: 0.4494\n",
      "Epoch 3265/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7780 - auc: 0.8550 - loss: 0.4656 - val_acc: 0.7866 - val_auc: 0.8655 - val_loss: 0.4478\n",
      "Epoch 3266/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7731 - auc: 0.8508 - loss: 0.4706 - val_acc: 0.7881 - val_auc: 0.8655 - val_loss: 0.4503\n",
      "Epoch 3267/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7754 - auc: 0.8544 - loss: 0.4669 - val_acc: 0.7839 - val_auc: 0.8648 - val_loss: 0.4505\n",
      "Epoch 3268/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7745 - auc: 0.8536 - loss: 0.4670 - val_acc: 0.7824 - val_auc: 0.8640 - val_loss: 0.4524\n",
      "Epoch 3269/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7716 - auc: 0.8525 - loss: 0.4691 - val_acc: 0.7845 - val_auc: 0.8650 - val_loss: 0.4497\n",
      "Epoch 3270/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7728 - auc: 0.8529 - loss: 0.4682 - val_acc: 0.7872 - val_auc: 0.8654 - val_loss: 0.4487\n",
      "Epoch 3271/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7729 - auc: 0.8523 - loss: 0.4692 - val_acc: 0.7864 - val_auc: 0.8644 - val_loss: 0.4492\n",
      "Epoch 3272/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7730 - auc: 0.8524 - loss: 0.4684 - val_acc: 0.7840 - val_auc: 0.8653 - val_loss: 0.4500\n",
      "Epoch 3273/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7732 - auc: 0.8538 - loss: 0.4671 - val_acc: 0.7843 - val_auc: 0.8654 - val_loss: 0.4495\n",
      "Epoch 3274/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7728 - auc: 0.8530 - loss: 0.4678 - val_acc: 0.7864 - val_auc: 0.8654 - val_loss: 0.4488\n",
      "Epoch 3275/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7728 - auc: 0.8529 - loss: 0.4678 - val_acc: 0.7822 - val_auc: 0.8639 - val_loss: 0.4516\n",
      "Epoch 3276/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7731 - auc: 0.8519 - loss: 0.4693 - val_acc: 0.7842 - val_auc: 0.8635 - val_loss: 0.4503\n",
      "Epoch 3277/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7747 - auc: 0.8530 - loss: 0.4683 - val_acc: 0.7855 - val_auc: 0.8661 - val_loss: 0.4481\n",
      "Epoch 3278/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7739 - auc: 0.8544 - loss: 0.4660 - val_acc: 0.7857 - val_auc: 0.8656 - val_loss: 0.4487\n",
      "Epoch 3279/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7742 - auc: 0.8531 - loss: 0.4680 - val_acc: 0.7851 - val_auc: 0.8644 - val_loss: 0.4503\n",
      "Epoch 3280/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7720 - auc: 0.8522 - loss: 0.4693 - val_acc: 0.7883 - val_auc: 0.8658 - val_loss: 0.4476\n",
      "Epoch 3281/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7710 - auc: 0.8514 - loss: 0.4710 - val_acc: 0.7855 - val_auc: 0.8646 - val_loss: 0.4494\n",
      "Epoch 3282/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7742 - auc: 0.8536 - loss: 0.4683 - val_acc: 0.7859 - val_auc: 0.8656 - val_loss: 0.4496\n",
      "Epoch 3283/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7724 - auc: 0.8523 - loss: 0.4693 - val_acc: 0.7836 - val_auc: 0.8640 - val_loss: 0.4509\n",
      "Epoch 3284/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7729 - auc: 0.8527 - loss: 0.4677 - val_acc: 0.7883 - val_auc: 0.8657 - val_loss: 0.4483\n",
      "Epoch 3285/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7722 - auc: 0.8526 - loss: 0.4682 - val_acc: 0.7837 - val_auc: 0.8649 - val_loss: 0.4504\n",
      "Epoch 3286/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7737 - auc: 0.8534 - loss: 0.4690 - val_acc: 0.7879 - val_auc: 0.8675 - val_loss: 0.4462\n",
      "Epoch 3287/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7730 - auc: 0.8522 - loss: 0.4690 - val_acc: 0.7882 - val_auc: 0.8666 - val_loss: 0.4475\n",
      "Epoch 3288/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7731 - auc: 0.8525 - loss: 0.4679 - val_acc: 0.7877 - val_auc: 0.8647 - val_loss: 0.4495\n",
      "Epoch 3289/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7716 - auc: 0.8515 - loss: 0.4710 - val_acc: 0.7857 - val_auc: 0.8653 - val_loss: 0.4493\n",
      "Epoch 3290/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7739 - auc: 0.8534 - loss: 0.4677 - val_acc: 0.7846 - val_auc: 0.8645 - val_loss: 0.4511\n",
      "Epoch 3291/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7718 - auc: 0.8529 - loss: 0.4682 - val_acc: 0.7867 - val_auc: 0.8658 - val_loss: 0.4475\n",
      "Epoch 3292/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7740 - auc: 0.8530 - loss: 0.4676 - val_acc: 0.7859 - val_auc: 0.8666 - val_loss: 0.4473\n",
      "Epoch 3293/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7740 - auc: 0.8522 - loss: 0.4694 - val_acc: 0.7886 - val_auc: 0.8660 - val_loss: 0.4469\n",
      "Epoch 3294/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7736 - auc: 0.8541 - loss: 0.4675 - val_acc: 0.7855 - val_auc: 0.8660 - val_loss: 0.4485\n",
      "Epoch 3295/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7734 - auc: 0.8523 - loss: 0.4679 - val_acc: 0.7865 - val_auc: 0.8669 - val_loss: 0.4489\n",
      "Epoch 3296/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7737 - auc: 0.8536 - loss: 0.4677 - val_acc: 0.7888 - val_auc: 0.8653 - val_loss: 0.4488\n",
      "Epoch 3297/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7731 - auc: 0.8522 - loss: 0.4699 - val_acc: 0.7873 - val_auc: 0.8665 - val_loss: 0.4474\n",
      "Epoch 3298/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7718 - auc: 0.8515 - loss: 0.4700 - val_acc: 0.7877 - val_auc: 0.8662 - val_loss: 0.4470\n",
      "Epoch 3299/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7735 - auc: 0.8542 - loss: 0.4656 - val_acc: 0.7883 - val_auc: 0.8661 - val_loss: 0.4467\n",
      "Epoch 3300/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7734 - auc: 0.8528 - loss: 0.4692 - val_acc: 0.7861 - val_auc: 0.8647 - val_loss: 0.4491\n",
      "Epoch 3301/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7752 - auc: 0.8543 - loss: 0.4659 - val_acc: 0.7899 - val_auc: 0.8655 - val_loss: 0.4485\n",
      "Epoch 3302/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7738 - auc: 0.8532 - loss: 0.4681 - val_acc: 0.7852 - val_auc: 0.8666 - val_loss: 0.4485\n",
      "Epoch 3303/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7719 - auc: 0.8534 - loss: 0.4680 - val_acc: 0.7900 - val_auc: 0.8674 - val_loss: 0.4460\n",
      "Epoch 3304/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7745 - auc: 0.8536 - loss: 0.4675 - val_acc: 0.7888 - val_auc: 0.8669 - val_loss: 0.4453\n",
      "Epoch 3305/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7735 - auc: 0.8539 - loss: 0.4667 - val_acc: 0.7870 - val_auc: 0.8661 - val_loss: 0.4475\n",
      "Epoch 3306/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7724 - auc: 0.8524 - loss: 0.4690 - val_acc: 0.7881 - val_auc: 0.8667 - val_loss: 0.4462\n",
      "Epoch 3307/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7745 - auc: 0.8533 - loss: 0.4676 - val_acc: 0.7860 - val_auc: 0.8646 - val_loss: 0.4482\n",
      "Epoch 3308/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7751 - auc: 0.8541 - loss: 0.4669 - val_acc: 0.7883 - val_auc: 0.8671 - val_loss: 0.4470\n",
      "Epoch 3309/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7731 - auc: 0.8527 - loss: 0.4688 - val_acc: 0.7860 - val_auc: 0.8652 - val_loss: 0.4498\n",
      "Epoch 3310/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7730 - auc: 0.8535 - loss: 0.4672 - val_acc: 0.7849 - val_auc: 0.8659 - val_loss: 0.4488\n",
      "Epoch 3311/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7738 - auc: 0.8529 - loss: 0.4676 - val_acc: 0.7865 - val_auc: 0.8652 - val_loss: 0.4500\n",
      "Epoch 3312/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7724 - auc: 0.8524 - loss: 0.4684 - val_acc: 0.7864 - val_auc: 0.8659 - val_loss: 0.4483\n",
      "Epoch 3313/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7742 - auc: 0.8540 - loss: 0.4681 - val_acc: 0.7849 - val_auc: 0.8657 - val_loss: 0.4494\n",
      "Epoch 3314/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7751 - auc: 0.8537 - loss: 0.4663 - val_acc: 0.7857 - val_auc: 0.8657 - val_loss: 0.4486\n",
      "Epoch 3315/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7740 - auc: 0.8535 - loss: 0.4674 - val_acc: 0.7836 - val_auc: 0.8653 - val_loss: 0.4490\n",
      "Epoch 3316/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7730 - auc: 0.8528 - loss: 0.4685 - val_acc: 0.7879 - val_auc: 0.8666 - val_loss: 0.4465\n",
      "Epoch 3317/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7752 - auc: 0.8536 - loss: 0.4677 - val_acc: 0.7865 - val_auc: 0.8668 - val_loss: 0.4479\n",
      "Epoch 3318/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7732 - auc: 0.8527 - loss: 0.4686 - val_acc: 0.7881 - val_auc: 0.8673 - val_loss: 0.4467\n",
      "Epoch 3319/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7735 - auc: 0.8532 - loss: 0.4680 - val_acc: 0.7872 - val_auc: 0.8655 - val_loss: 0.4479\n",
      "Epoch 3320/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7744 - auc: 0.8538 - loss: 0.4674 - val_acc: 0.7860 - val_auc: 0.8651 - val_loss: 0.4498\n",
      "Epoch 3321/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7714 - auc: 0.8527 - loss: 0.4694 - val_acc: 0.7877 - val_auc: 0.8667 - val_loss: 0.4458\n",
      "Epoch 3322/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7760 - auc: 0.8536 - loss: 0.4677 - val_acc: 0.7847 - val_auc: 0.8645 - val_loss: 0.4496\n",
      "Epoch 3323/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7756 - auc: 0.8544 - loss: 0.4664 - val_acc: 0.7874 - val_auc: 0.8668 - val_loss: 0.4458\n",
      "Epoch 3324/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7718 - auc: 0.8529 - loss: 0.4682 - val_acc: 0.7864 - val_auc: 0.8645 - val_loss: 0.4493\n",
      "Epoch 3325/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7752 - auc: 0.8552 - loss: 0.4650 - val_acc: 0.7866 - val_auc: 0.8654 - val_loss: 0.4485\n",
      "Epoch 3326/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7732 - auc: 0.8522 - loss: 0.4695 - val_acc: 0.7871 - val_auc: 0.8661 - val_loss: 0.4490\n",
      "Epoch 3327/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7732 - auc: 0.8514 - loss: 0.4694 - val_acc: 0.7891 - val_auc: 0.8669 - val_loss: 0.4468\n",
      "Epoch 3328/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7718 - auc: 0.8527 - loss: 0.4681 - val_acc: 0.7878 - val_auc: 0.8660 - val_loss: 0.4476\n",
      "Epoch 3329/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7718 - auc: 0.8515 - loss: 0.4693 - val_acc: 0.7889 - val_auc: 0.8670 - val_loss: 0.4478\n",
      "Epoch 3330/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7729 - auc: 0.8525 - loss: 0.4694 - val_acc: 0.7856 - val_auc: 0.8667 - val_loss: 0.4482\n",
      "Epoch 3331/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7748 - auc: 0.8536 - loss: 0.4675 - val_acc: 0.7864 - val_auc: 0.8662 - val_loss: 0.4476\n",
      "Epoch 3332/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7694 - auc: 0.8518 - loss: 0.4696 - val_acc: 0.7840 - val_auc: 0.8645 - val_loss: 0.4509\n",
      "Epoch 3333/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7732 - auc: 0.8531 - loss: 0.4685 - val_acc: 0.7866 - val_auc: 0.8664 - val_loss: 0.4483\n",
      "Epoch 3334/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7752 - auc: 0.8536 - loss: 0.4669 - val_acc: 0.7890 - val_auc: 0.8667 - val_loss: 0.4459\n",
      "Epoch 3335/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7728 - auc: 0.8528 - loss: 0.4680 - val_acc: 0.7877 - val_auc: 0.8668 - val_loss: 0.4459\n",
      "Epoch 3336/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7751 - auc: 0.8539 - loss: 0.4668 - val_acc: 0.7849 - val_auc: 0.8659 - val_loss: 0.4492\n",
      "Epoch 3337/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7743 - auc: 0.8542 - loss: 0.4672 - val_acc: 0.7881 - val_auc: 0.8664 - val_loss: 0.4476\n",
      "Epoch 3338/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7731 - auc: 0.8536 - loss: 0.4681 - val_acc: 0.7894 - val_auc: 0.8672 - val_loss: 0.4462\n",
      "Epoch 3339/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7738 - auc: 0.8533 - loss: 0.4675 - val_acc: 0.7869 - val_auc: 0.8657 - val_loss: 0.4484\n",
      "Epoch 3340/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7720 - auc: 0.8520 - loss: 0.4691 - val_acc: 0.7865 - val_auc: 0.8655 - val_loss: 0.4492\n",
      "Epoch 3341/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7723 - auc: 0.8528 - loss: 0.4689 - val_acc: 0.7893 - val_auc: 0.8663 - val_loss: 0.4477\n",
      "Epoch 3342/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7744 - auc: 0.8546 - loss: 0.4651 - val_acc: 0.7836 - val_auc: 0.8646 - val_loss: 0.4499\n",
      "Epoch 3343/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7729 - auc: 0.8536 - loss: 0.4674 - val_acc: 0.7876 - val_auc: 0.8660 - val_loss: 0.4473\n",
      "Epoch 3344/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7739 - auc: 0.8531 - loss: 0.4673 - val_acc: 0.7861 - val_auc: 0.8653 - val_loss: 0.4489\n",
      "Epoch 3345/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7740 - auc: 0.8523 - loss: 0.4687 - val_acc: 0.7860 - val_auc: 0.8655 - val_loss: 0.4493\n",
      "Epoch 3346/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7722 - auc: 0.8526 - loss: 0.4685 - val_acc: 0.7840 - val_auc: 0.8653 - val_loss: 0.4484\n",
      "Epoch 3347/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7713 - auc: 0.8520 - loss: 0.4695 - val_acc: 0.7859 - val_auc: 0.8657 - val_loss: 0.4478\n",
      "Epoch 3348/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7743 - auc: 0.8541 - loss: 0.4676 - val_acc: 0.7854 - val_auc: 0.8642 - val_loss: 0.4494\n",
      "Epoch 3349/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7733 - auc: 0.8524 - loss: 0.4693 - val_acc: 0.7803 - val_auc: 0.8632 - val_loss: 0.4523\n",
      "Epoch 3350/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7753 - auc: 0.8543 - loss: 0.4658 - val_acc: 0.7881 - val_auc: 0.8666 - val_loss: 0.4477\n",
      "Epoch 3351/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7738 - auc: 0.8536 - loss: 0.4682 - val_acc: 0.7873 - val_auc: 0.8658 - val_loss: 0.4477\n",
      "Epoch 3352/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7727 - auc: 0.8525 - loss: 0.4685 - val_acc: 0.7880 - val_auc: 0.8663 - val_loss: 0.4486\n",
      "Epoch 3353/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7737 - auc: 0.8527 - loss: 0.4681 - val_acc: 0.7893 - val_auc: 0.8672 - val_loss: 0.4465\n",
      "Epoch 3354/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7727 - auc: 0.8522 - loss: 0.4696 - val_acc: 0.7884 - val_auc: 0.8672 - val_loss: 0.4477\n",
      "Epoch 3355/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7733 - auc: 0.8521 - loss: 0.4695 - val_acc: 0.7850 - val_auc: 0.8660 - val_loss: 0.4494\n",
      "Epoch 3356/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7744 - auc: 0.8537 - loss: 0.4671 - val_acc: 0.7853 - val_auc: 0.8651 - val_loss: 0.4490\n",
      "Epoch 3357/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7728 - auc: 0.8525 - loss: 0.4687 - val_acc: 0.7842 - val_auc: 0.8639 - val_loss: 0.4515\n",
      "Epoch 3358/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7739 - auc: 0.8527 - loss: 0.4683 - val_acc: 0.7871 - val_auc: 0.8666 - val_loss: 0.4468\n",
      "Epoch 3359/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7723 - auc: 0.8518 - loss: 0.4708 - val_acc: 0.7831 - val_auc: 0.8651 - val_loss: 0.4517\n",
      "Epoch 3360/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7719 - auc: 0.8526 - loss: 0.4692 - val_acc: 0.7888 - val_auc: 0.8668 - val_loss: 0.4467\n",
      "Epoch 3361/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7732 - auc: 0.8515 - loss: 0.4696 - val_acc: 0.7873 - val_auc: 0.8670 - val_loss: 0.4482\n",
      "Epoch 3362/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7730 - auc: 0.8540 - loss: 0.4667 - val_acc: 0.7869 - val_auc: 0.8655 - val_loss: 0.4486\n",
      "Epoch 3363/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7714 - auc: 0.8524 - loss: 0.4693 - val_acc: 0.7872 - val_auc: 0.8669 - val_loss: 0.4488\n",
      "Epoch 3364/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7747 - auc: 0.8534 - loss: 0.4676 - val_acc: 0.7872 - val_auc: 0.8660 - val_loss: 0.4476\n",
      "Epoch 3365/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7763 - auc: 0.8554 - loss: 0.4645 - val_acc: 0.7864 - val_auc: 0.8660 - val_loss: 0.4476\n",
      "Epoch 3366/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7731 - auc: 0.8530 - loss: 0.4683 - val_acc: 0.7857 - val_auc: 0.8638 - val_loss: 0.4507\n",
      "Epoch 3367/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7737 - auc: 0.8530 - loss: 0.4678 - val_acc: 0.7863 - val_auc: 0.8660 - val_loss: 0.4492\n",
      "Epoch 3368/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7739 - auc: 0.8530 - loss: 0.4687 - val_acc: 0.7859 - val_auc: 0.8657 - val_loss: 0.4487\n",
      "Epoch 3369/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7719 - auc: 0.8513 - loss: 0.4710 - val_acc: 0.7878 - val_auc: 0.8652 - val_loss: 0.4498\n",
      "Epoch 3370/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7721 - auc: 0.8530 - loss: 0.4685 - val_acc: 0.7898 - val_auc: 0.8668 - val_loss: 0.4472\n",
      "Epoch 3371/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7744 - auc: 0.8545 - loss: 0.4653 - val_acc: 0.7884 - val_auc: 0.8662 - val_loss: 0.4486\n",
      "Epoch 3372/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7739 - auc: 0.8541 - loss: 0.4670 - val_acc: 0.7849 - val_auc: 0.8652 - val_loss: 0.4498\n",
      "Epoch 3373/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7733 - auc: 0.8535 - loss: 0.4673 - val_acc: 0.7873 - val_auc: 0.8658 - val_loss: 0.4488\n",
      "Epoch 3374/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7752 - auc: 0.8547 - loss: 0.4660 - val_acc: 0.7875 - val_auc: 0.8665 - val_loss: 0.4485\n",
      "Epoch 3375/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7734 - auc: 0.8530 - loss: 0.4682 - val_acc: 0.7860 - val_auc: 0.8664 - val_loss: 0.4489\n",
      "Epoch 3376/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7747 - auc: 0.8544 - loss: 0.4676 - val_acc: 0.7876 - val_auc: 0.8665 - val_loss: 0.4472\n",
      "Epoch 3377/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7719 - auc: 0.8523 - loss: 0.4695 - val_acc: 0.7874 - val_auc: 0.8666 - val_loss: 0.4477\n",
      "Epoch 3378/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7737 - auc: 0.8551 - loss: 0.4657 - val_acc: 0.7866 - val_auc: 0.8659 - val_loss: 0.4485\n",
      "Epoch 3379/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7741 - auc: 0.8527 - loss: 0.4693 - val_acc: 0.7850 - val_auc: 0.8647 - val_loss: 0.4527\n",
      "Epoch 3380/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7749 - auc: 0.8543 - loss: 0.4664 - val_acc: 0.7866 - val_auc: 0.8670 - val_loss: 0.4477\n",
      "Epoch 3381/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7738 - auc: 0.8527 - loss: 0.4686 - val_acc: 0.7888 - val_auc: 0.8658 - val_loss: 0.4471\n",
      "Epoch 3382/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7765 - auc: 0.8544 - loss: 0.4658 - val_acc: 0.7854 - val_auc: 0.8661 - val_loss: 0.4479\n",
      "Epoch 3383/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7740 - auc: 0.8538 - loss: 0.4668 - val_acc: 0.7871 - val_auc: 0.8660 - val_loss: 0.4471\n",
      "Epoch 3384/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7736 - auc: 0.8522 - loss: 0.4687 - val_acc: 0.7860 - val_auc: 0.8657 - val_loss: 0.4489\n",
      "Epoch 3385/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7737 - auc: 0.8534 - loss: 0.4679 - val_acc: 0.7848 - val_auc: 0.8656 - val_loss: 0.4489\n",
      "Epoch 3386/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7728 - auc: 0.8528 - loss: 0.4682 - val_acc: 0.7867 - val_auc: 0.8665 - val_loss: 0.4481\n",
      "Epoch 3387/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7742 - auc: 0.8523 - loss: 0.4680 - val_acc: 0.7882 - val_auc: 0.8659 - val_loss: 0.4482\n",
      "Epoch 3388/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7725 - auc: 0.8514 - loss: 0.4701 - val_acc: 0.7886 - val_auc: 0.8664 - val_loss: 0.4471\n",
      "Epoch 3389/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7702 - auc: 0.8515 - loss: 0.4698 - val_acc: 0.7862 - val_auc: 0.8647 - val_loss: 0.4501\n",
      "Epoch 3390/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7730 - auc: 0.8538 - loss: 0.4663 - val_acc: 0.7876 - val_auc: 0.8642 - val_loss: 0.4509\n",
      "Epoch 3391/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7765 - auc: 0.8543 - loss: 0.4669 - val_acc: 0.7864 - val_auc: 0.8656 - val_loss: 0.4489\n",
      "Epoch 3392/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7739 - auc: 0.8529 - loss: 0.4684 - val_acc: 0.7855 - val_auc: 0.8666 - val_loss: 0.4487\n",
      "Epoch 3393/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7739 - auc: 0.8539 - loss: 0.4666 - val_acc: 0.7868 - val_auc: 0.8664 - val_loss: 0.4473\n",
      "Epoch 3394/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7742 - auc: 0.8526 - loss: 0.4685 - val_acc: 0.7867 - val_auc: 0.8665 - val_loss: 0.4475\n",
      "Epoch 3395/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7756 - auc: 0.8546 - loss: 0.4657 - val_acc: 0.7890 - val_auc: 0.8680 - val_loss: 0.4469\n",
      "Epoch 3396/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7743 - auc: 0.8553 - loss: 0.4651 - val_acc: 0.7870 - val_auc: 0.8663 - val_loss: 0.4471\n",
      "Epoch 3397/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7741 - auc: 0.8535 - loss: 0.4676 - val_acc: 0.7867 - val_auc: 0.8670 - val_loss: 0.4482\n",
      "Epoch 3398/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7753 - auc: 0.8537 - loss: 0.4663 - val_acc: 0.7878 - val_auc: 0.8677 - val_loss: 0.4459\n",
      "Epoch 3399/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7735 - auc: 0.8525 - loss: 0.4673 - val_acc: 0.7905 - val_auc: 0.8671 - val_loss: 0.4470\n",
      "Epoch 3400/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7741 - auc: 0.8534 - loss: 0.4686 - val_acc: 0.7863 - val_auc: 0.8665 - val_loss: 0.4467\n",
      "Epoch 3401/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7729 - auc: 0.8546 - loss: 0.4671 - val_acc: 0.7860 - val_auc: 0.8668 - val_loss: 0.4461\n",
      "Epoch 3402/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7728 - auc: 0.8546 - loss: 0.4658 - val_acc: 0.7879 - val_auc: 0.8679 - val_loss: 0.4471\n",
      "Epoch 3403/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7743 - auc: 0.8534 - loss: 0.4674 - val_acc: 0.7896 - val_auc: 0.8669 - val_loss: 0.4454\n",
      "Epoch 3404/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7726 - auc: 0.8525 - loss: 0.4691 - val_acc: 0.7853 - val_auc: 0.8655 - val_loss: 0.4487\n",
      "Epoch 3405/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7737 - auc: 0.8536 - loss: 0.4681 - val_acc: 0.7857 - val_auc: 0.8660 - val_loss: 0.4499\n",
      "Epoch 3406/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7747 - auc: 0.8538 - loss: 0.4666 - val_acc: 0.7880 - val_auc: 0.8667 - val_loss: 0.4468\n",
      "Epoch 3407/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7734 - auc: 0.8534 - loss: 0.4675 - val_acc: 0.7868 - val_auc: 0.8664 - val_loss: 0.4482\n",
      "Epoch 3408/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7745 - auc: 0.8541 - loss: 0.4661 - val_acc: 0.7849 - val_auc: 0.8655 - val_loss: 0.4494\n",
      "Epoch 3409/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7732 - auc: 0.8538 - loss: 0.4672 - val_acc: 0.7876 - val_auc: 0.8660 - val_loss: 0.4491\n",
      "Epoch 3410/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7726 - auc: 0.8522 - loss: 0.4687 - val_acc: 0.7874 - val_auc: 0.8654 - val_loss: 0.4477\n",
      "Epoch 3411/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7741 - auc: 0.8547 - loss: 0.4662 - val_acc: 0.7901 - val_auc: 0.8681 - val_loss: 0.4464\n",
      "Epoch 3412/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7737 - auc: 0.8532 - loss: 0.4673 - val_acc: 0.7870 - val_auc: 0.8665 - val_loss: 0.4467\n",
      "Epoch 3413/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7741 - auc: 0.8530 - loss: 0.4681 - val_acc: 0.7847 - val_auc: 0.8649 - val_loss: 0.4499\n",
      "Epoch 3414/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7750 - auc: 0.8548 - loss: 0.4653 - val_acc: 0.7868 - val_auc: 0.8672 - val_loss: 0.4482\n",
      "Epoch 3415/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7753 - auc: 0.8531 - loss: 0.4681 - val_acc: 0.7874 - val_auc: 0.8667 - val_loss: 0.4474\n",
      "Epoch 3416/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7727 - auc: 0.8537 - loss: 0.4676 - val_acc: 0.7881 - val_auc: 0.8668 - val_loss: 0.4473\n",
      "Epoch 3417/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7729 - auc: 0.8514 - loss: 0.4702 - val_acc: 0.7868 - val_auc: 0.8657 - val_loss: 0.4484\n",
      "Epoch 3418/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7749 - auc: 0.8534 - loss: 0.4674 - val_acc: 0.7875 - val_auc: 0.8662 - val_loss: 0.4484\n",
      "Epoch 3419/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7755 - auc: 0.8542 - loss: 0.4657 - val_acc: 0.7863 - val_auc: 0.8658 - val_loss: 0.4480\n",
      "Epoch 3420/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7736 - auc: 0.8535 - loss: 0.4671 - val_acc: 0.7868 - val_auc: 0.8663 - val_loss: 0.4469\n",
      "Epoch 3421/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7748 - auc: 0.8544 - loss: 0.4665 - val_acc: 0.7878 - val_auc: 0.8670 - val_loss: 0.4460\n",
      "Epoch 3422/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7735 - auc: 0.8526 - loss: 0.4698 - val_acc: 0.7862 - val_auc: 0.8667 - val_loss: 0.4490\n",
      "Epoch 3423/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7758 - auc: 0.8535 - loss: 0.4676 - val_acc: 0.7905 - val_auc: 0.8669 - val_loss: 0.4474\n",
      "Epoch 3424/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7744 - auc: 0.8531 - loss: 0.4686 - val_acc: 0.7897 - val_auc: 0.8664 - val_loss: 0.4480\n",
      "Epoch 3425/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7715 - auc: 0.8522 - loss: 0.4683 - val_acc: 0.7865 - val_auc: 0.8652 - val_loss: 0.4517\n",
      "Epoch 3426/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7733 - auc: 0.8532 - loss: 0.4680 - val_acc: 0.7868 - val_auc: 0.8667 - val_loss: 0.4480\n",
      "Epoch 3427/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7742 - auc: 0.8535 - loss: 0.4675 - val_acc: 0.7872 - val_auc: 0.8667 - val_loss: 0.4489\n",
      "Epoch 3428/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7765 - auc: 0.8541 - loss: 0.4673 - val_acc: 0.7894 - val_auc: 0.8668 - val_loss: 0.4479\n",
      "Epoch 3429/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7743 - auc: 0.8543 - loss: 0.4665 - val_acc: 0.7852 - val_auc: 0.8666 - val_loss: 0.4485\n",
      "Epoch 3430/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7745 - auc: 0.8543 - loss: 0.4659 - val_acc: 0.7876 - val_auc: 0.8663 - val_loss: 0.4477\n",
      "Epoch 3431/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7721 - auc: 0.8537 - loss: 0.4671 - val_acc: 0.7870 - val_auc: 0.8663 - val_loss: 0.4479\n",
      "Epoch 3432/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7748 - auc: 0.8526 - loss: 0.4699 - val_acc: 0.7860 - val_auc: 0.8655 - val_loss: 0.4499\n",
      "Epoch 3433/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7760 - auc: 0.8537 - loss: 0.4659 - val_acc: 0.7861 - val_auc: 0.8668 - val_loss: 0.4464\n",
      "Epoch 3434/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7743 - auc: 0.8552 - loss: 0.4654 - val_acc: 0.7880 - val_auc: 0.8659 - val_loss: 0.4482\n",
      "Epoch 3435/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7746 - auc: 0.8528 - loss: 0.4675 - val_acc: 0.7888 - val_auc: 0.8665 - val_loss: 0.4482\n",
      "Epoch 3436/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7736 - auc: 0.8532 - loss: 0.4680 - val_acc: 0.7903 - val_auc: 0.8675 - val_loss: 0.4462\n",
      "Epoch 3437/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7730 - auc: 0.8527 - loss: 0.4685 - val_acc: 0.7879 - val_auc: 0.8661 - val_loss: 0.4475\n",
      "Epoch 3438/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7728 - auc: 0.8533 - loss: 0.4675 - val_acc: 0.7877 - val_auc: 0.8675 - val_loss: 0.4460\n",
      "Epoch 3439/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7726 - auc: 0.8528 - loss: 0.4680 - val_acc: 0.7872 - val_auc: 0.8672 - val_loss: 0.4477\n",
      "Epoch 3440/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7739 - auc: 0.8538 - loss: 0.4679 - val_acc: 0.7870 - val_auc: 0.8666 - val_loss: 0.4470\n",
      "Epoch 3441/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7744 - auc: 0.8541 - loss: 0.4677 - val_acc: 0.7902 - val_auc: 0.8675 - val_loss: 0.4459\n",
      "Epoch 3442/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7724 - auc: 0.8520 - loss: 0.4686 - val_acc: 0.7883 - val_auc: 0.8674 - val_loss: 0.4471\n",
      "Epoch 3443/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7754 - auc: 0.8545 - loss: 0.4653 - val_acc: 0.7885 - val_auc: 0.8669 - val_loss: 0.4478\n",
      "Epoch 3444/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7718 - auc: 0.8528 - loss: 0.4684 - val_acc: 0.7886 - val_auc: 0.8663 - val_loss: 0.4474\n",
      "Epoch 3445/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7728 - auc: 0.8535 - loss: 0.4687 - val_acc: 0.7893 - val_auc: 0.8658 - val_loss: 0.4478\n",
      "Epoch 3446/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7741 - auc: 0.8538 - loss: 0.4670 - val_acc: 0.7904 - val_auc: 0.8673 - val_loss: 0.4466\n",
      "Epoch 3447/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7741 - auc: 0.8540 - loss: 0.4670 - val_acc: 0.7874 - val_auc: 0.8675 - val_loss: 0.4465\n",
      "Epoch 3448/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7730 - auc: 0.8541 - loss: 0.4676 - val_acc: 0.7902 - val_auc: 0.8680 - val_loss: 0.4451\n",
      "Epoch 3449/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7740 - auc: 0.8551 - loss: 0.4651 - val_acc: 0.7880 - val_auc: 0.8665 - val_loss: 0.4462\n",
      "Epoch 3450/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7747 - auc: 0.8527 - loss: 0.4673 - val_acc: 0.7907 - val_auc: 0.8675 - val_loss: 0.4455\n",
      "Epoch 3451/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7759 - auc: 0.8541 - loss: 0.4673 - val_acc: 0.7879 - val_auc: 0.8669 - val_loss: 0.4461\n",
      "Epoch 3452/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7742 - auc: 0.8544 - loss: 0.4660 - val_acc: 0.7854 - val_auc: 0.8670 - val_loss: 0.4475\n",
      "Epoch 3453/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7745 - auc: 0.8539 - loss: 0.4674 - val_acc: 0.7893 - val_auc: 0.8672 - val_loss: 0.4459\n",
      "Epoch 3454/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7767 - auc: 0.8544 - loss: 0.4664 - val_acc: 0.7881 - val_auc: 0.8670 - val_loss: 0.4477\n",
      "Epoch 3455/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7736 - auc: 0.8533 - loss: 0.4664 - val_acc: 0.7874 - val_auc: 0.8669 - val_loss: 0.4473\n",
      "Epoch 3456/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7763 - auc: 0.8550 - loss: 0.4663 - val_acc: 0.7885 - val_auc: 0.8665 - val_loss: 0.4470\n",
      "Epoch 3457/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7741 - auc: 0.8540 - loss: 0.4666 - val_acc: 0.7876 - val_auc: 0.8666 - val_loss: 0.4481\n",
      "Epoch 3458/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7722 - auc: 0.8525 - loss: 0.4688 - val_acc: 0.7886 - val_auc: 0.8680 - val_loss: 0.4475\n",
      "Epoch 3459/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7738 - auc: 0.8537 - loss: 0.4673 - val_acc: 0.7881 - val_auc: 0.8667 - val_loss: 0.4475\n",
      "Epoch 3460/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7730 - auc: 0.8539 - loss: 0.4674 - val_acc: 0.7846 - val_auc: 0.8659 - val_loss: 0.4482\n",
      "Epoch 3461/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7735 - auc: 0.8539 - loss: 0.4669 - val_acc: 0.7888 - val_auc: 0.8669 - val_loss: 0.4470\n",
      "Epoch 3462/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7729 - auc: 0.8535 - loss: 0.4678 - val_acc: 0.7884 - val_auc: 0.8664 - val_loss: 0.4477\n",
      "Epoch 3463/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7752 - auc: 0.8534 - loss: 0.4681 - val_acc: 0.7866 - val_auc: 0.8661 - val_loss: 0.4482\n",
      "Epoch 3464/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7729 - auc: 0.8526 - loss: 0.4685 - val_acc: 0.7882 - val_auc: 0.8679 - val_loss: 0.4469\n",
      "Epoch 3465/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7719 - auc: 0.8527 - loss: 0.4685 - val_acc: 0.7886 - val_auc: 0.8661 - val_loss: 0.4483\n",
      "Epoch 3466/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7750 - auc: 0.8533 - loss: 0.4670 - val_acc: 0.7900 - val_auc: 0.8670 - val_loss: 0.4470\n",
      "Epoch 3467/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7738 - auc: 0.8544 - loss: 0.4661 - val_acc: 0.7888 - val_auc: 0.8665 - val_loss: 0.4478\n",
      "Epoch 3468/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7736 - auc: 0.8522 - loss: 0.4691 - val_acc: 0.7876 - val_auc: 0.8649 - val_loss: 0.4496\n",
      "Epoch 3469/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7724 - auc: 0.8535 - loss: 0.4661 - val_acc: 0.7888 - val_auc: 0.8667 - val_loss: 0.4471\n",
      "Epoch 3470/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7758 - auc: 0.8555 - loss: 0.4644 - val_acc: 0.7866 - val_auc: 0.8653 - val_loss: 0.4501\n",
      "Epoch 3471/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7734 - auc: 0.8538 - loss: 0.4663 - val_acc: 0.7895 - val_auc: 0.8663 - val_loss: 0.4473\n",
      "Epoch 3472/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7751 - auc: 0.8530 - loss: 0.4683 - val_acc: 0.7877 - val_auc: 0.8662 - val_loss: 0.4467\n",
      "Epoch 3473/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7740 - auc: 0.8537 - loss: 0.4666 - val_acc: 0.7843 - val_auc: 0.8663 - val_loss: 0.4480\n",
      "Epoch 3474/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7753 - auc: 0.8556 - loss: 0.4634 - val_acc: 0.7864 - val_auc: 0.8667 - val_loss: 0.4468\n",
      "Epoch 3475/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7755 - auc: 0.8539 - loss: 0.4674 - val_acc: 0.7837 - val_auc: 0.8655 - val_loss: 0.4496\n",
      "Epoch 3476/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7754 - auc: 0.8547 - loss: 0.4662 - val_acc: 0.7888 - val_auc: 0.8670 - val_loss: 0.4467\n",
      "Epoch 3477/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7730 - auc: 0.8536 - loss: 0.4666 - val_acc: 0.7866 - val_auc: 0.8663 - val_loss: 0.4475\n",
      "Epoch 3478/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7740 - auc: 0.8546 - loss: 0.4664 - val_acc: 0.7865 - val_auc: 0.8658 - val_loss: 0.4487\n",
      "Epoch 3479/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7752 - auc: 0.8539 - loss: 0.4677 - val_acc: 0.7862 - val_auc: 0.8660 - val_loss: 0.4491\n",
      "Epoch 3480/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7708 - auc: 0.8524 - loss: 0.4685 - val_acc: 0.7863 - val_auc: 0.8660 - val_loss: 0.4482\n",
      "Epoch 3481/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7722 - auc: 0.8525 - loss: 0.4686 - val_acc: 0.7872 - val_auc: 0.8662 - val_loss: 0.4479\n",
      "Epoch 3482/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7712 - auc: 0.8522 - loss: 0.4699 - val_acc: 0.7873 - val_auc: 0.8661 - val_loss: 0.4484\n",
      "Epoch 3483/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7745 - auc: 0.8539 - loss: 0.4672 - val_acc: 0.7864 - val_auc: 0.8662 - val_loss: 0.4479\n",
      "Epoch 3484/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7723 - auc: 0.8528 - loss: 0.4686 - val_acc: 0.7831 - val_auc: 0.8650 - val_loss: 0.4501\n",
      "Epoch 3485/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7738 - auc: 0.8534 - loss: 0.4678 - val_acc: 0.7874 - val_auc: 0.8657 - val_loss: 0.4489\n",
      "Epoch 3486/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7737 - auc: 0.8530 - loss: 0.4685 - val_acc: 0.7881 - val_auc: 0.8659 - val_loss: 0.4471\n",
      "Epoch 3487/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7745 - auc: 0.8538 - loss: 0.4672 - val_acc: 0.7881 - val_auc: 0.8665 - val_loss: 0.4462\n",
      "Epoch 3488/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7750 - auc: 0.8549 - loss: 0.4662 - val_acc: 0.7896 - val_auc: 0.8668 - val_loss: 0.4471\n",
      "Epoch 3489/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7735 - auc: 0.8530 - loss: 0.4682 - val_acc: 0.7844 - val_auc: 0.8665 - val_loss: 0.4502\n",
      "Epoch 3490/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7761 - auc: 0.8561 - loss: 0.4638 - val_acc: 0.7893 - val_auc: 0.8667 - val_loss: 0.4471\n",
      "Epoch 3491/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7755 - auc: 0.8532 - loss: 0.4686 - val_acc: 0.7887 - val_auc: 0.8657 - val_loss: 0.4483\n",
      "Epoch 3492/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7720 - auc: 0.8537 - loss: 0.4670 - val_acc: 0.7857 - val_auc: 0.8657 - val_loss: 0.4485\n",
      "Epoch 3493/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7748 - auc: 0.8544 - loss: 0.4662 - val_acc: 0.7871 - val_auc: 0.8656 - val_loss: 0.4486\n",
      "Epoch 3494/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7730 - auc: 0.8532 - loss: 0.4676 - val_acc: 0.7892 - val_auc: 0.8672 - val_loss: 0.4462\n",
      "Epoch 3495/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7730 - auc: 0.8537 - loss: 0.4679 - val_acc: 0.7859 - val_auc: 0.8659 - val_loss: 0.4508\n",
      "Epoch 3496/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7736 - auc: 0.8540 - loss: 0.4672 - val_acc: 0.7889 - val_auc: 0.8682 - val_loss: 0.4444\n",
      "Epoch 3497/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7730 - auc: 0.8520 - loss: 0.4702 - val_acc: 0.7847 - val_auc: 0.8659 - val_loss: 0.4468\n",
      "Epoch 3498/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7715 - auc: 0.8525 - loss: 0.4689 - val_acc: 0.7855 - val_auc: 0.8657 - val_loss: 0.4487\n",
      "Epoch 3499/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7745 - auc: 0.8541 - loss: 0.4671 - val_acc: 0.7884 - val_auc: 0.8667 - val_loss: 0.4474\n",
      "Epoch 3500/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7757 - auc: 0.8552 - loss: 0.4653 - val_acc: 0.7872 - val_auc: 0.8658 - val_loss: 0.4476\n",
      "Epoch 3501/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7765 - auc: 0.8564 - loss: 0.4634 - val_acc: 0.7832 - val_auc: 0.8660 - val_loss: 0.4474\n",
      "Epoch 3502/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7730 - auc: 0.8529 - loss: 0.4681 - val_acc: 0.7874 - val_auc: 0.8664 - val_loss: 0.4474\n",
      "Epoch 3503/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7728 - auc: 0.8533 - loss: 0.4681 - val_acc: 0.7878 - val_auc: 0.8663 - val_loss: 0.4489\n",
      "Epoch 3504/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7758 - auc: 0.8545 - loss: 0.4653 - val_acc: 0.7862 - val_auc: 0.8653 - val_loss: 0.4491\n",
      "Epoch 3505/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7750 - auc: 0.8546 - loss: 0.4672 - val_acc: 0.7847 - val_auc: 0.8654 - val_loss: 0.4509\n",
      "Epoch 3506/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7747 - auc: 0.8542 - loss: 0.4655 - val_acc: 0.7853 - val_auc: 0.8661 - val_loss: 0.4488\n",
      "Epoch 3507/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7740 - auc: 0.8542 - loss: 0.4672 - val_acc: 0.7881 - val_auc: 0.8660 - val_loss: 0.4469\n",
      "Epoch 3508/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7754 - auc: 0.8541 - loss: 0.4668 - val_acc: 0.7857 - val_auc: 0.8675 - val_loss: 0.4476\n",
      "Epoch 3509/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7724 - auc: 0.8522 - loss: 0.4692 - val_acc: 0.7835 - val_auc: 0.8659 - val_loss: 0.4494\n",
      "Epoch 3510/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7781 - auc: 0.8560 - loss: 0.4652 - val_acc: 0.7842 - val_auc: 0.8660 - val_loss: 0.4490\n",
      "Epoch 3511/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7766 - auc: 0.8548 - loss: 0.4654 - val_acc: 0.7877 - val_auc: 0.8671 - val_loss: 0.4462\n",
      "Epoch 3512/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7758 - auc: 0.8544 - loss: 0.4652 - val_acc: 0.7890 - val_auc: 0.8671 - val_loss: 0.4465\n",
      "Epoch 3513/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7733 - auc: 0.8537 - loss: 0.4670 - val_acc: 0.7864 - val_auc: 0.8655 - val_loss: 0.4499\n",
      "Epoch 3514/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7746 - auc: 0.8537 - loss: 0.4683 - val_acc: 0.7893 - val_auc: 0.8674 - val_loss: 0.4469\n",
      "Epoch 3515/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7744 - auc: 0.8516 - loss: 0.4708 - val_acc: 0.7861 - val_auc: 0.8670 - val_loss: 0.4477\n",
      "Epoch 3516/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7745 - auc: 0.8541 - loss: 0.4687 - val_acc: 0.7877 - val_auc: 0.8673 - val_loss: 0.4488\n",
      "Epoch 3517/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7741 - auc: 0.8522 - loss: 0.4689 - val_acc: 0.7856 - val_auc: 0.8650 - val_loss: 0.4485\n",
      "Epoch 3518/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7739 - auc: 0.8547 - loss: 0.4651 - val_acc: 0.7865 - val_auc: 0.8665 - val_loss: 0.4469\n",
      "Epoch 3519/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7755 - auc: 0.8548 - loss: 0.4653 - val_acc: 0.7890 - val_auc: 0.8663 - val_loss: 0.4478\n",
      "Epoch 3520/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7736 - auc: 0.8539 - loss: 0.4670 - val_acc: 0.7877 - val_auc: 0.8668 - val_loss: 0.4470\n",
      "Epoch 3521/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7766 - auc: 0.8553 - loss: 0.4646 - val_acc: 0.7865 - val_auc: 0.8647 - val_loss: 0.4491\n",
      "Epoch 3522/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7751 - auc: 0.8540 - loss: 0.4663 - val_acc: 0.7845 - val_auc: 0.8651 - val_loss: 0.4499\n",
      "Epoch 3523/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7717 - auc: 0.8538 - loss: 0.4662 - val_acc: 0.7898 - val_auc: 0.8679 - val_loss: 0.4455\n",
      "Epoch 3524/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7741 - auc: 0.8532 - loss: 0.4682 - val_acc: 0.7880 - val_auc: 0.8676 - val_loss: 0.4479\n",
      "Epoch 3525/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7763 - auc: 0.8546 - loss: 0.4659 - val_acc: 0.7877 - val_auc: 0.8671 - val_loss: 0.4476\n",
      "Epoch 3526/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7741 - auc: 0.8536 - loss: 0.4672 - val_acc: 0.7882 - val_auc: 0.8678 - val_loss: 0.4460\n",
      "Epoch 3527/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7723 - auc: 0.8518 - loss: 0.4703 - val_acc: 0.7924 - val_auc: 0.8670 - val_loss: 0.4455\n",
      "Epoch 3528/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7758 - auc: 0.8546 - loss: 0.4664 - val_acc: 0.7883 - val_auc: 0.8679 - val_loss: 0.4459\n",
      "Epoch 3529/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7755 - auc: 0.8544 - loss: 0.4659 - val_acc: 0.7881 - val_auc: 0.8664 - val_loss: 0.4476\n",
      "Epoch 3530/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7754 - auc: 0.8560 - loss: 0.4642 - val_acc: 0.7890 - val_auc: 0.8669 - val_loss: 0.4463\n",
      "Epoch 3531/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7738 - auc: 0.8538 - loss: 0.4670 - val_acc: 0.7868 - val_auc: 0.8655 - val_loss: 0.4489\n",
      "Epoch 3532/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7755 - auc: 0.8544 - loss: 0.4660 - val_acc: 0.7871 - val_auc: 0.8659 - val_loss: 0.4465\n",
      "Epoch 3533/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7740 - auc: 0.8545 - loss: 0.4661 - val_acc: 0.7877 - val_auc: 0.8656 - val_loss: 0.4475\n",
      "Epoch 3534/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7737 - auc: 0.8544 - loss: 0.4660 - val_acc: 0.7871 - val_auc: 0.8655 - val_loss: 0.4474\n",
      "Epoch 3535/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7753 - auc: 0.8539 - loss: 0.4668 - val_acc: 0.7868 - val_auc: 0.8657 - val_loss: 0.4482\n",
      "Epoch 3536/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7736 - auc: 0.8539 - loss: 0.4673 - val_acc: 0.7856 - val_auc: 0.8675 - val_loss: 0.4481\n",
      "Epoch 3537/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7748 - auc: 0.8539 - loss: 0.4668 - val_acc: 0.7855 - val_auc: 0.8661 - val_loss: 0.4494\n",
      "Epoch 3538/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7744 - auc: 0.8536 - loss: 0.4680 - val_acc: 0.7889 - val_auc: 0.8663 - val_loss: 0.4471\n",
      "Epoch 3539/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7737 - auc: 0.8540 - loss: 0.4666 - val_acc: 0.7881 - val_auc: 0.8660 - val_loss: 0.4471\n",
      "Epoch 3540/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7758 - auc: 0.8553 - loss: 0.4661 - val_acc: 0.7892 - val_auc: 0.8666 - val_loss: 0.4479\n",
      "Epoch 3541/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7745 - auc: 0.8540 - loss: 0.4662 - val_acc: 0.7871 - val_auc: 0.8661 - val_loss: 0.4472\n",
      "Epoch 3542/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7739 - auc: 0.8542 - loss: 0.4662 - val_acc: 0.7874 - val_auc: 0.8666 - val_loss: 0.4473\n",
      "Epoch 3543/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7738 - auc: 0.8541 - loss: 0.4660 - val_acc: 0.7885 - val_auc: 0.8672 - val_loss: 0.4464\n",
      "Epoch 3544/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7745 - auc: 0.8539 - loss: 0.4672 - val_acc: 0.7861 - val_auc: 0.8659 - val_loss: 0.4485\n",
      "Epoch 3545/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7762 - auc: 0.8548 - loss: 0.4651 - val_acc: 0.7867 - val_auc: 0.8675 - val_loss: 0.4463\n",
      "Epoch 3546/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7743 - auc: 0.8542 - loss: 0.4665 - val_acc: 0.7864 - val_auc: 0.8661 - val_loss: 0.4484\n",
      "Epoch 3547/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7750 - auc: 0.8544 - loss: 0.4662 - val_acc: 0.7869 - val_auc: 0.8664 - val_loss: 0.4473\n",
      "Epoch 3548/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7748 - auc: 0.8530 - loss: 0.4686 - val_acc: 0.7853 - val_auc: 0.8664 - val_loss: 0.4487\n",
      "Epoch 3549/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7755 - auc: 0.8530 - loss: 0.4679 - val_acc: 0.7889 - val_auc: 0.8675 - val_loss: 0.4465\n",
      "Epoch 3550/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7743 - auc: 0.8532 - loss: 0.4701 - val_acc: 0.7866 - val_auc: 0.8671 - val_loss: 0.4473\n",
      "Epoch 3551/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7758 - auc: 0.8540 - loss: 0.4669 - val_acc: 0.7867 - val_auc: 0.8659 - val_loss: 0.4475\n",
      "Epoch 3552/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7737 - auc: 0.8534 - loss: 0.4681 - val_acc: 0.7880 - val_auc: 0.8664 - val_loss: 0.4470\n",
      "Epoch 3553/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7740 - auc: 0.8542 - loss: 0.4662 - val_acc: 0.7882 - val_auc: 0.8665 - val_loss: 0.4449\n",
      "Epoch 3554/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7744 - auc: 0.8537 - loss: 0.4677 - val_acc: 0.7852 - val_auc: 0.8657 - val_loss: 0.4481\n",
      "Epoch 3555/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7746 - auc: 0.8536 - loss: 0.4676 - val_acc: 0.7865 - val_auc: 0.8667 - val_loss: 0.4473\n",
      "Epoch 3556/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7742 - auc: 0.8537 - loss: 0.4668 - val_acc: 0.7887 - val_auc: 0.8667 - val_loss: 0.4479\n",
      "Epoch 3557/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7747 - auc: 0.8536 - loss: 0.4676 - val_acc: 0.7887 - val_auc: 0.8673 - val_loss: 0.4463\n",
      "Epoch 3558/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7740 - auc: 0.8536 - loss: 0.4670 - val_acc: 0.7865 - val_auc: 0.8670 - val_loss: 0.4469\n",
      "Epoch 3559/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7738 - auc: 0.8545 - loss: 0.4658 - val_acc: 0.7890 - val_auc: 0.8668 - val_loss: 0.4470\n",
      "Epoch 3560/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7738 - auc: 0.8529 - loss: 0.4690 - val_acc: 0.7861 - val_auc: 0.8661 - val_loss: 0.4492\n",
      "Epoch 3561/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7749 - auc: 0.8535 - loss: 0.4678 - val_acc: 0.7871 - val_auc: 0.8667 - val_loss: 0.4466\n",
      "Epoch 3562/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7770 - auc: 0.8551 - loss: 0.4647 - val_acc: 0.7896 - val_auc: 0.8676 - val_loss: 0.4453\n",
      "Epoch 3563/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7759 - auc: 0.8557 - loss: 0.4656 - val_acc: 0.7835 - val_auc: 0.8648 - val_loss: 0.4497\n",
      "Epoch 3564/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7738 - auc: 0.8533 - loss: 0.4680 - val_acc: 0.7862 - val_auc: 0.8658 - val_loss: 0.4471\n",
      "Epoch 3565/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7770 - auc: 0.8555 - loss: 0.4647 - val_acc: 0.7840 - val_auc: 0.8656 - val_loss: 0.4481\n",
      "Epoch 3566/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7733 - auc: 0.8543 - loss: 0.4655 - val_acc: 0.7862 - val_auc: 0.8671 - val_loss: 0.4478\n",
      "Epoch 3567/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7737 - auc: 0.8530 - loss: 0.4677 - val_acc: 0.7823 - val_auc: 0.8646 - val_loss: 0.4500\n",
      "Epoch 3568/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7750 - auc: 0.8552 - loss: 0.4643 - val_acc: 0.7870 - val_auc: 0.8655 - val_loss: 0.4486\n",
      "Epoch 3569/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7769 - auc: 0.8553 - loss: 0.4642 - val_acc: 0.7878 - val_auc: 0.8656 - val_loss: 0.4486\n",
      "Epoch 3570/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7769 - auc: 0.8550 - loss: 0.4652 - val_acc: 0.7859 - val_auc: 0.8659 - val_loss: 0.4489\n",
      "Epoch 3571/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7725 - auc: 0.8536 - loss: 0.4668 - val_acc: 0.7868 - val_auc: 0.8650 - val_loss: 0.4478\n",
      "Epoch 3572/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7754 - auc: 0.8551 - loss: 0.4653 - val_acc: 0.7851 - val_auc: 0.8653 - val_loss: 0.4498\n",
      "Epoch 3573/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7734 - auc: 0.8538 - loss: 0.4671 - val_acc: 0.7870 - val_auc: 0.8672 - val_loss: 0.4469\n",
      "Epoch 3574/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7765 - auc: 0.8543 - loss: 0.4654 - val_acc: 0.7857 - val_auc: 0.8669 - val_loss: 0.4461\n",
      "Epoch 3575/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7751 - auc: 0.8550 - loss: 0.4659 - val_acc: 0.7848 - val_auc: 0.8656 - val_loss: 0.4479\n",
      "Epoch 3576/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7770 - auc: 0.8564 - loss: 0.4636 - val_acc: 0.7883 - val_auc: 0.8662 - val_loss: 0.4472\n",
      "Epoch 3577/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7729 - auc: 0.8538 - loss: 0.4661 - val_acc: 0.7872 - val_auc: 0.8678 - val_loss: 0.4457\n",
      "Epoch 3578/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7740 - auc: 0.8539 - loss: 0.4657 - val_acc: 0.7902 - val_auc: 0.8671 - val_loss: 0.4453\n",
      "Epoch 3579/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7757 - auc: 0.8543 - loss: 0.4660 - val_acc: 0.7863 - val_auc: 0.8674 - val_loss: 0.4481\n",
      "Epoch 3580/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7759 - auc: 0.8545 - loss: 0.4666 - val_acc: 0.7865 - val_auc: 0.8664 - val_loss: 0.4477\n",
      "Epoch 3581/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7755 - auc: 0.8555 - loss: 0.4656 - val_acc: 0.7890 - val_auc: 0.8660 - val_loss: 0.4478\n",
      "Epoch 3582/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7753 - auc: 0.8533 - loss: 0.4680 - val_acc: 0.7863 - val_auc: 0.8662 - val_loss: 0.4488\n",
      "Epoch 3583/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7764 - auc: 0.8554 - loss: 0.4650 - val_acc: 0.7866 - val_auc: 0.8662 - val_loss: 0.4474\n",
      "Epoch 3584/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7747 - auc: 0.8540 - loss: 0.4662 - val_acc: 0.7854 - val_auc: 0.8666 - val_loss: 0.4472\n",
      "Epoch 3585/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7749 - auc: 0.8539 - loss: 0.4665 - val_acc: 0.7869 - val_auc: 0.8680 - val_loss: 0.4461\n",
      "Epoch 3586/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7761 - auc: 0.8550 - loss: 0.4664 - val_acc: 0.7897 - val_auc: 0.8673 - val_loss: 0.4463\n",
      "Epoch 3587/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7740 - auc: 0.8549 - loss: 0.4654 - val_acc: 0.7881 - val_auc: 0.8667 - val_loss: 0.4476\n",
      "Epoch 3588/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7757 - auc: 0.8544 - loss: 0.4660 - val_acc: 0.7864 - val_auc: 0.8660 - val_loss: 0.4475\n",
      "Epoch 3589/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7726 - auc: 0.8533 - loss: 0.4668 - val_acc: 0.7885 - val_auc: 0.8678 - val_loss: 0.4456\n",
      "Epoch 3590/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7754 - auc: 0.8557 - loss: 0.4649 - val_acc: 0.7877 - val_auc: 0.8665 - val_loss: 0.4481\n",
      "Epoch 3591/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7743 - auc: 0.8539 - loss: 0.4658 - val_acc: 0.7862 - val_auc: 0.8661 - val_loss: 0.4478\n",
      "Epoch 3592/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7726 - auc: 0.8529 - loss: 0.4673 - val_acc: 0.7844 - val_auc: 0.8661 - val_loss: 0.4494\n",
      "Epoch 3593/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7737 - auc: 0.8545 - loss: 0.4659 - val_acc: 0.7845 - val_auc: 0.8652 - val_loss: 0.4497\n",
      "Epoch 3594/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7743 - auc: 0.8534 - loss: 0.4671 - val_acc: 0.7876 - val_auc: 0.8673 - val_loss: 0.4477\n",
      "Epoch 3595/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7733 - auc: 0.8532 - loss: 0.4684 - val_acc: 0.7901 - val_auc: 0.8663 - val_loss: 0.4472\n",
      "Epoch 3596/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7736 - auc: 0.8538 - loss: 0.4675 - val_acc: 0.7848 - val_auc: 0.8663 - val_loss: 0.4500\n",
      "Epoch 3597/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7737 - auc: 0.8542 - loss: 0.4665 - val_acc: 0.7857 - val_auc: 0.8641 - val_loss: 0.4500\n",
      "Epoch 3598/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7762 - auc: 0.8543 - loss: 0.4657 - val_acc: 0.7889 - val_auc: 0.8660 - val_loss: 0.4484\n",
      "Epoch 3599/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7736 - auc: 0.8533 - loss: 0.4674 - val_acc: 0.7829 - val_auc: 0.8657 - val_loss: 0.4505\n",
      "Epoch 3600/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7742 - auc: 0.8540 - loss: 0.4674 - val_acc: 0.7875 - val_auc: 0.8658 - val_loss: 0.4496\n",
      "Epoch 3601/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7725 - auc: 0.8529 - loss: 0.4684 - val_acc: 0.7862 - val_auc: 0.8662 - val_loss: 0.4497\n",
      "Epoch 3602/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7749 - auc: 0.8547 - loss: 0.4658 - val_acc: 0.7859 - val_auc: 0.8652 - val_loss: 0.4496\n",
      "Epoch 3603/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7761 - auc: 0.8558 - loss: 0.4643 - val_acc: 0.7902 - val_auc: 0.8666 - val_loss: 0.4468\n",
      "Epoch 3604/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7722 - auc: 0.8531 - loss: 0.4676 - val_acc: 0.7849 - val_auc: 0.8656 - val_loss: 0.4500\n",
      "Epoch 3605/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7746 - auc: 0.8558 - loss: 0.4650 - val_acc: 0.7859 - val_auc: 0.8654 - val_loss: 0.4497\n",
      "Epoch 3606/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7757 - auc: 0.8549 - loss: 0.4653 - val_acc: 0.7903 - val_auc: 0.8664 - val_loss: 0.4467\n",
      "Epoch 3607/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7759 - auc: 0.8556 - loss: 0.4640 - val_acc: 0.7898 - val_auc: 0.8683 - val_loss: 0.4452\n",
      "Epoch 3608/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7748 - auc: 0.8538 - loss: 0.4668 - val_acc: 0.7871 - val_auc: 0.8655 - val_loss: 0.4480\n",
      "Epoch 3609/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7750 - auc: 0.8537 - loss: 0.4667 - val_acc: 0.7843 - val_auc: 0.8666 - val_loss: 0.4478\n",
      "Epoch 3610/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7739 - auc: 0.8549 - loss: 0.4651 - val_acc: 0.7899 - val_auc: 0.8672 - val_loss: 0.4467\n",
      "Epoch 3611/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7739 - auc: 0.8538 - loss: 0.4674 - val_acc: 0.7886 - val_auc: 0.8671 - val_loss: 0.4477\n",
      "Epoch 3612/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7730 - auc: 0.8525 - loss: 0.4694 - val_acc: 0.7872 - val_auc: 0.8662 - val_loss: 0.4478\n",
      "Epoch 3613/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7759 - auc: 0.8556 - loss: 0.4649 - val_acc: 0.7855 - val_auc: 0.8655 - val_loss: 0.4486\n",
      "Epoch 3614/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7750 - auc: 0.8551 - loss: 0.4656 - val_acc: 0.7914 - val_auc: 0.8675 - val_loss: 0.4471\n",
      "Epoch 3615/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7743 - auc: 0.8539 - loss: 0.4680 - val_acc: 0.7866 - val_auc: 0.8662 - val_loss: 0.4472\n",
      "Epoch 3616/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7739 - auc: 0.8541 - loss: 0.4667 - val_acc: 0.7879 - val_auc: 0.8673 - val_loss: 0.4468\n",
      "Epoch 3617/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7744 - auc: 0.8542 - loss: 0.4666 - val_acc: 0.7898 - val_auc: 0.8666 - val_loss: 0.4468\n",
      "Epoch 3618/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7734 - auc: 0.8526 - loss: 0.4688 - val_acc: 0.7876 - val_auc: 0.8662 - val_loss: 0.4476\n",
      "Epoch 3619/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7729 - auc: 0.8528 - loss: 0.4682 - val_acc: 0.7874 - val_auc: 0.8667 - val_loss: 0.4485\n",
      "Epoch 3620/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7755 - auc: 0.8557 - loss: 0.4644 - val_acc: 0.7857 - val_auc: 0.8662 - val_loss: 0.4460\n",
      "Epoch 3621/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7750 - auc: 0.8542 - loss: 0.4659 - val_acc: 0.7845 - val_auc: 0.8663 - val_loss: 0.4485\n",
      "Epoch 3622/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7749 - auc: 0.8542 - loss: 0.4663 - val_acc: 0.7878 - val_auc: 0.8673 - val_loss: 0.4467\n",
      "Epoch 3623/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7740 - auc: 0.8528 - loss: 0.4693 - val_acc: 0.7879 - val_auc: 0.8675 - val_loss: 0.4457\n",
      "Epoch 3624/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7726 - auc: 0.8530 - loss: 0.4683 - val_acc: 0.7861 - val_auc: 0.8663 - val_loss: 0.4496\n",
      "Epoch 3625/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7752 - auc: 0.8547 - loss: 0.4658 - val_acc: 0.7880 - val_auc: 0.8664 - val_loss: 0.4476\n",
      "Epoch 3626/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7729 - auc: 0.8534 - loss: 0.4677 - val_acc: 0.7900 - val_auc: 0.8672 - val_loss: 0.4470\n",
      "Epoch 3627/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7757 - auc: 0.8541 - loss: 0.4666 - val_acc: 0.7882 - val_auc: 0.8662 - val_loss: 0.4475\n",
      "Epoch 3628/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7738 - auc: 0.8541 - loss: 0.4666 - val_acc: 0.7877 - val_auc: 0.8665 - val_loss: 0.4480\n",
      "Epoch 3629/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7749 - auc: 0.8532 - loss: 0.4685 - val_acc: 0.7867 - val_auc: 0.8660 - val_loss: 0.4477\n",
      "Epoch 3630/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7741 - auc: 0.8529 - loss: 0.4682 - val_acc: 0.7892 - val_auc: 0.8674 - val_loss: 0.4475\n",
      "Epoch 3631/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7742 - auc: 0.8548 - loss: 0.4649 - val_acc: 0.7885 - val_auc: 0.8673 - val_loss: 0.4473\n",
      "Epoch 3632/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7753 - auc: 0.8549 - loss: 0.4658 - val_acc: 0.7864 - val_auc: 0.8663 - val_loss: 0.4492\n",
      "Epoch 3633/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7740 - auc: 0.8529 - loss: 0.4688 - val_acc: 0.7882 - val_auc: 0.8673 - val_loss: 0.4464\n",
      "Epoch 3634/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7747 - auc: 0.8554 - loss: 0.4646 - val_acc: 0.7875 - val_auc: 0.8664 - val_loss: 0.4471\n",
      "Epoch 3635/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7754 - auc: 0.8537 - loss: 0.4686 - val_acc: 0.7850 - val_auc: 0.8661 - val_loss: 0.4484\n",
      "Epoch 3636/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7754 - auc: 0.8554 - loss: 0.4649 - val_acc: 0.7890 - val_auc: 0.8672 - val_loss: 0.4469\n",
      "Epoch 3637/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7743 - auc: 0.8553 - loss: 0.4648 - val_acc: 0.7899 - val_auc: 0.8679 - val_loss: 0.4462\n",
      "Epoch 3638/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7750 - auc: 0.8548 - loss: 0.4661 - val_acc: 0.7876 - val_auc: 0.8666 - val_loss: 0.4468\n",
      "Epoch 3639/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7757 - auc: 0.8550 - loss: 0.4656 - val_acc: 0.7882 - val_auc: 0.8671 - val_loss: 0.4483\n",
      "Epoch 3640/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7733 - auc: 0.8544 - loss: 0.4655 - val_acc: 0.7864 - val_auc: 0.8671 - val_loss: 0.4468\n",
      "Epoch 3641/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7750 - auc: 0.8550 - loss: 0.4647 - val_acc: 0.7894 - val_auc: 0.8662 - val_loss: 0.4483\n",
      "Epoch 3642/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7761 - auc: 0.8548 - loss: 0.4651 - val_acc: 0.7856 - val_auc: 0.8665 - val_loss: 0.4481\n",
      "Epoch 3643/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7738 - auc: 0.8538 - loss: 0.4659 - val_acc: 0.7860 - val_auc: 0.8659 - val_loss: 0.4484\n",
      "Epoch 3644/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7755 - auc: 0.8544 - loss: 0.4671 - val_acc: 0.7892 - val_auc: 0.8668 - val_loss: 0.4470\n",
      "Epoch 3645/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7744 - auc: 0.8535 - loss: 0.4669 - val_acc: 0.7882 - val_auc: 0.8672 - val_loss: 0.4466\n",
      "Epoch 3646/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7757 - auc: 0.8547 - loss: 0.4659 - val_acc: 0.7862 - val_auc: 0.8650 - val_loss: 0.4493\n",
      "Epoch 3647/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7753 - auc: 0.8557 - loss: 0.4647 - val_acc: 0.7901 - val_auc: 0.8673 - val_loss: 0.4466\n",
      "Epoch 3648/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7740 - auc: 0.8546 - loss: 0.4665 - val_acc: 0.7897 - val_auc: 0.8672 - val_loss: 0.4461\n",
      "Epoch 3649/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7731 - auc: 0.8530 - loss: 0.4678 - val_acc: 0.7858 - val_auc: 0.8664 - val_loss: 0.4492\n",
      "Epoch 3650/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7736 - auc: 0.8536 - loss: 0.4657 - val_acc: 0.7867 - val_auc: 0.8673 - val_loss: 0.4474\n",
      "Epoch 3651/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7748 - auc: 0.8543 - loss: 0.4662 - val_acc: 0.7877 - val_auc: 0.8656 - val_loss: 0.4483\n",
      "Epoch 3652/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7754 - auc: 0.8547 - loss: 0.4654 - val_acc: 0.7885 - val_auc: 0.8661 - val_loss: 0.4474\n",
      "Epoch 3653/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7746 - auc: 0.8530 - loss: 0.4679 - val_acc: 0.7890 - val_auc: 0.8677 - val_loss: 0.4475\n",
      "Epoch 3654/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7759 - auc: 0.8547 - loss: 0.4654 - val_acc: 0.7865 - val_auc: 0.8664 - val_loss: 0.4489\n",
      "Epoch 3655/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7768 - auc: 0.8549 - loss: 0.4653 - val_acc: 0.7883 - val_auc: 0.8669 - val_loss: 0.4473\n",
      "Epoch 3656/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7734 - auc: 0.8536 - loss: 0.4677 - val_acc: 0.7889 - val_auc: 0.8662 - val_loss: 0.4474\n",
      "Epoch 3657/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7755 - auc: 0.8558 - loss: 0.4643 - val_acc: 0.7887 - val_auc: 0.8675 - val_loss: 0.4463\n",
      "Epoch 3658/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7751 - auc: 0.8536 - loss: 0.4667 - val_acc: 0.7910 - val_auc: 0.8667 - val_loss: 0.4467\n",
      "Epoch 3659/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7756 - auc: 0.8557 - loss: 0.4639 - val_acc: 0.7891 - val_auc: 0.8670 - val_loss: 0.4460\n",
      "Epoch 3660/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7737 - auc: 0.8546 - loss: 0.4657 - val_acc: 0.7873 - val_auc: 0.8665 - val_loss: 0.4452\n",
      "Epoch 3661/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7736 - auc: 0.8539 - loss: 0.4671 - val_acc: 0.7896 - val_auc: 0.8677 - val_loss: 0.4470\n",
      "Epoch 3662/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7740 - auc: 0.8535 - loss: 0.4671 - val_acc: 0.7892 - val_auc: 0.8683 - val_loss: 0.4449\n",
      "Epoch 3663/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7755 - auc: 0.8553 - loss: 0.4654 - val_acc: 0.7883 - val_auc: 0.8664 - val_loss: 0.4464\n",
      "Epoch 3664/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7752 - auc: 0.8552 - loss: 0.4652 - val_acc: 0.7870 - val_auc: 0.8656 - val_loss: 0.4487\n",
      "Epoch 3665/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7748 - auc: 0.8541 - loss: 0.4661 - val_acc: 0.7902 - val_auc: 0.8681 - val_loss: 0.4451\n",
      "Epoch 3666/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7733 - auc: 0.8537 - loss: 0.4668 - val_acc: 0.7878 - val_auc: 0.8674 - val_loss: 0.4473\n",
      "Epoch 3667/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7764 - auc: 0.8545 - loss: 0.4650 - val_acc: 0.7907 - val_auc: 0.8691 - val_loss: 0.4438\n",
      "Epoch 3668/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7756 - auc: 0.8552 - loss: 0.4662 - val_acc: 0.7874 - val_auc: 0.8688 - val_loss: 0.4448\n",
      "Epoch 3669/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7762 - auc: 0.8547 - loss: 0.4658 - val_acc: 0.7884 - val_auc: 0.8680 - val_loss: 0.4454\n",
      "Epoch 3670/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7738 - auc: 0.8547 - loss: 0.4659 - val_acc: 0.7853 - val_auc: 0.8661 - val_loss: 0.4495\n",
      "Epoch 3671/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7752 - auc: 0.8549 - loss: 0.4660 - val_acc: 0.7861 - val_auc: 0.8664 - val_loss: 0.4473\n",
      "Epoch 3672/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7741 - auc: 0.8536 - loss: 0.4669 - val_acc: 0.7891 - val_auc: 0.8681 - val_loss: 0.4468\n",
      "Epoch 3673/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7736 - auc: 0.8538 - loss: 0.4679 - val_acc: 0.7875 - val_auc: 0.8671 - val_loss: 0.4482\n",
      "Epoch 3674/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7721 - auc: 0.8535 - loss: 0.4677 - val_acc: 0.7870 - val_auc: 0.8658 - val_loss: 0.4496\n",
      "Epoch 3675/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7748 - auc: 0.8547 - loss: 0.4667 - val_acc: 0.7863 - val_auc: 0.8659 - val_loss: 0.4482\n",
      "Epoch 3676/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7753 - auc: 0.8543 - loss: 0.4656 - val_acc: 0.7877 - val_auc: 0.8668 - val_loss: 0.4460\n",
      "Epoch 3677/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7761 - auc: 0.8551 - loss: 0.4646 - val_acc: 0.7867 - val_auc: 0.8663 - val_loss: 0.4471\n",
      "Epoch 3678/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7719 - auc: 0.8528 - loss: 0.4682 - val_acc: 0.7878 - val_auc: 0.8662 - val_loss: 0.4482\n",
      "Epoch 3679/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7741 - auc: 0.8547 - loss: 0.4657 - val_acc: 0.7864 - val_auc: 0.8662 - val_loss: 0.4471\n",
      "Epoch 3680/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7758 - auc: 0.8539 - loss: 0.4665 - val_acc: 0.7902 - val_auc: 0.8678 - val_loss: 0.4470\n",
      "Epoch 3681/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7753 - auc: 0.8540 - loss: 0.4659 - val_acc: 0.7854 - val_auc: 0.8656 - val_loss: 0.4492\n",
      "Epoch 3682/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7734 - auc: 0.8538 - loss: 0.4662 - val_acc: 0.7878 - val_auc: 0.8666 - val_loss: 0.4466\n",
      "Epoch 3683/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7762 - auc: 0.8558 - loss: 0.4649 - val_acc: 0.7895 - val_auc: 0.8677 - val_loss: 0.4467\n",
      "Epoch 3684/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7777 - auc: 0.8546 - loss: 0.4657 - val_acc: 0.7888 - val_auc: 0.8678 - val_loss: 0.4462\n",
      "Epoch 3685/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7760 - auc: 0.8552 - loss: 0.4644 - val_acc: 0.7890 - val_auc: 0.8666 - val_loss: 0.4470\n",
      "Epoch 3686/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7747 - auc: 0.8538 - loss: 0.4670 - val_acc: 0.7876 - val_auc: 0.8672 - val_loss: 0.4465\n",
      "Epoch 3687/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7747 - auc: 0.8539 - loss: 0.4668 - val_acc: 0.7898 - val_auc: 0.8666 - val_loss: 0.4464\n",
      "Epoch 3688/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7746 - auc: 0.8544 - loss: 0.4665 - val_acc: 0.7884 - val_auc: 0.8679 - val_loss: 0.4468\n",
      "Epoch 3689/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7754 - auc: 0.8552 - loss: 0.4640 - val_acc: 0.7897 - val_auc: 0.8672 - val_loss: 0.4465\n",
      "Epoch 3690/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7748 - auc: 0.8541 - loss: 0.4665 - val_acc: 0.7904 - val_auc: 0.8685 - val_loss: 0.4453\n",
      "Epoch 3691/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7736 - auc: 0.8542 - loss: 0.4658 - val_acc: 0.7880 - val_auc: 0.8678 - val_loss: 0.4441\n",
      "Epoch 3692/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7742 - auc: 0.8532 - loss: 0.4677 - val_acc: 0.7902 - val_auc: 0.8667 - val_loss: 0.4463\n",
      "Epoch 3693/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7738 - auc: 0.8519 - loss: 0.4697 - val_acc: 0.7866 - val_auc: 0.8670 - val_loss: 0.4494\n",
      "Epoch 3694/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7731 - auc: 0.8529 - loss: 0.4679 - val_acc: 0.7904 - val_auc: 0.8673 - val_loss: 0.4457\n",
      "Epoch 3695/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7746 - auc: 0.8544 - loss: 0.4676 - val_acc: 0.7883 - val_auc: 0.8664 - val_loss: 0.4480\n",
      "Epoch 3696/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7750 - auc: 0.8537 - loss: 0.4676 - val_acc: 0.7890 - val_auc: 0.8674 - val_loss: 0.4468\n",
      "Epoch 3697/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7744 - auc: 0.8542 - loss: 0.4658 - val_acc: 0.7900 - val_auc: 0.8674 - val_loss: 0.4457\n",
      "Epoch 3698/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7749 - auc: 0.8541 - loss: 0.4667 - val_acc: 0.7885 - val_auc: 0.8670 - val_loss: 0.4464\n",
      "Epoch 3699/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7747 - auc: 0.8550 - loss: 0.4651 - val_acc: 0.7889 - val_auc: 0.8681 - val_loss: 0.4454\n",
      "Epoch 3700/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7773 - auc: 0.8552 - loss: 0.4659 - val_acc: 0.7872 - val_auc: 0.8676 - val_loss: 0.4471\n",
      "Epoch 3701/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7751 - auc: 0.8552 - loss: 0.4650 - val_acc: 0.7893 - val_auc: 0.8675 - val_loss: 0.4470\n",
      "Epoch 3702/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7751 - auc: 0.8540 - loss: 0.4671 - val_acc: 0.7907 - val_auc: 0.8673 - val_loss: 0.4465\n",
      "Epoch 3703/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7757 - auc: 0.8552 - loss: 0.4651 - val_acc: 0.7899 - val_auc: 0.8686 - val_loss: 0.4436\n",
      "Epoch 3704/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7739 - auc: 0.8535 - loss: 0.4679 - val_acc: 0.7868 - val_auc: 0.8656 - val_loss: 0.4473\n",
      "Epoch 3705/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7755 - auc: 0.8555 - loss: 0.4637 - val_acc: 0.7901 - val_auc: 0.8679 - val_loss: 0.4454\n",
      "Epoch 3706/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7764 - auc: 0.8546 - loss: 0.4656 - val_acc: 0.7837 - val_auc: 0.8658 - val_loss: 0.4494\n",
      "Epoch 3707/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7748 - auc: 0.8549 - loss: 0.4648 - val_acc: 0.7907 - val_auc: 0.8692 - val_loss: 0.4450\n",
      "Epoch 3708/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7753 - auc: 0.8554 - loss: 0.4645 - val_acc: 0.7877 - val_auc: 0.8679 - val_loss: 0.4463\n",
      "Epoch 3709/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7718 - auc: 0.8535 - loss: 0.4681 - val_acc: 0.7903 - val_auc: 0.8681 - val_loss: 0.4434\n",
      "Epoch 3710/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7742 - auc: 0.8540 - loss: 0.4670 - val_acc: 0.7884 - val_auc: 0.8668 - val_loss: 0.4463\n",
      "Epoch 3711/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7758 - auc: 0.8547 - loss: 0.4652 - val_acc: 0.7895 - val_auc: 0.8671 - val_loss: 0.4472\n",
      "Epoch 3712/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7768 - auc: 0.8551 - loss: 0.4650 - val_acc: 0.7858 - val_auc: 0.8661 - val_loss: 0.4471\n",
      "Epoch 3713/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7756 - auc: 0.8548 - loss: 0.4659 - val_acc: 0.7896 - val_auc: 0.8683 - val_loss: 0.4464\n",
      "Epoch 3714/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7748 - auc: 0.8554 - loss: 0.4661 - val_acc: 0.7883 - val_auc: 0.8662 - val_loss: 0.4469\n",
      "Epoch 3715/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7765 - auc: 0.8556 - loss: 0.4644 - val_acc: 0.7890 - val_auc: 0.8672 - val_loss: 0.4460\n",
      "Epoch 3716/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7740 - auc: 0.8543 - loss: 0.4662 - val_acc: 0.7834 - val_auc: 0.8646 - val_loss: 0.4496\n",
      "Epoch 3717/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7755 - auc: 0.8543 - loss: 0.4658 - val_acc: 0.7890 - val_auc: 0.8671 - val_loss: 0.4464\n",
      "Epoch 3718/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7754 - auc: 0.8552 - loss: 0.4649 - val_acc: 0.7875 - val_auc: 0.8678 - val_loss: 0.4468\n",
      "Epoch 3719/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7743 - auc: 0.8544 - loss: 0.4659 - val_acc: 0.7892 - val_auc: 0.8671 - val_loss: 0.4470\n",
      "Epoch 3720/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7749 - auc: 0.8539 - loss: 0.4667 - val_acc: 0.7883 - val_auc: 0.8673 - val_loss: 0.4457\n",
      "Epoch 3721/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7722 - auc: 0.8534 - loss: 0.4685 - val_acc: 0.7869 - val_auc: 0.8673 - val_loss: 0.4470\n",
      "Epoch 3722/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7763 - auc: 0.8540 - loss: 0.4675 - val_acc: 0.7863 - val_auc: 0.8653 - val_loss: 0.4498\n",
      "Epoch 3723/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7751 - auc: 0.8549 - loss: 0.4651 - val_acc: 0.7902 - val_auc: 0.8678 - val_loss: 0.4446\n",
      "Epoch 3724/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7739 - auc: 0.8545 - loss: 0.4666 - val_acc: 0.7905 - val_auc: 0.8678 - val_loss: 0.4452\n",
      "Epoch 3725/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7766 - auc: 0.8550 - loss: 0.4651 - val_acc: 0.7872 - val_auc: 0.8664 - val_loss: 0.4472\n",
      "Epoch 3726/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7746 - auc: 0.8549 - loss: 0.4664 - val_acc: 0.7881 - val_auc: 0.8666 - val_loss: 0.4477\n",
      "Epoch 3727/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7760 - auc: 0.8546 - loss: 0.4657 - val_acc: 0.7875 - val_auc: 0.8672 - val_loss: 0.4463\n",
      "Epoch 3728/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7744 - auc: 0.8543 - loss: 0.4668 - val_acc: 0.7867 - val_auc: 0.8668 - val_loss: 0.4465\n",
      "Epoch 3729/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7753 - auc: 0.8552 - loss: 0.4653 - val_acc: 0.7866 - val_auc: 0.8674 - val_loss: 0.4461\n",
      "Epoch 3730/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7739 - auc: 0.8535 - loss: 0.4670 - val_acc: 0.7866 - val_auc: 0.8674 - val_loss: 0.4452\n",
      "Epoch 3731/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7754 - auc: 0.8546 - loss: 0.4654 - val_acc: 0.7887 - val_auc: 0.8668 - val_loss: 0.4453\n",
      "Epoch 3732/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7734 - auc: 0.8544 - loss: 0.4658 - val_acc: 0.7882 - val_auc: 0.8675 - val_loss: 0.4463\n",
      "Epoch 3733/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7737 - auc: 0.8544 - loss: 0.4656 - val_acc: 0.7861 - val_auc: 0.8672 - val_loss: 0.4465\n",
      "Epoch 3734/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7753 - auc: 0.8549 - loss: 0.4646 - val_acc: 0.7876 - val_auc: 0.8673 - val_loss: 0.4453\n",
      "Epoch 3735/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7748 - auc: 0.8546 - loss: 0.4654 - val_acc: 0.7857 - val_auc: 0.8667 - val_loss: 0.4485\n",
      "Epoch 3736/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7745 - auc: 0.8544 - loss: 0.4662 - val_acc: 0.7907 - val_auc: 0.8686 - val_loss: 0.4462\n",
      "Epoch 3737/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7766 - auc: 0.8561 - loss: 0.4647 - val_acc: 0.7889 - val_auc: 0.8665 - val_loss: 0.4468\n",
      "Epoch 3738/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7747 - auc: 0.8553 - loss: 0.4650 - val_acc: 0.7894 - val_auc: 0.8670 - val_loss: 0.4465\n",
      "Epoch 3739/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7754 - auc: 0.8541 - loss: 0.4666 - val_acc: 0.7894 - val_auc: 0.8673 - val_loss: 0.4464\n",
      "Epoch 3740/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7748 - auc: 0.8533 - loss: 0.4666 - val_acc: 0.7900 - val_auc: 0.8667 - val_loss: 0.4466\n",
      "Epoch 3741/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7738 - auc: 0.8541 - loss: 0.4665 - val_acc: 0.7864 - val_auc: 0.8669 - val_loss: 0.4482\n",
      "Epoch 3742/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7764 - auc: 0.8560 - loss: 0.4646 - val_acc: 0.7900 - val_auc: 0.8684 - val_loss: 0.4445\n",
      "Epoch 3743/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7748 - auc: 0.8549 - loss: 0.4658 - val_acc: 0.7867 - val_auc: 0.8673 - val_loss: 0.4465\n",
      "Epoch 3744/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7726 - auc: 0.8524 - loss: 0.4678 - val_acc: 0.7881 - val_auc: 0.8672 - val_loss: 0.4456\n",
      "Epoch 3745/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7747 - auc: 0.8544 - loss: 0.4656 - val_acc: 0.7867 - val_auc: 0.8675 - val_loss: 0.4466\n",
      "Epoch 3746/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7750 - auc: 0.8545 - loss: 0.4658 - val_acc: 0.7889 - val_auc: 0.8668 - val_loss: 0.4476\n",
      "Epoch 3747/7000\n",
      "106/106 - 2s - 15ms/step - acc: 0.7743 - auc: 0.8549 - loss: 0.4654 - val_acc: 0.7899 - val_auc: 0.8680 - val_loss: 0.4465\n",
      "Epoch 3748/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7739 - auc: 0.8535 - loss: 0.4682 - val_acc: 0.7856 - val_auc: 0.8669 - val_loss: 0.4486\n",
      "Epoch 3749/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7754 - auc: 0.8565 - loss: 0.4629 - val_acc: 0.7900 - val_auc: 0.8676 - val_loss: 0.4452\n",
      "Epoch 3750/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7756 - auc: 0.8553 - loss: 0.4649 - val_acc: 0.7892 - val_auc: 0.8676 - val_loss: 0.4461\n",
      "Epoch 3751/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7749 - auc: 0.8541 - loss: 0.4667 - val_acc: 0.7883 - val_auc: 0.8684 - val_loss: 0.4460\n",
      "Epoch 3752/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7738 - auc: 0.8546 - loss: 0.4653 - val_acc: 0.7909 - val_auc: 0.8680 - val_loss: 0.4456\n",
      "Epoch 3753/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7737 - auc: 0.8530 - loss: 0.4681 - val_acc: 0.7897 - val_auc: 0.8676 - val_loss: 0.4444\n",
      "Epoch 3754/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7769 - auc: 0.8558 - loss: 0.4654 - val_acc: 0.7902 - val_auc: 0.8675 - val_loss: 0.4466\n",
      "Epoch 3755/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7768 - auc: 0.8563 - loss: 0.4631 - val_acc: 0.7861 - val_auc: 0.8674 - val_loss: 0.4473\n",
      "Epoch 3756/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7757 - auc: 0.8546 - loss: 0.4659 - val_acc: 0.7890 - val_auc: 0.8675 - val_loss: 0.4460\n",
      "Epoch 3757/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7734 - auc: 0.8532 - loss: 0.4685 - val_acc: 0.7869 - val_auc: 0.8682 - val_loss: 0.4446\n",
      "Epoch 3758/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7759 - auc: 0.8550 - loss: 0.4653 - val_acc: 0.7871 - val_auc: 0.8666 - val_loss: 0.4460\n",
      "Epoch 3759/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7732 - auc: 0.8537 - loss: 0.4668 - val_acc: 0.7890 - val_auc: 0.8680 - val_loss: 0.4456\n",
      "Epoch 3760/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7753 - auc: 0.8541 - loss: 0.4666 - val_acc: 0.7886 - val_auc: 0.8668 - val_loss: 0.4468\n",
      "Epoch 3761/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7750 - auc: 0.8541 - loss: 0.4662 - val_acc: 0.7880 - val_auc: 0.8673 - val_loss: 0.4480\n",
      "Epoch 3762/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7762 - auc: 0.8552 - loss: 0.4656 - val_acc: 0.7892 - val_auc: 0.8674 - val_loss: 0.4476\n",
      "Epoch 3763/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7779 - auc: 0.8570 - loss: 0.4627 - val_acc: 0.7888 - val_auc: 0.8677 - val_loss: 0.4456\n",
      "Epoch 3764/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7769 - auc: 0.8559 - loss: 0.4645 - val_acc: 0.7879 - val_auc: 0.8690 - val_loss: 0.4446\n",
      "Epoch 3765/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7737 - auc: 0.8541 - loss: 0.4670 - val_acc: 0.7879 - val_auc: 0.8677 - val_loss: 0.4443\n",
      "Epoch 3766/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7741 - auc: 0.8539 - loss: 0.4670 - val_acc: 0.7892 - val_auc: 0.8673 - val_loss: 0.4462\n",
      "Epoch 3767/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7746 - auc: 0.8542 - loss: 0.4668 - val_acc: 0.7899 - val_auc: 0.8682 - val_loss: 0.4458\n",
      "Epoch 3768/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7744 - auc: 0.8542 - loss: 0.4662 - val_acc: 0.7863 - val_auc: 0.8659 - val_loss: 0.4490\n",
      "Epoch 3769/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7752 - auc: 0.8545 - loss: 0.4660 - val_acc: 0.7847 - val_auc: 0.8664 - val_loss: 0.4480\n",
      "Epoch 3770/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7738 - auc: 0.8550 - loss: 0.4652 - val_acc: 0.7869 - val_auc: 0.8680 - val_loss: 0.4486\n",
      "Epoch 3771/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7736 - auc: 0.8542 - loss: 0.4670 - val_acc: 0.7894 - val_auc: 0.8677 - val_loss: 0.4466\n",
      "Epoch 3772/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7741 - auc: 0.8542 - loss: 0.4662 - val_acc: 0.7881 - val_auc: 0.8680 - val_loss: 0.4464\n",
      "Epoch 3773/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7748 - auc: 0.8554 - loss: 0.4656 - val_acc: 0.7888 - val_auc: 0.8678 - val_loss: 0.4439\n",
      "Epoch 3774/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7743 - auc: 0.8552 - loss: 0.4652 - val_acc: 0.7879 - val_auc: 0.8667 - val_loss: 0.4488\n",
      "Epoch 3775/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7749 - auc: 0.8556 - loss: 0.4650 - val_acc: 0.7890 - val_auc: 0.8688 - val_loss: 0.4469\n",
      "Epoch 3776/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7744 - auc: 0.8550 - loss: 0.4649 - val_acc: 0.7867 - val_auc: 0.8664 - val_loss: 0.4475\n",
      "Epoch 3777/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7748 - auc: 0.8542 - loss: 0.4672 - val_acc: 0.7901 - val_auc: 0.8669 - val_loss: 0.4451\n",
      "Epoch 3778/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7738 - auc: 0.8538 - loss: 0.4674 - val_acc: 0.7906 - val_auc: 0.8671 - val_loss: 0.4465\n",
      "Epoch 3779/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7733 - auc: 0.8537 - loss: 0.4670 - val_acc: 0.7915 - val_auc: 0.8684 - val_loss: 0.4457\n",
      "Epoch 3780/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7762 - auc: 0.8550 - loss: 0.4651 - val_acc: 0.7901 - val_auc: 0.8667 - val_loss: 0.4466\n",
      "Epoch 3781/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7749 - auc: 0.8554 - loss: 0.4648 - val_acc: 0.7877 - val_auc: 0.8672 - val_loss: 0.4459\n",
      "Epoch 3782/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7740 - auc: 0.8551 - loss: 0.4648 - val_acc: 0.7888 - val_auc: 0.8663 - val_loss: 0.4480\n",
      "Epoch 3783/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7759 - auc: 0.8537 - loss: 0.4669 - val_acc: 0.7892 - val_auc: 0.8677 - val_loss: 0.4465\n",
      "Epoch 3784/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7768 - auc: 0.8554 - loss: 0.4644 - val_acc: 0.7895 - val_auc: 0.8688 - val_loss: 0.4452\n",
      "Epoch 3785/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7749 - auc: 0.8550 - loss: 0.4657 - val_acc: 0.7903 - val_auc: 0.8685 - val_loss: 0.4454\n",
      "Epoch 3786/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7769 - auc: 0.8556 - loss: 0.4645 - val_acc: 0.7890 - val_auc: 0.8680 - val_loss: 0.4460\n",
      "Epoch 3787/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7730 - auc: 0.8529 - loss: 0.4684 - val_acc: 0.7880 - val_auc: 0.8686 - val_loss: 0.4464\n",
      "Epoch 3788/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7735 - auc: 0.8534 - loss: 0.4675 - val_acc: 0.7889 - val_auc: 0.8673 - val_loss: 0.4465\n",
      "Epoch 3789/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7752 - auc: 0.8540 - loss: 0.4654 - val_acc: 0.7887 - val_auc: 0.8673 - val_loss: 0.4449\n",
      "Epoch 3790/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7747 - auc: 0.8539 - loss: 0.4670 - val_acc: 0.7885 - val_auc: 0.8673 - val_loss: 0.4460\n",
      "Epoch 3791/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7757 - auc: 0.8555 - loss: 0.4647 - val_acc: 0.7895 - val_auc: 0.8669 - val_loss: 0.4459\n",
      "Epoch 3792/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7741 - auc: 0.8551 - loss: 0.4648 - val_acc: 0.7882 - val_auc: 0.8672 - val_loss: 0.4465\n",
      "Epoch 3793/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7749 - auc: 0.8553 - loss: 0.4653 - val_acc: 0.7867 - val_auc: 0.8665 - val_loss: 0.4466\n",
      "Epoch 3794/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7776 - auc: 0.8549 - loss: 0.4664 - val_acc: 0.7870 - val_auc: 0.8672 - val_loss: 0.4465\n",
      "Epoch 3795/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7757 - auc: 0.8556 - loss: 0.4654 - val_acc: 0.7914 - val_auc: 0.8676 - val_loss: 0.4462\n",
      "Epoch 3796/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7757 - auc: 0.8560 - loss: 0.4640 - val_acc: 0.7886 - val_auc: 0.8674 - val_loss: 0.4458\n",
      "Epoch 3797/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7742 - auc: 0.8556 - loss: 0.4640 - val_acc: 0.7887 - val_auc: 0.8668 - val_loss: 0.4455\n",
      "Epoch 3798/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7758 - auc: 0.8550 - loss: 0.4652 - val_acc: 0.7892 - val_auc: 0.8692 - val_loss: 0.4441\n",
      "Epoch 3799/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7752 - auc: 0.8558 - loss: 0.4638 - val_acc: 0.7875 - val_auc: 0.8667 - val_loss: 0.4465\n",
      "Epoch 3800/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7758 - auc: 0.8556 - loss: 0.4644 - val_acc: 0.7889 - val_auc: 0.8670 - val_loss: 0.4479\n",
      "Epoch 3801/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7750 - auc: 0.8558 - loss: 0.4640 - val_acc: 0.7860 - val_auc: 0.8673 - val_loss: 0.4472\n",
      "Epoch 3802/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7727 - auc: 0.8536 - loss: 0.4674 - val_acc: 0.7895 - val_auc: 0.8678 - val_loss: 0.4447\n",
      "Epoch 3803/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7741 - auc: 0.8539 - loss: 0.4665 - val_acc: 0.7917 - val_auc: 0.8689 - val_loss: 0.4443\n",
      "Epoch 3804/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7755 - auc: 0.8551 - loss: 0.4660 - val_acc: 0.7908 - val_auc: 0.8678 - val_loss: 0.4467\n",
      "Epoch 3805/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7737 - auc: 0.8546 - loss: 0.4663 - val_acc: 0.7893 - val_auc: 0.8665 - val_loss: 0.4480\n",
      "Epoch 3806/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7771 - auc: 0.8566 - loss: 0.4635 - val_acc: 0.7902 - val_auc: 0.8678 - val_loss: 0.4450\n",
      "Epoch 3807/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7776 - auc: 0.8558 - loss: 0.4636 - val_acc: 0.7881 - val_auc: 0.8672 - val_loss: 0.4457\n",
      "Epoch 3808/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7748 - auc: 0.8545 - loss: 0.4662 - val_acc: 0.7907 - val_auc: 0.8680 - val_loss: 0.4465\n",
      "Epoch 3809/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7756 - auc: 0.8551 - loss: 0.4660 - val_acc: 0.7873 - val_auc: 0.8676 - val_loss: 0.4470\n",
      "Epoch 3810/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7775 - auc: 0.8574 - loss: 0.4610 - val_acc: 0.7917 - val_auc: 0.8680 - val_loss: 0.4439\n",
      "Epoch 3811/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7757 - auc: 0.8551 - loss: 0.4650 - val_acc: 0.7865 - val_auc: 0.8674 - val_loss: 0.4461\n",
      "Epoch 3812/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7736 - auc: 0.8539 - loss: 0.4668 - val_acc: 0.7893 - val_auc: 0.8675 - val_loss: 0.4471\n",
      "Epoch 3813/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7758 - auc: 0.8550 - loss: 0.4657 - val_acc: 0.7901 - val_auc: 0.8677 - val_loss: 0.4450\n",
      "Epoch 3814/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7750 - auc: 0.8551 - loss: 0.4660 - val_acc: 0.7918 - val_auc: 0.8662 - val_loss: 0.4471\n",
      "Epoch 3815/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7749 - auc: 0.8547 - loss: 0.4650 - val_acc: 0.7902 - val_auc: 0.8680 - val_loss: 0.4446\n",
      "Epoch 3816/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7744 - auc: 0.8544 - loss: 0.4662 - val_acc: 0.7909 - val_auc: 0.8678 - val_loss: 0.4460\n",
      "Epoch 3817/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7755 - auc: 0.8554 - loss: 0.4650 - val_acc: 0.7895 - val_auc: 0.8671 - val_loss: 0.4464\n",
      "Epoch 3818/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7757 - auc: 0.8550 - loss: 0.4648 - val_acc: 0.7891 - val_auc: 0.8677 - val_loss: 0.4460\n",
      "Epoch 3819/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7723 - auc: 0.8536 - loss: 0.4681 - val_acc: 0.7877 - val_auc: 0.8671 - val_loss: 0.4479\n",
      "Epoch 3820/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7761 - auc: 0.8568 - loss: 0.4628 - val_acc: 0.7880 - val_auc: 0.8668 - val_loss: 0.4462\n",
      "Epoch 3821/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7738 - auc: 0.8544 - loss: 0.4664 - val_acc: 0.7899 - val_auc: 0.8674 - val_loss: 0.4467\n",
      "Epoch 3822/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7739 - auc: 0.8549 - loss: 0.4661 - val_acc: 0.7869 - val_auc: 0.8665 - val_loss: 0.4488\n",
      "Epoch 3823/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7749 - auc: 0.8546 - loss: 0.4659 - val_acc: 0.7877 - val_auc: 0.8667 - val_loss: 0.4464\n",
      "Epoch 3824/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7761 - auc: 0.8532 - loss: 0.4667 - val_acc: 0.7902 - val_auc: 0.8680 - val_loss: 0.4461\n",
      "Epoch 3825/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7745 - auc: 0.8537 - loss: 0.4660 - val_acc: 0.7892 - val_auc: 0.8678 - val_loss: 0.4460\n",
      "Epoch 3826/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7764 - auc: 0.8559 - loss: 0.4638 - val_acc: 0.7871 - val_auc: 0.8673 - val_loss: 0.4465\n",
      "Epoch 3827/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7770 - auc: 0.8554 - loss: 0.4642 - val_acc: 0.7912 - val_auc: 0.8675 - val_loss: 0.4450\n",
      "Epoch 3828/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7758 - auc: 0.8553 - loss: 0.4639 - val_acc: 0.7877 - val_auc: 0.8654 - val_loss: 0.4486\n",
      "Epoch 3829/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7778 - auc: 0.8547 - loss: 0.4651 - val_acc: 0.7898 - val_auc: 0.8686 - val_loss: 0.4444\n",
      "Epoch 3830/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7753 - auc: 0.8547 - loss: 0.4654 - val_acc: 0.7894 - val_auc: 0.8680 - val_loss: 0.4454\n",
      "Epoch 3831/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7750 - auc: 0.8556 - loss: 0.4649 - val_acc: 0.7878 - val_auc: 0.8667 - val_loss: 0.4459\n",
      "Epoch 3832/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7767 - auc: 0.8548 - loss: 0.4648 - val_acc: 0.7904 - val_auc: 0.8677 - val_loss: 0.4449\n",
      "Epoch 3833/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7765 - auc: 0.8552 - loss: 0.4655 - val_acc: 0.7890 - val_auc: 0.8676 - val_loss: 0.4454\n",
      "Epoch 3834/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7742 - auc: 0.8547 - loss: 0.4666 - val_acc: 0.7914 - val_auc: 0.8687 - val_loss: 0.4442\n",
      "Epoch 3835/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7749 - auc: 0.8546 - loss: 0.4663 - val_acc: 0.7895 - val_auc: 0.8670 - val_loss: 0.4458\n",
      "Epoch 3836/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7742 - auc: 0.8535 - loss: 0.4679 - val_acc: 0.7909 - val_auc: 0.8692 - val_loss: 0.4442\n",
      "Epoch 3837/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7731 - auc: 0.8539 - loss: 0.4663 - val_acc: 0.7894 - val_auc: 0.8674 - val_loss: 0.4451\n",
      "Epoch 3838/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7773 - auc: 0.8560 - loss: 0.4638 - val_acc: 0.7870 - val_auc: 0.8673 - val_loss: 0.4480\n",
      "Epoch 3839/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7753 - auc: 0.8542 - loss: 0.4675 - val_acc: 0.7873 - val_auc: 0.8652 - val_loss: 0.4498\n",
      "Epoch 3840/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7738 - auc: 0.8540 - loss: 0.4670 - val_acc: 0.7881 - val_auc: 0.8681 - val_loss: 0.4451\n",
      "Epoch 3841/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7763 - auc: 0.8571 - loss: 0.4620 - val_acc: 0.7886 - val_auc: 0.8677 - val_loss: 0.4465\n",
      "Epoch 3842/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7745 - auc: 0.8544 - loss: 0.4661 - val_acc: 0.7893 - val_auc: 0.8682 - val_loss: 0.4454\n",
      "Epoch 3843/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7750 - auc: 0.8550 - loss: 0.4657 - val_acc: 0.7895 - val_auc: 0.8670 - val_loss: 0.4464\n",
      "Epoch 3844/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7773 - auc: 0.8549 - loss: 0.4653 - val_acc: 0.7904 - val_auc: 0.8688 - val_loss: 0.4436\n",
      "Epoch 3845/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7743 - auc: 0.8553 - loss: 0.4645 - val_acc: 0.7897 - val_auc: 0.8680 - val_loss: 0.4471\n",
      "Epoch 3846/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7759 - auc: 0.8559 - loss: 0.4646 - val_acc: 0.7917 - val_auc: 0.8677 - val_loss: 0.4456\n",
      "Epoch 3847/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7766 - auc: 0.8557 - loss: 0.4645 - val_acc: 0.7906 - val_auc: 0.8690 - val_loss: 0.4446\n",
      "Epoch 3848/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7740 - auc: 0.8545 - loss: 0.4663 - val_acc: 0.7887 - val_auc: 0.8663 - val_loss: 0.4466\n",
      "Epoch 3849/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7769 - auc: 0.8562 - loss: 0.4633 - val_acc: 0.7884 - val_auc: 0.8668 - val_loss: 0.4471\n",
      "Epoch 3850/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7746 - auc: 0.8559 - loss: 0.4645 - val_acc: 0.7915 - val_auc: 0.8687 - val_loss: 0.4429\n",
      "Epoch 3851/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7759 - auc: 0.8550 - loss: 0.4653 - val_acc: 0.7895 - val_auc: 0.8676 - val_loss: 0.4460\n",
      "Epoch 3852/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7734 - auc: 0.8535 - loss: 0.4661 - val_acc: 0.7915 - val_auc: 0.8679 - val_loss: 0.4450\n",
      "Epoch 3853/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7757 - auc: 0.8553 - loss: 0.4646 - val_acc: 0.7890 - val_auc: 0.8671 - val_loss: 0.4493\n",
      "Epoch 3854/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7760 - auc: 0.8549 - loss: 0.4651 - val_acc: 0.7883 - val_auc: 0.8669 - val_loss: 0.4462\n",
      "Epoch 3855/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7776 - auc: 0.8551 - loss: 0.4655 - val_acc: 0.7906 - val_auc: 0.8687 - val_loss: 0.4446\n",
      "Epoch 3856/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7755 - auc: 0.8556 - loss: 0.4645 - val_acc: 0.7910 - val_auc: 0.8683 - val_loss: 0.4447\n",
      "Epoch 3857/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7766 - auc: 0.8559 - loss: 0.4638 - val_acc: 0.7889 - val_auc: 0.8675 - val_loss: 0.4446\n",
      "Epoch 3858/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7783 - auc: 0.8562 - loss: 0.4638 - val_acc: 0.7906 - val_auc: 0.8686 - val_loss: 0.4435\n",
      "Epoch 3859/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7751 - auc: 0.8551 - loss: 0.4643 - val_acc: 0.7885 - val_auc: 0.8665 - val_loss: 0.4469\n",
      "Epoch 3860/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7729 - auc: 0.8532 - loss: 0.4673 - val_acc: 0.7897 - val_auc: 0.8668 - val_loss: 0.4475\n",
      "Epoch 3861/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7771 - auc: 0.8557 - loss: 0.4644 - val_acc: 0.7902 - val_auc: 0.8676 - val_loss: 0.4463\n",
      "Epoch 3862/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7748 - auc: 0.8559 - loss: 0.4642 - val_acc: 0.7909 - val_auc: 0.8681 - val_loss: 0.4445\n",
      "Epoch 3863/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7774 - auc: 0.8559 - loss: 0.4641 - val_acc: 0.7867 - val_auc: 0.8672 - val_loss: 0.4464\n",
      "Epoch 3864/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7736 - auc: 0.8543 - loss: 0.4660 - val_acc: 0.7902 - val_auc: 0.8680 - val_loss: 0.4455\n",
      "Epoch 3865/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7735 - auc: 0.8548 - loss: 0.4655 - val_acc: 0.7875 - val_auc: 0.8676 - val_loss: 0.4469\n",
      "Epoch 3866/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7755 - auc: 0.8543 - loss: 0.4660 - val_acc: 0.7893 - val_auc: 0.8676 - val_loss: 0.4461\n",
      "Epoch 3867/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7768 - auc: 0.8555 - loss: 0.4644 - val_acc: 0.7915 - val_auc: 0.8688 - val_loss: 0.4445\n",
      "Epoch 3868/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7753 - auc: 0.8540 - loss: 0.4662 - val_acc: 0.7877 - val_auc: 0.8678 - val_loss: 0.4456\n",
      "Epoch 3869/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7725 - auc: 0.8544 - loss: 0.4669 - val_acc: 0.7877 - val_auc: 0.8672 - val_loss: 0.4468\n",
      "Epoch 3870/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7759 - auc: 0.8564 - loss: 0.4642 - val_acc: 0.7902 - val_auc: 0.8689 - val_loss: 0.4463\n",
      "Epoch 3871/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7762 - auc: 0.8550 - loss: 0.4665 - val_acc: 0.7898 - val_auc: 0.8682 - val_loss: 0.4458\n",
      "Epoch 3872/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7737 - auc: 0.8546 - loss: 0.4668 - val_acc: 0.7878 - val_auc: 0.8670 - val_loss: 0.4466\n",
      "Epoch 3873/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7745 - auc: 0.8554 - loss: 0.4648 - val_acc: 0.7871 - val_auc: 0.8677 - val_loss: 0.4462\n",
      "Epoch 3874/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7759 - auc: 0.8549 - loss: 0.4659 - val_acc: 0.7868 - val_auc: 0.8668 - val_loss: 0.4466\n",
      "Epoch 3875/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7752 - auc: 0.8542 - loss: 0.4661 - val_acc: 0.7888 - val_auc: 0.8662 - val_loss: 0.4474\n",
      "Epoch 3876/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7716 - auc: 0.8534 - loss: 0.4667 - val_acc: 0.7907 - val_auc: 0.8687 - val_loss: 0.4443\n",
      "Epoch 3877/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7744 - auc: 0.8549 - loss: 0.4666 - val_acc: 0.7888 - val_auc: 0.8687 - val_loss: 0.4456\n",
      "Epoch 3878/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7743 - auc: 0.8549 - loss: 0.4660 - val_acc: 0.7900 - val_auc: 0.8680 - val_loss: 0.4467\n",
      "Epoch 3879/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7767 - auc: 0.8564 - loss: 0.4628 - val_acc: 0.7910 - val_auc: 0.8681 - val_loss: 0.4438\n",
      "Epoch 3880/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7755 - auc: 0.8545 - loss: 0.4658 - val_acc: 0.7887 - val_auc: 0.8672 - val_loss: 0.4468\n",
      "Epoch 3881/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7754 - auc: 0.8546 - loss: 0.4658 - val_acc: 0.7885 - val_auc: 0.8668 - val_loss: 0.4480\n",
      "Epoch 3882/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7744 - auc: 0.8553 - loss: 0.4643 - val_acc: 0.7885 - val_auc: 0.8686 - val_loss: 0.4449\n",
      "Epoch 3883/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7748 - auc: 0.8564 - loss: 0.4638 - val_acc: 0.7912 - val_auc: 0.8678 - val_loss: 0.4446\n",
      "Epoch 3884/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7764 - auc: 0.8553 - loss: 0.4663 - val_acc: 0.7901 - val_auc: 0.8678 - val_loss: 0.4461\n",
      "Epoch 3885/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7772 - auc: 0.8573 - loss: 0.4618 - val_acc: 0.7903 - val_auc: 0.8678 - val_loss: 0.4455\n",
      "Epoch 3886/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7752 - auc: 0.8545 - loss: 0.4656 - val_acc: 0.7895 - val_auc: 0.8670 - val_loss: 0.4465\n",
      "Epoch 3887/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7752 - auc: 0.8556 - loss: 0.4651 - val_acc: 0.7902 - val_auc: 0.8669 - val_loss: 0.4476\n",
      "Epoch 3888/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7765 - auc: 0.8559 - loss: 0.4642 - val_acc: 0.7918 - val_auc: 0.8693 - val_loss: 0.4427\n",
      "Epoch 3889/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7757 - auc: 0.8549 - loss: 0.4654 - val_acc: 0.7880 - val_auc: 0.8679 - val_loss: 0.4453\n",
      "Epoch 3890/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7751 - auc: 0.8549 - loss: 0.4650 - val_acc: 0.7853 - val_auc: 0.8662 - val_loss: 0.4481\n",
      "Epoch 3891/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7761 - auc: 0.8549 - loss: 0.4655 - val_acc: 0.7895 - val_auc: 0.8669 - val_loss: 0.4476\n",
      "Epoch 3892/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7749 - auc: 0.8559 - loss: 0.4636 - val_acc: 0.7891 - val_auc: 0.8677 - val_loss: 0.4453\n",
      "Epoch 3893/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7745 - auc: 0.8547 - loss: 0.4659 - val_acc: 0.7924 - val_auc: 0.8679 - val_loss: 0.4451\n",
      "Epoch 3894/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7764 - auc: 0.8548 - loss: 0.4664 - val_acc: 0.7888 - val_auc: 0.8676 - val_loss: 0.4468\n",
      "Epoch 3895/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7758 - auc: 0.8551 - loss: 0.4649 - val_acc: 0.7899 - val_auc: 0.8679 - val_loss: 0.4465\n",
      "Epoch 3896/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7750 - auc: 0.8545 - loss: 0.4670 - val_acc: 0.7886 - val_auc: 0.8673 - val_loss: 0.4454\n",
      "Epoch 3897/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7763 - auc: 0.8550 - loss: 0.4656 - val_acc: 0.7885 - val_auc: 0.8675 - val_loss: 0.4458\n",
      "Epoch 3898/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7778 - auc: 0.8563 - loss: 0.4634 - val_acc: 0.7884 - val_auc: 0.8678 - val_loss: 0.4452\n",
      "Epoch 3899/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7747 - auc: 0.8544 - loss: 0.4653 - val_acc: 0.7932 - val_auc: 0.8683 - val_loss: 0.4438\n",
      "Epoch 3900/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7762 - auc: 0.8571 - loss: 0.4623 - val_acc: 0.7898 - val_auc: 0.8677 - val_loss: 0.4447\n",
      "Epoch 3901/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7738 - auc: 0.8541 - loss: 0.4659 - val_acc: 0.7901 - val_auc: 0.8683 - val_loss: 0.4455\n",
      "Epoch 3902/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7757 - auc: 0.8564 - loss: 0.4637 - val_acc: 0.7876 - val_auc: 0.8681 - val_loss: 0.4459\n",
      "Epoch 3903/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7745 - auc: 0.8544 - loss: 0.4666 - val_acc: 0.7879 - val_auc: 0.8677 - val_loss: 0.4472\n",
      "Epoch 3904/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7762 - auc: 0.8551 - loss: 0.4651 - val_acc: 0.7912 - val_auc: 0.8686 - val_loss: 0.4443\n",
      "Epoch 3905/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7763 - auc: 0.8550 - loss: 0.4660 - val_acc: 0.7873 - val_auc: 0.8672 - val_loss: 0.4490\n",
      "Epoch 3906/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7752 - auc: 0.8545 - loss: 0.4659 - val_acc: 0.7872 - val_auc: 0.8676 - val_loss: 0.4456\n",
      "Epoch 3907/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7762 - auc: 0.8539 - loss: 0.4665 - val_acc: 0.7883 - val_auc: 0.8676 - val_loss: 0.4474\n",
      "Epoch 3908/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7756 - auc: 0.8546 - loss: 0.4660 - val_acc: 0.7921 - val_auc: 0.8688 - val_loss: 0.4457\n",
      "Epoch 3909/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7756 - auc: 0.8551 - loss: 0.4653 - val_acc: 0.7894 - val_auc: 0.8675 - val_loss: 0.4454\n",
      "Epoch 3910/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7759 - auc: 0.8558 - loss: 0.4635 - val_acc: 0.7890 - val_auc: 0.8684 - val_loss: 0.4445\n",
      "Epoch 3911/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7756 - auc: 0.8559 - loss: 0.4646 - val_acc: 0.7868 - val_auc: 0.8674 - val_loss: 0.4465\n",
      "Epoch 3912/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7768 - auc: 0.8562 - loss: 0.4641 - val_acc: 0.7898 - val_auc: 0.8681 - val_loss: 0.4439\n",
      "Epoch 3913/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7729 - auc: 0.8536 - loss: 0.4683 - val_acc: 0.7890 - val_auc: 0.8668 - val_loss: 0.4465\n",
      "Epoch 3914/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7742 - auc: 0.8543 - loss: 0.4660 - val_acc: 0.7908 - val_auc: 0.8667 - val_loss: 0.4458\n",
      "Epoch 3915/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7740 - auc: 0.8547 - loss: 0.4661 - val_acc: 0.7899 - val_auc: 0.8668 - val_loss: 0.4467\n",
      "Epoch 3916/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7748 - auc: 0.8544 - loss: 0.4656 - val_acc: 0.7898 - val_auc: 0.8682 - val_loss: 0.4437\n",
      "Epoch 3917/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7780 - auc: 0.8559 - loss: 0.4648 - val_acc: 0.7886 - val_auc: 0.8681 - val_loss: 0.4460\n",
      "Epoch 3918/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7736 - auc: 0.8535 - loss: 0.4682 - val_acc: 0.7872 - val_auc: 0.8670 - val_loss: 0.4475\n",
      "Epoch 3919/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7749 - auc: 0.8549 - loss: 0.4657 - val_acc: 0.7890 - val_auc: 0.8665 - val_loss: 0.4475\n",
      "Epoch 3920/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7743 - auc: 0.8556 - loss: 0.4643 - val_acc: 0.7888 - val_auc: 0.8680 - val_loss: 0.4460\n",
      "Epoch 3921/7000\n",
      "106/106 - 2s - 21ms/step - acc: 0.7753 - auc: 0.8565 - loss: 0.4630 - val_acc: 0.7877 - val_auc: 0.8679 - val_loss: 0.4462\n",
      "Epoch 3922/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7774 - auc: 0.8558 - loss: 0.4645 - val_acc: 0.7878 - val_auc: 0.8665 - val_loss: 0.4473\n",
      "Epoch 3923/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7748 - auc: 0.8542 - loss: 0.4673 - val_acc: 0.7882 - val_auc: 0.8683 - val_loss: 0.4454\n",
      "Epoch 3924/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7760 - auc: 0.8551 - loss: 0.4661 - val_acc: 0.7890 - val_auc: 0.8677 - val_loss: 0.4456\n",
      "Epoch 3925/7000\n",
      "106/106 - 2s - 23ms/step - acc: 0.7749 - auc: 0.8555 - loss: 0.4639 - val_acc: 0.7900 - val_auc: 0.8684 - val_loss: 0.4446\n",
      "Epoch 3926/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7763 - auc: 0.8550 - loss: 0.4668 - val_acc: 0.7905 - val_auc: 0.8680 - val_loss: 0.4456\n",
      "Epoch 3927/7000\n",
      "106/106 - 2s - 15ms/step - acc: 0.7751 - auc: 0.8546 - loss: 0.4660 - val_acc: 0.7876 - val_auc: 0.8684 - val_loss: 0.4463\n",
      "Epoch 3928/7000\n",
      "106/106 - 2s - 15ms/step - acc: 0.7744 - auc: 0.8544 - loss: 0.4663 - val_acc: 0.7897 - val_auc: 0.8675 - val_loss: 0.4440\n",
      "Epoch 3929/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7771 - auc: 0.8562 - loss: 0.4638 - val_acc: 0.7875 - val_auc: 0.8666 - val_loss: 0.4461\n",
      "Epoch 3930/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7751 - auc: 0.8549 - loss: 0.4658 - val_acc: 0.7897 - val_auc: 0.8686 - val_loss: 0.4448\n",
      "Epoch 3931/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7765 - auc: 0.8566 - loss: 0.4640 - val_acc: 0.7886 - val_auc: 0.8682 - val_loss: 0.4452\n",
      "Epoch 3932/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7772 - auc: 0.8556 - loss: 0.4654 - val_acc: 0.7892 - val_auc: 0.8677 - val_loss: 0.4473\n",
      "Epoch 3933/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7773 - auc: 0.8567 - loss: 0.4628 - val_acc: 0.7890 - val_auc: 0.8660 - val_loss: 0.4471\n",
      "Epoch 3934/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7739 - auc: 0.8549 - loss: 0.4659 - val_acc: 0.7921 - val_auc: 0.8693 - val_loss: 0.4434\n",
      "Epoch 3935/7000\n",
      "106/106 - 3s - 24ms/step - acc: 0.7753 - auc: 0.8551 - loss: 0.4653 - val_acc: 0.7891 - val_auc: 0.8673 - val_loss: 0.4455\n",
      "Epoch 3936/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7755 - auc: 0.8566 - loss: 0.4628 - val_acc: 0.7919 - val_auc: 0.8687 - val_loss: 0.4432\n",
      "Epoch 3937/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7733 - auc: 0.8546 - loss: 0.4653 - val_acc: 0.7910 - val_auc: 0.8689 - val_loss: 0.4439\n",
      "Epoch 3938/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7748 - auc: 0.8545 - loss: 0.4666 - val_acc: 0.7899 - val_auc: 0.8677 - val_loss: 0.4472\n",
      "Epoch 3939/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7748 - auc: 0.8557 - loss: 0.4650 - val_acc: 0.7918 - val_auc: 0.8693 - val_loss: 0.4457\n",
      "Epoch 3940/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7753 - auc: 0.8558 - loss: 0.4637 - val_acc: 0.7911 - val_auc: 0.8685 - val_loss: 0.4440\n",
      "Epoch 3941/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7763 - auc: 0.8564 - loss: 0.4638 - val_acc: 0.7894 - val_auc: 0.8683 - val_loss: 0.4440\n",
      "Epoch 3942/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7773 - auc: 0.8574 - loss: 0.4623 - val_acc: 0.7911 - val_auc: 0.8682 - val_loss: 0.4453\n",
      "Epoch 3943/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7745 - auc: 0.8543 - loss: 0.4662 - val_acc: 0.7927 - val_auc: 0.8678 - val_loss: 0.4447\n",
      "Epoch 3944/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7752 - auc: 0.8550 - loss: 0.4659 - val_acc: 0.7901 - val_auc: 0.8680 - val_loss: 0.4473\n",
      "Epoch 3945/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7772 - auc: 0.8573 - loss: 0.4622 - val_acc: 0.7899 - val_auc: 0.8666 - val_loss: 0.4471\n",
      "Epoch 3946/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7780 - auc: 0.8565 - loss: 0.4624 - val_acc: 0.7883 - val_auc: 0.8674 - val_loss: 0.4467\n",
      "Epoch 3947/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7757 - auc: 0.8545 - loss: 0.4650 - val_acc: 0.7910 - val_auc: 0.8691 - val_loss: 0.4426\n",
      "Epoch 3948/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7755 - auc: 0.8554 - loss: 0.4655 - val_acc: 0.7896 - val_auc: 0.8687 - val_loss: 0.4440\n",
      "Epoch 3949/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7781 - auc: 0.8560 - loss: 0.4637 - val_acc: 0.7906 - val_auc: 0.8681 - val_loss: 0.4441\n",
      "Epoch 3950/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7773 - auc: 0.8562 - loss: 0.4635 - val_acc: 0.7902 - val_auc: 0.8684 - val_loss: 0.4447\n",
      "Epoch 3951/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7754 - auc: 0.8539 - loss: 0.4667 - val_acc: 0.7917 - val_auc: 0.8676 - val_loss: 0.4456\n",
      "Epoch 3952/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7758 - auc: 0.8557 - loss: 0.4632 - val_acc: 0.7877 - val_auc: 0.8659 - val_loss: 0.4505\n",
      "Epoch 3953/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7755 - auc: 0.8552 - loss: 0.4645 - val_acc: 0.7886 - val_auc: 0.8668 - val_loss: 0.4461\n",
      "Epoch 3954/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7747 - auc: 0.8542 - loss: 0.4662 - val_acc: 0.7867 - val_auc: 0.8676 - val_loss: 0.4462\n",
      "Epoch 3955/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7762 - auc: 0.8548 - loss: 0.4653 - val_acc: 0.7888 - val_auc: 0.8687 - val_loss: 0.4459\n",
      "Epoch 3956/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7756 - auc: 0.8547 - loss: 0.4656 - val_acc: 0.7902 - val_auc: 0.8676 - val_loss: 0.4456\n",
      "Epoch 3957/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7768 - auc: 0.8547 - loss: 0.4664 - val_acc: 0.7891 - val_auc: 0.8671 - val_loss: 0.4480\n",
      "Epoch 3958/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7752 - auc: 0.8556 - loss: 0.4641 - val_acc: 0.7918 - val_auc: 0.8677 - val_loss: 0.4450\n",
      "Epoch 3959/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7741 - auc: 0.8542 - loss: 0.4662 - val_acc: 0.7917 - val_auc: 0.8691 - val_loss: 0.4440\n",
      "Epoch 3960/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7751 - auc: 0.8556 - loss: 0.4651 - val_acc: 0.7917 - val_auc: 0.8681 - val_loss: 0.4456\n",
      "Epoch 3961/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7757 - auc: 0.8566 - loss: 0.4636 - val_acc: 0.7904 - val_auc: 0.8673 - val_loss: 0.4466\n",
      "Epoch 3962/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7739 - auc: 0.8549 - loss: 0.4659 - val_acc: 0.7899 - val_auc: 0.8673 - val_loss: 0.4476\n",
      "Epoch 3963/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7764 - auc: 0.8548 - loss: 0.4661 - val_acc: 0.7895 - val_auc: 0.8675 - val_loss: 0.4454\n",
      "Epoch 3964/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7734 - auc: 0.8538 - loss: 0.4668 - val_acc: 0.7902 - val_auc: 0.8684 - val_loss: 0.4454\n",
      "Epoch 3965/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7744 - auc: 0.8548 - loss: 0.4652 - val_acc: 0.7893 - val_auc: 0.8676 - val_loss: 0.4452\n",
      "Epoch 3966/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7748 - auc: 0.8536 - loss: 0.4676 - val_acc: 0.7909 - val_auc: 0.8684 - val_loss: 0.4442\n",
      "Epoch 3967/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7772 - auc: 0.8554 - loss: 0.4649 - val_acc: 0.7883 - val_auc: 0.8675 - val_loss: 0.4464\n",
      "Epoch 3968/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7777 - auc: 0.8559 - loss: 0.4646 - val_acc: 0.7922 - val_auc: 0.8678 - val_loss: 0.4452\n",
      "Epoch 3969/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7750 - auc: 0.8548 - loss: 0.4654 - val_acc: 0.7893 - val_auc: 0.8671 - val_loss: 0.4479\n",
      "Epoch 3970/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7768 - auc: 0.8552 - loss: 0.4651 - val_acc: 0.7902 - val_auc: 0.8672 - val_loss: 0.4465\n",
      "Epoch 3971/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7763 - auc: 0.8562 - loss: 0.4643 - val_acc: 0.7851 - val_auc: 0.8675 - val_loss: 0.4485\n",
      "Epoch 3972/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7742 - auc: 0.8546 - loss: 0.4658 - val_acc: 0.7896 - val_auc: 0.8673 - val_loss: 0.4465\n",
      "Epoch 3973/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7763 - auc: 0.8561 - loss: 0.4627 - val_acc: 0.7898 - val_auc: 0.8683 - val_loss: 0.4438\n",
      "Epoch 3974/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7755 - auc: 0.8551 - loss: 0.4653 - val_acc: 0.7899 - val_auc: 0.8684 - val_loss: 0.4453\n",
      "Epoch 3975/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7759 - auc: 0.8547 - loss: 0.4655 - val_acc: 0.7913 - val_auc: 0.8688 - val_loss: 0.4441\n",
      "Epoch 3976/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7744 - auc: 0.8546 - loss: 0.4665 - val_acc: 0.7917 - val_auc: 0.8682 - val_loss: 0.4452\n",
      "Epoch 3977/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7754 - auc: 0.8551 - loss: 0.4656 - val_acc: 0.7887 - val_auc: 0.8681 - val_loss: 0.4469\n",
      "Epoch 3978/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7730 - auc: 0.8529 - loss: 0.4688 - val_acc: 0.7895 - val_auc: 0.8682 - val_loss: 0.4448\n",
      "Epoch 3979/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7760 - auc: 0.8552 - loss: 0.4651 - val_acc: 0.7886 - val_auc: 0.8671 - val_loss: 0.4462\n",
      "Epoch 3980/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7769 - auc: 0.8562 - loss: 0.4648 - val_acc: 0.7913 - val_auc: 0.8693 - val_loss: 0.4453\n",
      "Epoch 3981/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7758 - auc: 0.8555 - loss: 0.4639 - val_acc: 0.7892 - val_auc: 0.8678 - val_loss: 0.4469\n",
      "Epoch 3982/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7778 - auc: 0.8567 - loss: 0.4626 - val_acc: 0.7901 - val_auc: 0.8680 - val_loss: 0.4457\n",
      "Epoch 3983/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7759 - auc: 0.8561 - loss: 0.4638 - val_acc: 0.7890 - val_auc: 0.8676 - val_loss: 0.4455\n",
      "Epoch 3984/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7745 - auc: 0.8547 - loss: 0.4656 - val_acc: 0.7889 - val_auc: 0.8676 - val_loss: 0.4458\n",
      "Epoch 3985/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7771 - auc: 0.8565 - loss: 0.4633 - val_acc: 0.7866 - val_auc: 0.8681 - val_loss: 0.4459\n",
      "Epoch 3986/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7763 - auc: 0.8564 - loss: 0.4638 - val_acc: 0.7857 - val_auc: 0.8657 - val_loss: 0.4480\n",
      "Epoch 3987/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7751 - auc: 0.8560 - loss: 0.4639 - val_acc: 0.7918 - val_auc: 0.8688 - val_loss: 0.4447\n",
      "Epoch 3988/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7754 - auc: 0.8564 - loss: 0.4637 - val_acc: 0.7915 - val_auc: 0.8683 - val_loss: 0.4464\n",
      "Epoch 3989/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7747 - auc: 0.8547 - loss: 0.4659 - val_acc: 0.7921 - val_auc: 0.8693 - val_loss: 0.4440\n",
      "Epoch 3990/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7748 - auc: 0.8539 - loss: 0.4670 - val_acc: 0.7906 - val_auc: 0.8689 - val_loss: 0.4458\n",
      "Epoch 3991/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7773 - auc: 0.8563 - loss: 0.4626 - val_acc: 0.7903 - val_auc: 0.8661 - val_loss: 0.4466\n",
      "Epoch 3992/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7762 - auc: 0.8560 - loss: 0.4633 - val_acc: 0.7870 - val_auc: 0.8676 - val_loss: 0.4463\n",
      "Epoch 3993/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7768 - auc: 0.8581 - loss: 0.4622 - val_acc: 0.7870 - val_auc: 0.8672 - val_loss: 0.4449\n",
      "Epoch 3994/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7760 - auc: 0.8560 - loss: 0.4650 - val_acc: 0.7895 - val_auc: 0.8681 - val_loss: 0.4446\n",
      "Epoch 3995/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7759 - auc: 0.8562 - loss: 0.4631 - val_acc: 0.7869 - val_auc: 0.8683 - val_loss: 0.4467\n",
      "Epoch 3996/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7769 - auc: 0.8554 - loss: 0.4651 - val_acc: 0.7900 - val_auc: 0.8676 - val_loss: 0.4449\n",
      "Epoch 3997/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7760 - auc: 0.8561 - loss: 0.4640 - val_acc: 0.7907 - val_auc: 0.8683 - val_loss: 0.4447\n",
      "Epoch 3998/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7772 - auc: 0.8559 - loss: 0.4637 - val_acc: 0.7892 - val_auc: 0.8679 - val_loss: 0.4450\n",
      "Epoch 3999/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7734 - auc: 0.8539 - loss: 0.4673 - val_acc: 0.7899 - val_auc: 0.8675 - val_loss: 0.4472\n",
      "Epoch 4000/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7734 - auc: 0.8541 - loss: 0.4662 - val_acc: 0.7913 - val_auc: 0.8679 - val_loss: 0.4449\n",
      "Epoch 4001/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7753 - auc: 0.8545 - loss: 0.4664 - val_acc: 0.7927 - val_auc: 0.8698 - val_loss: 0.4429\n",
      "Epoch 4002/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7768 - auc: 0.8565 - loss: 0.4638 - val_acc: 0.7892 - val_auc: 0.8678 - val_loss: 0.4464\n",
      "Epoch 4003/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7755 - auc: 0.8562 - loss: 0.4646 - val_acc: 0.7890 - val_auc: 0.8680 - val_loss: 0.4458\n",
      "Epoch 4004/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7759 - auc: 0.8563 - loss: 0.4634 - val_acc: 0.7904 - val_auc: 0.8696 - val_loss: 0.4437\n",
      "Epoch 4005/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7755 - auc: 0.8567 - loss: 0.4630 - val_acc: 0.7886 - val_auc: 0.8668 - val_loss: 0.4459\n",
      "Epoch 4006/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7750 - auc: 0.8545 - loss: 0.4660 - val_acc: 0.7902 - val_auc: 0.8679 - val_loss: 0.4473\n",
      "Epoch 4007/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7753 - auc: 0.8556 - loss: 0.4646 - val_acc: 0.7884 - val_auc: 0.8672 - val_loss: 0.4468\n",
      "Epoch 4008/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7765 - auc: 0.8571 - loss: 0.4632 - val_acc: 0.7905 - val_auc: 0.8680 - val_loss: 0.4456\n",
      "Epoch 4009/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7768 - auc: 0.8553 - loss: 0.4650 - val_acc: 0.7890 - val_auc: 0.8672 - val_loss: 0.4458\n",
      "Epoch 4010/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7747 - auc: 0.8557 - loss: 0.4644 - val_acc: 0.7899 - val_auc: 0.8680 - val_loss: 0.4455\n",
      "Epoch 4011/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7765 - auc: 0.8549 - loss: 0.4655 - val_acc: 0.7880 - val_auc: 0.8690 - val_loss: 0.4458\n",
      "Epoch 4012/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7767 - auc: 0.8551 - loss: 0.4663 - val_acc: 0.7885 - val_auc: 0.8672 - val_loss: 0.4474\n",
      "Epoch 4013/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7768 - auc: 0.8559 - loss: 0.4639 - val_acc: 0.7867 - val_auc: 0.8670 - val_loss: 0.4457\n",
      "Epoch 4014/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7766 - auc: 0.8572 - loss: 0.4627 - val_acc: 0.7904 - val_auc: 0.8679 - val_loss: 0.4464\n",
      "Epoch 4015/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7763 - auc: 0.8551 - loss: 0.4652 - val_acc: 0.7881 - val_auc: 0.8671 - val_loss: 0.4459\n",
      "Epoch 4016/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7750 - auc: 0.8552 - loss: 0.4648 - val_acc: 0.7868 - val_auc: 0.8684 - val_loss: 0.4440\n",
      "Epoch 4017/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7751 - auc: 0.8546 - loss: 0.4658 - val_acc: 0.7868 - val_auc: 0.8679 - val_loss: 0.4455\n",
      "Epoch 4018/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7761 - auc: 0.8557 - loss: 0.4643 - val_acc: 0.7884 - val_auc: 0.8667 - val_loss: 0.4466\n",
      "Epoch 4019/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7747 - auc: 0.8542 - loss: 0.4663 - val_acc: 0.7915 - val_auc: 0.8699 - val_loss: 0.4440\n",
      "Epoch 4020/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7774 - auc: 0.8571 - loss: 0.4629 - val_acc: 0.7913 - val_auc: 0.8685 - val_loss: 0.4435\n",
      "Epoch 4021/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7740 - auc: 0.8551 - loss: 0.4647 - val_acc: 0.7886 - val_auc: 0.8676 - val_loss: 0.4458\n",
      "Epoch 4022/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7767 - auc: 0.8569 - loss: 0.4619 - val_acc: 0.7915 - val_auc: 0.8691 - val_loss: 0.4456\n",
      "Epoch 4023/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7782 - auc: 0.8562 - loss: 0.4634 - val_acc: 0.7919 - val_auc: 0.8692 - val_loss: 0.4444\n",
      "Epoch 4024/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7738 - auc: 0.8544 - loss: 0.4653 - val_acc: 0.7889 - val_auc: 0.8684 - val_loss: 0.4451\n",
      "Epoch 4025/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7782 - auc: 0.8585 - loss: 0.4609 - val_acc: 0.7909 - val_auc: 0.8690 - val_loss: 0.4437\n",
      "Epoch 4026/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7760 - auc: 0.8557 - loss: 0.4643 - val_acc: 0.7888 - val_auc: 0.8680 - val_loss: 0.4448\n",
      "Epoch 4027/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7770 - auc: 0.8571 - loss: 0.4626 - val_acc: 0.7881 - val_auc: 0.8673 - val_loss: 0.4468\n",
      "Epoch 4028/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7770 - auc: 0.8555 - loss: 0.4649 - val_acc: 0.7906 - val_auc: 0.8679 - val_loss: 0.4451\n",
      "Epoch 4029/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7753 - auc: 0.8550 - loss: 0.4652 - val_acc: 0.7885 - val_auc: 0.8669 - val_loss: 0.4473\n",
      "Epoch 4030/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7740 - auc: 0.8547 - loss: 0.4660 - val_acc: 0.7903 - val_auc: 0.8686 - val_loss: 0.4444\n",
      "Epoch 4031/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7753 - auc: 0.8555 - loss: 0.4642 - val_acc: 0.7912 - val_auc: 0.8684 - val_loss: 0.4453\n",
      "Epoch 4032/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7770 - auc: 0.8562 - loss: 0.4635 - val_acc: 0.7863 - val_auc: 0.8666 - val_loss: 0.4463\n",
      "Epoch 4033/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7738 - auc: 0.8554 - loss: 0.4643 - val_acc: 0.7895 - val_auc: 0.8680 - val_loss: 0.4460\n",
      "Epoch 4034/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7759 - auc: 0.8563 - loss: 0.4635 - val_acc: 0.7905 - val_auc: 0.8697 - val_loss: 0.4440\n",
      "Epoch 4035/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7765 - auc: 0.8561 - loss: 0.4643 - val_acc: 0.7908 - val_auc: 0.8685 - val_loss: 0.4452\n",
      "Epoch 4036/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7766 - auc: 0.8554 - loss: 0.4642 - val_acc: 0.7915 - val_auc: 0.8692 - val_loss: 0.4442\n",
      "Epoch 4037/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7776 - auc: 0.8559 - loss: 0.4636 - val_acc: 0.7868 - val_auc: 0.8673 - val_loss: 0.4464\n",
      "Epoch 4038/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7761 - auc: 0.8553 - loss: 0.4647 - val_acc: 0.7890 - val_auc: 0.8676 - val_loss: 0.4447\n",
      "Epoch 4039/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7770 - auc: 0.8557 - loss: 0.4646 - val_acc: 0.7904 - val_auc: 0.8681 - val_loss: 0.4449\n",
      "Epoch 4040/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7764 - auc: 0.8561 - loss: 0.4648 - val_acc: 0.7872 - val_auc: 0.8690 - val_loss: 0.4461\n",
      "Epoch 4041/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7750 - auc: 0.8561 - loss: 0.4644 - val_acc: 0.7916 - val_auc: 0.8689 - val_loss: 0.4438\n",
      "Epoch 4042/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7766 - auc: 0.8564 - loss: 0.4630 - val_acc: 0.7893 - val_auc: 0.8679 - val_loss: 0.4454\n",
      "Epoch 4043/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7756 - auc: 0.8541 - loss: 0.4671 - val_acc: 0.7884 - val_auc: 0.8673 - val_loss: 0.4465\n",
      "Epoch 4044/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7766 - auc: 0.8562 - loss: 0.4633 - val_acc: 0.7907 - val_auc: 0.8682 - val_loss: 0.4433\n",
      "Epoch 4045/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7760 - auc: 0.8565 - loss: 0.4631 - val_acc: 0.7923 - val_auc: 0.8700 - val_loss: 0.4425\n",
      "Epoch 4046/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7777 - auc: 0.8568 - loss: 0.4617 - val_acc: 0.7902 - val_auc: 0.8672 - val_loss: 0.4458\n",
      "Epoch 4047/7000\n",
      "106/106 - 2s - 15ms/step - acc: 0.7768 - auc: 0.8568 - loss: 0.4630 - val_acc: 0.7902 - val_auc: 0.8682 - val_loss: 0.4461\n",
      "Epoch 4048/7000\n",
      "106/106 - 2s - 14ms/step - acc: 0.7744 - auc: 0.8555 - loss: 0.4649 - val_acc: 0.7936 - val_auc: 0.8685 - val_loss: 0.4414\n",
      "Epoch 4049/7000\n",
      "106/106 - 2s - 18ms/step - acc: 0.7750 - auc: 0.8573 - loss: 0.4613 - val_acc: 0.7887 - val_auc: 0.8684 - val_loss: 0.4449\n",
      "Epoch 4050/7000\n",
      "106/106 - 2s - 14ms/step - acc: 0.7760 - auc: 0.8554 - loss: 0.4657 - val_acc: 0.7900 - val_auc: 0.8692 - val_loss: 0.4458\n",
      "Epoch 4051/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7779 - auc: 0.8565 - loss: 0.4634 - val_acc: 0.7911 - val_auc: 0.8686 - val_loss: 0.4457\n",
      "Epoch 4052/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7754 - auc: 0.8552 - loss: 0.4648 - val_acc: 0.7904 - val_auc: 0.8691 - val_loss: 0.4451\n",
      "Epoch 4053/7000\n",
      "106/106 - 2s - 14ms/step - acc: 0.7758 - auc: 0.8550 - loss: 0.4650 - val_acc: 0.7905 - val_auc: 0.8691 - val_loss: 0.4449\n",
      "Epoch 4054/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7743 - auc: 0.8558 - loss: 0.4651 - val_acc: 0.7891 - val_auc: 0.8674 - val_loss: 0.4453\n",
      "Epoch 4055/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7750 - auc: 0.8543 - loss: 0.4657 - val_acc: 0.7890 - val_auc: 0.8683 - val_loss: 0.4451\n",
      "Epoch 4056/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7751 - auc: 0.8552 - loss: 0.4646 - val_acc: 0.7900 - val_auc: 0.8680 - val_loss: 0.4460\n",
      "Epoch 4057/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7753 - auc: 0.8543 - loss: 0.4674 - val_acc: 0.7885 - val_auc: 0.8673 - val_loss: 0.4459\n",
      "Epoch 4058/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7778 - auc: 0.8582 - loss: 0.4621 - val_acc: 0.7917 - val_auc: 0.8692 - val_loss: 0.4427\n",
      "Epoch 4059/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7769 - auc: 0.8564 - loss: 0.4630 - val_acc: 0.7948 - val_auc: 0.8697 - val_loss: 0.4426\n",
      "Epoch 4060/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7763 - auc: 0.8562 - loss: 0.4639 - val_acc: 0.7875 - val_auc: 0.8679 - val_loss: 0.4462\n",
      "Epoch 4061/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7765 - auc: 0.8546 - loss: 0.4666 - val_acc: 0.7863 - val_auc: 0.8670 - val_loss: 0.4472\n",
      "Epoch 4062/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7749 - auc: 0.8558 - loss: 0.4641 - val_acc: 0.7877 - val_auc: 0.8674 - val_loss: 0.4464\n",
      "Epoch 4063/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7750 - auc: 0.8557 - loss: 0.4640 - val_acc: 0.7910 - val_auc: 0.8688 - val_loss: 0.4451\n",
      "Epoch 4064/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7792 - auc: 0.8570 - loss: 0.4626 - val_acc: 0.7891 - val_auc: 0.8675 - val_loss: 0.4461\n",
      "Epoch 4065/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7754 - auc: 0.8555 - loss: 0.4643 - val_acc: 0.7917 - val_auc: 0.8685 - val_loss: 0.4430\n",
      "Epoch 4066/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7773 - auc: 0.8565 - loss: 0.4630 - val_acc: 0.7888 - val_auc: 0.8670 - val_loss: 0.4456\n",
      "Epoch 4067/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7763 - auc: 0.8559 - loss: 0.4640 - val_acc: 0.7902 - val_auc: 0.8686 - val_loss: 0.4432\n",
      "Epoch 4068/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7763 - auc: 0.8559 - loss: 0.4643 - val_acc: 0.7926 - val_auc: 0.8682 - val_loss: 0.4447\n",
      "Epoch 4069/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7770 - auc: 0.8559 - loss: 0.4652 - val_acc: 0.7880 - val_auc: 0.8685 - val_loss: 0.4459\n",
      "Epoch 4070/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7750 - auc: 0.8556 - loss: 0.4644 - val_acc: 0.7886 - val_auc: 0.8676 - val_loss: 0.4467\n",
      "Epoch 4071/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7758 - auc: 0.8559 - loss: 0.4633 - val_acc: 0.7910 - val_auc: 0.8682 - val_loss: 0.4456\n",
      "Epoch 4072/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7760 - auc: 0.8561 - loss: 0.4644 - val_acc: 0.7915 - val_auc: 0.8687 - val_loss: 0.4444\n",
      "Epoch 4073/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7748 - auc: 0.8548 - loss: 0.4649 - val_acc: 0.7914 - val_auc: 0.8690 - val_loss: 0.4452\n",
      "Epoch 4074/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7748 - auc: 0.8545 - loss: 0.4668 - val_acc: 0.7873 - val_auc: 0.8671 - val_loss: 0.4474\n",
      "Epoch 4075/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7761 - auc: 0.8560 - loss: 0.4633 - val_acc: 0.7934 - val_auc: 0.8689 - val_loss: 0.4436\n",
      "Epoch 4076/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7740 - auc: 0.8545 - loss: 0.4658 - val_acc: 0.7865 - val_auc: 0.8671 - val_loss: 0.4478\n",
      "Epoch 4077/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7764 - auc: 0.8548 - loss: 0.4653 - val_acc: 0.7885 - val_auc: 0.8680 - val_loss: 0.4443\n",
      "Epoch 4078/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7755 - auc: 0.8563 - loss: 0.4638 - val_acc: 0.7889 - val_auc: 0.8683 - val_loss: 0.4446\n",
      "Epoch 4079/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7760 - auc: 0.8554 - loss: 0.4647 - val_acc: 0.7896 - val_auc: 0.8682 - val_loss: 0.4448\n",
      "Epoch 4080/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7741 - auc: 0.8546 - loss: 0.4661 - val_acc: 0.7907 - val_auc: 0.8695 - val_loss: 0.4441\n",
      "Epoch 4081/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7770 - auc: 0.8562 - loss: 0.4630 - val_acc: 0.7884 - val_auc: 0.8681 - val_loss: 0.4460\n",
      "Epoch 4082/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7748 - auc: 0.8545 - loss: 0.4651 - val_acc: 0.7920 - val_auc: 0.8694 - val_loss: 0.4437\n",
      "Epoch 4083/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7756 - auc: 0.8541 - loss: 0.4661 - val_acc: 0.7918 - val_auc: 0.8689 - val_loss: 0.4450\n",
      "Epoch 4084/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7765 - auc: 0.8569 - loss: 0.4626 - val_acc: 0.7877 - val_auc: 0.8673 - val_loss: 0.4467\n",
      "Epoch 4085/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7770 - auc: 0.8553 - loss: 0.4652 - val_acc: 0.7892 - val_auc: 0.8674 - val_loss: 0.4461\n",
      "Epoch 4086/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7769 - auc: 0.8552 - loss: 0.4645 - val_acc: 0.7898 - val_auc: 0.8673 - val_loss: 0.4451\n",
      "Epoch 4087/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7770 - auc: 0.8568 - loss: 0.4640 - val_acc: 0.7910 - val_auc: 0.8688 - val_loss: 0.4443\n",
      "Epoch 4088/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7774 - auc: 0.8569 - loss: 0.4627 - val_acc: 0.7924 - val_auc: 0.8682 - val_loss: 0.4435\n",
      "Epoch 4089/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7753 - auc: 0.8551 - loss: 0.4643 - val_acc: 0.7910 - val_auc: 0.8692 - val_loss: 0.4432\n",
      "Epoch 4090/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7756 - auc: 0.8554 - loss: 0.4650 - val_acc: 0.7908 - val_auc: 0.8687 - val_loss: 0.4436\n",
      "Epoch 4091/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7756 - auc: 0.8557 - loss: 0.4646 - val_acc: 0.7894 - val_auc: 0.8677 - val_loss: 0.4460\n",
      "Epoch 4092/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7765 - auc: 0.8559 - loss: 0.4641 - val_acc: 0.7919 - val_auc: 0.8681 - val_loss: 0.4450\n",
      "Epoch 4093/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7761 - auc: 0.8554 - loss: 0.4644 - val_acc: 0.7908 - val_auc: 0.8689 - val_loss: 0.4459\n",
      "Epoch 4094/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7740 - auc: 0.8546 - loss: 0.4659 - val_acc: 0.7910 - val_auc: 0.8677 - val_loss: 0.4445\n",
      "Epoch 4095/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7789 - auc: 0.8568 - loss: 0.4630 - val_acc: 0.7878 - val_auc: 0.8673 - val_loss: 0.4467\n",
      "Epoch 4096/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7758 - auc: 0.8560 - loss: 0.4640 - val_acc: 0.7890 - val_auc: 0.8678 - val_loss: 0.4450\n",
      "Epoch 4097/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7772 - auc: 0.8570 - loss: 0.4630 - val_acc: 0.7874 - val_auc: 0.8681 - val_loss: 0.4455\n",
      "Epoch 4098/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7749 - auc: 0.8554 - loss: 0.4643 - val_acc: 0.7872 - val_auc: 0.8674 - val_loss: 0.4468\n",
      "Epoch 4099/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7791 - auc: 0.8580 - loss: 0.4618 - val_acc: 0.7870 - val_auc: 0.8678 - val_loss: 0.4457\n",
      "Epoch 4100/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7767 - auc: 0.8559 - loss: 0.4640 - val_acc: 0.7916 - val_auc: 0.8693 - val_loss: 0.4418\n",
      "Epoch 4101/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7745 - auc: 0.8559 - loss: 0.4643 - val_acc: 0.7891 - val_auc: 0.8685 - val_loss: 0.4448\n",
      "Epoch 4102/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7767 - auc: 0.8570 - loss: 0.4620 - val_acc: 0.7878 - val_auc: 0.8671 - val_loss: 0.4471\n",
      "Epoch 4103/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7775 - auc: 0.8568 - loss: 0.4626 - val_acc: 0.7905 - val_auc: 0.8685 - val_loss: 0.4444\n",
      "Epoch 4104/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7763 - auc: 0.8548 - loss: 0.4648 - val_acc: 0.7912 - val_auc: 0.8681 - val_loss: 0.4454\n",
      "Epoch 4105/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7752 - auc: 0.8549 - loss: 0.4656 - val_acc: 0.7934 - val_auc: 0.8680 - val_loss: 0.4445\n",
      "Epoch 4106/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7780 - auc: 0.8568 - loss: 0.4622 - val_acc: 0.7933 - val_auc: 0.8698 - val_loss: 0.4447\n",
      "Epoch 4107/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7764 - auc: 0.8560 - loss: 0.4638 - val_acc: 0.7915 - val_auc: 0.8683 - val_loss: 0.4447\n",
      "Epoch 4108/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7753 - auc: 0.8559 - loss: 0.4636 - val_acc: 0.7914 - val_auc: 0.8678 - val_loss: 0.4448\n",
      "Epoch 4109/7000\n",
      "106/106 - 2s - 14ms/step - acc: 0.7749 - auc: 0.8544 - loss: 0.4654 - val_acc: 0.7905 - val_auc: 0.8678 - val_loss: 0.4460\n",
      "Epoch 4110/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7753 - auc: 0.8549 - loss: 0.4652 - val_acc: 0.7902 - val_auc: 0.8684 - val_loss: 0.4457\n",
      "Epoch 4111/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7765 - auc: 0.8556 - loss: 0.4639 - val_acc: 0.7897 - val_auc: 0.8681 - val_loss: 0.4460\n",
      "Epoch 4112/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7747 - auc: 0.8532 - loss: 0.4676 - val_acc: 0.7910 - val_auc: 0.8693 - val_loss: 0.4449\n",
      "Epoch 4113/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7743 - auc: 0.8549 - loss: 0.4645 - val_acc: 0.7899 - val_auc: 0.8680 - val_loss: 0.4439\n",
      "Epoch 4114/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7766 - auc: 0.8569 - loss: 0.4635 - val_acc: 0.7891 - val_auc: 0.8676 - val_loss: 0.4454\n",
      "Epoch 4115/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7752 - auc: 0.8555 - loss: 0.4643 - val_acc: 0.7858 - val_auc: 0.8668 - val_loss: 0.4479\n",
      "Epoch 4116/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7756 - auc: 0.8564 - loss: 0.4634 - val_acc: 0.7897 - val_auc: 0.8685 - val_loss: 0.4448\n",
      "Epoch 4117/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7775 - auc: 0.8577 - loss: 0.4621 - val_acc: 0.7891 - val_auc: 0.8683 - val_loss: 0.4468\n",
      "Epoch 4118/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7742 - auc: 0.8550 - loss: 0.4646 - val_acc: 0.7868 - val_auc: 0.8686 - val_loss: 0.4475\n",
      "Epoch 4119/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7754 - auc: 0.8553 - loss: 0.4650 - val_acc: 0.7894 - val_auc: 0.8684 - val_loss: 0.4440\n",
      "Epoch 4120/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7755 - auc: 0.8561 - loss: 0.4641 - val_acc: 0.7899 - val_auc: 0.8690 - val_loss: 0.4450\n",
      "Epoch 4121/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7742 - auc: 0.8549 - loss: 0.4659 - val_acc: 0.7915 - val_auc: 0.8687 - val_loss: 0.4440\n",
      "Epoch 4122/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7786 - auc: 0.8567 - loss: 0.4628 - val_acc: 0.7877 - val_auc: 0.8685 - val_loss: 0.4449\n",
      "Epoch 4123/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7770 - auc: 0.8572 - loss: 0.4617 - val_acc: 0.7880 - val_auc: 0.8680 - val_loss: 0.4442\n",
      "Epoch 4124/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7739 - auc: 0.8545 - loss: 0.4663 - val_acc: 0.7893 - val_auc: 0.8682 - val_loss: 0.4461\n",
      "Epoch 4125/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7755 - auc: 0.8553 - loss: 0.4653 - val_acc: 0.7916 - val_auc: 0.8676 - val_loss: 0.4457\n",
      "Epoch 4126/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7753 - auc: 0.8544 - loss: 0.4661 - val_acc: 0.7915 - val_auc: 0.8686 - val_loss: 0.4469\n",
      "Epoch 4127/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7759 - auc: 0.8569 - loss: 0.4628 - val_acc: 0.7880 - val_auc: 0.8677 - val_loss: 0.4460\n",
      "Epoch 4128/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7762 - auc: 0.8551 - loss: 0.4651 - val_acc: 0.7869 - val_auc: 0.8678 - val_loss: 0.4465\n",
      "Epoch 4129/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7762 - auc: 0.8554 - loss: 0.4662 - val_acc: 0.7897 - val_auc: 0.8683 - val_loss: 0.4451\n",
      "Epoch 4130/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7767 - auc: 0.8552 - loss: 0.4655 - val_acc: 0.7890 - val_auc: 0.8682 - val_loss: 0.4451\n",
      "Epoch 4131/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7771 - auc: 0.8567 - loss: 0.4639 - val_acc: 0.7907 - val_auc: 0.8689 - val_loss: 0.4446\n",
      "Epoch 4132/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7771 - auc: 0.8556 - loss: 0.4650 - val_acc: 0.7893 - val_auc: 0.8684 - val_loss: 0.4443\n",
      "Epoch 4133/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7764 - auc: 0.8558 - loss: 0.4634 - val_acc: 0.7910 - val_auc: 0.8693 - val_loss: 0.4437\n",
      "Epoch 4134/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7770 - auc: 0.8553 - loss: 0.4656 - val_acc: 0.7888 - val_auc: 0.8681 - val_loss: 0.4468\n",
      "Epoch 4135/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7768 - auc: 0.8557 - loss: 0.4644 - val_acc: 0.7915 - val_auc: 0.8681 - val_loss: 0.4449\n",
      "Epoch 4136/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7771 - auc: 0.8557 - loss: 0.4640 - val_acc: 0.7907 - val_auc: 0.8698 - val_loss: 0.4435\n",
      "Epoch 4137/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7750 - auc: 0.8553 - loss: 0.4642 - val_acc: 0.7913 - val_auc: 0.8691 - val_loss: 0.4436\n",
      "Epoch 4138/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7748 - auc: 0.8557 - loss: 0.4646 - val_acc: 0.7873 - val_auc: 0.8674 - val_loss: 0.4478\n",
      "Epoch 4139/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7773 - auc: 0.8549 - loss: 0.4643 - val_acc: 0.7904 - val_auc: 0.8688 - val_loss: 0.4438\n",
      "Epoch 4140/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7778 - auc: 0.8567 - loss: 0.4624 - val_acc: 0.7921 - val_auc: 0.8688 - val_loss: 0.4440\n",
      "Epoch 4141/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7746 - auc: 0.8545 - loss: 0.4666 - val_acc: 0.7877 - val_auc: 0.8676 - val_loss: 0.4453\n",
      "Epoch 4142/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7758 - auc: 0.8563 - loss: 0.4640 - val_acc: 0.7887 - val_auc: 0.8680 - val_loss: 0.4466\n",
      "Epoch 4143/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7769 - auc: 0.8562 - loss: 0.4644 - val_acc: 0.7900 - val_auc: 0.8684 - val_loss: 0.4450\n",
      "Epoch 4144/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7754 - auc: 0.8555 - loss: 0.4652 - val_acc: 0.7890 - val_auc: 0.8679 - val_loss: 0.4450\n",
      "Epoch 4145/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7763 - auc: 0.8562 - loss: 0.4644 - val_acc: 0.7881 - val_auc: 0.8689 - val_loss: 0.4445\n",
      "Epoch 4146/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7766 - auc: 0.8564 - loss: 0.4632 - val_acc: 0.7898 - val_auc: 0.8694 - val_loss: 0.4446\n",
      "Epoch 4147/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7767 - auc: 0.8571 - loss: 0.4620 - val_acc: 0.7906 - val_auc: 0.8685 - val_loss: 0.4429\n",
      "Epoch 4148/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7759 - auc: 0.8544 - loss: 0.4663 - val_acc: 0.7889 - val_auc: 0.8684 - val_loss: 0.4442\n",
      "Epoch 4149/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7744 - auc: 0.8552 - loss: 0.4652 - val_acc: 0.7876 - val_auc: 0.8684 - val_loss: 0.4457\n",
      "Epoch 4150/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7764 - auc: 0.8560 - loss: 0.4639 - val_acc: 0.7896 - val_auc: 0.8686 - val_loss: 0.4442\n",
      "Epoch 4151/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7760 - auc: 0.8550 - loss: 0.4649 - val_acc: 0.7901 - val_auc: 0.8686 - val_loss: 0.4451\n",
      "Epoch 4152/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7731 - auc: 0.8536 - loss: 0.4675 - val_acc: 0.7889 - val_auc: 0.8690 - val_loss: 0.4442\n",
      "Epoch 4153/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7760 - auc: 0.8555 - loss: 0.4633 - val_acc: 0.7915 - val_auc: 0.8686 - val_loss: 0.4437\n",
      "Epoch 4154/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7761 - auc: 0.8560 - loss: 0.4633 - val_acc: 0.7891 - val_auc: 0.8684 - val_loss: 0.4456\n",
      "Epoch 4155/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7772 - auc: 0.8562 - loss: 0.4637 - val_acc: 0.7910 - val_auc: 0.8692 - val_loss: 0.4436\n",
      "Epoch 4156/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7767 - auc: 0.8569 - loss: 0.4624 - val_acc: 0.7900 - val_auc: 0.8691 - val_loss: 0.4434\n",
      "Epoch 4157/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7765 - auc: 0.8551 - loss: 0.4656 - val_acc: 0.7927 - val_auc: 0.8700 - val_loss: 0.4433\n",
      "Epoch 4158/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7754 - auc: 0.8559 - loss: 0.4648 - val_acc: 0.7908 - val_auc: 0.8700 - val_loss: 0.4445\n",
      "Epoch 4159/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7757 - auc: 0.8553 - loss: 0.4652 - val_acc: 0.7879 - val_auc: 0.8683 - val_loss: 0.4458\n",
      "Epoch 4160/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7768 - auc: 0.8562 - loss: 0.4631 - val_acc: 0.7899 - val_auc: 0.8684 - val_loss: 0.4441\n",
      "Epoch 4161/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7761 - auc: 0.8553 - loss: 0.4634 - val_acc: 0.7894 - val_auc: 0.8693 - val_loss: 0.4454\n",
      "Epoch 4162/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7765 - auc: 0.8561 - loss: 0.4632 - val_acc: 0.7906 - val_auc: 0.8690 - val_loss: 0.4429\n",
      "Epoch 4163/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7760 - auc: 0.8567 - loss: 0.4636 - val_acc: 0.7877 - val_auc: 0.8676 - val_loss: 0.4467\n",
      "Epoch 4164/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7772 - auc: 0.8563 - loss: 0.4630 - val_acc: 0.7901 - val_auc: 0.8686 - val_loss: 0.4445\n",
      "Epoch 4165/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7763 - auc: 0.8551 - loss: 0.4653 - val_acc: 0.7922 - val_auc: 0.8692 - val_loss: 0.4448\n",
      "Epoch 4166/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7761 - auc: 0.8573 - loss: 0.4626 - val_acc: 0.7901 - val_auc: 0.8694 - val_loss: 0.4436\n",
      "Epoch 4167/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7772 - auc: 0.8550 - loss: 0.4649 - val_acc: 0.7902 - val_auc: 0.8689 - val_loss: 0.4429\n",
      "Epoch 4168/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7762 - auc: 0.8558 - loss: 0.4636 - val_acc: 0.7897 - val_auc: 0.8691 - val_loss: 0.4447\n",
      "Epoch 4169/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7758 - auc: 0.8569 - loss: 0.4630 - val_acc: 0.7875 - val_auc: 0.8690 - val_loss: 0.4463\n",
      "Epoch 4170/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7762 - auc: 0.8561 - loss: 0.4634 - val_acc: 0.7915 - val_auc: 0.8695 - val_loss: 0.4431\n",
      "Epoch 4171/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7774 - auc: 0.8554 - loss: 0.4645 - val_acc: 0.7891 - val_auc: 0.8688 - val_loss: 0.4454\n",
      "Epoch 4172/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7767 - auc: 0.8561 - loss: 0.4641 - val_acc: 0.7902 - val_auc: 0.8682 - val_loss: 0.4459\n",
      "Epoch 4173/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7754 - auc: 0.8564 - loss: 0.4626 - val_acc: 0.7904 - val_auc: 0.8690 - val_loss: 0.4451\n",
      "Epoch 4174/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7782 - auc: 0.8568 - loss: 0.4634 - val_acc: 0.7923 - val_auc: 0.8694 - val_loss: 0.4418\n",
      "Epoch 4175/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7762 - auc: 0.8560 - loss: 0.4634 - val_acc: 0.7889 - val_auc: 0.8685 - val_loss: 0.4464\n",
      "Epoch 4176/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7762 - auc: 0.8559 - loss: 0.4638 - val_acc: 0.7917 - val_auc: 0.8691 - val_loss: 0.4439\n",
      "Epoch 4177/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7773 - auc: 0.8571 - loss: 0.4627 - val_acc: 0.7937 - val_auc: 0.8691 - val_loss: 0.4435\n",
      "Epoch 4178/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7764 - auc: 0.8555 - loss: 0.4649 - val_acc: 0.7901 - val_auc: 0.8681 - val_loss: 0.4461\n",
      "Epoch 4179/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7797 - auc: 0.8579 - loss: 0.4610 - val_acc: 0.7886 - val_auc: 0.8672 - val_loss: 0.4457\n",
      "Epoch 4180/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7759 - auc: 0.8557 - loss: 0.4647 - val_acc: 0.7903 - val_auc: 0.8692 - val_loss: 0.4443\n",
      "Epoch 4181/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7765 - auc: 0.8561 - loss: 0.4630 - val_acc: 0.7879 - val_auc: 0.8677 - val_loss: 0.4445\n",
      "Epoch 4182/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7770 - auc: 0.8570 - loss: 0.4634 - val_acc: 0.7915 - val_auc: 0.8687 - val_loss: 0.4445\n",
      "Epoch 4183/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7778 - auc: 0.8571 - loss: 0.4628 - val_acc: 0.7878 - val_auc: 0.8680 - val_loss: 0.4466\n",
      "Epoch 4184/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7764 - auc: 0.8565 - loss: 0.4627 - val_acc: 0.7880 - val_auc: 0.8684 - val_loss: 0.4444\n",
      "Epoch 4185/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7762 - auc: 0.8557 - loss: 0.4643 - val_acc: 0.7891 - val_auc: 0.8690 - val_loss: 0.4452\n",
      "Epoch 4186/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7752 - auc: 0.8545 - loss: 0.4664 - val_acc: 0.7876 - val_auc: 0.8679 - val_loss: 0.4470\n",
      "Epoch 4187/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7748 - auc: 0.8548 - loss: 0.4656 - val_acc: 0.7933 - val_auc: 0.8692 - val_loss: 0.4428\n",
      "Epoch 4188/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7777 - auc: 0.8578 - loss: 0.4611 - val_acc: 0.7921 - val_auc: 0.8697 - val_loss: 0.4440\n",
      "Epoch 4189/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7761 - auc: 0.8565 - loss: 0.4629 - val_acc: 0.7900 - val_auc: 0.8693 - val_loss: 0.4445\n",
      "Epoch 4190/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7753 - auc: 0.8557 - loss: 0.4644 - val_acc: 0.7902 - val_auc: 0.8694 - val_loss: 0.4436\n",
      "Epoch 4191/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7759 - auc: 0.8559 - loss: 0.4638 - val_acc: 0.7921 - val_auc: 0.8688 - val_loss: 0.4437\n",
      "Epoch 4192/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7758 - auc: 0.8548 - loss: 0.4646 - val_acc: 0.7907 - val_auc: 0.8694 - val_loss: 0.4435\n",
      "Epoch 4193/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7784 - auc: 0.8571 - loss: 0.4631 - val_acc: 0.7894 - val_auc: 0.8681 - val_loss: 0.4458\n",
      "Epoch 4194/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7758 - auc: 0.8554 - loss: 0.4649 - val_acc: 0.7901 - val_auc: 0.8690 - val_loss: 0.4441\n",
      "Epoch 4195/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7752 - auc: 0.8554 - loss: 0.4649 - val_acc: 0.7893 - val_auc: 0.8680 - val_loss: 0.4461\n",
      "Epoch 4196/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7770 - auc: 0.8568 - loss: 0.4626 - val_acc: 0.7927 - val_auc: 0.8692 - val_loss: 0.4436\n",
      "Epoch 4197/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7767 - auc: 0.8565 - loss: 0.4633 - val_acc: 0.7909 - val_auc: 0.8697 - val_loss: 0.4433\n",
      "Epoch 4198/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7770 - auc: 0.8564 - loss: 0.4635 - val_acc: 0.7933 - val_auc: 0.8693 - val_loss: 0.4432\n",
      "Epoch 4199/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7772 - auc: 0.8559 - loss: 0.4631 - val_acc: 0.7901 - val_auc: 0.8683 - val_loss: 0.4451\n",
      "Epoch 4200/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7762 - auc: 0.8557 - loss: 0.4648 - val_acc: 0.7928 - val_auc: 0.8697 - val_loss: 0.4437\n",
      "Epoch 4201/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7775 - auc: 0.8571 - loss: 0.4626 - val_acc: 0.7934 - val_auc: 0.8698 - val_loss: 0.4415\n",
      "Epoch 4202/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7771 - auc: 0.8567 - loss: 0.4633 - val_acc: 0.7915 - val_auc: 0.8695 - val_loss: 0.4438\n",
      "Epoch 4203/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7756 - auc: 0.8564 - loss: 0.4635 - val_acc: 0.7913 - val_auc: 0.8669 - val_loss: 0.4459\n",
      "Epoch 4204/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7765 - auc: 0.8552 - loss: 0.4649 - val_acc: 0.7887 - val_auc: 0.8689 - val_loss: 0.4453\n",
      "Epoch 4205/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7765 - auc: 0.8552 - loss: 0.4658 - val_acc: 0.7900 - val_auc: 0.8685 - val_loss: 0.4448\n",
      "Epoch 4206/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7762 - auc: 0.8548 - loss: 0.4662 - val_acc: 0.7894 - val_auc: 0.8684 - val_loss: 0.4442\n",
      "Epoch 4207/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7766 - auc: 0.8545 - loss: 0.4663 - val_acc: 0.7886 - val_auc: 0.8682 - val_loss: 0.4468\n",
      "Epoch 4208/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7761 - auc: 0.8562 - loss: 0.4630 - val_acc: 0.7897 - val_auc: 0.8691 - val_loss: 0.4440\n",
      "Epoch 4209/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7781 - auc: 0.8576 - loss: 0.4626 - val_acc: 0.7916 - val_auc: 0.8688 - val_loss: 0.4434\n",
      "Epoch 4210/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7764 - auc: 0.8560 - loss: 0.4637 - val_acc: 0.7922 - val_auc: 0.8690 - val_loss: 0.4432\n",
      "Epoch 4211/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7778 - auc: 0.8552 - loss: 0.4655 - val_acc: 0.7893 - val_auc: 0.8681 - val_loss: 0.4462\n",
      "Epoch 4212/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7752 - auc: 0.8556 - loss: 0.4644 - val_acc: 0.7900 - val_auc: 0.8685 - val_loss: 0.4448\n",
      "Epoch 4213/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7752 - auc: 0.8556 - loss: 0.4647 - val_acc: 0.7908 - val_auc: 0.8681 - val_loss: 0.4450\n",
      "Epoch 4214/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7774 - auc: 0.8560 - loss: 0.4630 - val_acc: 0.7941 - val_auc: 0.8702 - val_loss: 0.4420\n",
      "Epoch 4215/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7782 - auc: 0.8573 - loss: 0.4616 - val_acc: 0.7897 - val_auc: 0.8691 - val_loss: 0.4442\n",
      "Epoch 4216/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7763 - auc: 0.8556 - loss: 0.4642 - val_acc: 0.7940 - val_auc: 0.8701 - val_loss: 0.4429\n",
      "Epoch 4217/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7752 - auc: 0.8551 - loss: 0.4654 - val_acc: 0.7903 - val_auc: 0.8708 - val_loss: 0.4442\n",
      "Epoch 4218/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7772 - auc: 0.8556 - loss: 0.4632 - val_acc: 0.7924 - val_auc: 0.8701 - val_loss: 0.4430\n",
      "Epoch 4219/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7782 - auc: 0.8572 - loss: 0.4621 - val_acc: 0.7897 - val_auc: 0.8677 - val_loss: 0.4454\n",
      "Epoch 4220/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7764 - auc: 0.8565 - loss: 0.4625 - val_acc: 0.7926 - val_auc: 0.8693 - val_loss: 0.4445\n",
      "Epoch 4221/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7785 - auc: 0.8575 - loss: 0.4616 - val_acc: 0.7933 - val_auc: 0.8687 - val_loss: 0.4438\n",
      "Epoch 4222/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7768 - auc: 0.8566 - loss: 0.4637 - val_acc: 0.7907 - val_auc: 0.8697 - val_loss: 0.4437\n",
      "Epoch 4223/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7761 - auc: 0.8567 - loss: 0.4626 - val_acc: 0.7924 - val_auc: 0.8697 - val_loss: 0.4430\n",
      "Epoch 4224/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7763 - auc: 0.8564 - loss: 0.4638 - val_acc: 0.7903 - val_auc: 0.8681 - val_loss: 0.4457\n",
      "Epoch 4225/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7778 - auc: 0.8576 - loss: 0.4625 - val_acc: 0.7927 - val_auc: 0.8691 - val_loss: 0.4425\n",
      "Epoch 4226/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7764 - auc: 0.8563 - loss: 0.4643 - val_acc: 0.7895 - val_auc: 0.8678 - val_loss: 0.4463\n",
      "Epoch 4227/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7796 - auc: 0.8574 - loss: 0.4620 - val_acc: 0.7875 - val_auc: 0.8677 - val_loss: 0.4455\n",
      "Epoch 4228/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7769 - auc: 0.8561 - loss: 0.4636 - val_acc: 0.7918 - val_auc: 0.8689 - val_loss: 0.4452\n",
      "Epoch 4229/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7785 - auc: 0.8574 - loss: 0.4615 - val_acc: 0.7927 - val_auc: 0.8674 - val_loss: 0.4439\n",
      "Epoch 4230/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7766 - auc: 0.8561 - loss: 0.4631 - val_acc: 0.7918 - val_auc: 0.8686 - val_loss: 0.4438\n",
      "Epoch 4231/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7778 - auc: 0.8567 - loss: 0.4622 - val_acc: 0.7876 - val_auc: 0.8673 - val_loss: 0.4478\n",
      "Epoch 4232/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7773 - auc: 0.8575 - loss: 0.4616 - val_acc: 0.7909 - val_auc: 0.8690 - val_loss: 0.4440\n",
      "Epoch 4233/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7763 - auc: 0.8557 - loss: 0.4647 - val_acc: 0.7929 - val_auc: 0.8692 - val_loss: 0.4418\n",
      "Epoch 4234/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7763 - auc: 0.8562 - loss: 0.4632 - val_acc: 0.7910 - val_auc: 0.8688 - val_loss: 0.4436\n",
      "Epoch 4235/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7762 - auc: 0.8548 - loss: 0.4643 - val_acc: 0.7893 - val_auc: 0.8683 - val_loss: 0.4448\n",
      "Epoch 4236/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7780 - auc: 0.8572 - loss: 0.4628 - val_acc: 0.7906 - val_auc: 0.8689 - val_loss: 0.4427\n",
      "Epoch 4237/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7771 - auc: 0.8568 - loss: 0.4638 - val_acc: 0.7886 - val_auc: 0.8697 - val_loss: 0.4462\n",
      "Epoch 4238/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7767 - auc: 0.8564 - loss: 0.4637 - val_acc: 0.7896 - val_auc: 0.8691 - val_loss: 0.4461\n",
      "Epoch 4239/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7789 - auc: 0.8571 - loss: 0.4619 - val_acc: 0.7909 - val_auc: 0.8679 - val_loss: 0.4439\n",
      "Epoch 4240/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7752 - auc: 0.8550 - loss: 0.4644 - val_acc: 0.7894 - val_auc: 0.8688 - val_loss: 0.4443\n",
      "Epoch 4241/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7738 - auc: 0.8548 - loss: 0.4663 - val_acc: 0.7888 - val_auc: 0.8682 - val_loss: 0.4445\n",
      "Epoch 4242/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7766 - auc: 0.8574 - loss: 0.4621 - val_acc: 0.7897 - val_auc: 0.8704 - val_loss: 0.4431\n",
      "Epoch 4243/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7762 - auc: 0.8549 - loss: 0.4661 - val_acc: 0.7937 - val_auc: 0.8698 - val_loss: 0.4436\n",
      "Epoch 4244/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7777 - auc: 0.8573 - loss: 0.4621 - val_acc: 0.7898 - val_auc: 0.8684 - val_loss: 0.4449\n",
      "Epoch 4245/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7770 - auc: 0.8563 - loss: 0.4629 - val_acc: 0.7888 - val_auc: 0.8681 - val_loss: 0.4439\n",
      "Epoch 4246/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7751 - auc: 0.8575 - loss: 0.4623 - val_acc: 0.7915 - val_auc: 0.8686 - val_loss: 0.4459\n",
      "Epoch 4247/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7777 - auc: 0.8564 - loss: 0.4622 - val_acc: 0.7926 - val_auc: 0.8705 - val_loss: 0.4419\n",
      "Epoch 4248/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7765 - auc: 0.8568 - loss: 0.4624 - val_acc: 0.7918 - val_auc: 0.8695 - val_loss: 0.4433\n",
      "Epoch 4249/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7771 - auc: 0.8563 - loss: 0.4636 - val_acc: 0.7902 - val_auc: 0.8688 - val_loss: 0.4443\n",
      "Epoch 4250/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7770 - auc: 0.8574 - loss: 0.4620 - val_acc: 0.7927 - val_auc: 0.8696 - val_loss: 0.4426\n",
      "Epoch 4251/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7769 - auc: 0.8567 - loss: 0.4631 - val_acc: 0.7910 - val_auc: 0.8690 - val_loss: 0.4441\n",
      "Epoch 4252/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7770 - auc: 0.8564 - loss: 0.4623 - val_acc: 0.7909 - val_auc: 0.8689 - val_loss: 0.4436\n",
      "Epoch 4253/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7751 - auc: 0.8560 - loss: 0.4639 - val_acc: 0.7889 - val_auc: 0.8681 - val_loss: 0.4446\n",
      "Epoch 4254/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7774 - auc: 0.8554 - loss: 0.4646 - val_acc: 0.7859 - val_auc: 0.8677 - val_loss: 0.4472\n",
      "Epoch 4255/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7760 - auc: 0.8554 - loss: 0.4649 - val_acc: 0.7902 - val_auc: 0.8699 - val_loss: 0.4434\n",
      "Epoch 4256/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7793 - auc: 0.8565 - loss: 0.4636 - val_acc: 0.7933 - val_auc: 0.8707 - val_loss: 0.4422\n",
      "Epoch 4257/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7767 - auc: 0.8570 - loss: 0.4636 - val_acc: 0.7924 - val_auc: 0.8699 - val_loss: 0.4438\n",
      "Epoch 4258/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7777 - auc: 0.8563 - loss: 0.4634 - val_acc: 0.7882 - val_auc: 0.8685 - val_loss: 0.4450\n",
      "Epoch 4259/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7771 - auc: 0.8574 - loss: 0.4623 - val_acc: 0.7910 - val_auc: 0.8695 - val_loss: 0.4433\n",
      "Epoch 4260/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7758 - auc: 0.8556 - loss: 0.4643 - val_acc: 0.7939 - val_auc: 0.8700 - val_loss: 0.4429\n",
      "Epoch 4261/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7755 - auc: 0.8555 - loss: 0.4655 - val_acc: 0.7902 - val_auc: 0.8680 - val_loss: 0.4445\n",
      "Epoch 4262/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7773 - auc: 0.8554 - loss: 0.4647 - val_acc: 0.7903 - val_auc: 0.8690 - val_loss: 0.4439\n",
      "Epoch 4263/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7762 - auc: 0.8565 - loss: 0.4644 - val_acc: 0.7914 - val_auc: 0.8688 - val_loss: 0.4446\n",
      "Epoch 4264/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7792 - auc: 0.8576 - loss: 0.4617 - val_acc: 0.7902 - val_auc: 0.8675 - val_loss: 0.4444\n",
      "Epoch 4265/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7767 - auc: 0.8559 - loss: 0.4640 - val_acc: 0.7915 - val_auc: 0.8696 - val_loss: 0.4435\n",
      "Epoch 4266/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7788 - auc: 0.8573 - loss: 0.4612 - val_acc: 0.7902 - val_auc: 0.8699 - val_loss: 0.4430\n",
      "Epoch 4267/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7785 - auc: 0.8566 - loss: 0.4635 - val_acc: 0.7905 - val_auc: 0.8698 - val_loss: 0.4442\n",
      "Epoch 4268/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7751 - auc: 0.8552 - loss: 0.4634 - val_acc: 0.7888 - val_auc: 0.8687 - val_loss: 0.4454\n",
      "Epoch 4269/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7768 - auc: 0.8569 - loss: 0.4625 - val_acc: 0.7924 - val_auc: 0.8697 - val_loss: 0.4447\n",
      "Epoch 4270/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7751 - auc: 0.8558 - loss: 0.4644 - val_acc: 0.7915 - val_auc: 0.8697 - val_loss: 0.4427\n",
      "Epoch 4271/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7766 - auc: 0.8558 - loss: 0.4651 - val_acc: 0.7924 - val_auc: 0.8703 - val_loss: 0.4422\n",
      "Epoch 4272/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7781 - auc: 0.8568 - loss: 0.4631 - val_acc: 0.7922 - val_auc: 0.8692 - val_loss: 0.4422\n",
      "Epoch 4273/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7770 - auc: 0.8574 - loss: 0.4611 - val_acc: 0.7905 - val_auc: 0.8693 - val_loss: 0.4424\n",
      "Epoch 4274/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7762 - auc: 0.8557 - loss: 0.4635 - val_acc: 0.7928 - val_auc: 0.8703 - val_loss: 0.4425\n",
      "Epoch 4275/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7778 - auc: 0.8569 - loss: 0.4639 - val_acc: 0.7899 - val_auc: 0.8696 - val_loss: 0.4443\n",
      "Epoch 4276/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7758 - auc: 0.8568 - loss: 0.4618 - val_acc: 0.7902 - val_auc: 0.8688 - val_loss: 0.4432\n",
      "Epoch 4277/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7770 - auc: 0.8578 - loss: 0.4617 - val_acc: 0.7948 - val_auc: 0.8700 - val_loss: 0.4423\n",
      "Epoch 4278/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7770 - auc: 0.8574 - loss: 0.4618 - val_acc: 0.7925 - val_auc: 0.8694 - val_loss: 0.4429\n",
      "Epoch 4279/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7754 - auc: 0.8570 - loss: 0.4629 - val_acc: 0.7896 - val_auc: 0.8688 - val_loss: 0.4450\n",
      "Epoch 4280/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7771 - auc: 0.8576 - loss: 0.4618 - val_acc: 0.7908 - val_auc: 0.8680 - val_loss: 0.4434\n",
      "Epoch 4281/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7750 - auc: 0.8560 - loss: 0.4648 - val_acc: 0.7907 - val_auc: 0.8697 - val_loss: 0.4445\n",
      "Epoch 4282/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7755 - auc: 0.8557 - loss: 0.4648 - val_acc: 0.7903 - val_auc: 0.8685 - val_loss: 0.4444\n",
      "Epoch 4283/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7783 - auc: 0.8581 - loss: 0.4619 - val_acc: 0.7945 - val_auc: 0.8700 - val_loss: 0.4434\n",
      "Epoch 4284/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7767 - auc: 0.8561 - loss: 0.4632 - val_acc: 0.7884 - val_auc: 0.8685 - val_loss: 0.4444\n",
      "Epoch 4285/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7756 - auc: 0.8565 - loss: 0.4644 - val_acc: 0.7895 - val_auc: 0.8680 - val_loss: 0.4453\n",
      "Epoch 4286/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7781 - auc: 0.8575 - loss: 0.4619 - val_acc: 0.7915 - val_auc: 0.8690 - val_loss: 0.4422\n",
      "Epoch 4287/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7775 - auc: 0.8577 - loss: 0.4629 - val_acc: 0.7925 - val_auc: 0.8687 - val_loss: 0.4437\n",
      "Epoch 4288/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7773 - auc: 0.8563 - loss: 0.4636 - val_acc: 0.7901 - val_auc: 0.8692 - val_loss: 0.4446\n",
      "Epoch 4289/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7762 - auc: 0.8571 - loss: 0.4624 - val_acc: 0.7921 - val_auc: 0.8692 - val_loss: 0.4436\n",
      "Epoch 4290/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7747 - auc: 0.8545 - loss: 0.4655 - val_acc: 0.7946 - val_auc: 0.8684 - val_loss: 0.4440\n",
      "Epoch 4291/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7757 - auc: 0.8553 - loss: 0.4657 - val_acc: 0.7902 - val_auc: 0.8690 - val_loss: 0.4449\n",
      "Epoch 4292/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7771 - auc: 0.8576 - loss: 0.4618 - val_acc: 0.7908 - val_auc: 0.8687 - val_loss: 0.4443\n",
      "Epoch 4293/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7742 - auc: 0.8553 - loss: 0.4655 - val_acc: 0.7872 - val_auc: 0.8670 - val_loss: 0.4477\n",
      "Epoch 4294/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7781 - auc: 0.8563 - loss: 0.4645 - val_acc: 0.7916 - val_auc: 0.8683 - val_loss: 0.4442\n",
      "Epoch 4295/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7755 - auc: 0.8580 - loss: 0.4605 - val_acc: 0.7907 - val_auc: 0.8694 - val_loss: 0.4440\n",
      "Epoch 4296/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7783 - auc: 0.8579 - loss: 0.4623 - val_acc: 0.7890 - val_auc: 0.8675 - val_loss: 0.4483\n",
      "Epoch 4297/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7770 - auc: 0.8555 - loss: 0.4652 - val_acc: 0.7882 - val_auc: 0.8674 - val_loss: 0.4485\n",
      "Epoch 4298/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7768 - auc: 0.8568 - loss: 0.4632 - val_acc: 0.7928 - val_auc: 0.8695 - val_loss: 0.4431\n",
      "Epoch 4299/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7764 - auc: 0.8564 - loss: 0.4629 - val_acc: 0.7912 - val_auc: 0.8687 - val_loss: 0.4442\n",
      "Epoch 4300/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7774 - auc: 0.8575 - loss: 0.4619 - val_acc: 0.7922 - val_auc: 0.8697 - val_loss: 0.4431\n",
      "Epoch 4301/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7767 - auc: 0.8569 - loss: 0.4627 - val_acc: 0.7913 - val_auc: 0.8687 - val_loss: 0.4436\n",
      "Epoch 4302/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7780 - auc: 0.8570 - loss: 0.4630 - val_acc: 0.7905 - val_auc: 0.8691 - val_loss: 0.4434\n",
      "Epoch 4303/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7748 - auc: 0.8546 - loss: 0.4664 - val_acc: 0.7909 - val_auc: 0.8699 - val_loss: 0.4458\n",
      "Epoch 4304/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7753 - auc: 0.8573 - loss: 0.4630 - val_acc: 0.7920 - val_auc: 0.8691 - val_loss: 0.4438\n",
      "Epoch 4305/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7765 - auc: 0.8558 - loss: 0.4631 - val_acc: 0.7926 - val_auc: 0.8695 - val_loss: 0.4432\n",
      "Epoch 4306/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7752 - auc: 0.8557 - loss: 0.4637 - val_acc: 0.7907 - val_auc: 0.8689 - val_loss: 0.4428\n",
      "Epoch 4307/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7766 - auc: 0.8573 - loss: 0.4623 - val_acc: 0.7916 - val_auc: 0.8701 - val_loss: 0.4431\n",
      "Epoch 4308/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7797 - auc: 0.8588 - loss: 0.4612 - val_acc: 0.7902 - val_auc: 0.8686 - val_loss: 0.4454\n",
      "Epoch 4309/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7765 - auc: 0.8553 - loss: 0.4645 - val_acc: 0.7898 - val_auc: 0.8696 - val_loss: 0.4438\n",
      "Epoch 4310/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7787 - auc: 0.8568 - loss: 0.4636 - val_acc: 0.7888 - val_auc: 0.8686 - val_loss: 0.4446\n",
      "Epoch 4311/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7771 - auc: 0.8573 - loss: 0.4610 - val_acc: 0.7907 - val_auc: 0.8690 - val_loss: 0.4444\n",
      "Epoch 4312/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7764 - auc: 0.8566 - loss: 0.4625 - val_acc: 0.7888 - val_auc: 0.8682 - val_loss: 0.4454\n",
      "Epoch 4313/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7777 - auc: 0.8570 - loss: 0.4628 - val_acc: 0.7871 - val_auc: 0.8685 - val_loss: 0.4460\n",
      "Epoch 4314/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7753 - auc: 0.8555 - loss: 0.4632 - val_acc: 0.7906 - val_auc: 0.8690 - val_loss: 0.4452\n",
      "Epoch 4315/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7783 - auc: 0.8578 - loss: 0.4614 - val_acc: 0.7912 - val_auc: 0.8673 - val_loss: 0.4463\n",
      "Epoch 4316/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7775 - auc: 0.8574 - loss: 0.4608 - val_acc: 0.7922 - val_auc: 0.8690 - val_loss: 0.4442\n",
      "Epoch 4317/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7763 - auc: 0.8557 - loss: 0.4641 - val_acc: 0.7915 - val_auc: 0.8699 - val_loss: 0.4429\n",
      "Epoch 4318/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7774 - auc: 0.8578 - loss: 0.4615 - val_acc: 0.7902 - val_auc: 0.8675 - val_loss: 0.4453\n",
      "Epoch 4319/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7785 - auc: 0.8570 - loss: 0.4627 - val_acc: 0.7903 - val_auc: 0.8693 - val_loss: 0.4435\n",
      "Epoch 4320/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7772 - auc: 0.8566 - loss: 0.4640 - val_acc: 0.7911 - val_auc: 0.8696 - val_loss: 0.4449\n",
      "Epoch 4321/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7787 - auc: 0.8567 - loss: 0.4624 - val_acc: 0.7902 - val_auc: 0.8684 - val_loss: 0.4450\n",
      "Epoch 4322/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7755 - auc: 0.8556 - loss: 0.4639 - val_acc: 0.7863 - val_auc: 0.8690 - val_loss: 0.4461\n",
      "Epoch 4323/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7789 - auc: 0.8572 - loss: 0.4619 - val_acc: 0.7905 - val_auc: 0.8683 - val_loss: 0.4451\n",
      "Epoch 4324/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7760 - auc: 0.8562 - loss: 0.4637 - val_acc: 0.7915 - val_auc: 0.8694 - val_loss: 0.4440\n",
      "Epoch 4325/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7760 - auc: 0.8561 - loss: 0.4635 - val_acc: 0.7902 - val_auc: 0.8697 - val_loss: 0.4448\n",
      "Epoch 4326/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7794 - auc: 0.8586 - loss: 0.4601 - val_acc: 0.7895 - val_auc: 0.8677 - val_loss: 0.4450\n",
      "Epoch 4327/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7754 - auc: 0.8554 - loss: 0.4644 - val_acc: 0.7865 - val_auc: 0.8673 - val_loss: 0.4480\n",
      "Epoch 4328/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7740 - auc: 0.8552 - loss: 0.4651 - val_acc: 0.7885 - val_auc: 0.8698 - val_loss: 0.4451\n",
      "Epoch 4329/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7746 - auc: 0.8562 - loss: 0.4641 - val_acc: 0.7915 - val_auc: 0.8684 - val_loss: 0.4438\n",
      "Epoch 4330/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7769 - auc: 0.8549 - loss: 0.4652 - val_acc: 0.7914 - val_auc: 0.8687 - val_loss: 0.4438\n",
      "Epoch 4331/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7756 - auc: 0.8557 - loss: 0.4640 - val_acc: 0.7900 - val_auc: 0.8689 - val_loss: 0.4423\n",
      "Epoch 4332/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7752 - auc: 0.8556 - loss: 0.4640 - val_acc: 0.7921 - val_auc: 0.8691 - val_loss: 0.4446\n",
      "Epoch 4333/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7764 - auc: 0.8570 - loss: 0.4625 - val_acc: 0.7911 - val_auc: 0.8693 - val_loss: 0.4431\n",
      "Epoch 4334/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7770 - auc: 0.8563 - loss: 0.4631 - val_acc: 0.7914 - val_auc: 0.8694 - val_loss: 0.4429\n",
      "Epoch 4335/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7754 - auc: 0.8558 - loss: 0.4641 - val_acc: 0.7902 - val_auc: 0.8678 - val_loss: 0.4448\n",
      "Epoch 4336/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7751 - auc: 0.8550 - loss: 0.4654 - val_acc: 0.7923 - val_auc: 0.8685 - val_loss: 0.4449\n",
      "Epoch 4337/7000\n",
      "106/106 - 2s - 24ms/step - acc: 0.7776 - auc: 0.8566 - loss: 0.4624 - val_acc: 0.7922 - val_auc: 0.8690 - val_loss: 0.4440\n",
      "Epoch 4338/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7754 - auc: 0.8561 - loss: 0.4636 - val_acc: 0.7902 - val_auc: 0.8691 - val_loss: 0.4439\n",
      "Epoch 4339/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7782 - auc: 0.8569 - loss: 0.4619 - val_acc: 0.7905 - val_auc: 0.8693 - val_loss: 0.4448\n",
      "Epoch 4340/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7755 - auc: 0.8559 - loss: 0.4639 - val_acc: 0.7906 - val_auc: 0.8687 - val_loss: 0.4438\n",
      "Epoch 4341/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7779 - auc: 0.8567 - loss: 0.4632 - val_acc: 0.7903 - val_auc: 0.8679 - val_loss: 0.4447\n",
      "Epoch 4342/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7765 - auc: 0.8559 - loss: 0.4642 - val_acc: 0.7922 - val_auc: 0.8683 - val_loss: 0.4446\n",
      "Epoch 4343/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7769 - auc: 0.8556 - loss: 0.4646 - val_acc: 0.7897 - val_auc: 0.8675 - val_loss: 0.4443\n",
      "Epoch 4344/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7789 - auc: 0.8577 - loss: 0.4623 - val_acc: 0.7912 - val_auc: 0.8697 - val_loss: 0.4439\n",
      "Epoch 4345/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7770 - auc: 0.8565 - loss: 0.4630 - val_acc: 0.7920 - val_auc: 0.8687 - val_loss: 0.4446\n",
      "Epoch 4346/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7766 - auc: 0.8565 - loss: 0.4626 - val_acc: 0.7902 - val_auc: 0.8696 - val_loss: 0.4420\n",
      "Epoch 4347/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7770 - auc: 0.8563 - loss: 0.4635 - val_acc: 0.7900 - val_auc: 0.8699 - val_loss: 0.4445\n",
      "Epoch 4348/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7765 - auc: 0.8557 - loss: 0.4646 - val_acc: 0.7900 - val_auc: 0.8687 - val_loss: 0.4437\n",
      "Epoch 4349/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7762 - auc: 0.8566 - loss: 0.4625 - val_acc: 0.7927 - val_auc: 0.8681 - val_loss: 0.4441\n",
      "Epoch 4350/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7777 - auc: 0.8574 - loss: 0.4619 - val_acc: 0.7888 - val_auc: 0.8680 - val_loss: 0.4455\n",
      "Epoch 4351/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7777 - auc: 0.8568 - loss: 0.4635 - val_acc: 0.7915 - val_auc: 0.8690 - val_loss: 0.4437\n",
      "Epoch 4352/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7767 - auc: 0.8571 - loss: 0.4625 - val_acc: 0.7877 - val_auc: 0.8693 - val_loss: 0.4444\n",
      "Epoch 4353/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7764 - auc: 0.8557 - loss: 0.4635 - val_acc: 0.7904 - val_auc: 0.8690 - val_loss: 0.4457\n",
      "Epoch 4354/7000\n",
      "106/106 - 2s - 14ms/step - acc: 0.7799 - auc: 0.8574 - loss: 0.4624 - val_acc: 0.7921 - val_auc: 0.8687 - val_loss: 0.4432\n",
      "Epoch 4355/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7792 - auc: 0.8578 - loss: 0.4622 - val_acc: 0.7880 - val_auc: 0.8675 - val_loss: 0.4474\n",
      "Epoch 4356/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7795 - auc: 0.8581 - loss: 0.4604 - val_acc: 0.7900 - val_auc: 0.8694 - val_loss: 0.4434\n",
      "Epoch 4357/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7804 - auc: 0.8587 - loss: 0.4605 - val_acc: 0.7922 - val_auc: 0.8694 - val_loss: 0.4427\n",
      "Epoch 4358/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7746 - auc: 0.8559 - loss: 0.4633 - val_acc: 0.7920 - val_auc: 0.8690 - val_loss: 0.4436\n",
      "Epoch 4359/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7758 - auc: 0.8554 - loss: 0.4648 - val_acc: 0.7917 - val_auc: 0.8685 - val_loss: 0.4446\n",
      "Epoch 4360/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7761 - auc: 0.8562 - loss: 0.4638 - val_acc: 0.7911 - val_auc: 0.8673 - val_loss: 0.4452\n",
      "Epoch 4361/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7754 - auc: 0.8553 - loss: 0.4647 - val_acc: 0.7893 - val_auc: 0.8677 - val_loss: 0.4462\n",
      "Epoch 4362/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7769 - auc: 0.8575 - loss: 0.4613 - val_acc: 0.7872 - val_auc: 0.8684 - val_loss: 0.4450\n",
      "Epoch 4363/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7780 - auc: 0.8568 - loss: 0.4622 - val_acc: 0.7888 - val_auc: 0.8690 - val_loss: 0.4448\n",
      "Epoch 4364/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7785 - auc: 0.8583 - loss: 0.4607 - val_acc: 0.7880 - val_auc: 0.8697 - val_loss: 0.4440\n",
      "Epoch 4365/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7786 - auc: 0.8583 - loss: 0.4612 - val_acc: 0.7853 - val_auc: 0.8691 - val_loss: 0.4453\n",
      "Epoch 4366/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7785 - auc: 0.8580 - loss: 0.4603 - val_acc: 0.7913 - val_auc: 0.8701 - val_loss: 0.4417\n",
      "Epoch 4367/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7767 - auc: 0.8566 - loss: 0.4635 - val_acc: 0.7939 - val_auc: 0.8701 - val_loss: 0.4415\n",
      "Epoch 4368/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7772 - auc: 0.8570 - loss: 0.4630 - val_acc: 0.7916 - val_auc: 0.8700 - val_loss: 0.4441\n",
      "Epoch 4369/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7760 - auc: 0.8558 - loss: 0.4637 - val_acc: 0.7871 - val_auc: 0.8678 - val_loss: 0.4465\n",
      "Epoch 4370/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7766 - auc: 0.8576 - loss: 0.4619 - val_acc: 0.7901 - val_auc: 0.8688 - val_loss: 0.4434\n",
      "Epoch 4371/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7767 - auc: 0.8562 - loss: 0.4649 - val_acc: 0.7922 - val_auc: 0.8700 - val_loss: 0.4443\n",
      "Epoch 4372/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7770 - auc: 0.8560 - loss: 0.4640 - val_acc: 0.7889 - val_auc: 0.8682 - val_loss: 0.4461\n",
      "Epoch 4373/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7775 - auc: 0.8559 - loss: 0.4639 - val_acc: 0.7924 - val_auc: 0.8691 - val_loss: 0.4438\n",
      "Epoch 4374/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7777 - auc: 0.8563 - loss: 0.4644 - val_acc: 0.7887 - val_auc: 0.8695 - val_loss: 0.4435\n",
      "Epoch 4375/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7768 - auc: 0.8569 - loss: 0.4625 - val_acc: 0.7915 - val_auc: 0.8695 - val_loss: 0.4440\n",
      "Epoch 4376/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7772 - auc: 0.8565 - loss: 0.4627 - val_acc: 0.7887 - val_auc: 0.8677 - val_loss: 0.4452\n",
      "Epoch 4377/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7774 - auc: 0.8566 - loss: 0.4631 - val_acc: 0.7899 - val_auc: 0.8676 - val_loss: 0.4448\n",
      "Epoch 4378/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7783 - auc: 0.8568 - loss: 0.4626 - val_acc: 0.7901 - val_auc: 0.8699 - val_loss: 0.4438\n",
      "Epoch 4379/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7773 - auc: 0.8565 - loss: 0.4632 - val_acc: 0.7902 - val_auc: 0.8689 - val_loss: 0.4434\n",
      "Epoch 4380/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7778 - auc: 0.8562 - loss: 0.4644 - val_acc: 0.7893 - val_auc: 0.8695 - val_loss: 0.4446\n",
      "Epoch 4381/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7777 - auc: 0.8567 - loss: 0.4625 - val_acc: 0.7915 - val_auc: 0.8687 - val_loss: 0.4438\n",
      "Epoch 4382/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7772 - auc: 0.8564 - loss: 0.4637 - val_acc: 0.7900 - val_auc: 0.8698 - val_loss: 0.4436\n",
      "Epoch 4383/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7793 - auc: 0.8582 - loss: 0.4617 - val_acc: 0.7902 - val_auc: 0.8690 - val_loss: 0.4438\n",
      "Epoch 4384/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7759 - auc: 0.8564 - loss: 0.4634 - val_acc: 0.7894 - val_auc: 0.8675 - val_loss: 0.4450\n",
      "Epoch 4385/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7777 - auc: 0.8570 - loss: 0.4631 - val_acc: 0.7910 - val_auc: 0.8693 - val_loss: 0.4456\n",
      "Epoch 4386/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7779 - auc: 0.8562 - loss: 0.4631 - val_acc: 0.7877 - val_auc: 0.8675 - val_loss: 0.4446\n",
      "Epoch 4387/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7778 - auc: 0.8571 - loss: 0.4618 - val_acc: 0.7921 - val_auc: 0.8689 - val_loss: 0.4436\n",
      "Epoch 4388/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7771 - auc: 0.8572 - loss: 0.4625 - val_acc: 0.7912 - val_auc: 0.8696 - val_loss: 0.4446\n",
      "Epoch 4389/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7773 - auc: 0.8574 - loss: 0.4613 - val_acc: 0.7900 - val_auc: 0.8686 - val_loss: 0.4458\n",
      "Epoch 4390/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7780 - auc: 0.8570 - loss: 0.4629 - val_acc: 0.7905 - val_auc: 0.8689 - val_loss: 0.4467\n",
      "Epoch 4391/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7782 - auc: 0.8587 - loss: 0.4617 - val_acc: 0.7907 - val_auc: 0.8688 - val_loss: 0.4455\n",
      "Epoch 4392/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7778 - auc: 0.8565 - loss: 0.4629 - val_acc: 0.7917 - val_auc: 0.8699 - val_loss: 0.4425\n",
      "Epoch 4393/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7797 - auc: 0.8588 - loss: 0.4611 - val_acc: 0.7887 - val_auc: 0.8670 - val_loss: 0.4451\n",
      "Epoch 4394/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7775 - auc: 0.8576 - loss: 0.4617 - val_acc: 0.7921 - val_auc: 0.8696 - val_loss: 0.4432\n",
      "Epoch 4395/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7774 - auc: 0.8564 - loss: 0.4627 - val_acc: 0.7908 - val_auc: 0.8691 - val_loss: 0.4441\n",
      "Epoch 4396/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7789 - auc: 0.8570 - loss: 0.4629 - val_acc: 0.7875 - val_auc: 0.8673 - val_loss: 0.4478\n",
      "Epoch 4397/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7772 - auc: 0.8562 - loss: 0.4640 - val_acc: 0.7922 - val_auc: 0.8691 - val_loss: 0.4448\n",
      "Epoch 4398/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7784 - auc: 0.8575 - loss: 0.4626 - val_acc: 0.7901 - val_auc: 0.8691 - val_loss: 0.4444\n",
      "Epoch 4399/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7756 - auc: 0.8565 - loss: 0.4629 - val_acc: 0.7930 - val_auc: 0.8700 - val_loss: 0.4445\n",
      "Epoch 4400/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7772 - auc: 0.8563 - loss: 0.4631 - val_acc: 0.7917 - val_auc: 0.8694 - val_loss: 0.4437\n",
      "Epoch 4401/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7766 - auc: 0.8579 - loss: 0.4618 - val_acc: 0.7906 - val_auc: 0.8698 - val_loss: 0.4447\n",
      "Epoch 4402/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7763 - auc: 0.8555 - loss: 0.4647 - val_acc: 0.7920 - val_auc: 0.8696 - val_loss: 0.4433\n",
      "Epoch 4403/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7776 - auc: 0.8565 - loss: 0.4631 - val_acc: 0.7943 - val_auc: 0.8706 - val_loss: 0.4411\n",
      "Epoch 4404/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7771 - auc: 0.8559 - loss: 0.4644 - val_acc: 0.7924 - val_auc: 0.8699 - val_loss: 0.4446\n",
      "Epoch 4405/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7758 - auc: 0.8567 - loss: 0.4632 - val_acc: 0.7908 - val_auc: 0.8689 - val_loss: 0.4451\n",
      "Epoch 4406/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7770 - auc: 0.8563 - loss: 0.4638 - val_acc: 0.7906 - val_auc: 0.8688 - val_loss: 0.4441\n",
      "Epoch 4407/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7775 - auc: 0.8568 - loss: 0.4636 - val_acc: 0.7936 - val_auc: 0.8709 - val_loss: 0.4420\n",
      "Epoch 4408/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7764 - auc: 0.8556 - loss: 0.4649 - val_acc: 0.7923 - val_auc: 0.8688 - val_loss: 0.4442\n",
      "Epoch 4409/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7777 - auc: 0.8572 - loss: 0.4624 - val_acc: 0.7911 - val_auc: 0.8695 - val_loss: 0.4448\n",
      "Epoch 4410/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7767 - auc: 0.8578 - loss: 0.4621 - val_acc: 0.7911 - val_auc: 0.8699 - val_loss: 0.4431\n",
      "Epoch 4411/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7741 - auc: 0.8557 - loss: 0.4654 - val_acc: 0.7896 - val_auc: 0.8690 - val_loss: 0.4447\n",
      "Epoch 4412/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7784 - auc: 0.8587 - loss: 0.4595 - val_acc: 0.7924 - val_auc: 0.8699 - val_loss: 0.4425\n",
      "Epoch 4413/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7768 - auc: 0.8568 - loss: 0.4633 - val_acc: 0.7913 - val_auc: 0.8688 - val_loss: 0.4445\n",
      "Epoch 4414/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7762 - auc: 0.8562 - loss: 0.4631 - val_acc: 0.7922 - val_auc: 0.8693 - val_loss: 0.4429\n",
      "Epoch 4415/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7771 - auc: 0.8570 - loss: 0.4628 - val_acc: 0.7909 - val_auc: 0.8696 - val_loss: 0.4418\n",
      "Epoch 4416/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7764 - auc: 0.8566 - loss: 0.4620 - val_acc: 0.7909 - val_auc: 0.8697 - val_loss: 0.4448\n",
      "Epoch 4417/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7802 - auc: 0.8587 - loss: 0.4606 - val_acc: 0.7916 - val_auc: 0.8690 - val_loss: 0.4426\n",
      "Epoch 4418/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7782 - auc: 0.8579 - loss: 0.4611 - val_acc: 0.7931 - val_auc: 0.8714 - val_loss: 0.4405\n",
      "Epoch 4419/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7758 - auc: 0.8560 - loss: 0.4639 - val_acc: 0.7916 - val_auc: 0.8700 - val_loss: 0.4451\n",
      "Epoch 4420/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7763 - auc: 0.8554 - loss: 0.4655 - val_acc: 0.7880 - val_auc: 0.8680 - val_loss: 0.4465\n",
      "Epoch 4421/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7784 - auc: 0.8570 - loss: 0.4628 - val_acc: 0.7902 - val_auc: 0.8694 - val_loss: 0.4468\n",
      "Epoch 4422/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7769 - auc: 0.8566 - loss: 0.4623 - val_acc: 0.7921 - val_auc: 0.8691 - val_loss: 0.4431\n",
      "Epoch 4423/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7753 - auc: 0.8554 - loss: 0.4658 - val_acc: 0.7897 - val_auc: 0.8695 - val_loss: 0.4429\n",
      "Epoch 4424/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7759 - auc: 0.8551 - loss: 0.4648 - val_acc: 0.7928 - val_auc: 0.8696 - val_loss: 0.4434\n",
      "Epoch 4425/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7765 - auc: 0.8564 - loss: 0.4624 - val_acc: 0.7911 - val_auc: 0.8683 - val_loss: 0.4444\n",
      "Epoch 4426/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7768 - auc: 0.8554 - loss: 0.4642 - val_acc: 0.7951 - val_auc: 0.8697 - val_loss: 0.4433\n",
      "Epoch 4427/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7777 - auc: 0.8575 - loss: 0.4631 - val_acc: 0.7935 - val_auc: 0.8707 - val_loss: 0.4426\n",
      "Epoch 4428/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7762 - auc: 0.8565 - loss: 0.4632 - val_acc: 0.7891 - val_auc: 0.8692 - val_loss: 0.4466\n",
      "Epoch 4429/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7763 - auc: 0.8565 - loss: 0.4629 - val_acc: 0.7913 - val_auc: 0.8691 - val_loss: 0.4437\n",
      "Epoch 4430/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7772 - auc: 0.8574 - loss: 0.4617 - val_acc: 0.7922 - val_auc: 0.8696 - val_loss: 0.4443\n",
      "Epoch 4431/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7780 - auc: 0.8577 - loss: 0.4624 - val_acc: 0.7902 - val_auc: 0.8686 - val_loss: 0.4449\n",
      "Epoch 4432/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7782 - auc: 0.8572 - loss: 0.4617 - val_acc: 0.7902 - val_auc: 0.8702 - val_loss: 0.4440\n",
      "Epoch 4433/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7775 - auc: 0.8582 - loss: 0.4613 - val_acc: 0.7927 - val_auc: 0.8691 - val_loss: 0.4429\n",
      "Epoch 4434/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7780 - auc: 0.8575 - loss: 0.4616 - val_acc: 0.7890 - val_auc: 0.8693 - val_loss: 0.4449\n",
      "Epoch 4435/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7761 - auc: 0.8569 - loss: 0.4629 - val_acc: 0.7944 - val_auc: 0.8711 - val_loss: 0.4426\n",
      "Epoch 4436/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7793 - auc: 0.8573 - loss: 0.4621 - val_acc: 0.7905 - val_auc: 0.8692 - val_loss: 0.4438\n",
      "Epoch 4437/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7779 - auc: 0.8574 - loss: 0.4609 - val_acc: 0.7915 - val_auc: 0.8688 - val_loss: 0.4429\n",
      "Epoch 4438/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7790 - auc: 0.8581 - loss: 0.4616 - val_acc: 0.7911 - val_auc: 0.8703 - val_loss: 0.4444\n",
      "Epoch 4439/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7785 - auc: 0.8580 - loss: 0.4609 - val_acc: 0.7926 - val_auc: 0.8699 - val_loss: 0.4440\n",
      "Epoch 4440/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7762 - auc: 0.8566 - loss: 0.4629 - val_acc: 0.7942 - val_auc: 0.8686 - val_loss: 0.4439\n",
      "Epoch 4441/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7784 - auc: 0.8571 - loss: 0.4632 - val_acc: 0.7929 - val_auc: 0.8705 - val_loss: 0.4418\n",
      "Epoch 4442/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7757 - auc: 0.8562 - loss: 0.4627 - val_acc: 0.7896 - val_auc: 0.8692 - val_loss: 0.4433\n",
      "Epoch 4443/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7758 - auc: 0.8561 - loss: 0.4644 - val_acc: 0.7902 - val_auc: 0.8691 - val_loss: 0.4451\n",
      "Epoch 4444/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7755 - auc: 0.8563 - loss: 0.4638 - val_acc: 0.7923 - val_auc: 0.8701 - val_loss: 0.4431\n",
      "Epoch 4445/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7765 - auc: 0.8567 - loss: 0.4628 - val_acc: 0.7902 - val_auc: 0.8697 - val_loss: 0.4442\n",
      "Epoch 4446/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7785 - auc: 0.8582 - loss: 0.4608 - val_acc: 0.7937 - val_auc: 0.8710 - val_loss: 0.4426\n",
      "Epoch 4447/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7747 - auc: 0.8561 - loss: 0.4647 - val_acc: 0.7906 - val_auc: 0.8693 - val_loss: 0.4431\n",
      "Epoch 4448/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7782 - auc: 0.8580 - loss: 0.4621 - val_acc: 0.7908 - val_auc: 0.8688 - val_loss: 0.4437\n",
      "Epoch 4449/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7761 - auc: 0.8570 - loss: 0.4632 - val_acc: 0.7908 - val_auc: 0.8698 - val_loss: 0.4448\n",
      "Epoch 4450/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7753 - auc: 0.8562 - loss: 0.4640 - val_acc: 0.7924 - val_auc: 0.8695 - val_loss: 0.4430\n",
      "Epoch 4451/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7771 - auc: 0.8568 - loss: 0.4632 - val_acc: 0.7939 - val_auc: 0.8702 - val_loss: 0.4440\n",
      "Epoch 4452/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7770 - auc: 0.8555 - loss: 0.4651 - val_acc: 0.7960 - val_auc: 0.8698 - val_loss: 0.4438\n",
      "Epoch 4453/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7770 - auc: 0.8565 - loss: 0.4636 - val_acc: 0.7910 - val_auc: 0.8687 - val_loss: 0.4439\n",
      "Epoch 4454/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7780 - auc: 0.8557 - loss: 0.4637 - val_acc: 0.7918 - val_auc: 0.8703 - val_loss: 0.4423\n",
      "Epoch 4455/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7768 - auc: 0.8565 - loss: 0.4640 - val_acc: 0.7910 - val_auc: 0.8683 - val_loss: 0.4457\n",
      "Epoch 4456/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7776 - auc: 0.8578 - loss: 0.4620 - val_acc: 0.7933 - val_auc: 0.8701 - val_loss: 0.4443\n",
      "Epoch 4457/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7760 - auc: 0.8564 - loss: 0.4631 - val_acc: 0.7940 - val_auc: 0.8700 - val_loss: 0.4425\n",
      "Epoch 4458/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7761 - auc: 0.8569 - loss: 0.4629 - val_acc: 0.7929 - val_auc: 0.8701 - val_loss: 0.4448\n",
      "Epoch 4459/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7757 - auc: 0.8568 - loss: 0.4625 - val_acc: 0.7928 - val_auc: 0.8701 - val_loss: 0.4420\n",
      "Epoch 4460/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7776 - auc: 0.8570 - loss: 0.4625 - val_acc: 0.7920 - val_auc: 0.8711 - val_loss: 0.4412\n",
      "Epoch 4461/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7785 - auc: 0.8586 - loss: 0.4602 - val_acc: 0.7925 - val_auc: 0.8700 - val_loss: 0.4407\n",
      "Epoch 4462/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7758 - auc: 0.8562 - loss: 0.4639 - val_acc: 0.7904 - val_auc: 0.8687 - val_loss: 0.4443\n",
      "Epoch 4463/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7767 - auc: 0.8566 - loss: 0.4637 - val_acc: 0.7941 - val_auc: 0.8706 - val_loss: 0.4429\n",
      "Epoch 4464/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7748 - auc: 0.8547 - loss: 0.4650 - val_acc: 0.7933 - val_auc: 0.8694 - val_loss: 0.4430\n",
      "Epoch 4465/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7775 - auc: 0.8573 - loss: 0.4626 - val_acc: 0.7912 - val_auc: 0.8700 - val_loss: 0.4418\n",
      "Epoch 4466/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7772 - auc: 0.8573 - loss: 0.4632 - val_acc: 0.7913 - val_auc: 0.8693 - val_loss: 0.4447\n",
      "Epoch 4467/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7791 - auc: 0.8572 - loss: 0.4624 - val_acc: 0.7915 - val_auc: 0.8695 - val_loss: 0.4450\n",
      "Epoch 4468/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7756 - auc: 0.8560 - loss: 0.4635 - val_acc: 0.7941 - val_auc: 0.8703 - val_loss: 0.4421\n",
      "Epoch 4469/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7767 - auc: 0.8577 - loss: 0.4613 - val_acc: 0.7928 - val_auc: 0.8684 - val_loss: 0.4436\n",
      "Epoch 4470/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7790 - auc: 0.8576 - loss: 0.4616 - val_acc: 0.7913 - val_auc: 0.8685 - val_loss: 0.4441\n",
      "Epoch 4471/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7780 - auc: 0.8579 - loss: 0.4619 - val_acc: 0.7934 - val_auc: 0.8714 - val_loss: 0.4409\n",
      "Epoch 4472/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7759 - auc: 0.8562 - loss: 0.4641 - val_acc: 0.7907 - val_auc: 0.8696 - val_loss: 0.4436\n",
      "Epoch 4473/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7773 - auc: 0.8569 - loss: 0.4625 - val_acc: 0.7918 - val_auc: 0.8690 - val_loss: 0.4432\n",
      "Epoch 4474/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7788 - auc: 0.8573 - loss: 0.4621 - val_acc: 0.7914 - val_auc: 0.8690 - val_loss: 0.4438\n",
      "Epoch 4475/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7758 - auc: 0.8554 - loss: 0.4650 - val_acc: 0.7942 - val_auc: 0.8704 - val_loss: 0.4408\n",
      "Epoch 4476/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7754 - auc: 0.8555 - loss: 0.4642 - val_acc: 0.7901 - val_auc: 0.8682 - val_loss: 0.4433\n",
      "Epoch 4477/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7778 - auc: 0.8564 - loss: 0.4634 - val_acc: 0.7913 - val_auc: 0.8694 - val_loss: 0.4450\n",
      "Epoch 4478/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7753 - auc: 0.8560 - loss: 0.4636 - val_acc: 0.7900 - val_auc: 0.8690 - val_loss: 0.4452\n",
      "Epoch 4479/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7768 - auc: 0.8563 - loss: 0.4633 - val_acc: 0.7907 - val_auc: 0.8695 - val_loss: 0.4438\n",
      "Epoch 4480/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7747 - auc: 0.8556 - loss: 0.4642 - val_acc: 0.7927 - val_auc: 0.8690 - val_loss: 0.4435\n",
      "Epoch 4481/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7782 - auc: 0.8564 - loss: 0.4625 - val_acc: 0.7929 - val_auc: 0.8681 - val_loss: 0.4444\n",
      "Epoch 4482/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7770 - auc: 0.8559 - loss: 0.4644 - val_acc: 0.7918 - val_auc: 0.8685 - val_loss: 0.4449\n",
      "Epoch 4483/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7767 - auc: 0.8564 - loss: 0.4630 - val_acc: 0.7907 - val_auc: 0.8693 - val_loss: 0.4437\n",
      "Epoch 4484/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7768 - auc: 0.8559 - loss: 0.4642 - val_acc: 0.7909 - val_auc: 0.8704 - val_loss: 0.4439\n",
      "Epoch 4485/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7788 - auc: 0.8585 - loss: 0.4613 - val_acc: 0.7926 - val_auc: 0.8693 - val_loss: 0.4436\n",
      "Epoch 4486/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7772 - auc: 0.8566 - loss: 0.4627 - val_acc: 0.7914 - val_auc: 0.8693 - val_loss: 0.4432\n",
      "Epoch 4487/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7763 - auc: 0.8567 - loss: 0.4637 - val_acc: 0.7952 - val_auc: 0.8719 - val_loss: 0.4417\n",
      "Epoch 4488/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7774 - auc: 0.8566 - loss: 0.4635 - val_acc: 0.7919 - val_auc: 0.8697 - val_loss: 0.4437\n",
      "Epoch 4489/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7793 - auc: 0.8579 - loss: 0.4618 - val_acc: 0.7931 - val_auc: 0.8697 - val_loss: 0.4424\n",
      "Epoch 4490/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7783 - auc: 0.8562 - loss: 0.4640 - val_acc: 0.7884 - val_auc: 0.8682 - val_loss: 0.4461\n",
      "Epoch 4491/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7783 - auc: 0.8572 - loss: 0.4618 - val_acc: 0.7895 - val_auc: 0.8688 - val_loss: 0.4437\n",
      "Epoch 4492/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7778 - auc: 0.8566 - loss: 0.4631 - val_acc: 0.7902 - val_auc: 0.8696 - val_loss: 0.4430\n",
      "Epoch 4493/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7756 - auc: 0.8569 - loss: 0.4620 - val_acc: 0.7925 - val_auc: 0.8684 - val_loss: 0.4438\n",
      "Epoch 4494/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7763 - auc: 0.8562 - loss: 0.4632 - val_acc: 0.7901 - val_auc: 0.8697 - val_loss: 0.4444\n",
      "Epoch 4495/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7789 - auc: 0.8580 - loss: 0.4603 - val_acc: 0.7918 - val_auc: 0.8690 - val_loss: 0.4431\n",
      "Epoch 4496/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7775 - auc: 0.8566 - loss: 0.4638 - val_acc: 0.7948 - val_auc: 0.8694 - val_loss: 0.4420\n",
      "Epoch 4497/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7790 - auc: 0.8574 - loss: 0.4627 - val_acc: 0.7923 - val_auc: 0.8692 - val_loss: 0.4438\n",
      "Epoch 4498/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7790 - auc: 0.8571 - loss: 0.4629 - val_acc: 0.7905 - val_auc: 0.8683 - val_loss: 0.4439\n",
      "Epoch 4499/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7779 - auc: 0.8581 - loss: 0.4593 - val_acc: 0.7941 - val_auc: 0.8708 - val_loss: 0.4414\n",
      "Epoch 4500/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7768 - auc: 0.8562 - loss: 0.4639 - val_acc: 0.7951 - val_auc: 0.8696 - val_loss: 0.4423\n",
      "Epoch 4501/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7790 - auc: 0.8580 - loss: 0.4606 - val_acc: 0.7932 - val_auc: 0.8689 - val_loss: 0.4430\n",
      "Epoch 4502/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7769 - auc: 0.8570 - loss: 0.4625 - val_acc: 0.7906 - val_auc: 0.8700 - val_loss: 0.4444\n",
      "Epoch 4503/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7765 - auc: 0.8553 - loss: 0.4648 - val_acc: 0.7915 - val_auc: 0.8695 - val_loss: 0.4420\n",
      "Epoch 4504/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7785 - auc: 0.8568 - loss: 0.4634 - val_acc: 0.7930 - val_auc: 0.8710 - val_loss: 0.4405\n",
      "Epoch 4505/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7777 - auc: 0.8571 - loss: 0.4624 - val_acc: 0.7932 - val_auc: 0.8706 - val_loss: 0.4435\n",
      "Epoch 4506/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7787 - auc: 0.8570 - loss: 0.4627 - val_acc: 0.7927 - val_auc: 0.8695 - val_loss: 0.4425\n",
      "Epoch 4507/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7769 - auc: 0.8582 - loss: 0.4606 - val_acc: 0.7920 - val_auc: 0.8708 - val_loss: 0.4413\n",
      "Epoch 4508/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7751 - auc: 0.8560 - loss: 0.4647 - val_acc: 0.7900 - val_auc: 0.8705 - val_loss: 0.4445\n",
      "Epoch 4509/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7775 - auc: 0.8562 - loss: 0.4630 - val_acc: 0.7933 - val_auc: 0.8697 - val_loss: 0.4437\n",
      "Epoch 4510/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7780 - auc: 0.8572 - loss: 0.4626 - val_acc: 0.7884 - val_auc: 0.8691 - val_loss: 0.4440\n",
      "Epoch 4511/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7773 - auc: 0.8575 - loss: 0.4613 - val_acc: 0.7898 - val_auc: 0.8701 - val_loss: 0.4422\n",
      "Epoch 4512/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7763 - auc: 0.8561 - loss: 0.4639 - val_acc: 0.7915 - val_auc: 0.8684 - val_loss: 0.4440\n",
      "Epoch 4513/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7787 - auc: 0.8573 - loss: 0.4618 - val_acc: 0.7879 - val_auc: 0.8691 - val_loss: 0.4429\n",
      "Epoch 4514/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7792 - auc: 0.8582 - loss: 0.4605 - val_acc: 0.7897 - val_auc: 0.8690 - val_loss: 0.4436\n",
      "Epoch 4515/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7790 - auc: 0.8584 - loss: 0.4612 - val_acc: 0.7926 - val_auc: 0.8700 - val_loss: 0.4431\n",
      "Epoch 4516/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7777 - auc: 0.8574 - loss: 0.4614 - val_acc: 0.7926 - val_auc: 0.8701 - val_loss: 0.4409\n",
      "Epoch 4517/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7773 - auc: 0.8567 - loss: 0.4632 - val_acc: 0.7919 - val_auc: 0.8693 - val_loss: 0.4448\n",
      "Epoch 4518/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7789 - auc: 0.8575 - loss: 0.4619 - val_acc: 0.7927 - val_auc: 0.8698 - val_loss: 0.4427\n",
      "Epoch 4519/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7763 - auc: 0.8569 - loss: 0.4630 - val_acc: 0.7920 - val_auc: 0.8690 - val_loss: 0.4428\n",
      "Epoch 4520/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7792 - auc: 0.8570 - loss: 0.4627 - val_acc: 0.7941 - val_auc: 0.8704 - val_loss: 0.4427\n",
      "Epoch 4521/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7780 - auc: 0.8574 - loss: 0.4633 - val_acc: 0.7890 - val_auc: 0.8684 - val_loss: 0.4455\n",
      "Epoch 4522/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7785 - auc: 0.8572 - loss: 0.4624 - val_acc: 0.7924 - val_auc: 0.8696 - val_loss: 0.4424\n",
      "Epoch 4523/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7771 - auc: 0.8562 - loss: 0.4642 - val_acc: 0.7929 - val_auc: 0.8712 - val_loss: 0.4418\n",
      "Epoch 4524/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7764 - auc: 0.8554 - loss: 0.4645 - val_acc: 0.7931 - val_auc: 0.8710 - val_loss: 0.4410\n",
      "Epoch 4525/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7803 - auc: 0.8582 - loss: 0.4608 - val_acc: 0.7896 - val_auc: 0.8698 - val_loss: 0.4435\n",
      "Epoch 4526/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7767 - auc: 0.8567 - loss: 0.4636 - val_acc: 0.7887 - val_auc: 0.8683 - val_loss: 0.4448\n",
      "Epoch 4527/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7791 - auc: 0.8576 - loss: 0.4618 - val_acc: 0.7912 - val_auc: 0.8702 - val_loss: 0.4445\n",
      "Epoch 4528/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7770 - auc: 0.8571 - loss: 0.4633 - val_acc: 0.7914 - val_auc: 0.8698 - val_loss: 0.4423\n",
      "Epoch 4529/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7790 - auc: 0.8584 - loss: 0.4603 - val_acc: 0.7906 - val_auc: 0.8689 - val_loss: 0.4446\n",
      "Epoch 4530/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7775 - auc: 0.8580 - loss: 0.4619 - val_acc: 0.7922 - val_auc: 0.8697 - val_loss: 0.4430\n",
      "Epoch 4531/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7752 - auc: 0.8570 - loss: 0.4631 - val_acc: 0.7952 - val_auc: 0.8698 - val_loss: 0.4424\n",
      "Epoch 4532/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7758 - auc: 0.8557 - loss: 0.4650 - val_acc: 0.7927 - val_auc: 0.8713 - val_loss: 0.4420\n",
      "Epoch 4533/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8583 - loss: 0.4616 - val_acc: 0.7882 - val_auc: 0.8680 - val_loss: 0.4464\n",
      "Epoch 4534/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7759 - auc: 0.8562 - loss: 0.4645 - val_acc: 0.7916 - val_auc: 0.8710 - val_loss: 0.4433\n",
      "Epoch 4535/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7758 - auc: 0.8566 - loss: 0.4630 - val_acc: 0.7934 - val_auc: 0.8702 - val_loss: 0.4425\n",
      "Epoch 4536/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7790 - auc: 0.8584 - loss: 0.4600 - val_acc: 0.7922 - val_auc: 0.8699 - val_loss: 0.4420\n",
      "Epoch 4537/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7771 - auc: 0.8563 - loss: 0.4630 - val_acc: 0.7911 - val_auc: 0.8683 - val_loss: 0.4429\n",
      "Epoch 4538/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7780 - auc: 0.8584 - loss: 0.4599 - val_acc: 0.7902 - val_auc: 0.8682 - val_loss: 0.4440\n",
      "Epoch 4539/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7810 - auc: 0.8590 - loss: 0.4597 - val_acc: 0.7926 - val_auc: 0.8709 - val_loss: 0.4408\n",
      "Epoch 4540/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7771 - auc: 0.8573 - loss: 0.4623 - val_acc: 0.7910 - val_auc: 0.8692 - val_loss: 0.4439\n",
      "Epoch 4541/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7775 - auc: 0.8571 - loss: 0.4626 - val_acc: 0.7939 - val_auc: 0.8710 - val_loss: 0.4398\n",
      "Epoch 4542/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7776 - auc: 0.8578 - loss: 0.4619 - val_acc: 0.7922 - val_auc: 0.8704 - val_loss: 0.4423\n",
      "Epoch 4543/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7770 - auc: 0.8560 - loss: 0.4629 - val_acc: 0.7895 - val_auc: 0.8696 - val_loss: 0.4428\n",
      "Epoch 4544/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7795 - auc: 0.8585 - loss: 0.4598 - val_acc: 0.7927 - val_auc: 0.8698 - val_loss: 0.4429\n",
      "Epoch 4545/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7783 - auc: 0.8571 - loss: 0.4632 - val_acc: 0.7917 - val_auc: 0.8707 - val_loss: 0.4424\n",
      "Epoch 4546/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7765 - auc: 0.8574 - loss: 0.4622 - val_acc: 0.7922 - val_auc: 0.8697 - val_loss: 0.4433\n",
      "Epoch 4547/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7783 - auc: 0.8574 - loss: 0.4620 - val_acc: 0.7913 - val_auc: 0.8696 - val_loss: 0.4436\n",
      "Epoch 4548/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7775 - auc: 0.8554 - loss: 0.4653 - val_acc: 0.7917 - val_auc: 0.8698 - val_loss: 0.4431\n",
      "Epoch 4549/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7796 - auc: 0.8578 - loss: 0.4611 - val_acc: 0.7925 - val_auc: 0.8694 - val_loss: 0.4426\n",
      "Epoch 4550/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7778 - auc: 0.8568 - loss: 0.4622 - val_acc: 0.7905 - val_auc: 0.8692 - val_loss: 0.4437\n",
      "Epoch 4551/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7773 - auc: 0.8564 - loss: 0.4644 - val_acc: 0.7915 - val_auc: 0.8698 - val_loss: 0.4442\n",
      "Epoch 4552/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7773 - auc: 0.8565 - loss: 0.4633 - val_acc: 0.7902 - val_auc: 0.8695 - val_loss: 0.4434\n",
      "Epoch 4553/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7777 - auc: 0.8564 - loss: 0.4633 - val_acc: 0.7931 - val_auc: 0.8694 - val_loss: 0.4438\n",
      "Epoch 4554/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7783 - auc: 0.8581 - loss: 0.4613 - val_acc: 0.7932 - val_auc: 0.8704 - val_loss: 0.4417\n",
      "Epoch 4555/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7780 - auc: 0.8577 - loss: 0.4618 - val_acc: 0.7933 - val_auc: 0.8698 - val_loss: 0.4412\n",
      "Epoch 4556/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7773 - auc: 0.8571 - loss: 0.4623 - val_acc: 0.7898 - val_auc: 0.8691 - val_loss: 0.4450\n",
      "Epoch 4557/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7775 - auc: 0.8580 - loss: 0.4612 - val_acc: 0.7921 - val_auc: 0.8708 - val_loss: 0.4428\n",
      "Epoch 4558/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7769 - auc: 0.8579 - loss: 0.4612 - val_acc: 0.7905 - val_auc: 0.8700 - val_loss: 0.4420\n",
      "Epoch 4559/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7805 - auc: 0.8596 - loss: 0.4585 - val_acc: 0.7919 - val_auc: 0.8686 - val_loss: 0.4441\n",
      "Epoch 4560/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7787 - auc: 0.8585 - loss: 0.4595 - val_acc: 0.7915 - val_auc: 0.8696 - val_loss: 0.4415\n",
      "Epoch 4561/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7762 - auc: 0.8572 - loss: 0.4633 - val_acc: 0.7904 - val_auc: 0.8685 - val_loss: 0.4450\n",
      "Epoch 4562/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7758 - auc: 0.8563 - loss: 0.4637 - val_acc: 0.7893 - val_auc: 0.8683 - val_loss: 0.4451\n",
      "Epoch 4563/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7777 - auc: 0.8571 - loss: 0.4620 - val_acc: 0.7928 - val_auc: 0.8702 - val_loss: 0.4439\n",
      "Epoch 4564/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7781 - auc: 0.8564 - loss: 0.4636 - val_acc: 0.7925 - val_auc: 0.8704 - val_loss: 0.4426\n",
      "Epoch 4565/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7789 - auc: 0.8599 - loss: 0.4582 - val_acc: 0.7911 - val_auc: 0.8700 - val_loss: 0.4419\n",
      "Epoch 4566/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7770 - auc: 0.8575 - loss: 0.4616 - val_acc: 0.7941 - val_auc: 0.8706 - val_loss: 0.4414\n",
      "Epoch 4567/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7796 - auc: 0.8578 - loss: 0.4616 - val_acc: 0.7881 - val_auc: 0.8692 - val_loss: 0.4439\n",
      "Epoch 4568/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7764 - auc: 0.8569 - loss: 0.4623 - val_acc: 0.7924 - val_auc: 0.8706 - val_loss: 0.4421\n",
      "Epoch 4569/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7790 - auc: 0.8583 - loss: 0.4606 - val_acc: 0.7939 - val_auc: 0.8702 - val_loss: 0.4429\n",
      "Epoch 4570/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7788 - auc: 0.8576 - loss: 0.4603 - val_acc: 0.7939 - val_auc: 0.8708 - val_loss: 0.4410\n",
      "Epoch 4571/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7763 - auc: 0.8571 - loss: 0.4631 - val_acc: 0.7897 - val_auc: 0.8704 - val_loss: 0.4426\n",
      "Epoch 4572/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7768 - auc: 0.8562 - loss: 0.4636 - val_acc: 0.7921 - val_auc: 0.8697 - val_loss: 0.4421\n",
      "Epoch 4573/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7759 - auc: 0.8557 - loss: 0.4652 - val_acc: 0.7900 - val_auc: 0.8689 - val_loss: 0.4447\n",
      "Epoch 4574/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7795 - auc: 0.8580 - loss: 0.4612 - val_acc: 0.7910 - val_auc: 0.8697 - val_loss: 0.4438\n",
      "Epoch 4575/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7781 - auc: 0.8584 - loss: 0.4610 - val_acc: 0.7926 - val_auc: 0.8703 - val_loss: 0.4420\n",
      "Epoch 4576/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7788 - auc: 0.8584 - loss: 0.4608 - val_acc: 0.7906 - val_auc: 0.8687 - val_loss: 0.4439\n",
      "Epoch 4577/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7776 - auc: 0.8573 - loss: 0.4621 - val_acc: 0.7944 - val_auc: 0.8703 - val_loss: 0.4415\n",
      "Epoch 4578/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7773 - auc: 0.8570 - loss: 0.4639 - val_acc: 0.7894 - val_auc: 0.8693 - val_loss: 0.4440\n",
      "Epoch 4579/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7781 - auc: 0.8568 - loss: 0.4629 - val_acc: 0.7895 - val_auc: 0.8695 - val_loss: 0.4430\n",
      "Epoch 4580/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7779 - auc: 0.8563 - loss: 0.4636 - val_acc: 0.7914 - val_auc: 0.8698 - val_loss: 0.4430\n",
      "Epoch 4581/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7783 - auc: 0.8582 - loss: 0.4607 - val_acc: 0.7908 - val_auc: 0.8696 - val_loss: 0.4430\n",
      "Epoch 4582/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7778 - auc: 0.8571 - loss: 0.4631 - val_acc: 0.7925 - val_auc: 0.8706 - val_loss: 0.4410\n",
      "Epoch 4583/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7755 - auc: 0.8551 - loss: 0.4656 - val_acc: 0.7905 - val_auc: 0.8691 - val_loss: 0.4444\n",
      "Epoch 4584/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7785 - auc: 0.8577 - loss: 0.4611 - val_acc: 0.7939 - val_auc: 0.8702 - val_loss: 0.4417\n",
      "Epoch 4585/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7781 - auc: 0.8576 - loss: 0.4617 - val_acc: 0.7915 - val_auc: 0.8689 - val_loss: 0.4439\n",
      "Epoch 4586/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7784 - auc: 0.8577 - loss: 0.4619 - val_acc: 0.7947 - val_auc: 0.8709 - val_loss: 0.4443\n",
      "Epoch 4587/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7801 - auc: 0.8591 - loss: 0.4601 - val_acc: 0.7904 - val_auc: 0.8693 - val_loss: 0.4436\n",
      "Epoch 4588/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7787 - auc: 0.8586 - loss: 0.4612 - val_acc: 0.7916 - val_auc: 0.8702 - val_loss: 0.4432\n",
      "Epoch 4589/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7785 - auc: 0.8583 - loss: 0.4614 - val_acc: 0.7898 - val_auc: 0.8689 - val_loss: 0.4442\n",
      "Epoch 4590/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7774 - auc: 0.8567 - loss: 0.4632 - val_acc: 0.7906 - val_auc: 0.8688 - val_loss: 0.4438\n",
      "Epoch 4591/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7755 - auc: 0.8569 - loss: 0.4635 - val_acc: 0.7886 - val_auc: 0.8686 - val_loss: 0.4450\n",
      "Epoch 4592/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7771 - auc: 0.8557 - loss: 0.4638 - val_acc: 0.7919 - val_auc: 0.8707 - val_loss: 0.4413\n",
      "Epoch 4593/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7770 - auc: 0.8573 - loss: 0.4626 - val_acc: 0.7923 - val_auc: 0.8684 - val_loss: 0.4440\n",
      "Epoch 4594/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7781 - auc: 0.8571 - loss: 0.4625 - val_acc: 0.7914 - val_auc: 0.8695 - val_loss: 0.4436\n",
      "Epoch 4595/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7785 - auc: 0.8577 - loss: 0.4616 - val_acc: 0.7932 - val_auc: 0.8704 - val_loss: 0.4408\n",
      "Epoch 4596/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7774 - auc: 0.8577 - loss: 0.4621 - val_acc: 0.7928 - val_auc: 0.8697 - val_loss: 0.4427\n",
      "Epoch 4597/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7775 - auc: 0.8561 - loss: 0.4640 - val_acc: 0.7874 - val_auc: 0.8691 - val_loss: 0.4447\n",
      "Epoch 4598/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7792 - auc: 0.8579 - loss: 0.4617 - val_acc: 0.7927 - val_auc: 0.8710 - val_loss: 0.4432\n",
      "Epoch 4599/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7791 - auc: 0.8579 - loss: 0.4617 - val_acc: 0.7911 - val_auc: 0.8701 - val_loss: 0.4414\n",
      "Epoch 4600/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7777 - auc: 0.8563 - loss: 0.4631 - val_acc: 0.7904 - val_auc: 0.8686 - val_loss: 0.4437\n",
      "Epoch 4601/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7773 - auc: 0.8567 - loss: 0.4633 - val_acc: 0.7915 - val_auc: 0.8698 - val_loss: 0.4437\n",
      "Epoch 4602/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7794 - auc: 0.8587 - loss: 0.4593 - val_acc: 0.7877 - val_auc: 0.8692 - val_loss: 0.4442\n",
      "Epoch 4603/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7758 - auc: 0.8560 - loss: 0.4646 - val_acc: 0.7910 - val_auc: 0.8694 - val_loss: 0.4433\n",
      "Epoch 4604/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7778 - auc: 0.8575 - loss: 0.4616 - val_acc: 0.7919 - val_auc: 0.8704 - val_loss: 0.4431\n",
      "Epoch 4605/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7787 - auc: 0.8575 - loss: 0.4617 - val_acc: 0.7920 - val_auc: 0.8698 - val_loss: 0.4433\n",
      "Epoch 4606/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7769 - auc: 0.8577 - loss: 0.4612 - val_acc: 0.7891 - val_auc: 0.8695 - val_loss: 0.4433\n",
      "Epoch 4607/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7779 - auc: 0.8564 - loss: 0.4638 - val_acc: 0.7911 - val_auc: 0.8695 - val_loss: 0.4440\n",
      "Epoch 4608/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7787 - auc: 0.8582 - loss: 0.4616 - val_acc: 0.7923 - val_auc: 0.8704 - val_loss: 0.4431\n",
      "Epoch 4609/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7762 - auc: 0.8570 - loss: 0.4622 - val_acc: 0.7926 - val_auc: 0.8704 - val_loss: 0.4424\n",
      "Epoch 4610/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7792 - auc: 0.8585 - loss: 0.4600 - val_acc: 0.7910 - val_auc: 0.8699 - val_loss: 0.4412\n",
      "Epoch 4611/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7776 - auc: 0.8565 - loss: 0.4625 - val_acc: 0.7924 - val_auc: 0.8703 - val_loss: 0.4430\n",
      "Epoch 4612/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7763 - auc: 0.8574 - loss: 0.4632 - val_acc: 0.7909 - val_auc: 0.8695 - val_loss: 0.4444\n",
      "Epoch 4613/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7784 - auc: 0.8584 - loss: 0.4601 - val_acc: 0.7928 - val_auc: 0.8700 - val_loss: 0.4419\n",
      "Epoch 4614/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7781 - auc: 0.8577 - loss: 0.4618 - val_acc: 0.7919 - val_auc: 0.8702 - val_loss: 0.4431\n",
      "Epoch 4615/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7776 - auc: 0.8583 - loss: 0.4621 - val_acc: 0.7901 - val_auc: 0.8693 - val_loss: 0.4440\n",
      "Epoch 4616/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7788 - auc: 0.8586 - loss: 0.4604 - val_acc: 0.7929 - val_auc: 0.8690 - val_loss: 0.4434\n",
      "Epoch 4617/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7774 - auc: 0.8579 - loss: 0.4617 - val_acc: 0.7939 - val_auc: 0.8709 - val_loss: 0.4413\n",
      "Epoch 4618/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7762 - auc: 0.8576 - loss: 0.4619 - val_acc: 0.7887 - val_auc: 0.8694 - val_loss: 0.4456\n",
      "Epoch 4619/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7790 - auc: 0.8581 - loss: 0.4614 - val_acc: 0.7917 - val_auc: 0.8701 - val_loss: 0.4432\n",
      "Epoch 4620/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7791 - auc: 0.8581 - loss: 0.4604 - val_acc: 0.7902 - val_auc: 0.8700 - val_loss: 0.4425\n",
      "Epoch 4621/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7816 - auc: 0.8592 - loss: 0.4587 - val_acc: 0.7926 - val_auc: 0.8698 - val_loss: 0.4430\n",
      "Epoch 4622/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7799 - auc: 0.8575 - loss: 0.4612 - val_acc: 0.7925 - val_auc: 0.8690 - val_loss: 0.4441\n",
      "Epoch 4623/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7773 - auc: 0.8574 - loss: 0.4621 - val_acc: 0.7913 - val_auc: 0.8705 - val_loss: 0.4416\n",
      "Epoch 4624/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7782 - auc: 0.8573 - loss: 0.4618 - val_acc: 0.7935 - val_auc: 0.8702 - val_loss: 0.4421\n",
      "Epoch 4625/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7768 - auc: 0.8568 - loss: 0.4632 - val_acc: 0.7918 - val_auc: 0.8706 - val_loss: 0.4429\n",
      "Epoch 4626/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7783 - auc: 0.8571 - loss: 0.4621 - val_acc: 0.7922 - val_auc: 0.8702 - val_loss: 0.4412\n",
      "Epoch 4627/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7778 - auc: 0.8584 - loss: 0.4611 - val_acc: 0.7906 - val_auc: 0.8718 - val_loss: 0.4423\n",
      "Epoch 4628/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7784 - auc: 0.8582 - loss: 0.4612 - val_acc: 0.7946 - val_auc: 0.8712 - val_loss: 0.4412\n",
      "Epoch 4629/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7787 - auc: 0.8582 - loss: 0.4610 - val_acc: 0.7915 - val_auc: 0.8699 - val_loss: 0.4434\n",
      "Epoch 4630/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7751 - auc: 0.8565 - loss: 0.4630 - val_acc: 0.7932 - val_auc: 0.8710 - val_loss: 0.4423\n",
      "Epoch 4631/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7772 - auc: 0.8570 - loss: 0.4627 - val_acc: 0.7916 - val_auc: 0.8705 - val_loss: 0.4423\n",
      "Epoch 4632/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7794 - auc: 0.8577 - loss: 0.4605 - val_acc: 0.7904 - val_auc: 0.8700 - val_loss: 0.4435\n",
      "Epoch 4633/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7780 - auc: 0.8574 - loss: 0.4623 - val_acc: 0.7904 - val_auc: 0.8713 - val_loss: 0.4419\n",
      "Epoch 4634/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7778 - auc: 0.8584 - loss: 0.4609 - val_acc: 0.7914 - val_auc: 0.8704 - val_loss: 0.4427\n",
      "Epoch 4635/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7745 - auc: 0.8552 - loss: 0.4647 - val_acc: 0.7949 - val_auc: 0.8712 - val_loss: 0.4410\n",
      "Epoch 4636/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7782 - auc: 0.8584 - loss: 0.4609 - val_acc: 0.7933 - val_auc: 0.8699 - val_loss: 0.4440\n",
      "Epoch 4637/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7775 - auc: 0.8563 - loss: 0.4627 - val_acc: 0.7946 - val_auc: 0.8711 - val_loss: 0.4410\n",
      "Epoch 4638/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7785 - auc: 0.8584 - loss: 0.4609 - val_acc: 0.7933 - val_auc: 0.8692 - val_loss: 0.4433\n",
      "Epoch 4639/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7802 - auc: 0.8593 - loss: 0.4593 - val_acc: 0.7939 - val_auc: 0.8706 - val_loss: 0.4423\n",
      "Epoch 4640/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7779 - auc: 0.8572 - loss: 0.4628 - val_acc: 0.7927 - val_auc: 0.8703 - val_loss: 0.4428\n",
      "Epoch 4641/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7784 - auc: 0.8576 - loss: 0.4630 - val_acc: 0.7940 - val_auc: 0.8710 - val_loss: 0.4408\n",
      "Epoch 4642/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7776 - auc: 0.8581 - loss: 0.4604 - val_acc: 0.7930 - val_auc: 0.8703 - val_loss: 0.4404\n",
      "Epoch 4643/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7767 - auc: 0.8561 - loss: 0.4641 - val_acc: 0.7919 - val_auc: 0.8688 - val_loss: 0.4434\n",
      "Epoch 4644/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7775 - auc: 0.8574 - loss: 0.4626 - val_acc: 0.7919 - val_auc: 0.8691 - val_loss: 0.4437\n",
      "Epoch 4645/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7791 - auc: 0.8581 - loss: 0.4606 - val_acc: 0.7915 - val_auc: 0.8711 - val_loss: 0.4416\n",
      "Epoch 4646/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7789 - auc: 0.8578 - loss: 0.4614 - val_acc: 0.7932 - val_auc: 0.8708 - val_loss: 0.4432\n",
      "Epoch 4647/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7777 - auc: 0.8572 - loss: 0.4621 - val_acc: 0.7930 - val_auc: 0.8707 - val_loss: 0.4411\n",
      "Epoch 4648/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7769 - auc: 0.8571 - loss: 0.4627 - val_acc: 0.7927 - val_auc: 0.8714 - val_loss: 0.4399\n",
      "Epoch 4649/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7801 - auc: 0.8589 - loss: 0.4592 - val_acc: 0.7926 - val_auc: 0.8700 - val_loss: 0.4407\n",
      "Epoch 4650/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7771 - auc: 0.8563 - loss: 0.4635 - val_acc: 0.7888 - val_auc: 0.8695 - val_loss: 0.4456\n",
      "Epoch 4651/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7758 - auc: 0.8563 - loss: 0.4632 - val_acc: 0.7939 - val_auc: 0.8712 - val_loss: 0.4414\n",
      "Epoch 4652/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7782 - auc: 0.8570 - loss: 0.4634 - val_acc: 0.7928 - val_auc: 0.8705 - val_loss: 0.4426\n",
      "Epoch 4653/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7791 - auc: 0.8573 - loss: 0.4621 - val_acc: 0.7930 - val_auc: 0.8704 - val_loss: 0.4424\n",
      "Epoch 4654/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7800 - auc: 0.8576 - loss: 0.4610 - val_acc: 0.7912 - val_auc: 0.8704 - val_loss: 0.4418\n",
      "Epoch 4655/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7760 - auc: 0.8565 - loss: 0.4630 - val_acc: 0.7916 - val_auc: 0.8695 - val_loss: 0.4441\n",
      "Epoch 4656/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7781 - auc: 0.8574 - loss: 0.4617 - val_acc: 0.7939 - val_auc: 0.8711 - val_loss: 0.4399\n",
      "Epoch 4657/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7759 - auc: 0.8563 - loss: 0.4635 - val_acc: 0.7917 - val_auc: 0.8699 - val_loss: 0.4446\n",
      "Epoch 4658/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7791 - auc: 0.8582 - loss: 0.4610 - val_acc: 0.7900 - val_auc: 0.8699 - val_loss: 0.4429\n",
      "Epoch 4659/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7785 - auc: 0.8572 - loss: 0.4615 - val_acc: 0.7909 - val_auc: 0.8690 - val_loss: 0.4452\n",
      "Epoch 4660/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7769 - auc: 0.8566 - loss: 0.4632 - val_acc: 0.7911 - val_auc: 0.8694 - val_loss: 0.4436\n",
      "Epoch 4661/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7805 - auc: 0.8597 - loss: 0.4597 - val_acc: 0.7913 - val_auc: 0.8691 - val_loss: 0.4438\n",
      "Epoch 4662/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7792 - auc: 0.8565 - loss: 0.4635 - val_acc: 0.7936 - val_auc: 0.8714 - val_loss: 0.4400\n",
      "Epoch 4663/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7767 - auc: 0.8558 - loss: 0.4649 - val_acc: 0.7928 - val_auc: 0.8693 - val_loss: 0.4423\n",
      "Epoch 4664/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7761 - auc: 0.8584 - loss: 0.4603 - val_acc: 0.7932 - val_auc: 0.8707 - val_loss: 0.4418\n",
      "Epoch 4665/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7797 - auc: 0.8575 - loss: 0.4611 - val_acc: 0.7924 - val_auc: 0.8707 - val_loss: 0.4441\n",
      "Epoch 4666/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7764 - auc: 0.8577 - loss: 0.4612 - val_acc: 0.7932 - val_auc: 0.8694 - val_loss: 0.4435\n",
      "Epoch 4667/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7799 - auc: 0.8601 - loss: 0.4582 - val_acc: 0.7907 - val_auc: 0.8697 - val_loss: 0.4450\n",
      "Epoch 4668/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7787 - auc: 0.8569 - loss: 0.4634 - val_acc: 0.7920 - val_auc: 0.8704 - val_loss: 0.4423\n",
      "Epoch 4669/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7793 - auc: 0.8578 - loss: 0.4611 - val_acc: 0.7925 - val_auc: 0.8696 - val_loss: 0.4434\n",
      "Epoch 4670/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7772 - auc: 0.8561 - loss: 0.4636 - val_acc: 0.7935 - val_auc: 0.8706 - val_loss: 0.4437\n",
      "Epoch 4671/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7768 - auc: 0.8569 - loss: 0.4629 - val_acc: 0.7932 - val_auc: 0.8708 - val_loss: 0.4422\n",
      "Epoch 4672/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7767 - auc: 0.8573 - loss: 0.4619 - val_acc: 0.7945 - val_auc: 0.8712 - val_loss: 0.4423\n",
      "Epoch 4673/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7790 - auc: 0.8576 - loss: 0.4617 - val_acc: 0.7927 - val_auc: 0.8705 - val_loss: 0.4437\n",
      "Epoch 4674/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7757 - auc: 0.8571 - loss: 0.4618 - val_acc: 0.7909 - val_auc: 0.8696 - val_loss: 0.4426\n",
      "Epoch 4675/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7784 - auc: 0.8587 - loss: 0.4605 - val_acc: 0.7905 - val_auc: 0.8697 - val_loss: 0.4441\n",
      "Epoch 4676/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7788 - auc: 0.8576 - loss: 0.4629 - val_acc: 0.7905 - val_auc: 0.8694 - val_loss: 0.4436\n",
      "Epoch 4677/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7763 - auc: 0.8562 - loss: 0.4642 - val_acc: 0.7925 - val_auc: 0.8697 - val_loss: 0.4441\n",
      "Epoch 4678/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7790 - auc: 0.8589 - loss: 0.4598 - val_acc: 0.7878 - val_auc: 0.8693 - val_loss: 0.4467\n",
      "Epoch 4679/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7774 - auc: 0.8587 - loss: 0.4594 - val_acc: 0.7905 - val_auc: 0.8673 - val_loss: 0.4440\n",
      "Epoch 4680/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7788 - auc: 0.8575 - loss: 0.4626 - val_acc: 0.7950 - val_auc: 0.8704 - val_loss: 0.4410\n",
      "Epoch 4681/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7771 - auc: 0.8566 - loss: 0.4621 - val_acc: 0.7929 - val_auc: 0.8704 - val_loss: 0.4418\n",
      "Epoch 4682/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7795 - auc: 0.8577 - loss: 0.4611 - val_acc: 0.7923 - val_auc: 0.8707 - val_loss: 0.4424\n",
      "Epoch 4683/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7774 - auc: 0.8570 - loss: 0.4624 - val_acc: 0.7911 - val_auc: 0.8700 - val_loss: 0.4437\n",
      "Epoch 4684/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7767 - auc: 0.8565 - loss: 0.4633 - val_acc: 0.7927 - val_auc: 0.8710 - val_loss: 0.4437\n",
      "Epoch 4685/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7748 - auc: 0.8572 - loss: 0.4625 - val_acc: 0.7910 - val_auc: 0.8688 - val_loss: 0.4436\n",
      "Epoch 4686/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7802 - auc: 0.8589 - loss: 0.4604 - val_acc: 0.7932 - val_auc: 0.8704 - val_loss: 0.4423\n",
      "Epoch 4687/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7787 - auc: 0.8588 - loss: 0.4603 - val_acc: 0.7913 - val_auc: 0.8699 - val_loss: 0.4410\n",
      "Epoch 4688/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7783 - auc: 0.8580 - loss: 0.4608 - val_acc: 0.7922 - val_auc: 0.8701 - val_loss: 0.4427\n",
      "Epoch 4689/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7799 - auc: 0.8582 - loss: 0.4605 - val_acc: 0.7929 - val_auc: 0.8704 - val_loss: 0.4425\n",
      "Epoch 4690/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7757 - auc: 0.8568 - loss: 0.4627 - val_acc: 0.7900 - val_auc: 0.8697 - val_loss: 0.4452\n",
      "Epoch 4691/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7787 - auc: 0.8590 - loss: 0.4596 - val_acc: 0.7906 - val_auc: 0.8706 - val_loss: 0.4436\n",
      "Epoch 4692/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7770 - auc: 0.8573 - loss: 0.4622 - val_acc: 0.7905 - val_auc: 0.8680 - val_loss: 0.4429\n",
      "Epoch 4693/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7789 - auc: 0.8588 - loss: 0.4586 - val_acc: 0.7908 - val_auc: 0.8691 - val_loss: 0.4450\n",
      "Epoch 4694/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7782 - auc: 0.8573 - loss: 0.4617 - val_acc: 0.7940 - val_auc: 0.8694 - val_loss: 0.4439\n",
      "Epoch 4695/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7783 - auc: 0.8573 - loss: 0.4627 - val_acc: 0.7908 - val_auc: 0.8699 - val_loss: 0.4424\n",
      "Epoch 4696/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7776 - auc: 0.8572 - loss: 0.4628 - val_acc: 0.7900 - val_auc: 0.8696 - val_loss: 0.4437\n",
      "Epoch 4697/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7787 - auc: 0.8587 - loss: 0.4597 - val_acc: 0.7901 - val_auc: 0.8691 - val_loss: 0.4448\n",
      "Epoch 4698/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7786 - auc: 0.8576 - loss: 0.4626 - val_acc: 0.7908 - val_auc: 0.8696 - val_loss: 0.4428\n",
      "Epoch 4699/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7791 - auc: 0.8592 - loss: 0.4593 - val_acc: 0.7937 - val_auc: 0.8689 - val_loss: 0.4420\n",
      "Epoch 4700/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7787 - auc: 0.8577 - loss: 0.4618 - val_acc: 0.7923 - val_auc: 0.8698 - val_loss: 0.4424\n",
      "Epoch 4701/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7782 - auc: 0.8575 - loss: 0.4625 - val_acc: 0.7893 - val_auc: 0.8703 - val_loss: 0.4441\n",
      "Epoch 4702/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7779 - auc: 0.8571 - loss: 0.4634 - val_acc: 0.7896 - val_auc: 0.8690 - val_loss: 0.4434\n",
      "Epoch 4703/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7785 - auc: 0.8581 - loss: 0.4622 - val_acc: 0.7915 - val_auc: 0.8698 - val_loss: 0.4418\n",
      "Epoch 4704/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7805 - auc: 0.8592 - loss: 0.4600 - val_acc: 0.7912 - val_auc: 0.8704 - val_loss: 0.4412\n",
      "Epoch 4705/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7769 - auc: 0.8564 - loss: 0.4646 - val_acc: 0.7909 - val_auc: 0.8697 - val_loss: 0.4430\n",
      "Epoch 4706/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7770 - auc: 0.8577 - loss: 0.4612 - val_acc: 0.7934 - val_auc: 0.8698 - val_loss: 0.4435\n",
      "Epoch 4707/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7766 - auc: 0.8562 - loss: 0.4635 - val_acc: 0.7927 - val_auc: 0.8709 - val_loss: 0.4419\n",
      "Epoch 4708/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7784 - auc: 0.8587 - loss: 0.4599 - val_acc: 0.7877 - val_auc: 0.8682 - val_loss: 0.4439\n",
      "Epoch 4709/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7792 - auc: 0.8582 - loss: 0.4615 - val_acc: 0.7930 - val_auc: 0.8704 - val_loss: 0.4411\n",
      "Epoch 4710/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7785 - auc: 0.8587 - loss: 0.4601 - val_acc: 0.7926 - val_auc: 0.8703 - val_loss: 0.4418\n",
      "Epoch 4711/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7794 - auc: 0.8583 - loss: 0.4616 - val_acc: 0.7946 - val_auc: 0.8718 - val_loss: 0.4412\n",
      "Epoch 4712/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7791 - auc: 0.8586 - loss: 0.4606 - val_acc: 0.7951 - val_auc: 0.8710 - val_loss: 0.4405\n",
      "Epoch 4713/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7770 - auc: 0.8572 - loss: 0.4619 - val_acc: 0.7890 - val_auc: 0.8689 - val_loss: 0.4444\n",
      "Epoch 4714/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7784 - auc: 0.8574 - loss: 0.4627 - val_acc: 0.7901 - val_auc: 0.8689 - val_loss: 0.4440\n",
      "Epoch 4715/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7776 - auc: 0.8576 - loss: 0.4623 - val_acc: 0.7930 - val_auc: 0.8700 - val_loss: 0.4437\n",
      "Epoch 4716/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7777 - auc: 0.8575 - loss: 0.4620 - val_acc: 0.7930 - val_auc: 0.8689 - val_loss: 0.4442\n",
      "Epoch 4717/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7777 - auc: 0.8571 - loss: 0.4630 - val_acc: 0.7923 - val_auc: 0.8707 - val_loss: 0.4422\n",
      "Epoch 4718/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7787 - auc: 0.8571 - loss: 0.4624 - val_acc: 0.7945 - val_auc: 0.8711 - val_loss: 0.4410\n",
      "Epoch 4719/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7778 - auc: 0.8564 - loss: 0.4624 - val_acc: 0.7903 - val_auc: 0.8705 - val_loss: 0.4424\n",
      "Epoch 4720/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7807 - auc: 0.8592 - loss: 0.4608 - val_acc: 0.7921 - val_auc: 0.8689 - val_loss: 0.4439\n",
      "Epoch 4721/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7774 - auc: 0.8565 - loss: 0.4638 - val_acc: 0.7925 - val_auc: 0.8692 - val_loss: 0.4449\n",
      "Epoch 4722/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7772 - auc: 0.8571 - loss: 0.4621 - val_acc: 0.7946 - val_auc: 0.8706 - val_loss: 0.4417\n",
      "Epoch 4723/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7755 - auc: 0.8561 - loss: 0.4637 - val_acc: 0.7932 - val_auc: 0.8697 - val_loss: 0.4424\n",
      "Epoch 4724/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7763 - auc: 0.8581 - loss: 0.4613 - val_acc: 0.7920 - val_auc: 0.8698 - val_loss: 0.4437\n",
      "Epoch 4725/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7767 - auc: 0.8569 - loss: 0.4633 - val_acc: 0.7916 - val_auc: 0.8704 - val_loss: 0.4441\n",
      "Epoch 4726/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7782 - auc: 0.8580 - loss: 0.4620 - val_acc: 0.7912 - val_auc: 0.8698 - val_loss: 0.4440\n",
      "Epoch 4727/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7774 - auc: 0.8580 - loss: 0.4619 - val_acc: 0.7950 - val_auc: 0.8705 - val_loss: 0.4410\n",
      "Epoch 4728/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7790 - auc: 0.8590 - loss: 0.4600 - val_acc: 0.7943 - val_auc: 0.8708 - val_loss: 0.4410\n",
      "Epoch 4729/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7785 - auc: 0.8581 - loss: 0.4612 - val_acc: 0.7927 - val_auc: 0.8702 - val_loss: 0.4420\n",
      "Epoch 4730/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7787 - auc: 0.8574 - loss: 0.4617 - val_acc: 0.7927 - val_auc: 0.8708 - val_loss: 0.4426\n",
      "Epoch 4731/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7788 - auc: 0.8577 - loss: 0.4623 - val_acc: 0.7923 - val_auc: 0.8717 - val_loss: 0.4417\n",
      "Epoch 4732/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7793 - auc: 0.8577 - loss: 0.4607 - val_acc: 0.7893 - val_auc: 0.8689 - val_loss: 0.4428\n",
      "Epoch 4733/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7787 - auc: 0.8570 - loss: 0.4619 - val_acc: 0.7911 - val_auc: 0.8713 - val_loss: 0.4417\n",
      "Epoch 4734/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7781 - auc: 0.8572 - loss: 0.4625 - val_acc: 0.7911 - val_auc: 0.8698 - val_loss: 0.4433\n",
      "Epoch 4735/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7774 - auc: 0.8573 - loss: 0.4620 - val_acc: 0.7926 - val_auc: 0.8701 - val_loss: 0.4418\n",
      "Epoch 4736/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7773 - auc: 0.8567 - loss: 0.4625 - val_acc: 0.7936 - val_auc: 0.8703 - val_loss: 0.4418\n",
      "Epoch 4737/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7778 - auc: 0.8573 - loss: 0.4623 - val_acc: 0.7915 - val_auc: 0.8708 - val_loss: 0.4419\n",
      "Epoch 4738/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7794 - auc: 0.8581 - loss: 0.4604 - val_acc: 0.7915 - val_auc: 0.8706 - val_loss: 0.4413\n",
      "Epoch 4739/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7782 - auc: 0.8588 - loss: 0.4609 - val_acc: 0.7884 - val_auc: 0.8697 - val_loss: 0.4452\n",
      "Epoch 4740/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7788 - auc: 0.8578 - loss: 0.4616 - val_acc: 0.7927 - val_auc: 0.8708 - val_loss: 0.4419\n",
      "Epoch 4741/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7767 - auc: 0.8579 - loss: 0.4618 - val_acc: 0.7896 - val_auc: 0.8699 - val_loss: 0.4425\n",
      "Epoch 4742/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7773 - auc: 0.8580 - loss: 0.4602 - val_acc: 0.7890 - val_auc: 0.8701 - val_loss: 0.4428\n",
      "Epoch 4743/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7767 - auc: 0.8571 - loss: 0.4627 - val_acc: 0.7934 - val_auc: 0.8712 - val_loss: 0.4416\n",
      "Epoch 4744/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7794 - auc: 0.8582 - loss: 0.4615 - val_acc: 0.7899 - val_auc: 0.8700 - val_loss: 0.4439\n",
      "Epoch 4745/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7767 - auc: 0.8580 - loss: 0.4608 - val_acc: 0.7924 - val_auc: 0.8691 - val_loss: 0.4422\n",
      "Epoch 4746/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7807 - auc: 0.8595 - loss: 0.4591 - val_acc: 0.7937 - val_auc: 0.8712 - val_loss: 0.4401\n",
      "Epoch 4747/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7774 - auc: 0.8567 - loss: 0.4633 - val_acc: 0.7925 - val_auc: 0.8701 - val_loss: 0.4422\n",
      "Epoch 4748/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7792 - auc: 0.8585 - loss: 0.4612 - val_acc: 0.7912 - val_auc: 0.8690 - val_loss: 0.4427\n",
      "Epoch 4749/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7786 - auc: 0.8575 - loss: 0.4617 - val_acc: 0.7934 - val_auc: 0.8697 - val_loss: 0.4426\n",
      "Epoch 4750/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7784 - auc: 0.8582 - loss: 0.4610 - val_acc: 0.7930 - val_auc: 0.8702 - val_loss: 0.4429\n",
      "Epoch 4751/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7793 - auc: 0.8571 - loss: 0.4619 - val_acc: 0.7937 - val_auc: 0.8702 - val_loss: 0.4434\n",
      "Epoch 4752/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7778 - auc: 0.8578 - loss: 0.4617 - val_acc: 0.7876 - val_auc: 0.8685 - val_loss: 0.4460\n",
      "Epoch 4753/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7783 - auc: 0.8582 - loss: 0.4614 - val_acc: 0.7927 - val_auc: 0.8703 - val_loss: 0.4420\n",
      "Epoch 4754/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7790 - auc: 0.8576 - loss: 0.4616 - val_acc: 0.7909 - val_auc: 0.8711 - val_loss: 0.4425\n",
      "Epoch 4755/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7769 - auc: 0.8580 - loss: 0.4611 - val_acc: 0.7919 - val_auc: 0.8695 - val_loss: 0.4440\n",
      "Epoch 4756/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7792 - auc: 0.8580 - loss: 0.4606 - val_acc: 0.7931 - val_auc: 0.8689 - val_loss: 0.4434\n",
      "Epoch 4757/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7795 - auc: 0.8577 - loss: 0.4607 - val_acc: 0.7896 - val_auc: 0.8708 - val_loss: 0.4449\n",
      "Epoch 4758/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7778 - auc: 0.8590 - loss: 0.4586 - val_acc: 0.7941 - val_auc: 0.8694 - val_loss: 0.4414\n",
      "Epoch 4759/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7786 - auc: 0.8583 - loss: 0.4598 - val_acc: 0.7916 - val_auc: 0.8690 - val_loss: 0.4434\n",
      "Epoch 4760/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7779 - auc: 0.8588 - loss: 0.4594 - val_acc: 0.7932 - val_auc: 0.8704 - val_loss: 0.4412\n",
      "Epoch 4761/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7792 - auc: 0.8585 - loss: 0.4605 - val_acc: 0.7937 - val_auc: 0.8710 - val_loss: 0.4402\n",
      "Epoch 4762/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7780 - auc: 0.8573 - loss: 0.4622 - val_acc: 0.7920 - val_auc: 0.8701 - val_loss: 0.4432\n",
      "Epoch 4763/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7771 - auc: 0.8585 - loss: 0.4606 - val_acc: 0.7912 - val_auc: 0.8712 - val_loss: 0.4431\n",
      "Epoch 4764/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7780 - auc: 0.8571 - loss: 0.4624 - val_acc: 0.7891 - val_auc: 0.8700 - val_loss: 0.4454\n",
      "Epoch 4765/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7773 - auc: 0.8574 - loss: 0.4617 - val_acc: 0.7931 - val_auc: 0.8695 - val_loss: 0.4421\n",
      "Epoch 4766/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7785 - auc: 0.8591 - loss: 0.4604 - val_acc: 0.7931 - val_auc: 0.8703 - val_loss: 0.4419\n",
      "Epoch 4767/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7790 - auc: 0.8582 - loss: 0.4610 - val_acc: 0.7910 - val_auc: 0.8703 - val_loss: 0.4412\n",
      "Epoch 4768/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7785 - auc: 0.8578 - loss: 0.4619 - val_acc: 0.7915 - val_auc: 0.8698 - val_loss: 0.4425\n",
      "Epoch 4769/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7771 - auc: 0.8564 - loss: 0.4626 - val_acc: 0.7891 - val_auc: 0.8698 - val_loss: 0.4424\n",
      "Epoch 4770/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7767 - auc: 0.8572 - loss: 0.4624 - val_acc: 0.7927 - val_auc: 0.8705 - val_loss: 0.4433\n",
      "Epoch 4771/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7784 - auc: 0.8580 - loss: 0.4601 - val_acc: 0.7945 - val_auc: 0.8724 - val_loss: 0.4405\n",
      "Epoch 4772/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7797 - auc: 0.8589 - loss: 0.4605 - val_acc: 0.7916 - val_auc: 0.8705 - val_loss: 0.4428\n",
      "Epoch 4773/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7758 - auc: 0.8558 - loss: 0.4656 - val_acc: 0.7923 - val_auc: 0.8705 - val_loss: 0.4420\n",
      "Epoch 4774/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7782 - auc: 0.8566 - loss: 0.4639 - val_acc: 0.7915 - val_auc: 0.8695 - val_loss: 0.4425\n",
      "Epoch 4775/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7786 - auc: 0.8561 - loss: 0.4654 - val_acc: 0.7918 - val_auc: 0.8709 - val_loss: 0.4414\n",
      "Epoch 4776/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7761 - auc: 0.8570 - loss: 0.4620 - val_acc: 0.7923 - val_auc: 0.8709 - val_loss: 0.4414\n",
      "Epoch 4777/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7808 - auc: 0.8587 - loss: 0.4600 - val_acc: 0.7943 - val_auc: 0.8709 - val_loss: 0.4436\n",
      "Epoch 4778/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7792 - auc: 0.8585 - loss: 0.4598 - val_acc: 0.7940 - val_auc: 0.8715 - val_loss: 0.4403\n",
      "Epoch 4779/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7810 - auc: 0.8593 - loss: 0.4593 - val_acc: 0.7918 - val_auc: 0.8702 - val_loss: 0.4420\n",
      "Epoch 4780/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7763 - auc: 0.8564 - loss: 0.4625 - val_acc: 0.7931 - val_auc: 0.8704 - val_loss: 0.4432\n",
      "Epoch 4781/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7780 - auc: 0.8579 - loss: 0.4616 - val_acc: 0.7922 - val_auc: 0.8698 - val_loss: 0.4427\n",
      "Epoch 4782/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7780 - auc: 0.8577 - loss: 0.4619 - val_acc: 0.7952 - val_auc: 0.8723 - val_loss: 0.4398\n",
      "Epoch 4783/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7808 - auc: 0.8596 - loss: 0.4591 - val_acc: 0.7937 - val_auc: 0.8720 - val_loss: 0.4396\n",
      "Epoch 4784/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7798 - auc: 0.8586 - loss: 0.4599 - val_acc: 0.7907 - val_auc: 0.8711 - val_loss: 0.4437\n",
      "Epoch 4785/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7801 - auc: 0.8589 - loss: 0.4601 - val_acc: 0.7926 - val_auc: 0.8704 - val_loss: 0.4433\n",
      "Epoch 4786/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7788 - auc: 0.8586 - loss: 0.4608 - val_acc: 0.7963 - val_auc: 0.8704 - val_loss: 0.4410\n",
      "Epoch 4787/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7788 - auc: 0.8575 - loss: 0.4618 - val_acc: 0.7941 - val_auc: 0.8714 - val_loss: 0.4412\n",
      "Epoch 4788/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7783 - auc: 0.8574 - loss: 0.4633 - val_acc: 0.7939 - val_auc: 0.8712 - val_loss: 0.4413\n",
      "Epoch 4789/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7775 - auc: 0.8569 - loss: 0.4633 - val_acc: 0.7937 - val_auc: 0.8715 - val_loss: 0.4409\n",
      "Epoch 4790/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7769 - auc: 0.8562 - loss: 0.4631 - val_acc: 0.7917 - val_auc: 0.8706 - val_loss: 0.4426\n",
      "Epoch 4791/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7789 - auc: 0.8585 - loss: 0.4605 - val_acc: 0.7899 - val_auc: 0.8694 - val_loss: 0.4428\n",
      "Epoch 4792/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7765 - auc: 0.8569 - loss: 0.4619 - val_acc: 0.7940 - val_auc: 0.8699 - val_loss: 0.4419\n",
      "Epoch 4793/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7806 - auc: 0.8601 - loss: 0.4575 - val_acc: 0.7947 - val_auc: 0.8713 - val_loss: 0.4401\n",
      "Epoch 4794/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7788 - auc: 0.8587 - loss: 0.4606 - val_acc: 0.7921 - val_auc: 0.8709 - val_loss: 0.4418\n",
      "Epoch 4795/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7799 - auc: 0.8580 - loss: 0.4609 - val_acc: 0.7924 - val_auc: 0.8701 - val_loss: 0.4429\n",
      "Epoch 4796/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7810 - auc: 0.8599 - loss: 0.4586 - val_acc: 0.7942 - val_auc: 0.8711 - val_loss: 0.4407\n",
      "Epoch 4797/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7786 - auc: 0.8591 - loss: 0.4592 - val_acc: 0.7938 - val_auc: 0.8701 - val_loss: 0.4418\n",
      "Epoch 4798/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7764 - auc: 0.8571 - loss: 0.4622 - val_acc: 0.7915 - val_auc: 0.8702 - val_loss: 0.4436\n",
      "Epoch 4799/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7800 - auc: 0.8580 - loss: 0.4619 - val_acc: 0.7913 - val_auc: 0.8711 - val_loss: 0.4426\n",
      "Epoch 4800/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7785 - auc: 0.8571 - loss: 0.4628 - val_acc: 0.7928 - val_auc: 0.8713 - val_loss: 0.4411\n",
      "Epoch 4801/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7778 - auc: 0.8578 - loss: 0.4616 - val_acc: 0.7929 - val_auc: 0.8706 - val_loss: 0.4430\n",
      "Epoch 4802/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7785 - auc: 0.8576 - loss: 0.4615 - val_acc: 0.7919 - val_auc: 0.8703 - val_loss: 0.4432\n",
      "Epoch 4803/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7777 - auc: 0.8579 - loss: 0.4611 - val_acc: 0.7884 - val_auc: 0.8681 - val_loss: 0.4445\n",
      "Epoch 4804/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7763 - auc: 0.8562 - loss: 0.4625 - val_acc: 0.7928 - val_auc: 0.8706 - val_loss: 0.4442\n",
      "Epoch 4805/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7783 - auc: 0.8584 - loss: 0.4608 - val_acc: 0.7911 - val_auc: 0.8693 - val_loss: 0.4436\n",
      "Epoch 4806/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7745 - auc: 0.8569 - loss: 0.4618 - val_acc: 0.7949 - val_auc: 0.8699 - val_loss: 0.4426\n",
      "Epoch 4807/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7795 - auc: 0.8592 - loss: 0.4590 - val_acc: 0.7929 - val_auc: 0.8709 - val_loss: 0.4413\n",
      "Epoch 4808/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7785 - auc: 0.8589 - loss: 0.4603 - val_acc: 0.7944 - val_auc: 0.8703 - val_loss: 0.4431\n",
      "Epoch 4809/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7775 - auc: 0.8556 - loss: 0.4637 - val_acc: 0.7926 - val_auc: 0.8690 - val_loss: 0.4453\n",
      "Epoch 4810/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7796 - auc: 0.8582 - loss: 0.4599 - val_acc: 0.7888 - val_auc: 0.8699 - val_loss: 0.4424\n",
      "Epoch 4811/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7780 - auc: 0.8567 - loss: 0.4626 - val_acc: 0.7940 - val_auc: 0.8704 - val_loss: 0.4420\n",
      "Epoch 4812/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7780 - auc: 0.8578 - loss: 0.4605 - val_acc: 0.7921 - val_auc: 0.8700 - val_loss: 0.4428\n",
      "Epoch 4813/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7781 - auc: 0.8581 - loss: 0.4612 - val_acc: 0.7923 - val_auc: 0.8697 - val_loss: 0.4426\n",
      "Epoch 4814/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7775 - auc: 0.8571 - loss: 0.4623 - val_acc: 0.7907 - val_auc: 0.8704 - val_loss: 0.4451\n",
      "Epoch 4815/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7774 - auc: 0.8581 - loss: 0.4615 - val_acc: 0.7926 - val_auc: 0.8702 - val_loss: 0.4420\n",
      "Epoch 4816/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7782 - auc: 0.8575 - loss: 0.4610 - val_acc: 0.7927 - val_auc: 0.8706 - val_loss: 0.4427\n",
      "Epoch 4817/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7773 - auc: 0.8584 - loss: 0.4610 - val_acc: 0.7926 - val_auc: 0.8702 - val_loss: 0.4412\n",
      "Epoch 4818/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7799 - auc: 0.8598 - loss: 0.4580 - val_acc: 0.7910 - val_auc: 0.8695 - val_loss: 0.4416\n",
      "Epoch 4819/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7786 - auc: 0.8576 - loss: 0.4619 - val_acc: 0.7930 - val_auc: 0.8701 - val_loss: 0.4417\n",
      "Epoch 4820/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7785 - auc: 0.8582 - loss: 0.4613 - val_acc: 0.7959 - val_auc: 0.8729 - val_loss: 0.4392\n",
      "Epoch 4821/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7788 - auc: 0.8584 - loss: 0.4603 - val_acc: 0.7932 - val_auc: 0.8706 - val_loss: 0.4420\n",
      "Epoch 4822/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7768 - auc: 0.8569 - loss: 0.4634 - val_acc: 0.7932 - val_auc: 0.8707 - val_loss: 0.4427\n",
      "Epoch 4823/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7771 - auc: 0.8567 - loss: 0.4634 - val_acc: 0.7925 - val_auc: 0.8702 - val_loss: 0.4417\n",
      "Epoch 4824/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7787 - auc: 0.8584 - loss: 0.4598 - val_acc: 0.7932 - val_auc: 0.8703 - val_loss: 0.4417\n",
      "Epoch 4825/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7793 - auc: 0.8579 - loss: 0.4616 - val_acc: 0.7926 - val_auc: 0.8707 - val_loss: 0.4404\n",
      "Epoch 4826/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7787 - auc: 0.8579 - loss: 0.4612 - val_acc: 0.7938 - val_auc: 0.8712 - val_loss: 0.4405\n",
      "Epoch 4827/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7787 - auc: 0.8582 - loss: 0.4602 - val_acc: 0.7916 - val_auc: 0.8702 - val_loss: 0.4431\n",
      "Epoch 4828/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7785 - auc: 0.8594 - loss: 0.4588 - val_acc: 0.7949 - val_auc: 0.8718 - val_loss: 0.4413\n",
      "Epoch 4829/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7772 - auc: 0.8573 - loss: 0.4633 - val_acc: 0.7937 - val_auc: 0.8709 - val_loss: 0.4417\n",
      "Epoch 4830/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7768 - auc: 0.8562 - loss: 0.4637 - val_acc: 0.7890 - val_auc: 0.8678 - val_loss: 0.4462\n",
      "Epoch 4831/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7790 - auc: 0.8579 - loss: 0.4620 - val_acc: 0.7892 - val_auc: 0.8697 - val_loss: 0.4450\n",
      "Epoch 4832/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7795 - auc: 0.8584 - loss: 0.4602 - val_acc: 0.7936 - val_auc: 0.8698 - val_loss: 0.4406\n",
      "Epoch 4833/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7789 - auc: 0.8594 - loss: 0.4599 - val_acc: 0.7911 - val_auc: 0.8702 - val_loss: 0.4431\n",
      "Epoch 4834/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7778 - auc: 0.8578 - loss: 0.4616 - val_acc: 0.7914 - val_auc: 0.8695 - val_loss: 0.4449\n",
      "Epoch 4835/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7770 - auc: 0.8571 - loss: 0.4629 - val_acc: 0.7918 - val_auc: 0.8693 - val_loss: 0.4427\n",
      "Epoch 4836/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7784 - auc: 0.8574 - loss: 0.4622 - val_acc: 0.7903 - val_auc: 0.8701 - val_loss: 0.4419\n",
      "Epoch 4837/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7786 - auc: 0.8571 - loss: 0.4618 - val_acc: 0.7909 - val_auc: 0.8695 - val_loss: 0.4426\n",
      "Epoch 4838/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7771 - auc: 0.8573 - loss: 0.4625 - val_acc: 0.7898 - val_auc: 0.8694 - val_loss: 0.4448\n",
      "Epoch 4839/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7789 - auc: 0.8582 - loss: 0.4605 - val_acc: 0.7923 - val_auc: 0.8695 - val_loss: 0.4423\n",
      "Epoch 4840/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7755 - auc: 0.8565 - loss: 0.4635 - val_acc: 0.7916 - val_auc: 0.8709 - val_loss: 0.4421\n",
      "Epoch 4841/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7789 - auc: 0.8582 - loss: 0.4612 - val_acc: 0.7928 - val_auc: 0.8698 - val_loss: 0.4431\n",
      "Epoch 4842/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7787 - auc: 0.8579 - loss: 0.4611 - val_acc: 0.7927 - val_auc: 0.8693 - val_loss: 0.4428\n",
      "Epoch 4843/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7802 - auc: 0.8583 - loss: 0.4601 - val_acc: 0.7937 - val_auc: 0.8697 - val_loss: 0.4429\n",
      "Epoch 4844/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7780 - auc: 0.8576 - loss: 0.4617 - val_acc: 0.7906 - val_auc: 0.8695 - val_loss: 0.4442\n",
      "Epoch 4845/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7772 - auc: 0.8579 - loss: 0.4611 - val_acc: 0.7917 - val_auc: 0.8707 - val_loss: 0.4424\n",
      "Epoch 4846/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7779 - auc: 0.8578 - loss: 0.4610 - val_acc: 0.7927 - val_auc: 0.8702 - val_loss: 0.4431\n",
      "Epoch 4847/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7787 - auc: 0.8582 - loss: 0.4609 - val_acc: 0.7914 - val_auc: 0.8689 - val_loss: 0.4424\n",
      "Epoch 4848/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7805 - auc: 0.8588 - loss: 0.4592 - val_acc: 0.7917 - val_auc: 0.8699 - val_loss: 0.4421\n",
      "Epoch 4849/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7786 - auc: 0.8574 - loss: 0.4630 - val_acc: 0.7920 - val_auc: 0.8701 - val_loss: 0.4425\n",
      "Epoch 4850/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7779 - auc: 0.8568 - loss: 0.4631 - val_acc: 0.7927 - val_auc: 0.8702 - val_loss: 0.4425\n",
      "Epoch 4851/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7758 - auc: 0.8570 - loss: 0.4612 - val_acc: 0.7909 - val_auc: 0.8706 - val_loss: 0.4441\n",
      "Epoch 4852/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7803 - auc: 0.8574 - loss: 0.4629 - val_acc: 0.7915 - val_auc: 0.8693 - val_loss: 0.4442\n",
      "Epoch 4853/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7798 - auc: 0.8582 - loss: 0.4619 - val_acc: 0.7948 - val_auc: 0.8704 - val_loss: 0.4427\n",
      "Epoch 4854/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7780 - auc: 0.8596 - loss: 0.4604 - val_acc: 0.7937 - val_auc: 0.8706 - val_loss: 0.4424\n",
      "Epoch 4855/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7802 - auc: 0.8586 - loss: 0.4606 - val_acc: 0.7945 - val_auc: 0.8708 - val_loss: 0.4417\n",
      "Epoch 4856/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7800 - auc: 0.8578 - loss: 0.4608 - val_acc: 0.7906 - val_auc: 0.8689 - val_loss: 0.4441\n",
      "Epoch 4857/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7780 - auc: 0.8574 - loss: 0.4615 - val_acc: 0.7928 - val_auc: 0.8700 - val_loss: 0.4412\n",
      "Epoch 4858/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7790 - auc: 0.8573 - loss: 0.4620 - val_acc: 0.7931 - val_auc: 0.8708 - val_loss: 0.4440\n",
      "Epoch 4859/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7782 - auc: 0.8579 - loss: 0.4617 - val_acc: 0.7927 - val_auc: 0.8710 - val_loss: 0.4415\n",
      "Epoch 4860/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7820 - auc: 0.8602 - loss: 0.4586 - val_acc: 0.7908 - val_auc: 0.8692 - val_loss: 0.4433\n",
      "Epoch 4861/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7766 - auc: 0.8565 - loss: 0.4627 - val_acc: 0.7916 - val_auc: 0.8694 - val_loss: 0.4425\n",
      "Epoch 4862/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7784 - auc: 0.8572 - loss: 0.4616 - val_acc: 0.7934 - val_auc: 0.8705 - val_loss: 0.4432\n",
      "Epoch 4863/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7771 - auc: 0.8587 - loss: 0.4613 - val_acc: 0.7950 - val_auc: 0.8707 - val_loss: 0.4412\n",
      "Epoch 4864/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7772 - auc: 0.8576 - loss: 0.4615 - val_acc: 0.7942 - val_auc: 0.8706 - val_loss: 0.4413\n",
      "Epoch 4865/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7763 - auc: 0.8570 - loss: 0.4636 - val_acc: 0.7937 - val_auc: 0.8704 - val_loss: 0.4412\n",
      "Epoch 4866/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7789 - auc: 0.8585 - loss: 0.4609 - val_acc: 0.7926 - val_auc: 0.8714 - val_loss: 0.4425\n",
      "Epoch 4867/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7783 - auc: 0.8585 - loss: 0.4609 - val_acc: 0.7931 - val_auc: 0.8710 - val_loss: 0.4421\n",
      "Epoch 4868/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7782 - auc: 0.8578 - loss: 0.4618 - val_acc: 0.7941 - val_auc: 0.8709 - val_loss: 0.4428\n",
      "Epoch 4869/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7773 - auc: 0.8574 - loss: 0.4613 - val_acc: 0.7945 - val_auc: 0.8697 - val_loss: 0.4432\n",
      "Epoch 4870/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7795 - auc: 0.8587 - loss: 0.4598 - val_acc: 0.7905 - val_auc: 0.8706 - val_loss: 0.4417\n",
      "Epoch 4871/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7785 - auc: 0.8572 - loss: 0.4635 - val_acc: 0.7902 - val_auc: 0.8702 - val_loss: 0.4439\n",
      "Epoch 4872/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7769 - auc: 0.8569 - loss: 0.4615 - val_acc: 0.7950 - val_auc: 0.8704 - val_loss: 0.4426\n",
      "Epoch 4873/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7793 - auc: 0.8587 - loss: 0.4605 - val_acc: 0.7903 - val_auc: 0.8692 - val_loss: 0.4429\n",
      "Epoch 4874/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7789 - auc: 0.8582 - loss: 0.4601 - val_acc: 0.7920 - val_auc: 0.8694 - val_loss: 0.4425\n",
      "Epoch 4875/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7753 - auc: 0.8557 - loss: 0.4636 - val_acc: 0.7945 - val_auc: 0.8694 - val_loss: 0.4430\n",
      "Epoch 4876/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7786 - auc: 0.8586 - loss: 0.4604 - val_acc: 0.7931 - val_auc: 0.8696 - val_loss: 0.4430\n",
      "Epoch 4877/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7774 - auc: 0.8576 - loss: 0.4621 - val_acc: 0.7912 - val_auc: 0.8688 - val_loss: 0.4444\n",
      "Epoch 4878/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7786 - auc: 0.8575 - loss: 0.4622 - val_acc: 0.7955 - val_auc: 0.8702 - val_loss: 0.4417\n",
      "Epoch 4879/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7778 - auc: 0.8585 - loss: 0.4608 - val_acc: 0.7939 - val_auc: 0.8712 - val_loss: 0.4413\n",
      "Epoch 4880/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7794 - auc: 0.8596 - loss: 0.4582 - val_acc: 0.7951 - val_auc: 0.8715 - val_loss: 0.4398\n",
      "Epoch 4881/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7780 - auc: 0.8583 - loss: 0.4604 - val_acc: 0.7906 - val_auc: 0.8701 - val_loss: 0.4434\n",
      "Epoch 4882/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7779 - auc: 0.8571 - loss: 0.4623 - val_acc: 0.7952 - val_auc: 0.8709 - val_loss: 0.4412\n",
      "Epoch 4883/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7796 - auc: 0.8581 - loss: 0.4615 - val_acc: 0.7903 - val_auc: 0.8703 - val_loss: 0.4427\n",
      "Epoch 4884/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7817 - auc: 0.8586 - loss: 0.4602 - val_acc: 0.7934 - val_auc: 0.8707 - val_loss: 0.4420\n",
      "Epoch 4885/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7777 - auc: 0.8580 - loss: 0.4611 - val_acc: 0.7942 - val_auc: 0.8713 - val_loss: 0.4403\n",
      "Epoch 4886/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7764 - auc: 0.8576 - loss: 0.4613 - val_acc: 0.7928 - val_auc: 0.8713 - val_loss: 0.4435\n",
      "Epoch 4887/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7790 - auc: 0.8572 - loss: 0.4614 - val_acc: 0.7939 - val_auc: 0.8718 - val_loss: 0.4403\n",
      "Epoch 4888/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7776 - auc: 0.8582 - loss: 0.4602 - val_acc: 0.7927 - val_auc: 0.8713 - val_loss: 0.4425\n",
      "Epoch 4889/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7768 - auc: 0.8565 - loss: 0.4627 - val_acc: 0.7937 - val_auc: 0.8716 - val_loss: 0.4392\n",
      "Epoch 4890/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7788 - auc: 0.8574 - loss: 0.4614 - val_acc: 0.7905 - val_auc: 0.8709 - val_loss: 0.4424\n",
      "Epoch 4891/7000\n",
      "106/106 - 2s - 14ms/step - acc: 0.7803 - auc: 0.8584 - loss: 0.4605 - val_acc: 0.7920 - val_auc: 0.8705 - val_loss: 0.4416\n",
      "Epoch 4892/7000\n",
      "106/106 - 3s - 29ms/step - acc: 0.7821 - auc: 0.8599 - loss: 0.4588 - val_acc: 0.7920 - val_auc: 0.8706 - val_loss: 0.4418\n",
      "Epoch 4893/7000\n",
      "106/106 - 2s - 16ms/step - acc: 0.7783 - auc: 0.8583 - loss: 0.4609 - val_acc: 0.7913 - val_auc: 0.8695 - val_loss: 0.4421\n",
      "Epoch 4894/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7798 - auc: 0.8593 - loss: 0.4596 - val_acc: 0.7942 - val_auc: 0.8707 - val_loss: 0.4412\n",
      "Epoch 4895/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7772 - auc: 0.8575 - loss: 0.4623 - val_acc: 0.7935 - val_auc: 0.8704 - val_loss: 0.4429\n",
      "Epoch 4896/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7788 - auc: 0.8570 - loss: 0.4613 - val_acc: 0.7935 - val_auc: 0.8702 - val_loss: 0.4419\n",
      "Epoch 4897/7000\n",
      "106/106 - 3s - 24ms/step - acc: 0.7792 - auc: 0.8583 - loss: 0.4618 - val_acc: 0.7921 - val_auc: 0.8692 - val_loss: 0.4420\n",
      "Epoch 4898/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7800 - auc: 0.8588 - loss: 0.4591 - val_acc: 0.7929 - val_auc: 0.8714 - val_loss: 0.4423\n",
      "Epoch 4899/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7793 - auc: 0.8583 - loss: 0.4605 - val_acc: 0.7931 - val_auc: 0.8698 - val_loss: 0.4424\n",
      "Epoch 4900/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7803 - auc: 0.8591 - loss: 0.4605 - val_acc: 0.7915 - val_auc: 0.8702 - val_loss: 0.4425\n",
      "Epoch 4901/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7790 - auc: 0.8589 - loss: 0.4596 - val_acc: 0.7919 - val_auc: 0.8698 - val_loss: 0.4411\n",
      "Epoch 4902/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7792 - auc: 0.8595 - loss: 0.4592 - val_acc: 0.7907 - val_auc: 0.8691 - val_loss: 0.4458\n",
      "Epoch 4903/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7779 - auc: 0.8574 - loss: 0.4623 - val_acc: 0.7927 - val_auc: 0.8701 - val_loss: 0.4419\n",
      "Epoch 4904/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7781 - auc: 0.8589 - loss: 0.4615 - val_acc: 0.7912 - val_auc: 0.8691 - val_loss: 0.4442\n",
      "Epoch 4905/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7788 - auc: 0.8587 - loss: 0.4603 - val_acc: 0.7931 - val_auc: 0.8714 - val_loss: 0.4415\n",
      "Epoch 4906/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7755 - auc: 0.8566 - loss: 0.4630 - val_acc: 0.7931 - val_auc: 0.8707 - val_loss: 0.4417\n",
      "Epoch 4907/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7789 - auc: 0.8580 - loss: 0.4611 - val_acc: 0.7926 - val_auc: 0.8702 - val_loss: 0.4431\n",
      "Epoch 4908/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7782 - auc: 0.8585 - loss: 0.4604 - val_acc: 0.7941 - val_auc: 0.8717 - val_loss: 0.4401\n",
      "Epoch 4909/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7785 - auc: 0.8587 - loss: 0.4596 - val_acc: 0.7910 - val_auc: 0.8704 - val_loss: 0.4431\n",
      "Epoch 4910/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7772 - auc: 0.8573 - loss: 0.4620 - val_acc: 0.7921 - val_auc: 0.8710 - val_loss: 0.4438\n",
      "Epoch 4911/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7775 - auc: 0.8571 - loss: 0.4621 - val_acc: 0.7915 - val_auc: 0.8708 - val_loss: 0.4430\n",
      "Epoch 4912/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7796 - auc: 0.8587 - loss: 0.4612 - val_acc: 0.7890 - val_auc: 0.8705 - val_loss: 0.4430\n",
      "Epoch 4913/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7816 - auc: 0.8605 - loss: 0.4579 - val_acc: 0.7919 - val_auc: 0.8692 - val_loss: 0.4440\n",
      "Epoch 4914/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7797 - auc: 0.8587 - loss: 0.4604 - val_acc: 0.7934 - val_auc: 0.8697 - val_loss: 0.4422\n",
      "Epoch 4915/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7797 - auc: 0.8592 - loss: 0.4591 - val_acc: 0.7902 - val_auc: 0.8693 - val_loss: 0.4426\n",
      "Epoch 4916/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7808 - auc: 0.8584 - loss: 0.4600 - val_acc: 0.7927 - val_auc: 0.8712 - val_loss: 0.4412\n",
      "Epoch 4917/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7780 - auc: 0.8572 - loss: 0.4619 - val_acc: 0.7938 - val_auc: 0.8702 - val_loss: 0.4435\n",
      "Epoch 4918/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7786 - auc: 0.8581 - loss: 0.4604 - val_acc: 0.7920 - val_auc: 0.8706 - val_loss: 0.4432\n",
      "Epoch 4919/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7802 - auc: 0.8588 - loss: 0.4610 - val_acc: 0.7935 - val_auc: 0.8713 - val_loss: 0.4413\n",
      "Epoch 4920/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7752 - auc: 0.8566 - loss: 0.4633 - val_acc: 0.7924 - val_auc: 0.8706 - val_loss: 0.4415\n",
      "Epoch 4921/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7777 - auc: 0.8580 - loss: 0.4611 - val_acc: 0.7922 - val_auc: 0.8720 - val_loss: 0.4412\n",
      "Epoch 4922/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7776 - auc: 0.8580 - loss: 0.4610 - val_acc: 0.7953 - val_auc: 0.8728 - val_loss: 0.4408\n",
      "Epoch 4923/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7779 - auc: 0.8587 - loss: 0.4597 - val_acc: 0.7939 - val_auc: 0.8705 - val_loss: 0.4412\n",
      "Epoch 4924/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7769 - auc: 0.8578 - loss: 0.4617 - val_acc: 0.7955 - val_auc: 0.8717 - val_loss: 0.4404\n",
      "Epoch 4925/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7792 - auc: 0.8579 - loss: 0.4609 - val_acc: 0.7930 - val_auc: 0.8707 - val_loss: 0.4406\n",
      "Epoch 4926/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7804 - auc: 0.8609 - loss: 0.4572 - val_acc: 0.7904 - val_auc: 0.8699 - val_loss: 0.4406\n",
      "Epoch 4927/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7779 - auc: 0.8591 - loss: 0.4594 - val_acc: 0.7939 - val_auc: 0.8717 - val_loss: 0.4417\n",
      "Epoch 4928/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7809 - auc: 0.8589 - loss: 0.4600 - val_acc: 0.7936 - val_auc: 0.8723 - val_loss: 0.4388\n",
      "Epoch 4929/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7807 - auc: 0.8594 - loss: 0.4595 - val_acc: 0.7913 - val_auc: 0.8709 - val_loss: 0.4415\n",
      "Epoch 4930/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7775 - auc: 0.8572 - loss: 0.4633 - val_acc: 0.7933 - val_auc: 0.8700 - val_loss: 0.4425\n",
      "Epoch 4931/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7780 - auc: 0.8567 - loss: 0.4644 - val_acc: 0.7927 - val_auc: 0.8714 - val_loss: 0.4413\n",
      "Epoch 4932/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7785 - auc: 0.8583 - loss: 0.4607 - val_acc: 0.7963 - val_auc: 0.8716 - val_loss: 0.4394\n",
      "Epoch 4933/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7790 - auc: 0.8586 - loss: 0.4605 - val_acc: 0.7927 - val_auc: 0.8718 - val_loss: 0.4431\n",
      "Epoch 4934/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7775 - auc: 0.8569 - loss: 0.4620 - val_acc: 0.7891 - val_auc: 0.8716 - val_loss: 0.4429\n",
      "Epoch 4935/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7794 - auc: 0.8581 - loss: 0.4606 - val_acc: 0.7945 - val_auc: 0.8720 - val_loss: 0.4405\n",
      "Epoch 4936/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7798 - auc: 0.8588 - loss: 0.4606 - val_acc: 0.7926 - val_auc: 0.8711 - val_loss: 0.4409\n",
      "Epoch 4937/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7793 - auc: 0.8576 - loss: 0.4613 - val_acc: 0.7940 - val_auc: 0.8719 - val_loss: 0.4398\n",
      "Epoch 4938/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7790 - auc: 0.8591 - loss: 0.4608 - val_acc: 0.7913 - val_auc: 0.8701 - val_loss: 0.4422\n",
      "Epoch 4939/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7782 - auc: 0.8582 - loss: 0.4614 - val_acc: 0.7926 - val_auc: 0.8709 - val_loss: 0.4423\n",
      "Epoch 4940/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7792 - auc: 0.8585 - loss: 0.4612 - val_acc: 0.7930 - val_auc: 0.8704 - val_loss: 0.4428\n",
      "Epoch 4941/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7800 - auc: 0.8584 - loss: 0.4604 - val_acc: 0.7927 - val_auc: 0.8694 - val_loss: 0.4428\n",
      "Epoch 4942/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7794 - auc: 0.8591 - loss: 0.4592 - val_acc: 0.7934 - val_auc: 0.8713 - val_loss: 0.4413\n",
      "Epoch 4943/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7788 - auc: 0.8593 - loss: 0.4601 - val_acc: 0.7939 - val_auc: 0.8709 - val_loss: 0.4412\n",
      "Epoch 4944/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7780 - auc: 0.8590 - loss: 0.4600 - val_acc: 0.7929 - val_auc: 0.8709 - val_loss: 0.4424\n",
      "Epoch 4945/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7783 - auc: 0.8577 - loss: 0.4612 - val_acc: 0.7918 - val_auc: 0.8703 - val_loss: 0.4436\n",
      "Epoch 4946/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7804 - auc: 0.8590 - loss: 0.4593 - val_acc: 0.7913 - val_auc: 0.8709 - val_loss: 0.4417\n",
      "Epoch 4947/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7796 - auc: 0.8592 - loss: 0.4611 - val_acc: 0.7908 - val_auc: 0.8692 - val_loss: 0.4449\n",
      "Epoch 4948/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7797 - auc: 0.8594 - loss: 0.4595 - val_acc: 0.7913 - val_auc: 0.8703 - val_loss: 0.4427\n",
      "Epoch 4949/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7805 - auc: 0.8593 - loss: 0.4592 - val_acc: 0.7893 - val_auc: 0.8698 - val_loss: 0.4423\n",
      "Epoch 4950/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7783 - auc: 0.8586 - loss: 0.4604 - val_acc: 0.7940 - val_auc: 0.8695 - val_loss: 0.4430\n",
      "Epoch 4951/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7787 - auc: 0.8580 - loss: 0.4613 - val_acc: 0.7960 - val_auc: 0.8711 - val_loss: 0.4407\n",
      "Epoch 4952/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7789 - auc: 0.8603 - loss: 0.4576 - val_acc: 0.7926 - val_auc: 0.8701 - val_loss: 0.4426\n",
      "Epoch 4953/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7786 - auc: 0.8580 - loss: 0.4616 - val_acc: 0.7908 - val_auc: 0.8697 - val_loss: 0.4442\n",
      "Epoch 4954/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7776 - auc: 0.8568 - loss: 0.4637 - val_acc: 0.7956 - val_auc: 0.8716 - val_loss: 0.4423\n",
      "Epoch 4955/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7797 - auc: 0.8574 - loss: 0.4617 - val_acc: 0.7915 - val_auc: 0.8709 - val_loss: 0.4426\n",
      "Epoch 4956/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7779 - auc: 0.8575 - loss: 0.4615 - val_acc: 0.7946 - val_auc: 0.8709 - val_loss: 0.4399\n",
      "Epoch 4957/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7797 - auc: 0.8596 - loss: 0.4590 - val_acc: 0.7959 - val_auc: 0.8731 - val_loss: 0.4385\n",
      "Epoch 4958/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7779 - auc: 0.8574 - loss: 0.4615 - val_acc: 0.7946 - val_auc: 0.8712 - val_loss: 0.4416\n",
      "Epoch 4959/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7796 - auc: 0.8586 - loss: 0.4597 - val_acc: 0.7946 - val_auc: 0.8714 - val_loss: 0.4420\n",
      "Epoch 4960/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7790 - auc: 0.8579 - loss: 0.4615 - val_acc: 0.7927 - val_auc: 0.8714 - val_loss: 0.4432\n",
      "Epoch 4961/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7787 - auc: 0.8566 - loss: 0.4631 - val_acc: 0.7928 - val_auc: 0.8705 - val_loss: 0.4421\n",
      "Epoch 4962/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7804 - auc: 0.8606 - loss: 0.4566 - val_acc: 0.7944 - val_auc: 0.8711 - val_loss: 0.4405\n",
      "Epoch 4963/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7777 - auc: 0.8579 - loss: 0.4607 - val_acc: 0.7920 - val_auc: 0.8706 - val_loss: 0.4421\n",
      "Epoch 4964/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7769 - auc: 0.8581 - loss: 0.4619 - val_acc: 0.7919 - val_auc: 0.8708 - val_loss: 0.4418\n",
      "Epoch 4965/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7794 - auc: 0.8577 - loss: 0.4613 - val_acc: 0.7925 - val_auc: 0.8710 - val_loss: 0.4433\n",
      "Epoch 4966/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7787 - auc: 0.8579 - loss: 0.4620 - val_acc: 0.7934 - val_auc: 0.8709 - val_loss: 0.4418\n",
      "Epoch 4967/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7773 - auc: 0.8565 - loss: 0.4637 - val_acc: 0.7917 - val_auc: 0.8715 - val_loss: 0.4428\n",
      "Epoch 4968/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7803 - auc: 0.8593 - loss: 0.4598 - val_acc: 0.7955 - val_auc: 0.8709 - val_loss: 0.4404\n",
      "Epoch 4969/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7793 - auc: 0.8587 - loss: 0.4597 - val_acc: 0.7943 - val_auc: 0.8714 - val_loss: 0.4413\n",
      "Epoch 4970/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7796 - auc: 0.8591 - loss: 0.4600 - val_acc: 0.7948 - val_auc: 0.8706 - val_loss: 0.4417\n",
      "Epoch 4971/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7792 - auc: 0.8591 - loss: 0.4596 - val_acc: 0.7888 - val_auc: 0.8705 - val_loss: 0.4448\n",
      "Epoch 4972/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7794 - auc: 0.8582 - loss: 0.4604 - val_acc: 0.7976 - val_auc: 0.8734 - val_loss: 0.4397\n",
      "Epoch 4973/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7773 - auc: 0.8583 - loss: 0.4598 - val_acc: 0.7935 - val_auc: 0.8733 - val_loss: 0.4396\n",
      "Epoch 4974/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7780 - auc: 0.8580 - loss: 0.4616 - val_acc: 0.7923 - val_auc: 0.8707 - val_loss: 0.4407\n",
      "Epoch 4975/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7775 - auc: 0.8573 - loss: 0.4614 - val_acc: 0.7939 - val_auc: 0.8706 - val_loss: 0.4423\n",
      "Epoch 4976/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7796 - auc: 0.8570 - loss: 0.4625 - val_acc: 0.7936 - val_auc: 0.8704 - val_loss: 0.4440\n",
      "Epoch 4977/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7783 - auc: 0.8576 - loss: 0.4616 - val_acc: 0.7948 - val_auc: 0.8717 - val_loss: 0.4410\n",
      "Epoch 4978/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7788 - auc: 0.8569 - loss: 0.4623 - val_acc: 0.7944 - val_auc: 0.8706 - val_loss: 0.4418\n",
      "Epoch 4979/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7788 - auc: 0.8572 - loss: 0.4617 - val_acc: 0.7935 - val_auc: 0.8706 - val_loss: 0.4432\n",
      "Epoch 4980/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7798 - auc: 0.8606 - loss: 0.4571 - val_acc: 0.7932 - val_auc: 0.8708 - val_loss: 0.4420\n",
      "Epoch 4981/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7781 - auc: 0.8580 - loss: 0.4610 - val_acc: 0.7936 - val_auc: 0.8702 - val_loss: 0.4428\n",
      "Epoch 4982/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7788 - auc: 0.8585 - loss: 0.4598 - val_acc: 0.7939 - val_auc: 0.8706 - val_loss: 0.4414\n",
      "Epoch 4983/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7775 - auc: 0.8576 - loss: 0.4619 - val_acc: 0.7926 - val_auc: 0.8708 - val_loss: 0.4413\n",
      "Epoch 4984/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7807 - auc: 0.8602 - loss: 0.4589 - val_acc: 0.7932 - val_auc: 0.8709 - val_loss: 0.4408\n",
      "Epoch 4985/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7801 - auc: 0.8591 - loss: 0.4591 - val_acc: 0.7921 - val_auc: 0.8714 - val_loss: 0.4416\n",
      "Epoch 4986/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7782 - auc: 0.8577 - loss: 0.4609 - val_acc: 0.7920 - val_auc: 0.8705 - val_loss: 0.4419\n",
      "Epoch 4987/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7803 - auc: 0.8595 - loss: 0.4598 - val_acc: 0.7947 - val_auc: 0.8715 - val_loss: 0.4414\n",
      "Epoch 4988/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7760 - auc: 0.8567 - loss: 0.4633 - val_acc: 0.7936 - val_auc: 0.8705 - val_loss: 0.4412\n",
      "Epoch 4989/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7784 - auc: 0.8603 - loss: 0.4590 - val_acc: 0.7957 - val_auc: 0.8708 - val_loss: 0.4421\n",
      "Epoch 4990/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7789 - auc: 0.8593 - loss: 0.4586 - val_acc: 0.7919 - val_auc: 0.8719 - val_loss: 0.4404\n",
      "Epoch 4991/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7805 - auc: 0.8596 - loss: 0.4579 - val_acc: 0.7951 - val_auc: 0.8713 - val_loss: 0.4403\n",
      "Epoch 4992/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7807 - auc: 0.8593 - loss: 0.4595 - val_acc: 0.7905 - val_auc: 0.8693 - val_loss: 0.4436\n",
      "Epoch 4993/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7796 - auc: 0.8584 - loss: 0.4604 - val_acc: 0.7895 - val_auc: 0.8701 - val_loss: 0.4451\n",
      "Epoch 4994/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7780 - auc: 0.8560 - loss: 0.4648 - val_acc: 0.7948 - val_auc: 0.8715 - val_loss: 0.4408\n",
      "Epoch 4995/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7802 - auc: 0.8591 - loss: 0.4588 - val_acc: 0.7966 - val_auc: 0.8716 - val_loss: 0.4396\n",
      "Epoch 4996/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7790 - auc: 0.8591 - loss: 0.4607 - val_acc: 0.7927 - val_auc: 0.8712 - val_loss: 0.4411\n",
      "Epoch 4997/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7791 - auc: 0.8574 - loss: 0.4608 - val_acc: 0.7933 - val_auc: 0.8706 - val_loss: 0.4410\n",
      "Epoch 4998/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7770 - auc: 0.8577 - loss: 0.4621 - val_acc: 0.7907 - val_auc: 0.8699 - val_loss: 0.4432\n",
      "Epoch 4999/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7781 - auc: 0.8576 - loss: 0.4603 - val_acc: 0.7929 - val_auc: 0.8703 - val_loss: 0.4419\n",
      "Epoch 5000/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7774 - auc: 0.8584 - loss: 0.4606 - val_acc: 0.7942 - val_auc: 0.8711 - val_loss: 0.4407\n",
      "Epoch 5001/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7775 - auc: 0.8583 - loss: 0.4609 - val_acc: 0.7929 - val_auc: 0.8714 - val_loss: 0.4416\n",
      "Epoch 5002/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7789 - auc: 0.8591 - loss: 0.4595 - val_acc: 0.7932 - val_auc: 0.8713 - val_loss: 0.4423\n",
      "Epoch 5003/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7780 - auc: 0.8580 - loss: 0.4620 - val_acc: 0.7918 - val_auc: 0.8709 - val_loss: 0.4427\n",
      "Epoch 5004/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7775 - auc: 0.8577 - loss: 0.4622 - val_acc: 0.7927 - val_auc: 0.8714 - val_loss: 0.4424\n",
      "Epoch 5005/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7826 - auc: 0.8600 - loss: 0.4596 - val_acc: 0.7943 - val_auc: 0.8717 - val_loss: 0.4404\n",
      "Epoch 5006/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7785 - auc: 0.8581 - loss: 0.4610 - val_acc: 0.7934 - val_auc: 0.8704 - val_loss: 0.4408\n",
      "Epoch 5007/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7803 - auc: 0.8586 - loss: 0.4598 - val_acc: 0.7942 - val_auc: 0.8726 - val_loss: 0.4394\n",
      "Epoch 5008/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7786 - auc: 0.8579 - loss: 0.4613 - val_acc: 0.7903 - val_auc: 0.8703 - val_loss: 0.4429\n",
      "Epoch 5009/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7783 - auc: 0.8580 - loss: 0.4607 - val_acc: 0.7904 - val_auc: 0.8715 - val_loss: 0.4423\n",
      "Epoch 5010/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7778 - auc: 0.8584 - loss: 0.4607 - val_acc: 0.7923 - val_auc: 0.8695 - val_loss: 0.4428\n",
      "Epoch 5011/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7788 - auc: 0.8585 - loss: 0.4600 - val_acc: 0.7937 - val_auc: 0.8720 - val_loss: 0.4408\n",
      "Epoch 5012/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7792 - auc: 0.8586 - loss: 0.4605 - val_acc: 0.7920 - val_auc: 0.8696 - val_loss: 0.4433\n",
      "Epoch 5013/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7780 - auc: 0.8588 - loss: 0.4601 - val_acc: 0.7951 - val_auc: 0.8721 - val_loss: 0.4400\n",
      "Epoch 5014/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7762 - auc: 0.8566 - loss: 0.4642 - val_acc: 0.7938 - val_auc: 0.8710 - val_loss: 0.4413\n",
      "Epoch 5015/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7810 - auc: 0.8597 - loss: 0.4585 - val_acc: 0.7963 - val_auc: 0.8721 - val_loss: 0.4410\n",
      "Epoch 5016/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7775 - auc: 0.8580 - loss: 0.4602 - val_acc: 0.7936 - val_auc: 0.8707 - val_loss: 0.4421\n",
      "Epoch 5017/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7804 - auc: 0.8592 - loss: 0.4599 - val_acc: 0.7919 - val_auc: 0.8704 - val_loss: 0.4425\n",
      "Epoch 5018/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7787 - auc: 0.8586 - loss: 0.4614 - val_acc: 0.7892 - val_auc: 0.8709 - val_loss: 0.4446\n",
      "Epoch 5019/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7795 - auc: 0.8595 - loss: 0.4589 - val_acc: 0.7918 - val_auc: 0.8700 - val_loss: 0.4429\n",
      "Epoch 5020/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7776 - auc: 0.8584 - loss: 0.4607 - val_acc: 0.7926 - val_auc: 0.8710 - val_loss: 0.4405\n",
      "Epoch 5021/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7821 - auc: 0.8599 - loss: 0.4598 - val_acc: 0.7943 - val_auc: 0.8720 - val_loss: 0.4404\n",
      "Epoch 5022/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7761 - auc: 0.8571 - loss: 0.4623 - val_acc: 0.7947 - val_auc: 0.8710 - val_loss: 0.4410\n",
      "Epoch 5023/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7791 - auc: 0.8589 - loss: 0.4608 - val_acc: 0.7919 - val_auc: 0.8715 - val_loss: 0.4406\n",
      "Epoch 5024/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7783 - auc: 0.8586 - loss: 0.4598 - val_acc: 0.7949 - val_auc: 0.8720 - val_loss: 0.4402\n",
      "Epoch 5025/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7784 - auc: 0.8582 - loss: 0.4607 - val_acc: 0.7930 - val_auc: 0.8711 - val_loss: 0.4407\n",
      "Epoch 5026/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7816 - auc: 0.8600 - loss: 0.4587 - val_acc: 0.7940 - val_auc: 0.8714 - val_loss: 0.4397\n",
      "Epoch 5027/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7781 - auc: 0.8581 - loss: 0.4599 - val_acc: 0.7934 - val_auc: 0.8710 - val_loss: 0.4408\n",
      "Epoch 5028/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7796 - auc: 0.8593 - loss: 0.4596 - val_acc: 0.7933 - val_auc: 0.8692 - val_loss: 0.4422\n",
      "Epoch 5029/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7796 - auc: 0.8597 - loss: 0.4599 - val_acc: 0.7948 - val_auc: 0.8723 - val_loss: 0.4407\n",
      "Epoch 5030/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7786 - auc: 0.8582 - loss: 0.4616 - val_acc: 0.7931 - val_auc: 0.8710 - val_loss: 0.4429\n",
      "Epoch 5031/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7767 - auc: 0.8575 - loss: 0.4614 - val_acc: 0.7952 - val_auc: 0.8719 - val_loss: 0.4402\n",
      "Epoch 5032/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7814 - auc: 0.8607 - loss: 0.4581 - val_acc: 0.7946 - val_auc: 0.8718 - val_loss: 0.4401\n",
      "Epoch 5033/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7771 - auc: 0.8572 - loss: 0.4613 - val_acc: 0.7931 - val_auc: 0.8705 - val_loss: 0.4425\n",
      "Epoch 5034/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7808 - auc: 0.8602 - loss: 0.4580 - val_acc: 0.7931 - val_auc: 0.8722 - val_loss: 0.4410\n",
      "Epoch 5035/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7809 - auc: 0.8589 - loss: 0.4599 - val_acc: 0.7932 - val_auc: 0.8694 - val_loss: 0.4429\n",
      "Epoch 5036/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7782 - auc: 0.8585 - loss: 0.4600 - val_acc: 0.7932 - val_auc: 0.8703 - val_loss: 0.4423\n",
      "Epoch 5037/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7783 - auc: 0.8575 - loss: 0.4624 - val_acc: 0.7927 - val_auc: 0.8712 - val_loss: 0.4414\n",
      "Epoch 5038/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7796 - auc: 0.8588 - loss: 0.4597 - val_acc: 0.7936 - val_auc: 0.8711 - val_loss: 0.4416\n",
      "Epoch 5039/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7799 - auc: 0.8589 - loss: 0.4610 - val_acc: 0.7964 - val_auc: 0.8719 - val_loss: 0.4411\n",
      "Epoch 5040/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7787 - auc: 0.8588 - loss: 0.4607 - val_acc: 0.7921 - val_auc: 0.8707 - val_loss: 0.4427\n",
      "Epoch 5041/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7808 - auc: 0.8592 - loss: 0.4600 - val_acc: 0.7925 - val_auc: 0.8703 - val_loss: 0.4407\n",
      "Epoch 5042/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7788 - auc: 0.8586 - loss: 0.4595 - val_acc: 0.7964 - val_auc: 0.8717 - val_loss: 0.4395\n",
      "Epoch 5043/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7785 - auc: 0.8579 - loss: 0.4621 - val_acc: 0.7960 - val_auc: 0.8704 - val_loss: 0.4410\n",
      "Epoch 5044/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7784 - auc: 0.8583 - loss: 0.4611 - val_acc: 0.7929 - val_auc: 0.8713 - val_loss: 0.4424\n",
      "Epoch 5045/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7773 - auc: 0.8568 - loss: 0.4629 - val_acc: 0.7902 - val_auc: 0.8704 - val_loss: 0.4431\n",
      "Epoch 5046/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7782 - auc: 0.8577 - loss: 0.4617 - val_acc: 0.7940 - val_auc: 0.8721 - val_loss: 0.4404\n",
      "Epoch 5047/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7782 - auc: 0.8594 - loss: 0.4585 - val_acc: 0.7890 - val_auc: 0.8698 - val_loss: 0.4427\n",
      "Epoch 5048/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7781 - auc: 0.8580 - loss: 0.4615 - val_acc: 0.7917 - val_auc: 0.8717 - val_loss: 0.4442\n",
      "Epoch 5049/7000\n",
      "106/106 - 2s - 14ms/step - acc: 0.7796 - auc: 0.8592 - loss: 0.4591 - val_acc: 0.7937 - val_auc: 0.8716 - val_loss: 0.4406\n",
      "Epoch 5050/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7772 - auc: 0.8573 - loss: 0.4622 - val_acc: 0.7927 - val_auc: 0.8717 - val_loss: 0.4433\n",
      "Epoch 5051/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7815 - auc: 0.8606 - loss: 0.4577 - val_acc: 0.7919 - val_auc: 0.8694 - val_loss: 0.4427\n",
      "Epoch 5052/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7806 - auc: 0.8580 - loss: 0.4599 - val_acc: 0.7956 - val_auc: 0.8719 - val_loss: 0.4406\n",
      "Epoch 5053/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7789 - auc: 0.8585 - loss: 0.4603 - val_acc: 0.7936 - val_auc: 0.8708 - val_loss: 0.4408\n",
      "Epoch 5054/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7796 - auc: 0.8586 - loss: 0.4608 - val_acc: 0.7924 - val_auc: 0.8711 - val_loss: 0.4425\n",
      "Epoch 5055/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7809 - auc: 0.8598 - loss: 0.4586 - val_acc: 0.7921 - val_auc: 0.8708 - val_loss: 0.4413\n",
      "Epoch 5056/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7784 - auc: 0.8582 - loss: 0.4612 - val_acc: 0.7934 - val_auc: 0.8718 - val_loss: 0.4402\n",
      "Epoch 5057/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7808 - auc: 0.8596 - loss: 0.4594 - val_acc: 0.7942 - val_auc: 0.8717 - val_loss: 0.4404\n",
      "Epoch 5058/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7788 - auc: 0.8597 - loss: 0.4597 - val_acc: 0.7963 - val_auc: 0.8730 - val_loss: 0.4389\n",
      "Epoch 5059/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7789 - auc: 0.8584 - loss: 0.4608 - val_acc: 0.7925 - val_auc: 0.8710 - val_loss: 0.4423\n",
      "Epoch 5060/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7782 - auc: 0.8577 - loss: 0.4623 - val_acc: 0.7915 - val_auc: 0.8701 - val_loss: 0.4448\n",
      "Epoch 5061/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7784 - auc: 0.8589 - loss: 0.4591 - val_acc: 0.7916 - val_auc: 0.8705 - val_loss: 0.4416\n",
      "Epoch 5062/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7793 - auc: 0.8581 - loss: 0.4610 - val_acc: 0.7943 - val_auc: 0.8719 - val_loss: 0.4407\n",
      "Epoch 5063/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7799 - auc: 0.8589 - loss: 0.4603 - val_acc: 0.7913 - val_auc: 0.8706 - val_loss: 0.4423\n",
      "Epoch 5064/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7800 - auc: 0.8590 - loss: 0.4590 - val_acc: 0.7920 - val_auc: 0.8711 - val_loss: 0.4406\n",
      "Epoch 5065/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7782 - auc: 0.8588 - loss: 0.4596 - val_acc: 0.7934 - val_auc: 0.8708 - val_loss: 0.4416\n",
      "Epoch 5066/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7772 - auc: 0.8575 - loss: 0.4622 - val_acc: 0.7950 - val_auc: 0.8707 - val_loss: 0.4423\n",
      "Epoch 5067/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7802 - auc: 0.8588 - loss: 0.4608 - val_acc: 0.7944 - val_auc: 0.8695 - val_loss: 0.4420\n",
      "Epoch 5068/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7751 - auc: 0.8564 - loss: 0.4652 - val_acc: 0.7907 - val_auc: 0.8697 - val_loss: 0.4444\n",
      "Epoch 5069/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7796 - auc: 0.8589 - loss: 0.4602 - val_acc: 0.7909 - val_auc: 0.8713 - val_loss: 0.4419\n",
      "Epoch 5070/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7767 - auc: 0.8581 - loss: 0.4604 - val_acc: 0.7937 - val_auc: 0.8697 - val_loss: 0.4420\n",
      "Epoch 5071/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7795 - auc: 0.8579 - loss: 0.4611 - val_acc: 0.7921 - val_auc: 0.8706 - val_loss: 0.4422\n",
      "Epoch 5072/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7771 - auc: 0.8579 - loss: 0.4611 - val_acc: 0.7900 - val_auc: 0.8697 - val_loss: 0.4436\n",
      "Epoch 5073/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7782 - auc: 0.8591 - loss: 0.4584 - val_acc: 0.7918 - val_auc: 0.8713 - val_loss: 0.4404\n",
      "Epoch 5074/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7808 - auc: 0.8588 - loss: 0.4603 - val_acc: 0.7933 - val_auc: 0.8712 - val_loss: 0.4418\n",
      "Epoch 5075/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7782 - auc: 0.8585 - loss: 0.4599 - val_acc: 0.7919 - val_auc: 0.8707 - val_loss: 0.4414\n",
      "Epoch 5076/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7800 - auc: 0.8592 - loss: 0.4590 - val_acc: 0.7946 - val_auc: 0.8714 - val_loss: 0.4419\n",
      "Epoch 5077/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7789 - auc: 0.8581 - loss: 0.4611 - val_acc: 0.7918 - val_auc: 0.8708 - val_loss: 0.4420\n",
      "Epoch 5078/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7763 - auc: 0.8584 - loss: 0.4606 - val_acc: 0.7915 - val_auc: 0.8702 - val_loss: 0.4431\n",
      "Epoch 5079/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7793 - auc: 0.8592 - loss: 0.4604 - val_acc: 0.7941 - val_auc: 0.8716 - val_loss: 0.4398\n",
      "Epoch 5080/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7778 - auc: 0.8584 - loss: 0.4606 - val_acc: 0.7907 - val_auc: 0.8708 - val_loss: 0.4405\n",
      "Epoch 5081/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7791 - auc: 0.8591 - loss: 0.4597 - val_acc: 0.7960 - val_auc: 0.8725 - val_loss: 0.4397\n",
      "Epoch 5082/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7804 - auc: 0.8587 - loss: 0.4605 - val_acc: 0.7925 - val_auc: 0.8707 - val_loss: 0.4409\n",
      "Epoch 5083/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7781 - auc: 0.8569 - loss: 0.4622 - val_acc: 0.7905 - val_auc: 0.8709 - val_loss: 0.4438\n",
      "Epoch 5084/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7815 - auc: 0.8597 - loss: 0.4589 - val_acc: 0.7963 - val_auc: 0.8724 - val_loss: 0.4396\n",
      "Epoch 5085/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7792 - auc: 0.8577 - loss: 0.4620 - val_acc: 0.7943 - val_auc: 0.8714 - val_loss: 0.4412\n",
      "Epoch 5086/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7800 - auc: 0.8588 - loss: 0.4603 - val_acc: 0.7927 - val_auc: 0.8707 - val_loss: 0.4426\n",
      "Epoch 5087/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7775 - auc: 0.8582 - loss: 0.4612 - val_acc: 0.7948 - val_auc: 0.8720 - val_loss: 0.4391\n",
      "Epoch 5088/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7795 - auc: 0.8581 - loss: 0.4601 - val_acc: 0.7903 - val_auc: 0.8696 - val_loss: 0.4436\n",
      "Epoch 5089/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7793 - auc: 0.8590 - loss: 0.4591 - val_acc: 0.7918 - val_auc: 0.8711 - val_loss: 0.4426\n",
      "Epoch 5090/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7774 - auc: 0.8594 - loss: 0.4592 - val_acc: 0.7927 - val_auc: 0.8706 - val_loss: 0.4422\n",
      "Epoch 5091/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7782 - auc: 0.8584 - loss: 0.4605 - val_acc: 0.7956 - val_auc: 0.8710 - val_loss: 0.4409\n",
      "Epoch 5092/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7787 - auc: 0.8577 - loss: 0.4620 - val_acc: 0.7936 - val_auc: 0.8716 - val_loss: 0.4428\n",
      "Epoch 5093/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7788 - auc: 0.8582 - loss: 0.4609 - val_acc: 0.7939 - val_auc: 0.8714 - val_loss: 0.4417\n",
      "Epoch 5094/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7798 - auc: 0.8592 - loss: 0.4604 - val_acc: 0.7919 - val_auc: 0.8717 - val_loss: 0.4404\n",
      "Epoch 5095/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7799 - auc: 0.8593 - loss: 0.4591 - val_acc: 0.7931 - val_auc: 0.8707 - val_loss: 0.4424\n",
      "Epoch 5096/7000\n",
      "106/106 - 2s - 14ms/step - acc: 0.7788 - auc: 0.8584 - loss: 0.4599 - val_acc: 0.7949 - val_auc: 0.8714 - val_loss: 0.4403\n",
      "Epoch 5097/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7793 - auc: 0.8574 - loss: 0.4621 - val_acc: 0.7933 - val_auc: 0.8708 - val_loss: 0.4420\n",
      "Epoch 5098/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7815 - auc: 0.8599 - loss: 0.4581 - val_acc: 0.7930 - val_auc: 0.8710 - val_loss: 0.4425\n",
      "Epoch 5099/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7789 - auc: 0.8581 - loss: 0.4607 - val_acc: 0.7930 - val_auc: 0.8705 - val_loss: 0.4423\n",
      "Epoch 5100/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7795 - auc: 0.8584 - loss: 0.4605 - val_acc: 0.7913 - val_auc: 0.8704 - val_loss: 0.4438\n",
      "Epoch 5101/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7773 - auc: 0.8586 - loss: 0.4605 - val_acc: 0.7924 - val_auc: 0.8699 - val_loss: 0.4423\n",
      "Epoch 5102/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7787 - auc: 0.8591 - loss: 0.4593 - val_acc: 0.7879 - val_auc: 0.8702 - val_loss: 0.4417\n",
      "Epoch 5103/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7777 - auc: 0.8577 - loss: 0.4621 - val_acc: 0.7931 - val_auc: 0.8712 - val_loss: 0.4399\n",
      "Epoch 5104/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7759 - auc: 0.8565 - loss: 0.4636 - val_acc: 0.7916 - val_auc: 0.8705 - val_loss: 0.4435\n",
      "Epoch 5105/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7793 - auc: 0.8598 - loss: 0.4588 - val_acc: 0.7949 - val_auc: 0.8720 - val_loss: 0.4403\n",
      "Epoch 5106/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7790 - auc: 0.8588 - loss: 0.4612 - val_acc: 0.7936 - val_auc: 0.8717 - val_loss: 0.4409\n",
      "Epoch 5107/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7791 - auc: 0.8589 - loss: 0.4602 - val_acc: 0.7933 - val_auc: 0.8718 - val_loss: 0.4397\n",
      "Epoch 5108/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7763 - auc: 0.8576 - loss: 0.4618 - val_acc: 0.7948 - val_auc: 0.8710 - val_loss: 0.4416\n",
      "Epoch 5109/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7790 - auc: 0.8590 - loss: 0.4602 - val_acc: 0.7946 - val_auc: 0.8723 - val_loss: 0.4397\n",
      "Epoch 5110/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7776 - auc: 0.8581 - loss: 0.4604 - val_acc: 0.7933 - val_auc: 0.8723 - val_loss: 0.4421\n",
      "Epoch 5111/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7775 - auc: 0.8581 - loss: 0.4624 - val_acc: 0.7924 - val_auc: 0.8709 - val_loss: 0.4432\n",
      "Epoch 5112/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7810 - auc: 0.8597 - loss: 0.4587 - val_acc: 0.7941 - val_auc: 0.8712 - val_loss: 0.4406\n",
      "Epoch 5113/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7795 - auc: 0.8590 - loss: 0.4596 - val_acc: 0.7916 - val_auc: 0.8720 - val_loss: 0.4414\n",
      "Epoch 5114/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7798 - auc: 0.8584 - loss: 0.4605 - val_acc: 0.7945 - val_auc: 0.8712 - val_loss: 0.4390\n",
      "Epoch 5115/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7782 - auc: 0.8581 - loss: 0.4603 - val_acc: 0.7923 - val_auc: 0.8720 - val_loss: 0.4408\n",
      "Epoch 5116/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7816 - auc: 0.8593 - loss: 0.4590 - val_acc: 0.7915 - val_auc: 0.8712 - val_loss: 0.4413\n",
      "Epoch 5117/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7794 - auc: 0.8596 - loss: 0.4584 - val_acc: 0.7950 - val_auc: 0.8715 - val_loss: 0.4391\n",
      "Epoch 5118/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7781 - auc: 0.8572 - loss: 0.4621 - val_acc: 0.7939 - val_auc: 0.8715 - val_loss: 0.4407\n",
      "Epoch 5119/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7802 - auc: 0.8601 - loss: 0.4579 - val_acc: 0.7908 - val_auc: 0.8696 - val_loss: 0.4427\n",
      "Epoch 5120/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7790 - auc: 0.8580 - loss: 0.4603 - val_acc: 0.7941 - val_auc: 0.8718 - val_loss: 0.4413\n",
      "Epoch 5121/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7786 - auc: 0.8593 - loss: 0.4591 - val_acc: 0.7948 - val_auc: 0.8709 - val_loss: 0.4417\n",
      "Epoch 5122/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7809 - auc: 0.8597 - loss: 0.4595 - val_acc: 0.7942 - val_auc: 0.8713 - val_loss: 0.4406\n",
      "Epoch 5123/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7765 - auc: 0.8568 - loss: 0.4620 - val_acc: 0.7913 - val_auc: 0.8710 - val_loss: 0.4434\n",
      "Epoch 5124/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7778 - auc: 0.8589 - loss: 0.4609 - val_acc: 0.7902 - val_auc: 0.8714 - val_loss: 0.4429\n",
      "Epoch 5125/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7782 - auc: 0.8574 - loss: 0.4618 - val_acc: 0.7938 - val_auc: 0.8703 - val_loss: 0.4420\n",
      "Epoch 5126/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7809 - auc: 0.8604 - loss: 0.4585 - val_acc: 0.7953 - val_auc: 0.8708 - val_loss: 0.4412\n",
      "Epoch 5127/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7770 - auc: 0.8580 - loss: 0.4621 - val_acc: 0.7953 - val_auc: 0.8701 - val_loss: 0.4404\n",
      "Epoch 5128/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7785 - auc: 0.8577 - loss: 0.4593 - val_acc: 0.7951 - val_auc: 0.8710 - val_loss: 0.4409\n",
      "Epoch 5129/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7820 - auc: 0.8598 - loss: 0.4589 - val_acc: 0.7926 - val_auc: 0.8718 - val_loss: 0.4413\n",
      "Epoch 5130/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7816 - auc: 0.8596 - loss: 0.4579 - val_acc: 0.7907 - val_auc: 0.8707 - val_loss: 0.4425\n",
      "Epoch 5131/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7804 - auc: 0.8600 - loss: 0.4588 - val_acc: 0.7951 - val_auc: 0.8711 - val_loss: 0.4401\n",
      "Epoch 5132/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7789 - auc: 0.8582 - loss: 0.4613 - val_acc: 0.7921 - val_auc: 0.8706 - val_loss: 0.4410\n",
      "Epoch 5133/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7809 - auc: 0.8607 - loss: 0.4574 - val_acc: 0.7934 - val_auc: 0.8705 - val_loss: 0.4402\n",
      "Epoch 5134/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7794 - auc: 0.8581 - loss: 0.4606 - val_acc: 0.7935 - val_auc: 0.8703 - val_loss: 0.4411\n",
      "Epoch 5135/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7785 - auc: 0.8579 - loss: 0.4611 - val_acc: 0.7939 - val_auc: 0.8702 - val_loss: 0.4408\n",
      "Epoch 5136/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7788 - auc: 0.8586 - loss: 0.4604 - val_acc: 0.7921 - val_auc: 0.8718 - val_loss: 0.4438\n",
      "Epoch 5137/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7785 - auc: 0.8576 - loss: 0.4620 - val_acc: 0.7927 - val_auc: 0.8700 - val_loss: 0.4427\n",
      "Epoch 5138/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7785 - auc: 0.8579 - loss: 0.4608 - val_acc: 0.7966 - val_auc: 0.8717 - val_loss: 0.4392\n",
      "Epoch 5139/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7795 - auc: 0.8595 - loss: 0.4592 - val_acc: 0.7946 - val_auc: 0.8715 - val_loss: 0.4407\n",
      "Epoch 5140/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7785 - auc: 0.8583 - loss: 0.4613 - val_acc: 0.7907 - val_auc: 0.8713 - val_loss: 0.4442\n",
      "Epoch 5141/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7806 - auc: 0.8593 - loss: 0.4608 - val_acc: 0.7947 - val_auc: 0.8713 - val_loss: 0.4427\n",
      "Epoch 5142/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7802 - auc: 0.8582 - loss: 0.4609 - val_acc: 0.7962 - val_auc: 0.8716 - val_loss: 0.4421\n",
      "Epoch 5143/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7785 - auc: 0.8585 - loss: 0.4600 - val_acc: 0.7961 - val_auc: 0.8730 - val_loss: 0.4395\n",
      "Epoch 5144/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7780 - auc: 0.8576 - loss: 0.4609 - val_acc: 0.7943 - val_auc: 0.8724 - val_loss: 0.4413\n",
      "Epoch 5145/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7796 - auc: 0.8586 - loss: 0.4611 - val_acc: 0.7923 - val_auc: 0.8715 - val_loss: 0.4404\n",
      "Epoch 5146/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7785 - auc: 0.8578 - loss: 0.4612 - val_acc: 0.7965 - val_auc: 0.8721 - val_loss: 0.4406\n",
      "Epoch 5147/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7794 - auc: 0.8586 - loss: 0.4607 - val_acc: 0.7947 - val_auc: 0.8708 - val_loss: 0.4424\n",
      "Epoch 5148/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7791 - auc: 0.8578 - loss: 0.4614 - val_acc: 0.7917 - val_auc: 0.8706 - val_loss: 0.4433\n",
      "Epoch 5149/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7815 - auc: 0.8601 - loss: 0.4577 - val_acc: 0.7952 - val_auc: 0.8723 - val_loss: 0.4381\n",
      "Epoch 5150/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7782 - auc: 0.8596 - loss: 0.4598 - val_acc: 0.7935 - val_auc: 0.8718 - val_loss: 0.4408\n",
      "Epoch 5151/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7793 - auc: 0.8580 - loss: 0.4613 - val_acc: 0.7912 - val_auc: 0.8717 - val_loss: 0.4419\n",
      "Epoch 5152/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7789 - auc: 0.8580 - loss: 0.4609 - val_acc: 0.7908 - val_auc: 0.8710 - val_loss: 0.4424\n",
      "Epoch 5153/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7767 - auc: 0.8580 - loss: 0.4607 - val_acc: 0.7931 - val_auc: 0.8707 - val_loss: 0.4411\n",
      "Epoch 5154/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7797 - auc: 0.8590 - loss: 0.4587 - val_acc: 0.7973 - val_auc: 0.8721 - val_loss: 0.4400\n",
      "Epoch 5155/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7783 - auc: 0.8590 - loss: 0.4598 - val_acc: 0.7956 - val_auc: 0.8717 - val_loss: 0.4396\n",
      "Epoch 5156/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8599 - loss: 0.4582 - val_acc: 0.7920 - val_auc: 0.8715 - val_loss: 0.4411\n",
      "Epoch 5157/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7774 - auc: 0.8580 - loss: 0.4617 - val_acc: 0.7938 - val_auc: 0.8717 - val_loss: 0.4423\n",
      "Epoch 5158/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7784 - auc: 0.8583 - loss: 0.4611 - val_acc: 0.7926 - val_auc: 0.8720 - val_loss: 0.4403\n",
      "Epoch 5159/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7810 - auc: 0.8585 - loss: 0.4596 - val_acc: 0.7939 - val_auc: 0.8716 - val_loss: 0.4398\n",
      "Epoch 5160/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7781 - auc: 0.8582 - loss: 0.4615 - val_acc: 0.7950 - val_auc: 0.8720 - val_loss: 0.4409\n",
      "Epoch 5161/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7784 - auc: 0.8576 - loss: 0.4617 - val_acc: 0.7952 - val_auc: 0.8730 - val_loss: 0.4393\n",
      "Epoch 5162/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7832 - auc: 0.8617 - loss: 0.4569 - val_acc: 0.7910 - val_auc: 0.8708 - val_loss: 0.4415\n",
      "Epoch 5163/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7788 - auc: 0.8590 - loss: 0.4602 - val_acc: 0.7974 - val_auc: 0.8726 - val_loss: 0.4391\n",
      "Epoch 5164/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7797 - auc: 0.8590 - loss: 0.4602 - val_acc: 0.7946 - val_auc: 0.8719 - val_loss: 0.4404\n",
      "Epoch 5165/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7780 - auc: 0.8576 - loss: 0.4618 - val_acc: 0.7934 - val_auc: 0.8710 - val_loss: 0.4412\n",
      "Epoch 5166/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7808 - auc: 0.8600 - loss: 0.4585 - val_acc: 0.7971 - val_auc: 0.8728 - val_loss: 0.4393\n",
      "Epoch 5167/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7787 - auc: 0.8587 - loss: 0.4599 - val_acc: 0.7960 - val_auc: 0.8719 - val_loss: 0.4400\n",
      "Epoch 5168/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7788 - auc: 0.8595 - loss: 0.4583 - val_acc: 0.7947 - val_auc: 0.8717 - val_loss: 0.4383\n",
      "Epoch 5169/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7815 - auc: 0.8603 - loss: 0.4584 - val_acc: 0.7923 - val_auc: 0.8720 - val_loss: 0.4404\n",
      "Epoch 5170/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7818 - auc: 0.8607 - loss: 0.4574 - val_acc: 0.7939 - val_auc: 0.8703 - val_loss: 0.4423\n",
      "Epoch 5171/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7802 - auc: 0.8574 - loss: 0.4619 - val_acc: 0.7925 - val_auc: 0.8705 - val_loss: 0.4410\n",
      "Epoch 5172/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7806 - auc: 0.8597 - loss: 0.4580 - val_acc: 0.7942 - val_auc: 0.8714 - val_loss: 0.4395\n",
      "Epoch 5173/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7805 - auc: 0.8593 - loss: 0.4593 - val_acc: 0.7937 - val_auc: 0.8713 - val_loss: 0.4411\n",
      "Epoch 5174/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8595 - loss: 0.4593 - val_acc: 0.7931 - val_auc: 0.8709 - val_loss: 0.4401\n",
      "Epoch 5175/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7809 - auc: 0.8599 - loss: 0.4587 - val_acc: 0.7962 - val_auc: 0.8726 - val_loss: 0.4389\n",
      "Epoch 5176/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7780 - auc: 0.8575 - loss: 0.4612 - val_acc: 0.7952 - val_auc: 0.8716 - val_loss: 0.4403\n",
      "Epoch 5177/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7799 - auc: 0.8578 - loss: 0.4602 - val_acc: 0.7935 - val_auc: 0.8702 - val_loss: 0.4413\n",
      "Epoch 5178/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7806 - auc: 0.8594 - loss: 0.4589 - val_acc: 0.7931 - val_auc: 0.8719 - val_loss: 0.4401\n",
      "Epoch 5179/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7793 - auc: 0.8581 - loss: 0.4607 - val_acc: 0.7952 - val_auc: 0.8723 - val_loss: 0.4401\n",
      "Epoch 5180/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7789 - auc: 0.8579 - loss: 0.4614 - val_acc: 0.7934 - val_auc: 0.8713 - val_loss: 0.4406\n",
      "Epoch 5181/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7796 - auc: 0.8583 - loss: 0.4606 - val_acc: 0.7939 - val_auc: 0.8713 - val_loss: 0.4421\n",
      "Epoch 5182/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7798 - auc: 0.8588 - loss: 0.4593 - val_acc: 0.7918 - val_auc: 0.8711 - val_loss: 0.4427\n",
      "Epoch 5183/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7783 - auc: 0.8587 - loss: 0.4601 - val_acc: 0.7931 - val_auc: 0.8702 - val_loss: 0.4415\n",
      "Epoch 5184/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7796 - auc: 0.8590 - loss: 0.4604 - val_acc: 0.7939 - val_auc: 0.8712 - val_loss: 0.4422\n",
      "Epoch 5185/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7788 - auc: 0.8582 - loss: 0.4615 - val_acc: 0.7883 - val_auc: 0.8687 - val_loss: 0.4452\n",
      "Epoch 5186/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7784 - auc: 0.8579 - loss: 0.4618 - val_acc: 0.7952 - val_auc: 0.8720 - val_loss: 0.4409\n",
      "Epoch 5187/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7794 - auc: 0.8601 - loss: 0.4578 - val_acc: 0.7959 - val_auc: 0.8724 - val_loss: 0.4400\n",
      "Epoch 5188/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7802 - auc: 0.8587 - loss: 0.4606 - val_acc: 0.7954 - val_auc: 0.8718 - val_loss: 0.4408\n",
      "Epoch 5189/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7802 - auc: 0.8590 - loss: 0.4602 - val_acc: 0.7916 - val_auc: 0.8710 - val_loss: 0.4407\n",
      "Epoch 5190/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7797 - auc: 0.8593 - loss: 0.4596 - val_acc: 0.7939 - val_auc: 0.8712 - val_loss: 0.4403\n",
      "Epoch 5191/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7787 - auc: 0.8596 - loss: 0.4596 - val_acc: 0.7915 - val_auc: 0.8719 - val_loss: 0.4408\n",
      "Epoch 5192/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7790 - auc: 0.8585 - loss: 0.4611 - val_acc: 0.7912 - val_auc: 0.8704 - val_loss: 0.4423\n",
      "Epoch 5193/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7779 - auc: 0.8588 - loss: 0.4603 - val_acc: 0.7925 - val_auc: 0.8720 - val_loss: 0.4409\n",
      "Epoch 5194/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7778 - auc: 0.8583 - loss: 0.4603 - val_acc: 0.7934 - val_auc: 0.8721 - val_loss: 0.4406\n",
      "Epoch 5195/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7775 - auc: 0.8597 - loss: 0.4590 - val_acc: 0.7966 - val_auc: 0.8719 - val_loss: 0.4421\n",
      "Epoch 5196/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7790 - auc: 0.8593 - loss: 0.4592 - val_acc: 0.7955 - val_auc: 0.8721 - val_loss: 0.4394\n",
      "Epoch 5197/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7799 - auc: 0.8595 - loss: 0.4595 - val_acc: 0.7948 - val_auc: 0.8706 - val_loss: 0.4397\n",
      "Epoch 5198/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7790 - auc: 0.8589 - loss: 0.4602 - val_acc: 0.7939 - val_auc: 0.8706 - val_loss: 0.4405\n",
      "Epoch 5199/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7808 - auc: 0.8600 - loss: 0.4585 - val_acc: 0.7927 - val_auc: 0.8716 - val_loss: 0.4418\n",
      "Epoch 5200/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7804 - auc: 0.8601 - loss: 0.4583 - val_acc: 0.7924 - val_auc: 0.8702 - val_loss: 0.4394\n",
      "Epoch 5201/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7793 - auc: 0.8592 - loss: 0.4599 - val_acc: 0.7930 - val_auc: 0.8711 - val_loss: 0.4410\n",
      "Epoch 5202/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7779 - auc: 0.8585 - loss: 0.4598 - val_acc: 0.7936 - val_auc: 0.8704 - val_loss: 0.4415\n",
      "Epoch 5203/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7790 - auc: 0.8591 - loss: 0.4598 - val_acc: 0.7944 - val_auc: 0.8715 - val_loss: 0.4409\n",
      "Epoch 5204/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7777 - auc: 0.8581 - loss: 0.4614 - val_acc: 0.7921 - val_auc: 0.8712 - val_loss: 0.4421\n",
      "Epoch 5205/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7802 - auc: 0.8598 - loss: 0.4585 - val_acc: 0.7903 - val_auc: 0.8710 - val_loss: 0.4410\n",
      "Epoch 5206/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7787 - auc: 0.8582 - loss: 0.4604 - val_acc: 0.7970 - val_auc: 0.8722 - val_loss: 0.4398\n",
      "Epoch 5207/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7765 - auc: 0.8563 - loss: 0.4634 - val_acc: 0.7931 - val_auc: 0.8725 - val_loss: 0.4408\n",
      "Epoch 5208/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7779 - auc: 0.8594 - loss: 0.4594 - val_acc: 0.7922 - val_auc: 0.8709 - val_loss: 0.4421\n",
      "Epoch 5209/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7791 - auc: 0.8592 - loss: 0.4601 - val_acc: 0.7942 - val_auc: 0.8716 - val_loss: 0.4397\n",
      "Epoch 5210/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7783 - auc: 0.8590 - loss: 0.4596 - val_acc: 0.7925 - val_auc: 0.8716 - val_loss: 0.4398\n",
      "Epoch 5211/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7786 - auc: 0.8590 - loss: 0.4597 - val_acc: 0.7940 - val_auc: 0.8730 - val_loss: 0.4400\n",
      "Epoch 5212/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7797 - auc: 0.8585 - loss: 0.4611 - val_acc: 0.7933 - val_auc: 0.8708 - val_loss: 0.4423\n",
      "Epoch 5213/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7789 - auc: 0.8582 - loss: 0.4605 - val_acc: 0.7927 - val_auc: 0.8711 - val_loss: 0.4415\n",
      "Epoch 5214/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7796 - auc: 0.8586 - loss: 0.4603 - val_acc: 0.7960 - val_auc: 0.8726 - val_loss: 0.4401\n",
      "Epoch 5215/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7798 - auc: 0.8578 - loss: 0.4605 - val_acc: 0.7952 - val_auc: 0.8723 - val_loss: 0.4386\n",
      "Epoch 5216/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7785 - auc: 0.8581 - loss: 0.4619 - val_acc: 0.7949 - val_auc: 0.8716 - val_loss: 0.4410\n",
      "Epoch 5217/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7788 - auc: 0.8579 - loss: 0.4605 - val_acc: 0.7948 - val_auc: 0.8712 - val_loss: 0.4401\n",
      "Epoch 5218/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7768 - auc: 0.8583 - loss: 0.4601 - val_acc: 0.7937 - val_auc: 0.8714 - val_loss: 0.4405\n",
      "Epoch 5219/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7798 - auc: 0.8599 - loss: 0.4592 - val_acc: 0.7932 - val_auc: 0.8716 - val_loss: 0.4402\n",
      "Epoch 5220/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7792 - auc: 0.8576 - loss: 0.4607 - val_acc: 0.7939 - val_auc: 0.8733 - val_loss: 0.4396\n",
      "Epoch 5221/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7795 - auc: 0.8587 - loss: 0.4605 - val_acc: 0.7935 - val_auc: 0.8717 - val_loss: 0.4415\n",
      "Epoch 5222/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7790 - auc: 0.8593 - loss: 0.4600 - val_acc: 0.7939 - val_auc: 0.8728 - val_loss: 0.4385\n",
      "Epoch 5223/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7815 - auc: 0.8593 - loss: 0.4599 - val_acc: 0.7917 - val_auc: 0.8714 - val_loss: 0.4412\n",
      "Epoch 5224/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7802 - auc: 0.8581 - loss: 0.4611 - val_acc: 0.7928 - val_auc: 0.8724 - val_loss: 0.4411\n",
      "Epoch 5225/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7796 - auc: 0.8598 - loss: 0.4578 - val_acc: 0.7948 - val_auc: 0.8719 - val_loss: 0.4401\n",
      "Epoch 5226/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7778 - auc: 0.8580 - loss: 0.4604 - val_acc: 0.7964 - val_auc: 0.8722 - val_loss: 0.4393\n",
      "Epoch 5227/7000\n",
      "106/106 - 2s - 22ms/step - acc: 0.7797 - auc: 0.8592 - loss: 0.4601 - val_acc: 0.7916 - val_auc: 0.8708 - val_loss: 0.4434\n",
      "Epoch 5228/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7810 - auc: 0.8594 - loss: 0.4594 - val_acc: 0.7933 - val_auc: 0.8711 - val_loss: 0.4410\n",
      "Epoch 5229/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7807 - auc: 0.8617 - loss: 0.4563 - val_acc: 0.7953 - val_auc: 0.8726 - val_loss: 0.4403\n",
      "Epoch 5230/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7785 - auc: 0.8571 - loss: 0.4623 - val_acc: 0.7940 - val_auc: 0.8725 - val_loss: 0.4405\n",
      "Epoch 5231/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7808 - auc: 0.8600 - loss: 0.4580 - val_acc: 0.7934 - val_auc: 0.8715 - val_loss: 0.4421\n",
      "Epoch 5232/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7806 - auc: 0.8595 - loss: 0.4583 - val_acc: 0.7937 - val_auc: 0.8717 - val_loss: 0.4392\n",
      "Epoch 5233/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7794 - auc: 0.8588 - loss: 0.4602 - val_acc: 0.7941 - val_auc: 0.8726 - val_loss: 0.4417\n",
      "Epoch 5234/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7793 - auc: 0.8588 - loss: 0.4603 - val_acc: 0.7931 - val_auc: 0.8721 - val_loss: 0.4399\n",
      "Epoch 5235/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7799 - auc: 0.8592 - loss: 0.4598 - val_acc: 0.7933 - val_auc: 0.8706 - val_loss: 0.4417\n",
      "Epoch 5236/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7780 - auc: 0.8584 - loss: 0.4609 - val_acc: 0.7944 - val_auc: 0.8715 - val_loss: 0.4418\n",
      "Epoch 5237/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7774 - auc: 0.8589 - loss: 0.4597 - val_acc: 0.7936 - val_auc: 0.8718 - val_loss: 0.4401\n",
      "Epoch 5238/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7784 - auc: 0.8581 - loss: 0.4613 - val_acc: 0.7919 - val_auc: 0.8712 - val_loss: 0.4420\n",
      "Epoch 5239/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7801 - auc: 0.8596 - loss: 0.4589 - val_acc: 0.7919 - val_auc: 0.8720 - val_loss: 0.4414\n",
      "Epoch 5240/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7780 - auc: 0.8575 - loss: 0.4620 - val_acc: 0.7934 - val_auc: 0.8709 - val_loss: 0.4413\n",
      "Epoch 5241/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7807 - auc: 0.8589 - loss: 0.4597 - val_acc: 0.7968 - val_auc: 0.8718 - val_loss: 0.4389\n",
      "Epoch 5242/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7792 - auc: 0.8593 - loss: 0.4591 - val_acc: 0.7940 - val_auc: 0.8720 - val_loss: 0.4404\n",
      "Epoch 5243/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7808 - auc: 0.8598 - loss: 0.4595 - val_acc: 0.7957 - val_auc: 0.8727 - val_loss: 0.4387\n",
      "Epoch 5244/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7813 - auc: 0.8607 - loss: 0.4562 - val_acc: 0.7920 - val_auc: 0.8701 - val_loss: 0.4419\n",
      "Epoch 5245/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7802 - auc: 0.8588 - loss: 0.4607 - val_acc: 0.7957 - val_auc: 0.8726 - val_loss: 0.4384\n",
      "Epoch 5246/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7803 - auc: 0.8590 - loss: 0.4590 - val_acc: 0.7948 - val_auc: 0.8729 - val_loss: 0.4386\n",
      "Epoch 5247/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7784 - auc: 0.8594 - loss: 0.4599 - val_acc: 0.7964 - val_auc: 0.8723 - val_loss: 0.4405\n",
      "Epoch 5248/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7801 - auc: 0.8599 - loss: 0.4588 - val_acc: 0.7920 - val_auc: 0.8705 - val_loss: 0.4409\n",
      "Epoch 5249/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7796 - auc: 0.8592 - loss: 0.4591 - val_acc: 0.7933 - val_auc: 0.8711 - val_loss: 0.4404\n",
      "Epoch 5250/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7792 - auc: 0.8594 - loss: 0.4595 - val_acc: 0.7915 - val_auc: 0.8706 - val_loss: 0.4431\n",
      "Epoch 5251/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7775 - auc: 0.8579 - loss: 0.4601 - val_acc: 0.7939 - val_auc: 0.8709 - val_loss: 0.4407\n",
      "Epoch 5252/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7801 - auc: 0.8604 - loss: 0.4579 - val_acc: 0.7933 - val_auc: 0.8719 - val_loss: 0.4407\n",
      "Epoch 5253/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8601 - loss: 0.4581 - val_acc: 0.7934 - val_auc: 0.8718 - val_loss: 0.4403\n",
      "Epoch 5254/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7814 - auc: 0.8603 - loss: 0.4581 - val_acc: 0.7940 - val_auc: 0.8722 - val_loss: 0.4396\n",
      "Epoch 5255/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7788 - auc: 0.8579 - loss: 0.4602 - val_acc: 0.7959 - val_auc: 0.8721 - val_loss: 0.4402\n",
      "Epoch 5256/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7807 - auc: 0.8603 - loss: 0.4574 - val_acc: 0.7957 - val_auc: 0.8714 - val_loss: 0.4394\n",
      "Epoch 5257/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7794 - auc: 0.8589 - loss: 0.4597 - val_acc: 0.7940 - val_auc: 0.8717 - val_loss: 0.4400\n",
      "Epoch 5258/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7771 - auc: 0.8579 - loss: 0.4615 - val_acc: 0.7933 - val_auc: 0.8712 - val_loss: 0.4421\n",
      "Epoch 5259/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7800 - auc: 0.8594 - loss: 0.4583 - val_acc: 0.7923 - val_auc: 0.8703 - val_loss: 0.4409\n",
      "Epoch 5260/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7790 - auc: 0.8595 - loss: 0.4587 - val_acc: 0.7926 - val_auc: 0.8719 - val_loss: 0.4421\n",
      "Epoch 5261/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7782 - auc: 0.8571 - loss: 0.4621 - val_acc: 0.7954 - val_auc: 0.8718 - val_loss: 0.4391\n",
      "Epoch 5262/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7794 - auc: 0.8598 - loss: 0.4584 - val_acc: 0.7937 - val_auc: 0.8725 - val_loss: 0.4406\n",
      "Epoch 5263/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7811 - auc: 0.8595 - loss: 0.4592 - val_acc: 0.7939 - val_auc: 0.8722 - val_loss: 0.4386\n",
      "Epoch 5264/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7783 - auc: 0.8581 - loss: 0.4610 - val_acc: 0.7919 - val_auc: 0.8712 - val_loss: 0.4407\n",
      "Epoch 5265/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7787 - auc: 0.8580 - loss: 0.4622 - val_acc: 0.7982 - val_auc: 0.8732 - val_loss: 0.4384\n",
      "Epoch 5266/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7791 - auc: 0.8589 - loss: 0.4591 - val_acc: 0.7933 - val_auc: 0.8713 - val_loss: 0.4415\n",
      "Epoch 5267/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7771 - auc: 0.8564 - loss: 0.4613 - val_acc: 0.7938 - val_auc: 0.8713 - val_loss: 0.4407\n",
      "Epoch 5268/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7808 - auc: 0.8592 - loss: 0.4595 - val_acc: 0.7927 - val_auc: 0.8712 - val_loss: 0.4412\n",
      "Epoch 5269/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7789 - auc: 0.8577 - loss: 0.4615 - val_acc: 0.7962 - val_auc: 0.8722 - val_loss: 0.4390\n",
      "Epoch 5270/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7806 - auc: 0.8594 - loss: 0.4593 - val_acc: 0.7926 - val_auc: 0.8719 - val_loss: 0.4406\n",
      "Epoch 5271/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8595 - loss: 0.4592 - val_acc: 0.7925 - val_auc: 0.8718 - val_loss: 0.4400\n",
      "Epoch 5272/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7783 - auc: 0.8580 - loss: 0.4615 - val_acc: 0.7945 - val_auc: 0.8710 - val_loss: 0.4400\n",
      "Epoch 5273/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7812 - auc: 0.8606 - loss: 0.4579 - val_acc: 0.7972 - val_auc: 0.8731 - val_loss: 0.4397\n",
      "Epoch 5274/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7769 - auc: 0.8565 - loss: 0.4635 - val_acc: 0.7923 - val_auc: 0.8711 - val_loss: 0.4406\n",
      "Epoch 5275/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7791 - auc: 0.8590 - loss: 0.4599 - val_acc: 0.7947 - val_auc: 0.8725 - val_loss: 0.4396\n",
      "Epoch 5276/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7774 - auc: 0.8571 - loss: 0.4631 - val_acc: 0.7942 - val_auc: 0.8730 - val_loss: 0.4404\n",
      "Epoch 5277/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7795 - auc: 0.8586 - loss: 0.4606 - val_acc: 0.7964 - val_auc: 0.8718 - val_loss: 0.4391\n",
      "Epoch 5278/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7792 - auc: 0.8596 - loss: 0.4587 - val_acc: 0.7949 - val_auc: 0.8709 - val_loss: 0.4412\n",
      "Epoch 5279/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7788 - auc: 0.8578 - loss: 0.4619 - val_acc: 0.7938 - val_auc: 0.8706 - val_loss: 0.4415\n",
      "Epoch 5280/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7806 - auc: 0.8594 - loss: 0.4587 - val_acc: 0.7953 - val_auc: 0.8727 - val_loss: 0.4402\n",
      "Epoch 5281/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8596 - loss: 0.4582 - val_acc: 0.7931 - val_auc: 0.8714 - val_loss: 0.4416\n",
      "Epoch 5282/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7800 - auc: 0.8595 - loss: 0.4593 - val_acc: 0.7967 - val_auc: 0.8718 - val_loss: 0.4387\n",
      "Epoch 5283/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7798 - auc: 0.8585 - loss: 0.4597 - val_acc: 0.7928 - val_auc: 0.8703 - val_loss: 0.4432\n",
      "Epoch 5284/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7803 - auc: 0.8585 - loss: 0.4608 - val_acc: 0.7918 - val_auc: 0.8710 - val_loss: 0.4407\n",
      "Epoch 5285/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7777 - auc: 0.8582 - loss: 0.4606 - val_acc: 0.7929 - val_auc: 0.8714 - val_loss: 0.4413\n",
      "Epoch 5286/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7785 - auc: 0.8591 - loss: 0.4597 - val_acc: 0.7976 - val_auc: 0.8733 - val_loss: 0.4386\n",
      "Epoch 5287/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7786 - auc: 0.8591 - loss: 0.4591 - val_acc: 0.7959 - val_auc: 0.8716 - val_loss: 0.4403\n",
      "Epoch 5288/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7805 - auc: 0.8609 - loss: 0.4576 - val_acc: 0.7965 - val_auc: 0.8721 - val_loss: 0.4411\n",
      "Epoch 5289/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7787 - auc: 0.8585 - loss: 0.4607 - val_acc: 0.7939 - val_auc: 0.8724 - val_loss: 0.4400\n",
      "Epoch 5290/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7780 - auc: 0.8578 - loss: 0.4610 - val_acc: 0.7947 - val_auc: 0.8729 - val_loss: 0.4381\n",
      "Epoch 5291/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7766 - auc: 0.8566 - loss: 0.4628 - val_acc: 0.7960 - val_auc: 0.8731 - val_loss: 0.4386\n",
      "Epoch 5292/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7786 - auc: 0.8577 - loss: 0.4609 - val_acc: 0.7953 - val_auc: 0.8725 - val_loss: 0.4393\n",
      "Epoch 5293/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7799 - auc: 0.8591 - loss: 0.4594 - val_acc: 0.7952 - val_auc: 0.8727 - val_loss: 0.4408\n",
      "Epoch 5294/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7779 - auc: 0.8591 - loss: 0.4597 - val_acc: 0.7953 - val_auc: 0.8729 - val_loss: 0.4380\n",
      "Epoch 5295/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7799 - auc: 0.8589 - loss: 0.4596 - val_acc: 0.7939 - val_auc: 0.8702 - val_loss: 0.4415\n",
      "Epoch 5296/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7803 - auc: 0.8583 - loss: 0.4616 - val_acc: 0.7952 - val_auc: 0.8716 - val_loss: 0.4396\n",
      "Epoch 5297/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7788 - auc: 0.8570 - loss: 0.4616 - val_acc: 0.7905 - val_auc: 0.8727 - val_loss: 0.4418\n",
      "Epoch 5298/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7777 - auc: 0.8582 - loss: 0.4618 - val_acc: 0.7932 - val_auc: 0.8715 - val_loss: 0.4418\n",
      "Epoch 5299/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7833 - auc: 0.8611 - loss: 0.4564 - val_acc: 0.7939 - val_auc: 0.8724 - val_loss: 0.4407\n",
      "Epoch 5300/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7775 - auc: 0.8580 - loss: 0.4597 - val_acc: 0.7940 - val_auc: 0.8712 - val_loss: 0.4424\n",
      "Epoch 5301/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7763 - auc: 0.8575 - loss: 0.4623 - val_acc: 0.7953 - val_auc: 0.8728 - val_loss: 0.4398\n",
      "Epoch 5302/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7800 - auc: 0.8596 - loss: 0.4588 - val_acc: 0.7951 - val_auc: 0.8712 - val_loss: 0.4390\n",
      "Epoch 5303/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8586 - loss: 0.4611 - val_acc: 0.7952 - val_auc: 0.8706 - val_loss: 0.4412\n",
      "Epoch 5304/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7799 - auc: 0.8592 - loss: 0.4605 - val_acc: 0.7941 - val_auc: 0.8718 - val_loss: 0.4422\n",
      "Epoch 5305/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7800 - auc: 0.8594 - loss: 0.4586 - val_acc: 0.7954 - val_auc: 0.8723 - val_loss: 0.4404\n",
      "Epoch 5306/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7798 - auc: 0.8605 - loss: 0.4573 - val_acc: 0.7947 - val_auc: 0.8727 - val_loss: 0.4401\n",
      "Epoch 5307/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7771 - auc: 0.8570 - loss: 0.4622 - val_acc: 0.7964 - val_auc: 0.8730 - val_loss: 0.4395\n",
      "Epoch 5308/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7788 - auc: 0.8588 - loss: 0.4592 - val_acc: 0.7937 - val_auc: 0.8716 - val_loss: 0.4421\n",
      "Epoch 5309/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7800 - auc: 0.8597 - loss: 0.4597 - val_acc: 0.7951 - val_auc: 0.8723 - val_loss: 0.4393\n",
      "Epoch 5310/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7808 - auc: 0.8598 - loss: 0.4580 - val_acc: 0.7932 - val_auc: 0.8706 - val_loss: 0.4407\n",
      "Epoch 5311/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7785 - auc: 0.8585 - loss: 0.4603 - val_acc: 0.7933 - val_auc: 0.8725 - val_loss: 0.4405\n",
      "Epoch 5312/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7794 - auc: 0.8579 - loss: 0.4602 - val_acc: 0.7947 - val_auc: 0.8716 - val_loss: 0.4397\n",
      "Epoch 5313/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7781 - auc: 0.8583 - loss: 0.4607 - val_acc: 0.7927 - val_auc: 0.8716 - val_loss: 0.4412\n",
      "Epoch 5314/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7787 - auc: 0.8600 - loss: 0.4584 - val_acc: 0.7952 - val_auc: 0.8725 - val_loss: 0.4411\n",
      "Epoch 5315/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7806 - auc: 0.8597 - loss: 0.4581 - val_acc: 0.7942 - val_auc: 0.8723 - val_loss: 0.4385\n",
      "Epoch 5316/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7810 - auc: 0.8598 - loss: 0.4590 - val_acc: 0.7948 - val_auc: 0.8717 - val_loss: 0.4397\n",
      "Epoch 5317/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7768 - auc: 0.8584 - loss: 0.4608 - val_acc: 0.7931 - val_auc: 0.8716 - val_loss: 0.4412\n",
      "Epoch 5318/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8608 - loss: 0.4564 - val_acc: 0.7951 - val_auc: 0.8723 - val_loss: 0.4389\n",
      "Epoch 5319/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7789 - auc: 0.8594 - loss: 0.4595 - val_acc: 0.7919 - val_auc: 0.8703 - val_loss: 0.4417\n",
      "Epoch 5320/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7821 - auc: 0.8603 - loss: 0.4580 - val_acc: 0.7947 - val_auc: 0.8735 - val_loss: 0.4396\n",
      "Epoch 5321/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7809 - auc: 0.8594 - loss: 0.4593 - val_acc: 0.7933 - val_auc: 0.8714 - val_loss: 0.4404\n",
      "Epoch 5322/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7810 - auc: 0.8588 - loss: 0.4595 - val_acc: 0.7952 - val_auc: 0.8732 - val_loss: 0.4402\n",
      "Epoch 5323/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7812 - auc: 0.8607 - loss: 0.4582 - val_acc: 0.7952 - val_auc: 0.8724 - val_loss: 0.4402\n",
      "Epoch 5324/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7787 - auc: 0.8593 - loss: 0.4591 - val_acc: 0.7944 - val_auc: 0.8717 - val_loss: 0.4408\n",
      "Epoch 5325/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7814 - auc: 0.8600 - loss: 0.4583 - val_acc: 0.7956 - val_auc: 0.8723 - val_loss: 0.4412\n",
      "Epoch 5326/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7795 - auc: 0.8590 - loss: 0.4595 - val_acc: 0.7954 - val_auc: 0.8728 - val_loss: 0.4397\n",
      "Epoch 5327/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7799 - auc: 0.8583 - loss: 0.4612 - val_acc: 0.7904 - val_auc: 0.8708 - val_loss: 0.4452\n",
      "Epoch 5328/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7800 - auc: 0.8598 - loss: 0.4585 - val_acc: 0.7939 - val_auc: 0.8718 - val_loss: 0.4411\n",
      "Epoch 5329/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7795 - auc: 0.8592 - loss: 0.4595 - val_acc: 0.7957 - val_auc: 0.8726 - val_loss: 0.4393\n",
      "Epoch 5330/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7787 - auc: 0.8603 - loss: 0.4574 - val_acc: 0.7949 - val_auc: 0.8728 - val_loss: 0.4398\n",
      "Epoch 5331/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7807 - auc: 0.8598 - loss: 0.4588 - val_acc: 0.7941 - val_auc: 0.8728 - val_loss: 0.4406\n",
      "Epoch 5332/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7795 - auc: 0.8591 - loss: 0.4595 - val_acc: 0.7927 - val_auc: 0.8715 - val_loss: 0.4397\n",
      "Epoch 5333/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7810 - auc: 0.8605 - loss: 0.4580 - val_acc: 0.7938 - val_auc: 0.8716 - val_loss: 0.4412\n",
      "Epoch 5334/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7779 - auc: 0.8583 - loss: 0.4602 - val_acc: 0.7958 - val_auc: 0.8720 - val_loss: 0.4403\n",
      "Epoch 5335/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7778 - auc: 0.8587 - loss: 0.4603 - val_acc: 0.7964 - val_auc: 0.8720 - val_loss: 0.4402\n",
      "Epoch 5336/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7809 - auc: 0.8593 - loss: 0.4594 - val_acc: 0.7943 - val_auc: 0.8721 - val_loss: 0.4410\n",
      "Epoch 5337/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7771 - auc: 0.8587 - loss: 0.4602 - val_acc: 0.7934 - val_auc: 0.8714 - val_loss: 0.4416\n",
      "Epoch 5338/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7797 - auc: 0.8594 - loss: 0.4589 - val_acc: 0.7946 - val_auc: 0.8724 - val_loss: 0.4409\n",
      "Epoch 5339/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7812 - auc: 0.8603 - loss: 0.4583 - val_acc: 0.7939 - val_auc: 0.8721 - val_loss: 0.4403\n",
      "Epoch 5340/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7807 - auc: 0.8599 - loss: 0.4595 - val_acc: 0.7884 - val_auc: 0.8697 - val_loss: 0.4446\n",
      "Epoch 5341/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7804 - auc: 0.8606 - loss: 0.4568 - val_acc: 0.7913 - val_auc: 0.8708 - val_loss: 0.4416\n",
      "Epoch 5342/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7772 - auc: 0.8577 - loss: 0.4616 - val_acc: 0.7909 - val_auc: 0.8707 - val_loss: 0.4433\n",
      "Epoch 5343/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7795 - auc: 0.8596 - loss: 0.4591 - val_acc: 0.7953 - val_auc: 0.8728 - val_loss: 0.4411\n",
      "Epoch 5344/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7805 - auc: 0.8612 - loss: 0.4578 - val_acc: 0.7957 - val_auc: 0.8730 - val_loss: 0.4387\n",
      "Epoch 5345/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7791 - auc: 0.8591 - loss: 0.4588 - val_acc: 0.7933 - val_auc: 0.8716 - val_loss: 0.4406\n",
      "Epoch 5346/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7795 - auc: 0.8585 - loss: 0.4603 - val_acc: 0.7918 - val_auc: 0.8719 - val_loss: 0.4396\n",
      "Epoch 5347/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7804 - auc: 0.8591 - loss: 0.4592 - val_acc: 0.7952 - val_auc: 0.8721 - val_loss: 0.4378\n",
      "Epoch 5348/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7795 - auc: 0.8596 - loss: 0.4586 - val_acc: 0.7976 - val_auc: 0.8720 - val_loss: 0.4397\n",
      "Epoch 5349/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7788 - auc: 0.8587 - loss: 0.4601 - val_acc: 0.7936 - val_auc: 0.8715 - val_loss: 0.4412\n",
      "Epoch 5350/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7792 - auc: 0.8587 - loss: 0.4598 - val_acc: 0.7954 - val_auc: 0.8723 - val_loss: 0.4400\n",
      "Epoch 5351/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7798 - auc: 0.8590 - loss: 0.4596 - val_acc: 0.7942 - val_auc: 0.8712 - val_loss: 0.4412\n",
      "Epoch 5352/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7796 - auc: 0.8584 - loss: 0.4602 - val_acc: 0.7939 - val_auc: 0.8709 - val_loss: 0.4420\n",
      "Epoch 5353/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7812 - auc: 0.8600 - loss: 0.4576 - val_acc: 0.7973 - val_auc: 0.8714 - val_loss: 0.4395\n",
      "Epoch 5354/7000\n",
      "106/106 - 2s - 15ms/step - acc: 0.7800 - auc: 0.8602 - loss: 0.4578 - val_acc: 0.7943 - val_auc: 0.8725 - val_loss: 0.4382\n",
      "Epoch 5355/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7793 - auc: 0.8596 - loss: 0.4584 - val_acc: 0.7952 - val_auc: 0.8730 - val_loss: 0.4388\n",
      "Epoch 5356/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7800 - auc: 0.8592 - loss: 0.4591 - val_acc: 0.7938 - val_auc: 0.8731 - val_loss: 0.4381\n",
      "Epoch 5357/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7801 - auc: 0.8592 - loss: 0.4599 - val_acc: 0.7945 - val_auc: 0.8710 - val_loss: 0.4417\n",
      "Epoch 5358/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7810 - auc: 0.8603 - loss: 0.4577 - val_acc: 0.7939 - val_auc: 0.8713 - val_loss: 0.4404\n",
      "Epoch 5359/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7811 - auc: 0.8597 - loss: 0.4596 - val_acc: 0.7947 - val_auc: 0.8727 - val_loss: 0.4398\n",
      "Epoch 5360/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7778 - auc: 0.8580 - loss: 0.4620 - val_acc: 0.7980 - val_auc: 0.8720 - val_loss: 0.4400\n",
      "Epoch 5361/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8590 - loss: 0.4594 - val_acc: 0.7951 - val_auc: 0.8722 - val_loss: 0.4393\n",
      "Epoch 5362/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7793 - auc: 0.8583 - loss: 0.4605 - val_acc: 0.7956 - val_auc: 0.8718 - val_loss: 0.4398\n",
      "Epoch 5363/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7814 - auc: 0.8601 - loss: 0.4584 - val_acc: 0.7927 - val_auc: 0.8728 - val_loss: 0.4414\n",
      "Epoch 5364/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7782 - auc: 0.8575 - loss: 0.4614 - val_acc: 0.7965 - val_auc: 0.8735 - val_loss: 0.4393\n",
      "Epoch 5365/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7802 - auc: 0.8588 - loss: 0.4604 - val_acc: 0.7936 - val_auc: 0.8718 - val_loss: 0.4409\n",
      "Epoch 5366/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7787 - auc: 0.8589 - loss: 0.4595 - val_acc: 0.7961 - val_auc: 0.8728 - val_loss: 0.4393\n",
      "Epoch 5367/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7792 - auc: 0.8585 - loss: 0.4600 - val_acc: 0.7929 - val_auc: 0.8718 - val_loss: 0.4402\n",
      "Epoch 5368/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7791 - auc: 0.8591 - loss: 0.4596 - val_acc: 0.7954 - val_auc: 0.8726 - val_loss: 0.4392\n",
      "Epoch 5369/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7811 - auc: 0.8605 - loss: 0.4575 - val_acc: 0.7967 - val_auc: 0.8737 - val_loss: 0.4373\n",
      "Epoch 5370/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7787 - auc: 0.8597 - loss: 0.4585 - val_acc: 0.7965 - val_auc: 0.8729 - val_loss: 0.4391\n",
      "Epoch 5371/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7795 - auc: 0.8584 - loss: 0.4603 - val_acc: 0.7959 - val_auc: 0.8724 - val_loss: 0.4397\n",
      "Epoch 5372/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7803 - auc: 0.8606 - loss: 0.4595 - val_acc: 0.7965 - val_auc: 0.8720 - val_loss: 0.4409\n",
      "Epoch 5373/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7802 - auc: 0.8593 - loss: 0.4593 - val_acc: 0.7944 - val_auc: 0.8706 - val_loss: 0.4419\n",
      "Epoch 5374/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7801 - auc: 0.8601 - loss: 0.4574 - val_acc: 0.7941 - val_auc: 0.8723 - val_loss: 0.4411\n",
      "Epoch 5375/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7790 - auc: 0.8587 - loss: 0.4609 - val_acc: 0.7923 - val_auc: 0.8714 - val_loss: 0.4421\n",
      "Epoch 5376/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7811 - auc: 0.8610 - loss: 0.4567 - val_acc: 0.7957 - val_auc: 0.8738 - val_loss: 0.4384\n",
      "Epoch 5377/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7805 - auc: 0.8599 - loss: 0.4576 - val_acc: 0.7955 - val_auc: 0.8714 - val_loss: 0.4396\n",
      "Epoch 5378/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7793 - auc: 0.8588 - loss: 0.4595 - val_acc: 0.7915 - val_auc: 0.8711 - val_loss: 0.4432\n",
      "Epoch 5379/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8594 - loss: 0.4593 - val_acc: 0.7960 - val_auc: 0.8716 - val_loss: 0.4406\n",
      "Epoch 5380/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7810 - auc: 0.8604 - loss: 0.4569 - val_acc: 0.7944 - val_auc: 0.8735 - val_loss: 0.4389\n",
      "Epoch 5381/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7793 - auc: 0.8594 - loss: 0.4596 - val_acc: 0.7992 - val_auc: 0.8739 - val_loss: 0.4370\n",
      "Epoch 5382/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7765 - auc: 0.8568 - loss: 0.4636 - val_acc: 0.7951 - val_auc: 0.8710 - val_loss: 0.4429\n",
      "Epoch 5383/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7779 - auc: 0.8580 - loss: 0.4616 - val_acc: 0.7961 - val_auc: 0.8730 - val_loss: 0.4402\n",
      "Epoch 5384/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7797 - auc: 0.8583 - loss: 0.4621 - val_acc: 0.7952 - val_auc: 0.8724 - val_loss: 0.4396\n",
      "Epoch 5385/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7792 - auc: 0.8588 - loss: 0.4602 - val_acc: 0.7942 - val_auc: 0.8722 - val_loss: 0.4409\n",
      "Epoch 5386/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7787 - auc: 0.8599 - loss: 0.4587 - val_acc: 0.7929 - val_auc: 0.8719 - val_loss: 0.4419\n",
      "Epoch 5387/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7804 - auc: 0.8601 - loss: 0.4574 - val_acc: 0.7963 - val_auc: 0.8729 - val_loss: 0.4389\n",
      "Epoch 5388/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7792 - auc: 0.8581 - loss: 0.4618 - val_acc: 0.7942 - val_auc: 0.8717 - val_loss: 0.4410\n",
      "Epoch 5389/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7814 - auc: 0.8596 - loss: 0.4588 - val_acc: 0.7952 - val_auc: 0.8730 - val_loss: 0.4387\n",
      "Epoch 5390/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7821 - auc: 0.8599 - loss: 0.4585 - val_acc: 0.7942 - val_auc: 0.8705 - val_loss: 0.4414\n",
      "Epoch 5391/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7815 - auc: 0.8600 - loss: 0.4578 - val_acc: 0.7905 - val_auc: 0.8713 - val_loss: 0.4416\n",
      "Epoch 5392/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7782 - auc: 0.8584 - loss: 0.4600 - val_acc: 0.7914 - val_auc: 0.8714 - val_loss: 0.4414\n",
      "Epoch 5393/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7818 - auc: 0.8602 - loss: 0.4578 - val_acc: 0.7972 - val_auc: 0.8728 - val_loss: 0.4398\n",
      "Epoch 5394/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7808 - auc: 0.8602 - loss: 0.4580 - val_acc: 0.7966 - val_auc: 0.8722 - val_loss: 0.4384\n",
      "Epoch 5395/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7798 - auc: 0.8591 - loss: 0.4605 - val_acc: 0.7968 - val_auc: 0.8726 - val_loss: 0.4393\n",
      "Epoch 5396/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7799 - auc: 0.8591 - loss: 0.4606 - val_acc: 0.7938 - val_auc: 0.8711 - val_loss: 0.4415\n",
      "Epoch 5397/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7800 - auc: 0.8596 - loss: 0.4591 - val_acc: 0.7953 - val_auc: 0.8721 - val_loss: 0.4413\n",
      "Epoch 5398/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7798 - auc: 0.8589 - loss: 0.4605 - val_acc: 0.7959 - val_auc: 0.8723 - val_loss: 0.4403\n",
      "Epoch 5399/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7818 - auc: 0.8612 - loss: 0.4570 - val_acc: 0.7954 - val_auc: 0.8715 - val_loss: 0.4399\n",
      "Epoch 5400/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7806 - auc: 0.8608 - loss: 0.4574 - val_acc: 0.7952 - val_auc: 0.8724 - val_loss: 0.4392\n",
      "Epoch 5401/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7806 - auc: 0.8604 - loss: 0.4577 - val_acc: 0.7978 - val_auc: 0.8721 - val_loss: 0.4398\n",
      "Epoch 5402/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7816 - auc: 0.8592 - loss: 0.4594 - val_acc: 0.7954 - val_auc: 0.8726 - val_loss: 0.4407\n",
      "Epoch 5403/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7804 - auc: 0.8594 - loss: 0.4588 - val_acc: 0.7951 - val_auc: 0.8725 - val_loss: 0.4395\n",
      "Epoch 5404/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7790 - auc: 0.8576 - loss: 0.4624 - val_acc: 0.7963 - val_auc: 0.8735 - val_loss: 0.4376\n",
      "Epoch 5405/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7803 - auc: 0.8612 - loss: 0.4570 - val_acc: 0.7931 - val_auc: 0.8719 - val_loss: 0.4399\n",
      "Epoch 5406/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7781 - auc: 0.8587 - loss: 0.4610 - val_acc: 0.7962 - val_auc: 0.8729 - val_loss: 0.4407\n",
      "Epoch 5407/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7777 - auc: 0.8582 - loss: 0.4606 - val_acc: 0.7915 - val_auc: 0.8718 - val_loss: 0.4432\n",
      "Epoch 5408/7000\n",
      "106/106 - 2s - 15ms/step - acc: 0.7798 - auc: 0.8594 - loss: 0.4600 - val_acc: 0.7956 - val_auc: 0.8735 - val_loss: 0.4393\n",
      "Epoch 5409/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7803 - auc: 0.8599 - loss: 0.4602 - val_acc: 0.7922 - val_auc: 0.8713 - val_loss: 0.4404\n",
      "Epoch 5410/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7816 - auc: 0.8605 - loss: 0.4580 - val_acc: 0.7944 - val_auc: 0.8717 - val_loss: 0.4412\n",
      "Epoch 5411/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7793 - auc: 0.8598 - loss: 0.4584 - val_acc: 0.7972 - val_auc: 0.8734 - val_loss: 0.4384\n",
      "Epoch 5412/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7802 - auc: 0.8600 - loss: 0.4583 - val_acc: 0.7948 - val_auc: 0.8726 - val_loss: 0.4402\n",
      "Epoch 5413/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7801 - auc: 0.8587 - loss: 0.4603 - val_acc: 0.7976 - val_auc: 0.8730 - val_loss: 0.4391\n",
      "Epoch 5414/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7798 - auc: 0.8584 - loss: 0.4613 - val_acc: 0.7962 - val_auc: 0.8721 - val_loss: 0.4406\n",
      "Epoch 5415/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8592 - loss: 0.4599 - val_acc: 0.7919 - val_auc: 0.8713 - val_loss: 0.4423\n",
      "Epoch 5416/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7777 - auc: 0.8597 - loss: 0.4592 - val_acc: 0.7943 - val_auc: 0.8727 - val_loss: 0.4407\n",
      "Epoch 5417/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7790 - auc: 0.8593 - loss: 0.4600 - val_acc: 0.7947 - val_auc: 0.8725 - val_loss: 0.4403\n",
      "Epoch 5418/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7786 - auc: 0.8587 - loss: 0.4594 - val_acc: 0.7955 - val_auc: 0.8725 - val_loss: 0.4403\n",
      "Epoch 5419/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7803 - auc: 0.8597 - loss: 0.4590 - val_acc: 0.7974 - val_auc: 0.8724 - val_loss: 0.4398\n",
      "Epoch 5420/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7783 - auc: 0.8592 - loss: 0.4589 - val_acc: 0.7947 - val_auc: 0.8723 - val_loss: 0.4406\n",
      "Epoch 5421/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7800 - auc: 0.8578 - loss: 0.4600 - val_acc: 0.7930 - val_auc: 0.8718 - val_loss: 0.4413\n",
      "Epoch 5422/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7783 - auc: 0.8579 - loss: 0.4608 - val_acc: 0.7924 - val_auc: 0.8723 - val_loss: 0.4411\n",
      "Epoch 5423/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7798 - auc: 0.8592 - loss: 0.4596 - val_acc: 0.7939 - val_auc: 0.8719 - val_loss: 0.4413\n",
      "Epoch 5424/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7803 - auc: 0.8600 - loss: 0.4593 - val_acc: 0.7948 - val_auc: 0.8723 - val_loss: 0.4394\n",
      "Epoch 5425/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7819 - auc: 0.8598 - loss: 0.4587 - val_acc: 0.7960 - val_auc: 0.8730 - val_loss: 0.4400\n",
      "Epoch 5426/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7795 - auc: 0.8590 - loss: 0.4605 - val_acc: 0.7968 - val_auc: 0.8735 - val_loss: 0.4389\n",
      "Epoch 5427/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7810 - auc: 0.8611 - loss: 0.4564 - val_acc: 0.7931 - val_auc: 0.8713 - val_loss: 0.4400\n",
      "Epoch 5428/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8593 - loss: 0.4593 - val_acc: 0.7972 - val_auc: 0.8734 - val_loss: 0.4393\n",
      "Epoch 5429/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7785 - auc: 0.8589 - loss: 0.4592 - val_acc: 0.7959 - val_auc: 0.8722 - val_loss: 0.4398\n",
      "Epoch 5430/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7805 - auc: 0.8607 - loss: 0.4582 - val_acc: 0.7962 - val_auc: 0.8738 - val_loss: 0.4390\n",
      "Epoch 5431/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7817 - auc: 0.8605 - loss: 0.4567 - val_acc: 0.7926 - val_auc: 0.8730 - val_loss: 0.4403\n",
      "Epoch 5432/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7792 - auc: 0.8592 - loss: 0.4603 - val_acc: 0.7961 - val_auc: 0.8742 - val_loss: 0.4383\n",
      "Epoch 5433/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7813 - auc: 0.8603 - loss: 0.4580 - val_acc: 0.7935 - val_auc: 0.8725 - val_loss: 0.4394\n",
      "Epoch 5434/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7822 - auc: 0.8605 - loss: 0.4572 - val_acc: 0.7957 - val_auc: 0.8728 - val_loss: 0.4391\n",
      "Epoch 5435/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7770 - auc: 0.8590 - loss: 0.4598 - val_acc: 0.7929 - val_auc: 0.8714 - val_loss: 0.4404\n",
      "Epoch 5436/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7801 - auc: 0.8598 - loss: 0.4587 - val_acc: 0.7923 - val_auc: 0.8728 - val_loss: 0.4402\n",
      "Epoch 5437/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7805 - auc: 0.8606 - loss: 0.4578 - val_acc: 0.7937 - val_auc: 0.8718 - val_loss: 0.4393\n",
      "Epoch 5438/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7805 - auc: 0.8592 - loss: 0.4591 - val_acc: 0.7959 - val_auc: 0.8730 - val_loss: 0.4391\n",
      "Epoch 5439/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7792 - auc: 0.8601 - loss: 0.4586 - val_acc: 0.7940 - val_auc: 0.8728 - val_loss: 0.4391\n",
      "Epoch 5440/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7780 - auc: 0.8590 - loss: 0.4593 - val_acc: 0.7948 - val_auc: 0.8714 - val_loss: 0.4402\n",
      "Epoch 5441/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7809 - auc: 0.8610 - loss: 0.4558 - val_acc: 0.7979 - val_auc: 0.8729 - val_loss: 0.4381\n",
      "Epoch 5442/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7804 - auc: 0.8578 - loss: 0.4606 - val_acc: 0.7974 - val_auc: 0.8730 - val_loss: 0.4386\n",
      "Epoch 5443/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7795 - auc: 0.8583 - loss: 0.4597 - val_acc: 0.7970 - val_auc: 0.8731 - val_loss: 0.4389\n",
      "Epoch 5444/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7790 - auc: 0.8592 - loss: 0.4598 - val_acc: 0.7939 - val_auc: 0.8722 - val_loss: 0.4409\n",
      "Epoch 5445/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7778 - auc: 0.8584 - loss: 0.4604 - val_acc: 0.7942 - val_auc: 0.8722 - val_loss: 0.4405\n",
      "Epoch 5446/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7802 - auc: 0.8589 - loss: 0.4607 - val_acc: 0.7962 - val_auc: 0.8736 - val_loss: 0.4401\n",
      "Epoch 5447/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7788 - auc: 0.8594 - loss: 0.4601 - val_acc: 0.7956 - val_auc: 0.8726 - val_loss: 0.4409\n",
      "Epoch 5448/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7791 - auc: 0.8583 - loss: 0.4619 - val_acc: 0.7954 - val_auc: 0.8714 - val_loss: 0.4405\n",
      "Epoch 5449/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7804 - auc: 0.8587 - loss: 0.4593 - val_acc: 0.7984 - val_auc: 0.8724 - val_loss: 0.4388\n",
      "Epoch 5450/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7793 - auc: 0.8587 - loss: 0.4600 - val_acc: 0.7954 - val_auc: 0.8716 - val_loss: 0.4412\n",
      "Epoch 5451/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7811 - auc: 0.8604 - loss: 0.4571 - val_acc: 0.7961 - val_auc: 0.8721 - val_loss: 0.4392\n",
      "Epoch 5452/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7819 - auc: 0.8598 - loss: 0.4586 - val_acc: 0.7946 - val_auc: 0.8720 - val_loss: 0.4423\n",
      "Epoch 5453/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7805 - auc: 0.8601 - loss: 0.4584 - val_acc: 0.7951 - val_auc: 0.8724 - val_loss: 0.4412\n",
      "Epoch 5454/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7786 - auc: 0.8599 - loss: 0.4583 - val_acc: 0.7961 - val_auc: 0.8723 - val_loss: 0.4408\n",
      "Epoch 5455/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7802 - auc: 0.8601 - loss: 0.4577 - val_acc: 0.7920 - val_auc: 0.8717 - val_loss: 0.4413\n",
      "Epoch 5456/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7803 - auc: 0.8599 - loss: 0.4583 - val_acc: 0.7953 - val_auc: 0.8721 - val_loss: 0.4401\n",
      "Epoch 5457/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7820 - auc: 0.8600 - loss: 0.4578 - val_acc: 0.7964 - val_auc: 0.8725 - val_loss: 0.4386\n",
      "Epoch 5458/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7787 - auc: 0.8575 - loss: 0.4612 - val_acc: 0.7961 - val_auc: 0.8731 - val_loss: 0.4409\n",
      "Epoch 5459/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7788 - auc: 0.8596 - loss: 0.4588 - val_acc: 0.7944 - val_auc: 0.8709 - val_loss: 0.4410\n",
      "Epoch 5460/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7789 - auc: 0.8598 - loss: 0.4589 - val_acc: 0.7962 - val_auc: 0.8729 - val_loss: 0.4383\n",
      "Epoch 5461/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7791 - auc: 0.8593 - loss: 0.4601 - val_acc: 0.7939 - val_auc: 0.8715 - val_loss: 0.4407\n",
      "Epoch 5462/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7804 - auc: 0.8590 - loss: 0.4589 - val_acc: 0.7953 - val_auc: 0.8725 - val_loss: 0.4400\n",
      "Epoch 5463/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7793 - auc: 0.8606 - loss: 0.4574 - val_acc: 0.7934 - val_auc: 0.8719 - val_loss: 0.4408\n",
      "Epoch 5464/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7807 - auc: 0.8602 - loss: 0.4588 - val_acc: 0.7979 - val_auc: 0.8721 - val_loss: 0.4396\n",
      "Epoch 5465/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7795 - auc: 0.8599 - loss: 0.4590 - val_acc: 0.7949 - val_auc: 0.8713 - val_loss: 0.4418\n",
      "Epoch 5466/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7783 - auc: 0.8594 - loss: 0.4590 - val_acc: 0.7950 - val_auc: 0.8719 - val_loss: 0.4397\n",
      "Epoch 5467/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7793 - auc: 0.8596 - loss: 0.4587 - val_acc: 0.7947 - val_auc: 0.8723 - val_loss: 0.4396\n",
      "Epoch 5468/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7799 - auc: 0.8597 - loss: 0.4583 - val_acc: 0.7933 - val_auc: 0.8698 - val_loss: 0.4422\n",
      "Epoch 5469/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8589 - loss: 0.4597 - val_acc: 0.7904 - val_auc: 0.8701 - val_loss: 0.4441\n",
      "Epoch 5470/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7802 - auc: 0.8599 - loss: 0.4580 - val_acc: 0.7945 - val_auc: 0.8720 - val_loss: 0.4415\n",
      "Epoch 5471/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7806 - auc: 0.8597 - loss: 0.4586 - val_acc: 0.7931 - val_auc: 0.8736 - val_loss: 0.4399\n",
      "Epoch 5472/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7807 - auc: 0.8592 - loss: 0.4600 - val_acc: 0.7938 - val_auc: 0.8725 - val_loss: 0.4397\n",
      "Epoch 5473/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7800 - auc: 0.8607 - loss: 0.4564 - val_acc: 0.7933 - val_auc: 0.8712 - val_loss: 0.4401\n",
      "Epoch 5474/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7797 - auc: 0.8593 - loss: 0.4579 - val_acc: 0.7953 - val_auc: 0.8718 - val_loss: 0.4401\n",
      "Epoch 5475/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7793 - auc: 0.8584 - loss: 0.4599 - val_acc: 0.7927 - val_auc: 0.8699 - val_loss: 0.4422\n",
      "Epoch 5476/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7808 - auc: 0.8603 - loss: 0.4571 - val_acc: 0.7931 - val_auc: 0.8701 - val_loss: 0.4411\n",
      "Epoch 5477/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7789 - auc: 0.8586 - loss: 0.4601 - val_acc: 0.7956 - val_auc: 0.8717 - val_loss: 0.4392\n",
      "Epoch 5478/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7816 - auc: 0.8603 - loss: 0.4579 - val_acc: 0.7977 - val_auc: 0.8729 - val_loss: 0.4383\n",
      "Epoch 5479/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7813 - auc: 0.8598 - loss: 0.4582 - val_acc: 0.7944 - val_auc: 0.8712 - val_loss: 0.4415\n",
      "Epoch 5480/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7796 - auc: 0.8588 - loss: 0.4591 - val_acc: 0.7928 - val_auc: 0.8719 - val_loss: 0.4405\n",
      "Epoch 5481/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7781 - auc: 0.8587 - loss: 0.4607 - val_acc: 0.7932 - val_auc: 0.8720 - val_loss: 0.4403\n",
      "Epoch 5482/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7814 - auc: 0.8603 - loss: 0.4579 - val_acc: 0.7963 - val_auc: 0.8724 - val_loss: 0.4398\n",
      "Epoch 5483/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7792 - auc: 0.8596 - loss: 0.4585 - val_acc: 0.7949 - val_auc: 0.8724 - val_loss: 0.4415\n",
      "Epoch 5484/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7816 - auc: 0.8604 - loss: 0.4576 - val_acc: 0.7926 - val_auc: 0.8714 - val_loss: 0.4401\n",
      "Epoch 5485/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7810 - auc: 0.8592 - loss: 0.4597 - val_acc: 0.7943 - val_auc: 0.8714 - val_loss: 0.4423\n",
      "Epoch 5486/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7805 - auc: 0.8604 - loss: 0.4578 - val_acc: 0.7947 - val_auc: 0.8728 - val_loss: 0.4400\n",
      "Epoch 5487/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7806 - auc: 0.8600 - loss: 0.4592 - val_acc: 0.7971 - val_auc: 0.8732 - val_loss: 0.4374\n",
      "Epoch 5488/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7802 - auc: 0.8605 - loss: 0.4575 - val_acc: 0.7970 - val_auc: 0.8732 - val_loss: 0.4380\n",
      "Epoch 5489/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7788 - auc: 0.8592 - loss: 0.4597 - val_acc: 0.7968 - val_auc: 0.8733 - val_loss: 0.4389\n",
      "Epoch 5490/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8588 - loss: 0.4596 - val_acc: 0.7953 - val_auc: 0.8718 - val_loss: 0.4403\n",
      "Epoch 5491/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7807 - auc: 0.8598 - loss: 0.4585 - val_acc: 0.7921 - val_auc: 0.8712 - val_loss: 0.4416\n",
      "Epoch 5492/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7794 - auc: 0.8591 - loss: 0.4601 - val_acc: 0.7955 - val_auc: 0.8725 - val_loss: 0.4404\n",
      "Epoch 5493/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7794 - auc: 0.8597 - loss: 0.4587 - val_acc: 0.7961 - val_auc: 0.8713 - val_loss: 0.4392\n",
      "Epoch 5494/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7803 - auc: 0.8597 - loss: 0.4586 - val_acc: 0.7928 - val_auc: 0.8718 - val_loss: 0.4418\n",
      "Epoch 5495/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7777 - auc: 0.8575 - loss: 0.4621 - val_acc: 0.7956 - val_auc: 0.8725 - val_loss: 0.4392\n",
      "Epoch 5496/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7825 - auc: 0.8613 - loss: 0.4559 - val_acc: 0.7939 - val_auc: 0.8710 - val_loss: 0.4397\n",
      "Epoch 5497/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7773 - auc: 0.8587 - loss: 0.4598 - val_acc: 0.7945 - val_auc: 0.8719 - val_loss: 0.4406\n",
      "Epoch 5498/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7785 - auc: 0.8585 - loss: 0.4610 - val_acc: 0.7965 - val_auc: 0.8731 - val_loss: 0.4386\n",
      "Epoch 5499/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7783 - auc: 0.8593 - loss: 0.4598 - val_acc: 0.7976 - val_auc: 0.8736 - val_loss: 0.4378\n",
      "Epoch 5500/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7801 - auc: 0.8603 - loss: 0.4569 - val_acc: 0.7927 - val_auc: 0.8720 - val_loss: 0.4407\n",
      "Epoch 5501/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7799 - auc: 0.8589 - loss: 0.4606 - val_acc: 0.7966 - val_auc: 0.8730 - val_loss: 0.4405\n",
      "Epoch 5502/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7793 - auc: 0.8595 - loss: 0.4589 - val_acc: 0.7988 - val_auc: 0.8734 - val_loss: 0.4378\n",
      "Epoch 5503/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7800 - auc: 0.8595 - loss: 0.4587 - val_acc: 0.7958 - val_auc: 0.8725 - val_loss: 0.4390\n",
      "Epoch 5504/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7795 - auc: 0.8586 - loss: 0.4595 - val_acc: 0.7949 - val_auc: 0.8731 - val_loss: 0.4390\n",
      "Epoch 5505/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7805 - auc: 0.8589 - loss: 0.4599 - val_acc: 0.7932 - val_auc: 0.8729 - val_loss: 0.4404\n",
      "Epoch 5506/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7813 - auc: 0.8602 - loss: 0.4580 - val_acc: 0.7953 - val_auc: 0.8735 - val_loss: 0.4385\n",
      "Epoch 5507/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7799 - auc: 0.8587 - loss: 0.4595 - val_acc: 0.7935 - val_auc: 0.8713 - val_loss: 0.4395\n",
      "Epoch 5508/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7806 - auc: 0.8596 - loss: 0.4586 - val_acc: 0.7931 - val_auc: 0.8717 - val_loss: 0.4416\n",
      "Epoch 5509/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7794 - auc: 0.8585 - loss: 0.4592 - val_acc: 0.7921 - val_auc: 0.8719 - val_loss: 0.4415\n",
      "Epoch 5510/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7794 - auc: 0.8599 - loss: 0.4586 - val_acc: 0.7959 - val_auc: 0.8718 - val_loss: 0.4399\n",
      "Epoch 5511/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7802 - auc: 0.8579 - loss: 0.4605 - val_acc: 0.7948 - val_auc: 0.8728 - val_loss: 0.4396\n",
      "Epoch 5512/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7800 - auc: 0.8605 - loss: 0.4580 - val_acc: 0.7932 - val_auc: 0.8711 - val_loss: 0.4418\n",
      "Epoch 5513/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7802 - auc: 0.8585 - loss: 0.4605 - val_acc: 0.7944 - val_auc: 0.8716 - val_loss: 0.4407\n",
      "Epoch 5514/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7800 - auc: 0.8594 - loss: 0.4593 - val_acc: 0.7918 - val_auc: 0.8712 - val_loss: 0.4417\n",
      "Epoch 5515/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7820 - auc: 0.8615 - loss: 0.4566 - val_acc: 0.7929 - val_auc: 0.8710 - val_loss: 0.4425\n",
      "Epoch 5516/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7795 - auc: 0.8596 - loss: 0.4588 - val_acc: 0.7955 - val_auc: 0.8721 - val_loss: 0.4383\n",
      "Epoch 5517/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7784 - auc: 0.8580 - loss: 0.4607 - val_acc: 0.7957 - val_auc: 0.8722 - val_loss: 0.4400\n",
      "Epoch 5518/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7811 - auc: 0.8596 - loss: 0.4589 - val_acc: 0.7955 - val_auc: 0.8717 - val_loss: 0.4395\n",
      "Epoch 5519/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7809 - auc: 0.8600 - loss: 0.4579 - val_acc: 0.7938 - val_auc: 0.8712 - val_loss: 0.4405\n",
      "Epoch 5520/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7774 - auc: 0.8576 - loss: 0.4620 - val_acc: 0.7948 - val_auc: 0.8712 - val_loss: 0.4406\n",
      "Epoch 5521/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7791 - auc: 0.8588 - loss: 0.4607 - val_acc: 0.7956 - val_auc: 0.8730 - val_loss: 0.4400\n",
      "Epoch 5522/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7782 - auc: 0.8572 - loss: 0.4615 - val_acc: 0.7949 - val_auc: 0.8716 - val_loss: 0.4403\n",
      "Epoch 5523/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7802 - auc: 0.8596 - loss: 0.4588 - val_acc: 0.7935 - val_auc: 0.8718 - val_loss: 0.4408\n",
      "Epoch 5524/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7827 - auc: 0.8608 - loss: 0.4572 - val_acc: 0.7917 - val_auc: 0.8721 - val_loss: 0.4427\n",
      "Epoch 5525/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7804 - auc: 0.8600 - loss: 0.4587 - val_acc: 0.7948 - val_auc: 0.8716 - val_loss: 0.4399\n",
      "Epoch 5526/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7824 - auc: 0.8618 - loss: 0.4554 - val_acc: 0.7956 - val_auc: 0.8732 - val_loss: 0.4393\n",
      "Epoch 5527/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7814 - auc: 0.8616 - loss: 0.4561 - val_acc: 0.7942 - val_auc: 0.8729 - val_loss: 0.4396\n",
      "Epoch 5528/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7788 - auc: 0.8586 - loss: 0.4595 - val_acc: 0.7964 - val_auc: 0.8723 - val_loss: 0.4405\n",
      "Epoch 5529/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7782 - auc: 0.8582 - loss: 0.4619 - val_acc: 0.7926 - val_auc: 0.8720 - val_loss: 0.4427\n",
      "Epoch 5530/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7787 - auc: 0.8587 - loss: 0.4607 - val_acc: 0.7965 - val_auc: 0.8731 - val_loss: 0.4392\n",
      "Epoch 5531/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7815 - auc: 0.8615 - loss: 0.4564 - val_acc: 0.7943 - val_auc: 0.8711 - val_loss: 0.4404\n",
      "Epoch 5532/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7803 - auc: 0.8606 - loss: 0.4571 - val_acc: 0.7927 - val_auc: 0.8715 - val_loss: 0.4411\n",
      "Epoch 5533/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7810 - auc: 0.8601 - loss: 0.4574 - val_acc: 0.7973 - val_auc: 0.8728 - val_loss: 0.4388\n",
      "Epoch 5534/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7821 - auc: 0.8606 - loss: 0.4578 - val_acc: 0.7940 - val_auc: 0.8715 - val_loss: 0.4415\n",
      "Epoch 5535/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7805 - auc: 0.8596 - loss: 0.4589 - val_acc: 0.7978 - val_auc: 0.8739 - val_loss: 0.4369\n",
      "Epoch 5536/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7811 - auc: 0.8594 - loss: 0.4592 - val_acc: 0.7949 - val_auc: 0.8718 - val_loss: 0.4408\n",
      "Epoch 5537/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7807 - auc: 0.8604 - loss: 0.4578 - val_acc: 0.7918 - val_auc: 0.8722 - val_loss: 0.4399\n",
      "Epoch 5538/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7788 - auc: 0.8578 - loss: 0.4615 - val_acc: 0.7939 - val_auc: 0.8723 - val_loss: 0.4399\n",
      "Epoch 5539/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7792 - auc: 0.8593 - loss: 0.4601 - val_acc: 0.7947 - val_auc: 0.8734 - val_loss: 0.4403\n",
      "Epoch 5540/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7809 - auc: 0.8602 - loss: 0.4586 - val_acc: 0.7942 - val_auc: 0.8720 - val_loss: 0.4392\n",
      "Epoch 5541/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7787 - auc: 0.8592 - loss: 0.4596 - val_acc: 0.7932 - val_auc: 0.8732 - val_loss: 0.4403\n",
      "Epoch 5542/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7804 - auc: 0.8580 - loss: 0.4608 - val_acc: 0.7959 - val_auc: 0.8732 - val_loss: 0.4384\n",
      "Epoch 5543/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7818 - auc: 0.8610 - loss: 0.4570 - val_acc: 0.7948 - val_auc: 0.8714 - val_loss: 0.4391\n",
      "Epoch 5544/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7787 - auc: 0.8592 - loss: 0.4604 - val_acc: 0.7954 - val_auc: 0.8720 - val_loss: 0.4399\n",
      "Epoch 5545/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7770 - auc: 0.8583 - loss: 0.4605 - val_acc: 0.7944 - val_auc: 0.8726 - val_loss: 0.4412\n",
      "Epoch 5546/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7814 - auc: 0.8589 - loss: 0.4589 - val_acc: 0.7947 - val_auc: 0.8723 - val_loss: 0.4399\n",
      "Epoch 5547/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7801 - auc: 0.8595 - loss: 0.4586 - val_acc: 0.7951 - val_auc: 0.8719 - val_loss: 0.4405\n",
      "Epoch 5548/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7805 - auc: 0.8604 - loss: 0.4575 - val_acc: 0.7932 - val_auc: 0.8723 - val_loss: 0.4382\n",
      "Epoch 5549/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7795 - auc: 0.8603 - loss: 0.4587 - val_acc: 0.7933 - val_auc: 0.8714 - val_loss: 0.4397\n",
      "Epoch 5550/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7781 - auc: 0.8580 - loss: 0.4619 - val_acc: 0.7951 - val_auc: 0.8735 - val_loss: 0.4394\n",
      "Epoch 5551/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7795 - auc: 0.8603 - loss: 0.4583 - val_acc: 0.7931 - val_auc: 0.8719 - val_loss: 0.4422\n",
      "Epoch 5552/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7804 - auc: 0.8593 - loss: 0.4594 - val_acc: 0.7922 - val_auc: 0.8721 - val_loss: 0.4409\n",
      "Epoch 5553/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7801 - auc: 0.8597 - loss: 0.4584 - val_acc: 0.7946 - val_auc: 0.8727 - val_loss: 0.4389\n",
      "Epoch 5554/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7805 - auc: 0.8596 - loss: 0.4598 - val_acc: 0.7955 - val_auc: 0.8726 - val_loss: 0.4409\n",
      "Epoch 5555/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7805 - auc: 0.8595 - loss: 0.4588 - val_acc: 0.7919 - val_auc: 0.8721 - val_loss: 0.4410\n",
      "Epoch 5556/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7788 - auc: 0.8593 - loss: 0.4595 - val_acc: 0.7937 - val_auc: 0.8721 - val_loss: 0.4400\n",
      "Epoch 5557/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7807 - auc: 0.8602 - loss: 0.4583 - val_acc: 0.7955 - val_auc: 0.8724 - val_loss: 0.4390\n",
      "Epoch 5558/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7777 - auc: 0.8581 - loss: 0.4616 - val_acc: 0.7974 - val_auc: 0.8742 - val_loss: 0.4388\n",
      "Epoch 5559/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7781 - auc: 0.8601 - loss: 0.4578 - val_acc: 0.7951 - val_auc: 0.8733 - val_loss: 0.4390\n",
      "Epoch 5560/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7804 - auc: 0.8601 - loss: 0.4573 - val_acc: 0.7942 - val_auc: 0.8727 - val_loss: 0.4417\n",
      "Epoch 5561/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7806 - auc: 0.8603 - loss: 0.4587 - val_acc: 0.7928 - val_auc: 0.8716 - val_loss: 0.4408\n",
      "Epoch 5562/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7789 - auc: 0.8587 - loss: 0.4607 - val_acc: 0.7976 - val_auc: 0.8729 - val_loss: 0.4390\n",
      "Epoch 5563/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7812 - auc: 0.8608 - loss: 0.4568 - val_acc: 0.7987 - val_auc: 0.8733 - val_loss: 0.4374\n",
      "Epoch 5564/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7808 - auc: 0.8600 - loss: 0.4582 - val_acc: 0.7950 - val_auc: 0.8727 - val_loss: 0.4388\n",
      "Epoch 5565/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7804 - auc: 0.8596 - loss: 0.4584 - val_acc: 0.7967 - val_auc: 0.8735 - val_loss: 0.4377\n",
      "Epoch 5566/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7803 - auc: 0.8608 - loss: 0.4575 - val_acc: 0.7925 - val_auc: 0.8727 - val_loss: 0.4390\n",
      "Epoch 5567/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7792 - auc: 0.8595 - loss: 0.4578 - val_acc: 0.7927 - val_auc: 0.8706 - val_loss: 0.4420\n",
      "Epoch 5568/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7789 - auc: 0.8590 - loss: 0.4596 - val_acc: 0.7954 - val_auc: 0.8723 - val_loss: 0.4386\n",
      "Epoch 5569/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7777 - auc: 0.8587 - loss: 0.4602 - val_acc: 0.7951 - val_auc: 0.8720 - val_loss: 0.4399\n",
      "Epoch 5570/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7836 - auc: 0.8616 - loss: 0.4554 - val_acc: 0.7941 - val_auc: 0.8716 - val_loss: 0.4400\n",
      "Epoch 5571/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7798 - auc: 0.8597 - loss: 0.4588 - val_acc: 0.7956 - val_auc: 0.8729 - val_loss: 0.4381\n",
      "Epoch 5572/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8596 - loss: 0.4584 - val_acc: 0.7935 - val_auc: 0.8716 - val_loss: 0.4407\n",
      "Epoch 5573/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7822 - auc: 0.8605 - loss: 0.4576 - val_acc: 0.7973 - val_auc: 0.8730 - val_loss: 0.4381\n",
      "Epoch 5574/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8606 - loss: 0.4587 - val_acc: 0.7963 - val_auc: 0.8725 - val_loss: 0.4402\n",
      "Epoch 5575/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7811 - auc: 0.8592 - loss: 0.4600 - val_acc: 0.7957 - val_auc: 0.8727 - val_loss: 0.4401\n",
      "Epoch 5576/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7787 - auc: 0.8591 - loss: 0.4601 - val_acc: 0.7963 - val_auc: 0.8731 - val_loss: 0.4391\n",
      "Epoch 5577/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7825 - auc: 0.8596 - loss: 0.4580 - val_acc: 0.7959 - val_auc: 0.8723 - val_loss: 0.4394\n",
      "Epoch 5578/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7812 - auc: 0.8605 - loss: 0.4582 - val_acc: 0.7964 - val_auc: 0.8718 - val_loss: 0.4390\n",
      "Epoch 5579/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7790 - auc: 0.8597 - loss: 0.4584 - val_acc: 0.7937 - val_auc: 0.8714 - val_loss: 0.4395\n",
      "Epoch 5580/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7798 - auc: 0.8598 - loss: 0.4592 - val_acc: 0.7954 - val_auc: 0.8722 - val_loss: 0.4393\n",
      "Epoch 5581/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7802 - auc: 0.8601 - loss: 0.4583 - val_acc: 0.7939 - val_auc: 0.8719 - val_loss: 0.4414\n",
      "Epoch 5582/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7792 - auc: 0.8592 - loss: 0.4588 - val_acc: 0.7971 - val_auc: 0.8725 - val_loss: 0.4400\n",
      "Epoch 5583/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8603 - loss: 0.4578 - val_acc: 0.7953 - val_auc: 0.8735 - val_loss: 0.4382\n",
      "Epoch 5584/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7779 - auc: 0.8587 - loss: 0.4601 - val_acc: 0.7934 - val_auc: 0.8720 - val_loss: 0.4418\n",
      "Epoch 5585/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7803 - auc: 0.8596 - loss: 0.4581 - val_acc: 0.7952 - val_auc: 0.8739 - val_loss: 0.4393\n",
      "Epoch 5586/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7804 - auc: 0.8604 - loss: 0.4574 - val_acc: 0.7942 - val_auc: 0.8716 - val_loss: 0.4400\n",
      "Epoch 5587/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7799 - auc: 0.8593 - loss: 0.4604 - val_acc: 0.7945 - val_auc: 0.8726 - val_loss: 0.4416\n",
      "Epoch 5588/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7793 - auc: 0.8599 - loss: 0.4595 - val_acc: 0.7936 - val_auc: 0.8717 - val_loss: 0.4414\n",
      "Epoch 5589/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7798 - auc: 0.8589 - loss: 0.4602 - val_acc: 0.7978 - val_auc: 0.8734 - val_loss: 0.4386\n",
      "Epoch 5590/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7806 - auc: 0.8598 - loss: 0.4585 - val_acc: 0.7927 - val_auc: 0.8715 - val_loss: 0.4399\n",
      "Epoch 5591/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7827 - auc: 0.8606 - loss: 0.4566 - val_acc: 0.7955 - val_auc: 0.8722 - val_loss: 0.4393\n",
      "Epoch 5592/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8597 - loss: 0.4580 - val_acc: 0.7924 - val_auc: 0.8716 - val_loss: 0.4398\n",
      "Epoch 5593/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7794 - auc: 0.8594 - loss: 0.4594 - val_acc: 0.7939 - val_auc: 0.8728 - val_loss: 0.4396\n",
      "Epoch 5594/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7807 - auc: 0.8596 - loss: 0.4588 - val_acc: 0.7928 - val_auc: 0.8715 - val_loss: 0.4411\n",
      "Epoch 5595/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7800 - auc: 0.8597 - loss: 0.4578 - val_acc: 0.7915 - val_auc: 0.8723 - val_loss: 0.4411\n",
      "Epoch 5596/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7777 - auc: 0.8576 - loss: 0.4614 - val_acc: 0.7944 - val_auc: 0.8722 - val_loss: 0.4388\n",
      "Epoch 5597/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7803 - auc: 0.8595 - loss: 0.4586 - val_acc: 0.7937 - val_auc: 0.8717 - val_loss: 0.4408\n",
      "Epoch 5598/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7811 - auc: 0.8600 - loss: 0.4590 - val_acc: 0.7935 - val_auc: 0.8727 - val_loss: 0.4390\n",
      "Epoch 5599/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7824 - auc: 0.8610 - loss: 0.4567 - val_acc: 0.7946 - val_auc: 0.8724 - val_loss: 0.4398\n",
      "Epoch 5600/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7788 - auc: 0.8584 - loss: 0.4608 - val_acc: 0.7919 - val_auc: 0.8723 - val_loss: 0.4398\n",
      "Epoch 5601/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7792 - auc: 0.8601 - loss: 0.4587 - val_acc: 0.7929 - val_auc: 0.8717 - val_loss: 0.4406\n",
      "Epoch 5602/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7803 - auc: 0.8605 - loss: 0.4579 - val_acc: 0.7946 - val_auc: 0.8714 - val_loss: 0.4413\n",
      "Epoch 5603/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7800 - auc: 0.8586 - loss: 0.4597 - val_acc: 0.7958 - val_auc: 0.8729 - val_loss: 0.4385\n",
      "Epoch 5604/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7810 - auc: 0.8595 - loss: 0.4591 - val_acc: 0.7912 - val_auc: 0.8712 - val_loss: 0.4428\n",
      "Epoch 5605/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7801 - auc: 0.8599 - loss: 0.4585 - val_acc: 0.7952 - val_auc: 0.8729 - val_loss: 0.4393\n",
      "Epoch 5606/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7789 - auc: 0.8589 - loss: 0.4598 - val_acc: 0.7945 - val_auc: 0.8723 - val_loss: 0.4407\n",
      "Epoch 5607/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7802 - auc: 0.8598 - loss: 0.4594 - val_acc: 0.7937 - val_auc: 0.8730 - val_loss: 0.4398\n",
      "Epoch 5608/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7804 - auc: 0.8596 - loss: 0.4583 - val_acc: 0.7977 - val_auc: 0.8729 - val_loss: 0.4400\n",
      "Epoch 5609/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7793 - auc: 0.8594 - loss: 0.4604 - val_acc: 0.7952 - val_auc: 0.8723 - val_loss: 0.4396\n",
      "Epoch 5610/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7816 - auc: 0.8613 - loss: 0.4570 - val_acc: 0.7960 - val_auc: 0.8728 - val_loss: 0.4399\n",
      "Epoch 5611/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7825 - auc: 0.8610 - loss: 0.4578 - val_acc: 0.7921 - val_auc: 0.8723 - val_loss: 0.4399\n",
      "Epoch 5612/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7785 - auc: 0.8596 - loss: 0.4595 - val_acc: 0.7936 - val_auc: 0.8718 - val_loss: 0.4399\n",
      "Epoch 5613/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7784 - auc: 0.8586 - loss: 0.4590 - val_acc: 0.7955 - val_auc: 0.8720 - val_loss: 0.4402\n",
      "Epoch 5614/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7807 - auc: 0.8593 - loss: 0.4599 - val_acc: 0.7927 - val_auc: 0.8718 - val_loss: 0.4411\n",
      "Epoch 5615/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7808 - auc: 0.8596 - loss: 0.4596 - val_acc: 0.7959 - val_auc: 0.8727 - val_loss: 0.4402\n",
      "Epoch 5616/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7788 - auc: 0.8595 - loss: 0.4587 - val_acc: 0.7940 - val_auc: 0.8709 - val_loss: 0.4415\n",
      "Epoch 5617/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7802 - auc: 0.8600 - loss: 0.4575 - val_acc: 0.7961 - val_auc: 0.8727 - val_loss: 0.4391\n",
      "Epoch 5618/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7782 - auc: 0.8591 - loss: 0.4600 - val_acc: 0.7926 - val_auc: 0.8730 - val_loss: 0.4394\n",
      "Epoch 5619/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7833 - auc: 0.8600 - loss: 0.4577 - val_acc: 0.7945 - val_auc: 0.8715 - val_loss: 0.4424\n",
      "Epoch 5620/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7813 - auc: 0.8610 - loss: 0.4565 - val_acc: 0.7961 - val_auc: 0.8723 - val_loss: 0.4381\n",
      "Epoch 5621/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7813 - auc: 0.8607 - loss: 0.4577 - val_acc: 0.7946 - val_auc: 0.8724 - val_loss: 0.4414\n",
      "Epoch 5622/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7807 - auc: 0.8600 - loss: 0.4591 - val_acc: 0.7956 - val_auc: 0.8729 - val_loss: 0.4395\n",
      "Epoch 5623/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7803 - auc: 0.8590 - loss: 0.4592 - val_acc: 0.7942 - val_auc: 0.8718 - val_loss: 0.4393\n",
      "Epoch 5624/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7804 - auc: 0.8611 - loss: 0.4565 - val_acc: 0.7960 - val_auc: 0.8726 - val_loss: 0.4385\n",
      "Epoch 5625/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7783 - auc: 0.8576 - loss: 0.4630 - val_acc: 0.7975 - val_auc: 0.8746 - val_loss: 0.4395\n",
      "Epoch 5626/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7795 - auc: 0.8598 - loss: 0.4574 - val_acc: 0.7954 - val_auc: 0.8729 - val_loss: 0.4402\n",
      "Epoch 5627/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7790 - auc: 0.8589 - loss: 0.4605 - val_acc: 0.7923 - val_auc: 0.8709 - val_loss: 0.4431\n",
      "Epoch 5628/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7800 - auc: 0.8608 - loss: 0.4574 - val_acc: 0.7964 - val_auc: 0.8724 - val_loss: 0.4405\n",
      "Epoch 5629/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7820 - auc: 0.8605 - loss: 0.4574 - val_acc: 0.7966 - val_auc: 0.8729 - val_loss: 0.4376\n",
      "Epoch 5630/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7805 - auc: 0.8597 - loss: 0.4579 - val_acc: 0.7950 - val_auc: 0.8720 - val_loss: 0.4398\n",
      "Epoch 5631/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7805 - auc: 0.8602 - loss: 0.4578 - val_acc: 0.7949 - val_auc: 0.8734 - val_loss: 0.4382\n",
      "Epoch 5632/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7811 - auc: 0.8608 - loss: 0.4568 - val_acc: 0.7953 - val_auc: 0.8722 - val_loss: 0.4396\n",
      "Epoch 5633/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7798 - auc: 0.8594 - loss: 0.4592 - val_acc: 0.7939 - val_auc: 0.8724 - val_loss: 0.4402\n",
      "Epoch 5634/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7800 - auc: 0.8600 - loss: 0.4593 - val_acc: 0.7955 - val_auc: 0.8725 - val_loss: 0.4394\n",
      "Epoch 5635/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7844 - auc: 0.8608 - loss: 0.4575 - val_acc: 0.7937 - val_auc: 0.8729 - val_loss: 0.4389\n",
      "Epoch 5636/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7801 - auc: 0.8610 - loss: 0.4568 - val_acc: 0.7978 - val_auc: 0.8726 - val_loss: 0.4389\n",
      "Epoch 5637/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7808 - auc: 0.8608 - loss: 0.4571 - val_acc: 0.7964 - val_auc: 0.8724 - val_loss: 0.4395\n",
      "Epoch 5638/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7789 - auc: 0.8582 - loss: 0.4610 - val_acc: 0.7941 - val_auc: 0.8722 - val_loss: 0.4417\n",
      "Epoch 5639/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7798 - auc: 0.8596 - loss: 0.4585 - val_acc: 0.7942 - val_auc: 0.8723 - val_loss: 0.4398\n",
      "Epoch 5640/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7804 - auc: 0.8604 - loss: 0.4577 - val_acc: 0.7958 - val_auc: 0.8720 - val_loss: 0.4406\n",
      "Epoch 5641/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7799 - auc: 0.8590 - loss: 0.4600 - val_acc: 0.7958 - val_auc: 0.8726 - val_loss: 0.4401\n",
      "Epoch 5642/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8578 - loss: 0.4620 - val_acc: 0.7938 - val_auc: 0.8731 - val_loss: 0.4415\n",
      "Epoch 5643/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7791 - auc: 0.8591 - loss: 0.4598 - val_acc: 0.7924 - val_auc: 0.8720 - val_loss: 0.4417\n",
      "Epoch 5644/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7803 - auc: 0.8591 - loss: 0.4598 - val_acc: 0.7943 - val_auc: 0.8723 - val_loss: 0.4406\n",
      "Epoch 5645/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7796 - auc: 0.8599 - loss: 0.4582 - val_acc: 0.7962 - val_auc: 0.8724 - val_loss: 0.4398\n",
      "Epoch 5646/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7828 - auc: 0.8609 - loss: 0.4574 - val_acc: 0.7972 - val_auc: 0.8727 - val_loss: 0.4391\n",
      "Epoch 5647/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7808 - auc: 0.8612 - loss: 0.4570 - val_acc: 0.7956 - val_auc: 0.8729 - val_loss: 0.4384\n",
      "Epoch 5648/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7791 - auc: 0.8595 - loss: 0.4585 - val_acc: 0.7971 - val_auc: 0.8727 - val_loss: 0.4395\n",
      "Epoch 5649/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7817 - auc: 0.8616 - loss: 0.4559 - val_acc: 0.7936 - val_auc: 0.8721 - val_loss: 0.4395\n",
      "Epoch 5650/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7817 - auc: 0.8592 - loss: 0.4602 - val_acc: 0.7927 - val_auc: 0.8722 - val_loss: 0.4401\n",
      "Epoch 5651/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7825 - auc: 0.8617 - loss: 0.4555 - val_acc: 0.7960 - val_auc: 0.8723 - val_loss: 0.4387\n",
      "Epoch 5652/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7827 - auc: 0.8610 - loss: 0.4577 - val_acc: 0.7940 - val_auc: 0.8724 - val_loss: 0.4399\n",
      "Epoch 5653/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7809 - auc: 0.8604 - loss: 0.4581 - val_acc: 0.7964 - val_auc: 0.8733 - val_loss: 0.4399\n",
      "Epoch 5654/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7786 - auc: 0.8594 - loss: 0.4581 - val_acc: 0.7941 - val_auc: 0.8730 - val_loss: 0.4402\n",
      "Epoch 5655/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7812 - auc: 0.8605 - loss: 0.4574 - val_acc: 0.7961 - val_auc: 0.8721 - val_loss: 0.4381\n",
      "Epoch 5656/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7809 - auc: 0.8597 - loss: 0.4587 - val_acc: 0.7966 - val_auc: 0.8729 - val_loss: 0.4377\n",
      "Epoch 5657/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7816 - auc: 0.8609 - loss: 0.4572 - val_acc: 0.7950 - val_auc: 0.8721 - val_loss: 0.4385\n",
      "Epoch 5658/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7793 - auc: 0.8590 - loss: 0.4590 - val_acc: 0.7950 - val_auc: 0.8719 - val_loss: 0.4400\n",
      "Epoch 5659/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7787 - auc: 0.8586 - loss: 0.4605 - val_acc: 0.7940 - val_auc: 0.8723 - val_loss: 0.4406\n",
      "Epoch 5660/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7798 - auc: 0.8591 - loss: 0.4591 - val_acc: 0.7932 - val_auc: 0.8709 - val_loss: 0.4398\n",
      "Epoch 5661/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7819 - auc: 0.8607 - loss: 0.4572 - val_acc: 0.7952 - val_auc: 0.8717 - val_loss: 0.4398\n",
      "Epoch 5662/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7786 - auc: 0.8598 - loss: 0.4588 - val_acc: 0.7960 - val_auc: 0.8734 - val_loss: 0.4397\n",
      "Epoch 5663/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7820 - auc: 0.8610 - loss: 0.4572 - val_acc: 0.7959 - val_auc: 0.8722 - val_loss: 0.4393\n",
      "Epoch 5664/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7806 - auc: 0.8597 - loss: 0.4594 - val_acc: 0.7945 - val_auc: 0.8724 - val_loss: 0.4416\n",
      "Epoch 5665/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7819 - auc: 0.8613 - loss: 0.4564 - val_acc: 0.7950 - val_auc: 0.8734 - val_loss: 0.4391\n",
      "Epoch 5666/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7812 - auc: 0.8611 - loss: 0.4568 - val_acc: 0.7941 - val_auc: 0.8717 - val_loss: 0.4401\n",
      "Epoch 5667/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7800 - auc: 0.8595 - loss: 0.4581 - val_acc: 0.7922 - val_auc: 0.8718 - val_loss: 0.4407\n",
      "Epoch 5668/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7799 - auc: 0.8598 - loss: 0.4580 - val_acc: 0.7942 - val_auc: 0.8726 - val_loss: 0.4397\n",
      "Epoch 5669/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7811 - auc: 0.8603 - loss: 0.4577 - val_acc: 0.7974 - val_auc: 0.8732 - val_loss: 0.4385\n",
      "Epoch 5670/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7812 - auc: 0.8604 - loss: 0.4576 - val_acc: 0.7953 - val_auc: 0.8728 - val_loss: 0.4400\n",
      "Epoch 5671/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7832 - auc: 0.8613 - loss: 0.4554 - val_acc: 0.7967 - val_auc: 0.8737 - val_loss: 0.4368\n",
      "Epoch 5672/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7793 - auc: 0.8589 - loss: 0.4599 - val_acc: 0.7950 - val_auc: 0.8732 - val_loss: 0.4403\n",
      "Epoch 5673/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7813 - auc: 0.8613 - loss: 0.4567 - val_acc: 0.7963 - val_auc: 0.8731 - val_loss: 0.4373\n",
      "Epoch 5674/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7808 - auc: 0.8605 - loss: 0.4573 - val_acc: 0.7976 - val_auc: 0.8741 - val_loss: 0.4393\n",
      "Epoch 5675/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7826 - auc: 0.8604 - loss: 0.4582 - val_acc: 0.7953 - val_auc: 0.8727 - val_loss: 0.4390\n",
      "Epoch 5676/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7805 - auc: 0.8613 - loss: 0.4570 - val_acc: 0.7957 - val_auc: 0.8729 - val_loss: 0.4406\n",
      "Epoch 5677/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7795 - auc: 0.8596 - loss: 0.4585 - val_acc: 0.7972 - val_auc: 0.8722 - val_loss: 0.4398\n",
      "Epoch 5678/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7785 - auc: 0.8597 - loss: 0.4588 - val_acc: 0.7964 - val_auc: 0.8739 - val_loss: 0.4370\n",
      "Epoch 5679/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7812 - auc: 0.8600 - loss: 0.4584 - val_acc: 0.7963 - val_auc: 0.8726 - val_loss: 0.4399\n",
      "Epoch 5680/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7798 - auc: 0.8598 - loss: 0.4586 - val_acc: 0.7939 - val_auc: 0.8723 - val_loss: 0.4393\n",
      "Epoch 5681/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7794 - auc: 0.8592 - loss: 0.4592 - val_acc: 0.7949 - val_auc: 0.8726 - val_loss: 0.4391\n",
      "Epoch 5682/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7821 - auc: 0.8610 - loss: 0.4560 - val_acc: 0.7963 - val_auc: 0.8716 - val_loss: 0.4394\n",
      "Epoch 5683/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7809 - auc: 0.8596 - loss: 0.4585 - val_acc: 0.7938 - val_auc: 0.8710 - val_loss: 0.4412\n",
      "Epoch 5684/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7800 - auc: 0.8590 - loss: 0.4598 - val_acc: 0.7952 - val_auc: 0.8728 - val_loss: 0.4391\n",
      "Epoch 5685/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7811 - auc: 0.8599 - loss: 0.4582 - val_acc: 0.7959 - val_auc: 0.8729 - val_loss: 0.4412\n",
      "Epoch 5686/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7788 - auc: 0.8592 - loss: 0.4588 - val_acc: 0.7964 - val_auc: 0.8721 - val_loss: 0.4396\n",
      "Epoch 5687/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7810 - auc: 0.8603 - loss: 0.4571 - val_acc: 0.7956 - val_auc: 0.8736 - val_loss: 0.4387\n",
      "Epoch 5688/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7803 - auc: 0.8601 - loss: 0.4582 - val_acc: 0.7960 - val_auc: 0.8741 - val_loss: 0.4374\n",
      "Epoch 5689/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7807 - auc: 0.8602 - loss: 0.4582 - val_acc: 0.7959 - val_auc: 0.8727 - val_loss: 0.4386\n",
      "Epoch 5690/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7796 - auc: 0.8601 - loss: 0.4584 - val_acc: 0.7945 - val_auc: 0.8718 - val_loss: 0.4385\n",
      "Epoch 5691/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7810 - auc: 0.8608 - loss: 0.4570 - val_acc: 0.7954 - val_auc: 0.8737 - val_loss: 0.4379\n",
      "Epoch 5692/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7773 - auc: 0.8593 - loss: 0.4599 - val_acc: 0.7976 - val_auc: 0.8734 - val_loss: 0.4396\n",
      "Epoch 5693/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7816 - auc: 0.8605 - loss: 0.4576 - val_acc: 0.7959 - val_auc: 0.8735 - val_loss: 0.4379\n",
      "Epoch 5694/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7809 - auc: 0.8600 - loss: 0.4589 - val_acc: 0.7938 - val_auc: 0.8714 - val_loss: 0.4415\n",
      "Epoch 5695/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7804 - auc: 0.8591 - loss: 0.4601 - val_acc: 0.7965 - val_auc: 0.8734 - val_loss: 0.4397\n",
      "Epoch 5696/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7794 - auc: 0.8599 - loss: 0.4591 - val_acc: 0.7952 - val_auc: 0.8724 - val_loss: 0.4400\n",
      "Epoch 5697/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7829 - auc: 0.8604 - loss: 0.4581 - val_acc: 0.7949 - val_auc: 0.8738 - val_loss: 0.4385\n",
      "Epoch 5698/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7792 - auc: 0.8595 - loss: 0.4589 - val_acc: 0.7953 - val_auc: 0.8729 - val_loss: 0.4399\n",
      "Epoch 5699/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7811 - auc: 0.8614 - loss: 0.4561 - val_acc: 0.7960 - val_auc: 0.8737 - val_loss: 0.4393\n",
      "Epoch 5700/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7794 - auc: 0.8588 - loss: 0.4605 - val_acc: 0.7959 - val_auc: 0.8727 - val_loss: 0.4393\n",
      "Epoch 5701/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7807 - auc: 0.8603 - loss: 0.4586 - val_acc: 0.7940 - val_auc: 0.8721 - val_loss: 0.4409\n",
      "Epoch 5702/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7808 - auc: 0.8591 - loss: 0.4602 - val_acc: 0.7963 - val_auc: 0.8710 - val_loss: 0.4412\n",
      "Epoch 5703/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7810 - auc: 0.8595 - loss: 0.4584 - val_acc: 0.7970 - val_auc: 0.8726 - val_loss: 0.4392\n",
      "Epoch 5704/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7818 - auc: 0.8608 - loss: 0.4578 - val_acc: 0.7951 - val_auc: 0.8732 - val_loss: 0.4388\n",
      "Epoch 5705/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7796 - auc: 0.8597 - loss: 0.4601 - val_acc: 0.7952 - val_auc: 0.8727 - val_loss: 0.4403\n",
      "Epoch 5706/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7831 - auc: 0.8615 - loss: 0.4563 - val_acc: 0.7967 - val_auc: 0.8720 - val_loss: 0.4391\n",
      "Epoch 5707/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8601 - loss: 0.4585 - val_acc: 0.7979 - val_auc: 0.8723 - val_loss: 0.4389\n",
      "Epoch 5708/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7794 - auc: 0.8594 - loss: 0.4593 - val_acc: 0.7952 - val_auc: 0.8722 - val_loss: 0.4387\n",
      "Epoch 5709/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7821 - auc: 0.8620 - loss: 0.4554 - val_acc: 0.7979 - val_auc: 0.8737 - val_loss: 0.4376\n",
      "Epoch 5710/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7804 - auc: 0.8610 - loss: 0.4573 - val_acc: 0.7953 - val_auc: 0.8736 - val_loss: 0.4382\n",
      "Epoch 5711/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7789 - auc: 0.8594 - loss: 0.4586 - val_acc: 0.7956 - val_auc: 0.8720 - val_loss: 0.4391\n",
      "Epoch 5712/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7813 - auc: 0.8601 - loss: 0.4580 - val_acc: 0.7956 - val_auc: 0.8736 - val_loss: 0.4394\n",
      "Epoch 5713/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7798 - auc: 0.8595 - loss: 0.4595 - val_acc: 0.7980 - val_auc: 0.8728 - val_loss: 0.4396\n",
      "Epoch 5714/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7796 - auc: 0.8594 - loss: 0.4596 - val_acc: 0.7983 - val_auc: 0.8726 - val_loss: 0.4387\n",
      "Epoch 5715/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7781 - auc: 0.8592 - loss: 0.4592 - val_acc: 0.7939 - val_auc: 0.8735 - val_loss: 0.4382\n",
      "Epoch 5716/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7816 - auc: 0.8600 - loss: 0.4589 - val_acc: 0.7947 - val_auc: 0.8717 - val_loss: 0.4419\n",
      "Epoch 5717/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7802 - auc: 0.8612 - loss: 0.4578 - val_acc: 0.7971 - val_auc: 0.8737 - val_loss: 0.4381\n",
      "Epoch 5718/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7817 - auc: 0.8603 - loss: 0.4592 - val_acc: 0.7964 - val_auc: 0.8731 - val_loss: 0.4388\n",
      "Epoch 5719/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7811 - auc: 0.8624 - loss: 0.4551 - val_acc: 0.7950 - val_auc: 0.8731 - val_loss: 0.4396\n",
      "Epoch 5720/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7806 - auc: 0.8596 - loss: 0.4591 - val_acc: 0.7938 - val_auc: 0.8710 - val_loss: 0.4425\n",
      "Epoch 5721/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8602 - loss: 0.4578 - val_acc: 0.7959 - val_auc: 0.8719 - val_loss: 0.4401\n",
      "Epoch 5722/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7784 - auc: 0.8591 - loss: 0.4601 - val_acc: 0.7938 - val_auc: 0.8731 - val_loss: 0.4401\n",
      "Epoch 5723/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7806 - auc: 0.8598 - loss: 0.4591 - val_acc: 0.7938 - val_auc: 0.8725 - val_loss: 0.4410\n",
      "Epoch 5724/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7811 - auc: 0.8607 - loss: 0.4574 - val_acc: 0.7948 - val_auc: 0.8727 - val_loss: 0.4397\n",
      "Epoch 5725/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7805 - auc: 0.8591 - loss: 0.4588 - val_acc: 0.7926 - val_auc: 0.8716 - val_loss: 0.4404\n",
      "Epoch 5726/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7810 - auc: 0.8598 - loss: 0.4592 - val_acc: 0.7956 - val_auc: 0.8735 - val_loss: 0.4376\n",
      "Epoch 5727/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7784 - auc: 0.8594 - loss: 0.4590 - val_acc: 0.7943 - val_auc: 0.8736 - val_loss: 0.4411\n",
      "Epoch 5728/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7795 - auc: 0.8588 - loss: 0.4608 - val_acc: 0.7943 - val_auc: 0.8725 - val_loss: 0.4400\n",
      "Epoch 5729/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7802 - auc: 0.8594 - loss: 0.4593 - val_acc: 0.7940 - val_auc: 0.8724 - val_loss: 0.4408\n",
      "Epoch 5730/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7803 - auc: 0.8588 - loss: 0.4591 - val_acc: 0.7923 - val_auc: 0.8716 - val_loss: 0.4420\n",
      "Epoch 5731/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7806 - auc: 0.8602 - loss: 0.4582 - val_acc: 0.7961 - val_auc: 0.8724 - val_loss: 0.4396\n",
      "Epoch 5732/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7829 - auc: 0.8614 - loss: 0.4563 - val_acc: 0.7964 - val_auc: 0.8735 - val_loss: 0.4395\n",
      "Epoch 5733/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7840 - auc: 0.8618 - loss: 0.4550 - val_acc: 0.7927 - val_auc: 0.8726 - val_loss: 0.4392\n",
      "Epoch 5734/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7800 - auc: 0.8604 - loss: 0.4579 - val_acc: 0.7947 - val_auc: 0.8723 - val_loss: 0.4396\n",
      "Epoch 5735/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7830 - auc: 0.8619 - loss: 0.4554 - val_acc: 0.7971 - val_auc: 0.8732 - val_loss: 0.4370\n",
      "Epoch 5736/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7807 - auc: 0.8600 - loss: 0.4588 - val_acc: 0.7959 - val_auc: 0.8735 - val_loss: 0.4392\n",
      "Epoch 5737/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7824 - auc: 0.8614 - loss: 0.4572 - val_acc: 0.7970 - val_auc: 0.8726 - val_loss: 0.4399\n",
      "Epoch 5738/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7802 - auc: 0.8591 - loss: 0.4598 - val_acc: 0.7903 - val_auc: 0.8722 - val_loss: 0.4421\n",
      "Epoch 5739/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7800 - auc: 0.8595 - loss: 0.4592 - val_acc: 0.7974 - val_auc: 0.8733 - val_loss: 0.4385\n",
      "Epoch 5740/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7842 - auc: 0.8630 - loss: 0.4531 - val_acc: 0.7981 - val_auc: 0.8735 - val_loss: 0.4386\n",
      "Epoch 5741/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7803 - auc: 0.8594 - loss: 0.4599 - val_acc: 0.7958 - val_auc: 0.8718 - val_loss: 0.4410\n",
      "Epoch 5742/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8594 - loss: 0.4580 - val_acc: 0.7926 - val_auc: 0.8705 - val_loss: 0.4436\n",
      "Epoch 5743/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7781 - auc: 0.8595 - loss: 0.4601 - val_acc: 0.8008 - val_auc: 0.8741 - val_loss: 0.4390\n",
      "Epoch 5744/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7805 - auc: 0.8606 - loss: 0.4573 - val_acc: 0.7948 - val_auc: 0.8736 - val_loss: 0.4377\n",
      "Epoch 5745/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7810 - auc: 0.8606 - loss: 0.4580 - val_acc: 0.7964 - val_auc: 0.8743 - val_loss: 0.4381\n",
      "Epoch 5746/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7793 - auc: 0.8585 - loss: 0.4596 - val_acc: 0.7938 - val_auc: 0.8726 - val_loss: 0.4405\n",
      "Epoch 5747/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7812 - auc: 0.8600 - loss: 0.4591 - val_acc: 0.7952 - val_auc: 0.8725 - val_loss: 0.4390\n",
      "Epoch 5748/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7793 - auc: 0.8596 - loss: 0.4582 - val_acc: 0.7989 - val_auc: 0.8740 - val_loss: 0.4389\n",
      "Epoch 5749/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7811 - auc: 0.8608 - loss: 0.4568 - val_acc: 0.7943 - val_auc: 0.8733 - val_loss: 0.4392\n",
      "Epoch 5750/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7802 - auc: 0.8600 - loss: 0.4574 - val_acc: 0.7940 - val_auc: 0.8720 - val_loss: 0.4413\n",
      "Epoch 5751/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7797 - auc: 0.8599 - loss: 0.4582 - val_acc: 0.7969 - val_auc: 0.8736 - val_loss: 0.4384\n",
      "Epoch 5752/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7826 - auc: 0.8617 - loss: 0.4560 - val_acc: 0.7938 - val_auc: 0.8726 - val_loss: 0.4404\n",
      "Epoch 5753/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7794 - auc: 0.8591 - loss: 0.4596 - val_acc: 0.7976 - val_auc: 0.8736 - val_loss: 0.4385\n",
      "Epoch 5754/7000\n",
      "106/106 - 2s - 14ms/step - acc: 0.7807 - auc: 0.8608 - loss: 0.4575 - val_acc: 0.7949 - val_auc: 0.8736 - val_loss: 0.4394\n",
      "Epoch 5755/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7796 - auc: 0.8592 - loss: 0.4593 - val_acc: 0.7963 - val_auc: 0.8726 - val_loss: 0.4393\n",
      "Epoch 5756/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7792 - auc: 0.8600 - loss: 0.4587 - val_acc: 0.7951 - val_auc: 0.8728 - val_loss: 0.4400\n",
      "Epoch 5757/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7822 - auc: 0.8619 - loss: 0.4554 - val_acc: 0.7942 - val_auc: 0.8728 - val_loss: 0.4401\n",
      "Epoch 5758/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7798 - auc: 0.8601 - loss: 0.4580 - val_acc: 0.7962 - val_auc: 0.8733 - val_loss: 0.4388\n",
      "Epoch 5759/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7814 - auc: 0.8615 - loss: 0.4564 - val_acc: 0.7970 - val_auc: 0.8742 - val_loss: 0.4390\n",
      "Epoch 5760/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7809 - auc: 0.8607 - loss: 0.4563 - val_acc: 0.7967 - val_auc: 0.8729 - val_loss: 0.4385\n",
      "Epoch 5761/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7821 - auc: 0.8631 - loss: 0.4541 - val_acc: 0.7985 - val_auc: 0.8746 - val_loss: 0.4377\n",
      "Epoch 5762/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7794 - auc: 0.8601 - loss: 0.4580 - val_acc: 0.7970 - val_auc: 0.8738 - val_loss: 0.4367\n",
      "Epoch 5763/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7821 - auc: 0.8618 - loss: 0.4556 - val_acc: 0.7960 - val_auc: 0.8735 - val_loss: 0.4393\n",
      "Epoch 5764/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7801 - auc: 0.8604 - loss: 0.4590 - val_acc: 0.7966 - val_auc: 0.8731 - val_loss: 0.4384\n",
      "Epoch 5765/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7809 - auc: 0.8606 - loss: 0.4569 - val_acc: 0.7926 - val_auc: 0.8735 - val_loss: 0.4407\n",
      "Epoch 5766/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7804 - auc: 0.8597 - loss: 0.4586 - val_acc: 0.7957 - val_auc: 0.8725 - val_loss: 0.4387\n",
      "Epoch 5767/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7788 - auc: 0.8586 - loss: 0.4609 - val_acc: 0.7950 - val_auc: 0.8731 - val_loss: 0.4385\n",
      "Epoch 5768/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7812 - auc: 0.8609 - loss: 0.4570 - val_acc: 0.7951 - val_auc: 0.8724 - val_loss: 0.4408\n",
      "Epoch 5769/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7811 - auc: 0.8607 - loss: 0.4581 - val_acc: 0.7945 - val_auc: 0.8716 - val_loss: 0.4395\n",
      "Epoch 5770/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7827 - auc: 0.8618 - loss: 0.4559 - val_acc: 0.7965 - val_auc: 0.8717 - val_loss: 0.4396\n",
      "Epoch 5771/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7814 - auc: 0.8609 - loss: 0.4569 - val_acc: 0.7930 - val_auc: 0.8711 - val_loss: 0.4407\n",
      "Epoch 5772/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7815 - auc: 0.8606 - loss: 0.4574 - val_acc: 0.7975 - val_auc: 0.8705 - val_loss: 0.4411\n",
      "Epoch 5773/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7834 - auc: 0.8602 - loss: 0.4594 - val_acc: 0.7965 - val_auc: 0.8730 - val_loss: 0.4396\n",
      "Epoch 5774/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7808 - auc: 0.8596 - loss: 0.4589 - val_acc: 0.7923 - val_auc: 0.8719 - val_loss: 0.4401\n",
      "Epoch 5775/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7815 - auc: 0.8608 - loss: 0.4568 - val_acc: 0.7947 - val_auc: 0.8733 - val_loss: 0.4386\n",
      "Epoch 5776/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8606 - loss: 0.4584 - val_acc: 0.7940 - val_auc: 0.8722 - val_loss: 0.4407\n",
      "Epoch 5777/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7789 - auc: 0.8595 - loss: 0.4589 - val_acc: 0.7992 - val_auc: 0.8741 - val_loss: 0.4381\n",
      "Epoch 5778/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7812 - auc: 0.8613 - loss: 0.4558 - val_acc: 0.7941 - val_auc: 0.8727 - val_loss: 0.4390\n",
      "Epoch 5779/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7800 - auc: 0.8612 - loss: 0.4560 - val_acc: 0.7973 - val_auc: 0.8726 - val_loss: 0.4394\n",
      "Epoch 5780/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7795 - auc: 0.8596 - loss: 0.4584 - val_acc: 0.7942 - val_auc: 0.8726 - val_loss: 0.4409\n",
      "Epoch 5781/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7840 - auc: 0.8629 - loss: 0.4548 - val_acc: 0.7968 - val_auc: 0.8723 - val_loss: 0.4399\n",
      "Epoch 5782/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7806 - auc: 0.8592 - loss: 0.4596 - val_acc: 0.7955 - val_auc: 0.8720 - val_loss: 0.4392\n",
      "Epoch 5783/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7801 - auc: 0.8594 - loss: 0.4602 - val_acc: 0.7948 - val_auc: 0.8726 - val_loss: 0.4401\n",
      "Epoch 5784/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7796 - auc: 0.8581 - loss: 0.4610 - val_acc: 0.7949 - val_auc: 0.8718 - val_loss: 0.4406\n",
      "Epoch 5785/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7827 - auc: 0.8607 - loss: 0.4574 - val_acc: 0.7963 - val_auc: 0.8733 - val_loss: 0.4393\n",
      "Epoch 5786/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7821 - auc: 0.8610 - loss: 0.4570 - val_acc: 0.7952 - val_auc: 0.8716 - val_loss: 0.4397\n",
      "Epoch 5787/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8601 - loss: 0.4585 - val_acc: 0.7958 - val_auc: 0.8721 - val_loss: 0.4400\n",
      "Epoch 5788/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7819 - auc: 0.8606 - loss: 0.4573 - val_acc: 0.7962 - val_auc: 0.8734 - val_loss: 0.4392\n",
      "Epoch 5789/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7824 - auc: 0.8602 - loss: 0.4577 - val_acc: 0.7951 - val_auc: 0.8720 - val_loss: 0.4427\n",
      "Epoch 5790/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7793 - auc: 0.8601 - loss: 0.4586 - val_acc: 0.7943 - val_auc: 0.8726 - val_loss: 0.4415\n",
      "Epoch 5791/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7796 - auc: 0.8605 - loss: 0.4571 - val_acc: 0.7959 - val_auc: 0.8719 - val_loss: 0.4386\n",
      "Epoch 5792/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7808 - auc: 0.8604 - loss: 0.4565 - val_acc: 0.7967 - val_auc: 0.8727 - val_loss: 0.4383\n",
      "Epoch 5793/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7820 - auc: 0.8610 - loss: 0.4580 - val_acc: 0.7952 - val_auc: 0.8730 - val_loss: 0.4398\n",
      "Epoch 5794/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7814 - auc: 0.8622 - loss: 0.4554 - val_acc: 0.7940 - val_auc: 0.8733 - val_loss: 0.4381\n",
      "Epoch 5795/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7799 - auc: 0.8607 - loss: 0.4567 - val_acc: 0.7952 - val_auc: 0.8726 - val_loss: 0.4377\n",
      "Epoch 5796/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7786 - auc: 0.8589 - loss: 0.4589 - val_acc: 0.7960 - val_auc: 0.8731 - val_loss: 0.4395\n",
      "Epoch 5797/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7814 - auc: 0.8604 - loss: 0.4568 - val_acc: 0.7950 - val_auc: 0.8719 - val_loss: 0.4405\n",
      "Epoch 5798/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7826 - auc: 0.8616 - loss: 0.4569 - val_acc: 0.7939 - val_auc: 0.8723 - val_loss: 0.4403\n",
      "Epoch 5799/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7809 - auc: 0.8612 - loss: 0.4563 - val_acc: 0.7957 - val_auc: 0.8738 - val_loss: 0.4372\n",
      "Epoch 5800/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7822 - auc: 0.8604 - loss: 0.4580 - val_acc: 0.7963 - val_auc: 0.8714 - val_loss: 0.4401\n",
      "Epoch 5801/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7799 - auc: 0.8597 - loss: 0.4603 - val_acc: 0.7973 - val_auc: 0.8725 - val_loss: 0.4384\n",
      "Epoch 5802/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7806 - auc: 0.8601 - loss: 0.4588 - val_acc: 0.7953 - val_auc: 0.8737 - val_loss: 0.4409\n",
      "Epoch 5803/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7808 - auc: 0.8609 - loss: 0.4579 - val_acc: 0.7961 - val_auc: 0.8730 - val_loss: 0.4379\n",
      "Epoch 5804/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7794 - auc: 0.8597 - loss: 0.4596 - val_acc: 0.7966 - val_auc: 0.8728 - val_loss: 0.4400\n",
      "Epoch 5805/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7819 - auc: 0.8597 - loss: 0.4587 - val_acc: 0.7933 - val_auc: 0.8710 - val_loss: 0.4416\n",
      "Epoch 5806/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7796 - auc: 0.8594 - loss: 0.4596 - val_acc: 0.7925 - val_auc: 0.8728 - val_loss: 0.4411\n",
      "Epoch 5807/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7827 - auc: 0.8614 - loss: 0.4563 - val_acc: 0.7954 - val_auc: 0.8730 - val_loss: 0.4385\n",
      "Epoch 5808/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7803 - auc: 0.8611 - loss: 0.4564 - val_acc: 0.7965 - val_auc: 0.8736 - val_loss: 0.4372\n",
      "Epoch 5809/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7812 - auc: 0.8610 - loss: 0.4574 - val_acc: 0.7980 - val_auc: 0.8738 - val_loss: 0.4379\n",
      "Epoch 5810/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7818 - auc: 0.8601 - loss: 0.4578 - val_acc: 0.7978 - val_auc: 0.8730 - val_loss: 0.4385\n",
      "Epoch 5811/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7801 - auc: 0.8604 - loss: 0.4579 - val_acc: 0.7968 - val_auc: 0.8730 - val_loss: 0.4394\n",
      "Epoch 5812/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7803 - auc: 0.8591 - loss: 0.4604 - val_acc: 0.7954 - val_auc: 0.8718 - val_loss: 0.4405\n",
      "Epoch 5813/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7819 - auc: 0.8600 - loss: 0.4583 - val_acc: 0.7943 - val_auc: 0.8720 - val_loss: 0.4393\n",
      "Epoch 5814/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7797 - auc: 0.8601 - loss: 0.4588 - val_acc: 0.7966 - val_auc: 0.8733 - val_loss: 0.4392\n",
      "Epoch 5815/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7813 - auc: 0.8601 - loss: 0.4584 - val_acc: 0.7961 - val_auc: 0.8730 - val_loss: 0.4395\n",
      "Epoch 5816/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7822 - auc: 0.8604 - loss: 0.4590 - val_acc: 0.7942 - val_auc: 0.8721 - val_loss: 0.4400\n",
      "Epoch 5817/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7821 - auc: 0.8618 - loss: 0.4558 - val_acc: 0.7960 - val_auc: 0.8727 - val_loss: 0.4380\n",
      "Epoch 5818/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7811 - auc: 0.8604 - loss: 0.4583 - val_acc: 0.7972 - val_auc: 0.8733 - val_loss: 0.4398\n",
      "Epoch 5819/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7812 - auc: 0.8602 - loss: 0.4584 - val_acc: 0.7944 - val_auc: 0.8733 - val_loss: 0.4378\n",
      "Epoch 5820/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7814 - auc: 0.8598 - loss: 0.4581 - val_acc: 0.7926 - val_auc: 0.8708 - val_loss: 0.4405\n",
      "Epoch 5821/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7815 - auc: 0.8614 - loss: 0.4567 - val_acc: 0.7956 - val_auc: 0.8722 - val_loss: 0.4383\n",
      "Epoch 5822/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7831 - auc: 0.8625 - loss: 0.4557 - val_acc: 0.7991 - val_auc: 0.8739 - val_loss: 0.4385\n",
      "Epoch 5823/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7826 - auc: 0.8621 - loss: 0.4549 - val_acc: 0.7958 - val_auc: 0.8728 - val_loss: 0.4371\n",
      "Epoch 5824/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7813 - auc: 0.8594 - loss: 0.4591 - val_acc: 0.7951 - val_auc: 0.8727 - val_loss: 0.4402\n",
      "Epoch 5825/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7808 - auc: 0.8601 - loss: 0.4584 - val_acc: 0.7975 - val_auc: 0.8743 - val_loss: 0.4386\n",
      "Epoch 5826/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7802 - auc: 0.8603 - loss: 0.4577 - val_acc: 0.7979 - val_auc: 0.8733 - val_loss: 0.4380\n",
      "Epoch 5827/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7819 - auc: 0.8611 - loss: 0.4567 - val_acc: 0.7977 - val_auc: 0.8739 - val_loss: 0.4378\n",
      "Epoch 5828/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7812 - auc: 0.8608 - loss: 0.4573 - val_acc: 0.7969 - val_auc: 0.8729 - val_loss: 0.4382\n",
      "Epoch 5829/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7809 - auc: 0.8600 - loss: 0.4587 - val_acc: 0.7966 - val_auc: 0.8737 - val_loss: 0.4379\n",
      "Epoch 5830/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7800 - auc: 0.8603 - loss: 0.4575 - val_acc: 0.7969 - val_auc: 0.8741 - val_loss: 0.4382\n",
      "Epoch 5831/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7816 - auc: 0.8608 - loss: 0.4570 - val_acc: 0.7984 - val_auc: 0.8739 - val_loss: 0.4370\n",
      "Epoch 5832/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7804 - auc: 0.8609 - loss: 0.4562 - val_acc: 0.7968 - val_auc: 0.8743 - val_loss: 0.4362\n",
      "Epoch 5833/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7804 - auc: 0.8606 - loss: 0.4569 - val_acc: 0.7969 - val_auc: 0.8734 - val_loss: 0.4389\n",
      "Epoch 5834/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7812 - auc: 0.8600 - loss: 0.4588 - val_acc: 0.7958 - val_auc: 0.8732 - val_loss: 0.4382\n",
      "Epoch 5835/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7808 - auc: 0.8610 - loss: 0.4579 - val_acc: 0.7930 - val_auc: 0.8729 - val_loss: 0.4382\n",
      "Epoch 5836/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7794 - auc: 0.8585 - loss: 0.4614 - val_acc: 0.7974 - val_auc: 0.8741 - val_loss: 0.4390\n",
      "Epoch 5837/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7787 - auc: 0.8598 - loss: 0.4585 - val_acc: 0.7976 - val_auc: 0.8741 - val_loss: 0.4380\n",
      "Epoch 5838/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7813 - auc: 0.8614 - loss: 0.4572 - val_acc: 0.7942 - val_auc: 0.8724 - val_loss: 0.4401\n",
      "Epoch 5839/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7804 - auc: 0.8589 - loss: 0.4600 - val_acc: 0.7931 - val_auc: 0.8723 - val_loss: 0.4392\n",
      "Epoch 5840/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7831 - auc: 0.8618 - loss: 0.4558 - val_acc: 0.7953 - val_auc: 0.8733 - val_loss: 0.4390\n",
      "Epoch 5841/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7799 - auc: 0.8599 - loss: 0.4586 - val_acc: 0.7929 - val_auc: 0.8720 - val_loss: 0.4402\n",
      "Epoch 5842/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7787 - auc: 0.8588 - loss: 0.4602 - val_acc: 0.7932 - val_auc: 0.8709 - val_loss: 0.4416\n",
      "Epoch 5843/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7800 - auc: 0.8593 - loss: 0.4596 - val_acc: 0.7965 - val_auc: 0.8739 - val_loss: 0.4382\n",
      "Epoch 5844/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7799 - auc: 0.8595 - loss: 0.4590 - val_acc: 0.7944 - val_auc: 0.8721 - val_loss: 0.4394\n",
      "Epoch 5845/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7793 - auc: 0.8593 - loss: 0.4580 - val_acc: 0.7931 - val_auc: 0.8722 - val_loss: 0.4404\n",
      "Epoch 5846/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7797 - auc: 0.8591 - loss: 0.4596 - val_acc: 0.7964 - val_auc: 0.8735 - val_loss: 0.4394\n",
      "Epoch 5847/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7806 - auc: 0.8604 - loss: 0.4577 - val_acc: 0.7974 - val_auc: 0.8724 - val_loss: 0.4394\n",
      "Epoch 5848/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7814 - auc: 0.8602 - loss: 0.4581 - val_acc: 0.7926 - val_auc: 0.8720 - val_loss: 0.4395\n",
      "Epoch 5849/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7817 - auc: 0.8604 - loss: 0.4580 - val_acc: 0.7951 - val_auc: 0.8726 - val_loss: 0.4393\n",
      "Epoch 5850/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7792 - auc: 0.8585 - loss: 0.4600 - val_acc: 0.7961 - val_auc: 0.8721 - val_loss: 0.4409\n",
      "Epoch 5851/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7800 - auc: 0.8601 - loss: 0.4581 - val_acc: 0.7941 - val_auc: 0.8718 - val_loss: 0.4404\n",
      "Epoch 5852/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8611 - loss: 0.4576 - val_acc: 0.7969 - val_auc: 0.8736 - val_loss: 0.4389\n",
      "Epoch 5853/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7781 - auc: 0.8600 - loss: 0.4587 - val_acc: 0.7978 - val_auc: 0.8740 - val_loss: 0.4375\n",
      "Epoch 5854/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7802 - auc: 0.8610 - loss: 0.4570 - val_acc: 0.7951 - val_auc: 0.8728 - val_loss: 0.4385\n",
      "Epoch 5855/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7788 - auc: 0.8589 - loss: 0.4605 - val_acc: 0.7944 - val_auc: 0.8712 - val_loss: 0.4397\n",
      "Epoch 5856/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7805 - auc: 0.8594 - loss: 0.4594 - val_acc: 0.7958 - val_auc: 0.8718 - val_loss: 0.4410\n",
      "Epoch 5857/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7793 - auc: 0.8584 - loss: 0.4596 - val_acc: 0.7962 - val_auc: 0.8729 - val_loss: 0.4389\n",
      "Epoch 5858/7000\n",
      "106/106 - 2s - 15ms/step - acc: 0.7820 - auc: 0.8614 - loss: 0.4550 - val_acc: 0.7967 - val_auc: 0.8728 - val_loss: 0.4385\n",
      "Epoch 5859/7000\n",
      "106/106 - 2s - 15ms/step - acc: 0.7807 - auc: 0.8600 - loss: 0.4580 - val_acc: 0.7944 - val_auc: 0.8738 - val_loss: 0.4384\n",
      "Epoch 5860/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7801 - auc: 0.8598 - loss: 0.4590 - val_acc: 0.7942 - val_auc: 0.8731 - val_loss: 0.4398\n",
      "Epoch 5861/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7798 - auc: 0.8599 - loss: 0.4595 - val_acc: 0.7959 - val_auc: 0.8739 - val_loss: 0.4388\n",
      "Epoch 5862/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7817 - auc: 0.8608 - loss: 0.4567 - val_acc: 0.7974 - val_auc: 0.8737 - val_loss: 0.4377\n",
      "Epoch 5863/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7796 - auc: 0.8597 - loss: 0.4592 - val_acc: 0.7968 - val_auc: 0.8737 - val_loss: 0.4383\n",
      "Epoch 5864/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7818 - auc: 0.8620 - loss: 0.4557 - val_acc: 0.7979 - val_auc: 0.8728 - val_loss: 0.4386\n",
      "Epoch 5865/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7813 - auc: 0.8612 - loss: 0.4562 - val_acc: 0.7959 - val_auc: 0.8732 - val_loss: 0.4389\n",
      "Epoch 5866/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7806 - auc: 0.8596 - loss: 0.4587 - val_acc: 0.7947 - val_auc: 0.8716 - val_loss: 0.4412\n",
      "Epoch 5867/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7822 - auc: 0.8606 - loss: 0.4568 - val_acc: 0.7943 - val_auc: 0.8724 - val_loss: 0.4394\n",
      "Epoch 5868/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7807 - auc: 0.8607 - loss: 0.4575 - val_acc: 0.7950 - val_auc: 0.8726 - val_loss: 0.4396\n",
      "Epoch 5869/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7806 - auc: 0.8591 - loss: 0.4611 - val_acc: 0.7945 - val_auc: 0.8728 - val_loss: 0.4403\n",
      "Epoch 5870/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7806 - auc: 0.8607 - loss: 0.4573 - val_acc: 0.7966 - val_auc: 0.8722 - val_loss: 0.4403\n",
      "Epoch 5871/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7795 - auc: 0.8588 - loss: 0.4596 - val_acc: 0.7966 - val_auc: 0.8723 - val_loss: 0.4389\n",
      "Epoch 5872/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7817 - auc: 0.8606 - loss: 0.4569 - val_acc: 0.7945 - val_auc: 0.8731 - val_loss: 0.4398\n",
      "Epoch 5873/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7806 - auc: 0.8594 - loss: 0.4585 - val_acc: 0.7944 - val_auc: 0.8732 - val_loss: 0.4396\n",
      "Epoch 5874/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7822 - auc: 0.8614 - loss: 0.4562 - val_acc: 0.7949 - val_auc: 0.8721 - val_loss: 0.4406\n",
      "Epoch 5875/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7804 - auc: 0.8600 - loss: 0.4585 - val_acc: 0.7963 - val_auc: 0.8745 - val_loss: 0.4383\n",
      "Epoch 5876/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7824 - auc: 0.8604 - loss: 0.4567 - val_acc: 0.7924 - val_auc: 0.8727 - val_loss: 0.4390\n",
      "Epoch 5877/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7813 - auc: 0.8608 - loss: 0.4564 - val_acc: 0.7972 - val_auc: 0.8734 - val_loss: 0.4371\n",
      "Epoch 5878/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7802 - auc: 0.8608 - loss: 0.4576 - val_acc: 0.7980 - val_auc: 0.8724 - val_loss: 0.4388\n",
      "Epoch 5879/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7806 - auc: 0.8603 - loss: 0.4578 - val_acc: 0.7948 - val_auc: 0.8720 - val_loss: 0.4391\n",
      "Epoch 5880/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7802 - auc: 0.8594 - loss: 0.4594 - val_acc: 0.7953 - val_auc: 0.8739 - val_loss: 0.4377\n",
      "Epoch 5881/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7790 - auc: 0.8583 - loss: 0.4597 - val_acc: 0.7944 - val_auc: 0.8727 - val_loss: 0.4399\n",
      "Epoch 5882/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7804 - auc: 0.8598 - loss: 0.4580 - val_acc: 0.7960 - val_auc: 0.8734 - val_loss: 0.4393\n",
      "Epoch 5883/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7777 - auc: 0.8592 - loss: 0.4594 - val_acc: 0.7940 - val_auc: 0.8739 - val_loss: 0.4384\n",
      "Epoch 5884/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7794 - auc: 0.8593 - loss: 0.4587 - val_acc: 0.7968 - val_auc: 0.8737 - val_loss: 0.4382\n",
      "Epoch 5885/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7818 - auc: 0.8609 - loss: 0.4576 - val_acc: 0.7949 - val_auc: 0.8731 - val_loss: 0.4404\n",
      "Epoch 5886/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7811 - auc: 0.8604 - loss: 0.4588 - val_acc: 0.7955 - val_auc: 0.8737 - val_loss: 0.4378\n",
      "Epoch 5887/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7828 - auc: 0.8619 - loss: 0.4556 - val_acc: 0.7938 - val_auc: 0.8724 - val_loss: 0.4394\n",
      "Epoch 5888/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7798 - auc: 0.8589 - loss: 0.4603 - val_acc: 0.7955 - val_auc: 0.8732 - val_loss: 0.4397\n",
      "Epoch 5889/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7809 - auc: 0.8613 - loss: 0.4563 - val_acc: 0.7954 - val_auc: 0.8729 - val_loss: 0.4398\n",
      "Epoch 5890/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7818 - auc: 0.8606 - loss: 0.4585 - val_acc: 0.7966 - val_auc: 0.8736 - val_loss: 0.4396\n",
      "Epoch 5891/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7804 - auc: 0.8596 - loss: 0.4593 - val_acc: 0.7964 - val_auc: 0.8727 - val_loss: 0.4393\n",
      "Epoch 5892/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7804 - auc: 0.8606 - loss: 0.4571 - val_acc: 0.7932 - val_auc: 0.8711 - val_loss: 0.4414\n",
      "Epoch 5893/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7822 - auc: 0.8610 - loss: 0.4573 - val_acc: 0.7970 - val_auc: 0.8732 - val_loss: 0.4397\n",
      "Epoch 5894/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7807 - auc: 0.8601 - loss: 0.4590 - val_acc: 0.7968 - val_auc: 0.8732 - val_loss: 0.4386\n",
      "Epoch 5895/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7826 - auc: 0.8607 - loss: 0.4575 - val_acc: 0.7962 - val_auc: 0.8714 - val_loss: 0.4397\n",
      "Epoch 5896/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7817 - auc: 0.8608 - loss: 0.4571 - val_acc: 0.7955 - val_auc: 0.8732 - val_loss: 0.4393\n",
      "Epoch 5897/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7831 - auc: 0.8616 - loss: 0.4563 - val_acc: 0.7948 - val_auc: 0.8727 - val_loss: 0.4392\n",
      "Epoch 5898/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8602 - loss: 0.4574 - val_acc: 0.7964 - val_auc: 0.8741 - val_loss: 0.4389\n",
      "Epoch 5899/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7806 - auc: 0.8608 - loss: 0.4567 - val_acc: 0.8006 - val_auc: 0.8729 - val_loss: 0.4386\n",
      "Epoch 5900/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7783 - auc: 0.8592 - loss: 0.4593 - val_acc: 0.7970 - val_auc: 0.8743 - val_loss: 0.4382\n",
      "Epoch 5901/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7806 - auc: 0.8601 - loss: 0.4571 - val_acc: 0.7974 - val_auc: 0.8727 - val_loss: 0.4385\n",
      "Epoch 5902/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7788 - auc: 0.8588 - loss: 0.4599 - val_acc: 0.7974 - val_auc: 0.8736 - val_loss: 0.4383\n",
      "Epoch 5903/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7805 - auc: 0.8595 - loss: 0.4587 - val_acc: 0.7985 - val_auc: 0.8733 - val_loss: 0.4374\n",
      "Epoch 5904/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7804 - auc: 0.8603 - loss: 0.4586 - val_acc: 0.7976 - val_auc: 0.8744 - val_loss: 0.4372\n",
      "Epoch 5905/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7801 - auc: 0.8603 - loss: 0.4588 - val_acc: 0.7934 - val_auc: 0.8718 - val_loss: 0.4404\n",
      "Epoch 5906/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7809 - auc: 0.8602 - loss: 0.4578 - val_acc: 0.7973 - val_auc: 0.8729 - val_loss: 0.4399\n",
      "Epoch 5907/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7784 - auc: 0.8596 - loss: 0.4603 - val_acc: 0.7957 - val_auc: 0.8725 - val_loss: 0.4387\n",
      "Epoch 5908/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7802 - auc: 0.8595 - loss: 0.4585 - val_acc: 0.7977 - val_auc: 0.8731 - val_loss: 0.4376\n",
      "Epoch 5909/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7807 - auc: 0.8594 - loss: 0.4584 - val_acc: 0.7977 - val_auc: 0.8739 - val_loss: 0.4386\n",
      "Epoch 5910/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8602 - loss: 0.4581 - val_acc: 0.7963 - val_auc: 0.8731 - val_loss: 0.4385\n",
      "Epoch 5911/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7811 - auc: 0.8610 - loss: 0.4571 - val_acc: 0.7959 - val_auc: 0.8728 - val_loss: 0.4389\n",
      "Epoch 5912/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7794 - auc: 0.8599 - loss: 0.4588 - val_acc: 0.7953 - val_auc: 0.8720 - val_loss: 0.4404\n",
      "Epoch 5913/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7806 - auc: 0.8595 - loss: 0.4594 - val_acc: 0.7950 - val_auc: 0.8733 - val_loss: 0.4393\n",
      "Epoch 5914/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7823 - auc: 0.8611 - loss: 0.4558 - val_acc: 0.7976 - val_auc: 0.8742 - val_loss: 0.4377\n",
      "Epoch 5915/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7811 - auc: 0.8592 - loss: 0.4590 - val_acc: 0.7934 - val_auc: 0.8722 - val_loss: 0.4421\n",
      "Epoch 5916/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7826 - auc: 0.8623 - loss: 0.4553 - val_acc: 0.7962 - val_auc: 0.8721 - val_loss: 0.4385\n",
      "Epoch 5917/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7803 - auc: 0.8604 - loss: 0.4570 - val_acc: 0.7979 - val_auc: 0.8735 - val_loss: 0.4386\n",
      "Epoch 5918/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7804 - auc: 0.8603 - loss: 0.4574 - val_acc: 0.7976 - val_auc: 0.8732 - val_loss: 0.4382\n",
      "Epoch 5919/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7830 - auc: 0.8619 - loss: 0.4548 - val_acc: 0.7950 - val_auc: 0.8725 - val_loss: 0.4379\n",
      "Epoch 5920/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7824 - auc: 0.8606 - loss: 0.4568 - val_acc: 0.7977 - val_auc: 0.8745 - val_loss: 0.4374\n",
      "Epoch 5921/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7786 - auc: 0.8587 - loss: 0.4611 - val_acc: 0.7974 - val_auc: 0.8743 - val_loss: 0.4382\n",
      "Epoch 5922/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7792 - auc: 0.8576 - loss: 0.4625 - val_acc: 0.7974 - val_auc: 0.8739 - val_loss: 0.4374\n",
      "Epoch 5923/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7790 - auc: 0.8590 - loss: 0.4605 - val_acc: 0.7976 - val_auc: 0.8751 - val_loss: 0.4368\n",
      "Epoch 5924/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7829 - auc: 0.8616 - loss: 0.4551 - val_acc: 0.7975 - val_auc: 0.8740 - val_loss: 0.4377\n",
      "Epoch 5925/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7824 - auc: 0.8620 - loss: 0.4557 - val_acc: 0.7993 - val_auc: 0.8743 - val_loss: 0.4374\n",
      "Epoch 5926/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7805 - auc: 0.8597 - loss: 0.4582 - val_acc: 0.7974 - val_auc: 0.8738 - val_loss: 0.4374\n",
      "Epoch 5927/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7803 - auc: 0.8595 - loss: 0.4590 - val_acc: 0.7958 - val_auc: 0.8730 - val_loss: 0.4390\n",
      "Epoch 5928/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7796 - auc: 0.8601 - loss: 0.4583 - val_acc: 0.7952 - val_auc: 0.8729 - val_loss: 0.4391\n",
      "Epoch 5929/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8611 - loss: 0.4577 - val_acc: 0.7956 - val_auc: 0.8729 - val_loss: 0.4398\n",
      "Epoch 5930/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7792 - auc: 0.8595 - loss: 0.4597 - val_acc: 0.7981 - val_auc: 0.8742 - val_loss: 0.4376\n",
      "Epoch 5931/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7824 - auc: 0.8619 - loss: 0.4563 - val_acc: 0.7979 - val_auc: 0.8743 - val_loss: 0.4363\n",
      "Epoch 5932/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7806 - auc: 0.8598 - loss: 0.4586 - val_acc: 0.7975 - val_auc: 0.8731 - val_loss: 0.4381\n",
      "Epoch 5933/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7785 - auc: 0.8585 - loss: 0.4607 - val_acc: 0.7957 - val_auc: 0.8731 - val_loss: 0.4408\n",
      "Epoch 5934/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7819 - auc: 0.8598 - loss: 0.4581 - val_acc: 0.7980 - val_auc: 0.8748 - val_loss: 0.4377\n",
      "Epoch 5935/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7803 - auc: 0.8589 - loss: 0.4602 - val_acc: 0.7995 - val_auc: 0.8742 - val_loss: 0.4373\n",
      "Epoch 5936/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7836 - auc: 0.8613 - loss: 0.4562 - val_acc: 0.7960 - val_auc: 0.8739 - val_loss: 0.4387\n",
      "Epoch 5937/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7819 - auc: 0.8610 - loss: 0.4563 - val_acc: 0.7962 - val_auc: 0.8730 - val_loss: 0.4395\n",
      "Epoch 5938/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7798 - auc: 0.8599 - loss: 0.4583 - val_acc: 0.7985 - val_auc: 0.8742 - val_loss: 0.4368\n",
      "Epoch 5939/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7799 - auc: 0.8589 - loss: 0.4610 - val_acc: 0.7990 - val_auc: 0.8742 - val_loss: 0.4371\n",
      "Epoch 5940/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7804 - auc: 0.8586 - loss: 0.4597 - val_acc: 0.7972 - val_auc: 0.8728 - val_loss: 0.4376\n",
      "Epoch 5941/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7808 - auc: 0.8617 - loss: 0.4558 - val_acc: 0.7928 - val_auc: 0.8727 - val_loss: 0.4383\n",
      "Epoch 5942/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7823 - auc: 0.8617 - loss: 0.4558 - val_acc: 0.7952 - val_auc: 0.8743 - val_loss: 0.4389\n",
      "Epoch 5943/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7795 - auc: 0.8606 - loss: 0.4575 - val_acc: 0.7971 - val_auc: 0.8739 - val_loss: 0.4375\n",
      "Epoch 5944/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7810 - auc: 0.8617 - loss: 0.4567 - val_acc: 0.7968 - val_auc: 0.8730 - val_loss: 0.4397\n",
      "Epoch 5945/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7805 - auc: 0.8607 - loss: 0.4574 - val_acc: 0.7940 - val_auc: 0.8725 - val_loss: 0.4397\n",
      "Epoch 5946/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7794 - auc: 0.8590 - loss: 0.4591 - val_acc: 0.7960 - val_auc: 0.8741 - val_loss: 0.4382\n",
      "Epoch 5947/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7824 - auc: 0.8599 - loss: 0.4580 - val_acc: 0.7958 - val_auc: 0.8715 - val_loss: 0.4390\n",
      "Epoch 5948/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7804 - auc: 0.8615 - loss: 0.4566 - val_acc: 0.7942 - val_auc: 0.8739 - val_loss: 0.4390\n",
      "Epoch 5949/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7813 - auc: 0.8616 - loss: 0.4552 - val_acc: 0.7964 - val_auc: 0.8732 - val_loss: 0.4379\n",
      "Epoch 5950/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7791 - auc: 0.8584 - loss: 0.4607 - val_acc: 0.7964 - val_auc: 0.8744 - val_loss: 0.4376\n",
      "Epoch 5951/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7805 - auc: 0.8591 - loss: 0.4602 - val_acc: 0.7953 - val_auc: 0.8736 - val_loss: 0.4387\n",
      "Epoch 5952/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7807 - auc: 0.8615 - loss: 0.4568 - val_acc: 0.7977 - val_auc: 0.8741 - val_loss: 0.4378\n",
      "Epoch 5953/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7804 - auc: 0.8608 - loss: 0.4581 - val_acc: 0.7954 - val_auc: 0.8742 - val_loss: 0.4383\n",
      "Epoch 5954/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7807 - auc: 0.8605 - loss: 0.4575 - val_acc: 0.7964 - val_auc: 0.8727 - val_loss: 0.4401\n",
      "Epoch 5955/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7794 - auc: 0.8611 - loss: 0.4565 - val_acc: 0.7989 - val_auc: 0.8746 - val_loss: 0.4360\n",
      "Epoch 5956/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7820 - auc: 0.8603 - loss: 0.4579 - val_acc: 0.7954 - val_auc: 0.8740 - val_loss: 0.4389\n",
      "Epoch 5957/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7803 - auc: 0.8593 - loss: 0.4593 - val_acc: 0.7983 - val_auc: 0.8741 - val_loss: 0.4383\n",
      "Epoch 5958/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7816 - auc: 0.8605 - loss: 0.4575 - val_acc: 0.7957 - val_auc: 0.8732 - val_loss: 0.4383\n",
      "Epoch 5959/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7819 - auc: 0.8600 - loss: 0.4589 - val_acc: 0.7984 - val_auc: 0.8743 - val_loss: 0.4371\n",
      "Epoch 5960/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7807 - auc: 0.8611 - loss: 0.4573 - val_acc: 0.7984 - val_auc: 0.8732 - val_loss: 0.4376\n",
      "Epoch 5961/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7801 - auc: 0.8599 - loss: 0.4587 - val_acc: 0.7983 - val_auc: 0.8735 - val_loss: 0.4397\n",
      "Epoch 5962/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7814 - auc: 0.8622 - loss: 0.4559 - val_acc: 0.7965 - val_auc: 0.8732 - val_loss: 0.4379\n",
      "Epoch 5963/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8606 - loss: 0.4567 - val_acc: 0.7976 - val_auc: 0.8743 - val_loss: 0.4372\n",
      "Epoch 5964/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7809 - auc: 0.8595 - loss: 0.4590 - val_acc: 0.7963 - val_auc: 0.8733 - val_loss: 0.4384\n",
      "Epoch 5965/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7813 - auc: 0.8600 - loss: 0.4585 - val_acc: 0.7959 - val_auc: 0.8734 - val_loss: 0.4396\n",
      "Epoch 5966/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7804 - auc: 0.8603 - loss: 0.4582 - val_acc: 0.7965 - val_auc: 0.8727 - val_loss: 0.4403\n",
      "Epoch 5967/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7807 - auc: 0.8593 - loss: 0.4594 - val_acc: 0.7970 - val_auc: 0.8742 - val_loss: 0.4372\n",
      "Epoch 5968/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8595 - loss: 0.4590 - val_acc: 0.7971 - val_auc: 0.8725 - val_loss: 0.4405\n",
      "Epoch 5969/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7809 - auc: 0.8604 - loss: 0.4574 - val_acc: 0.7939 - val_auc: 0.8722 - val_loss: 0.4425\n",
      "Epoch 5970/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7804 - auc: 0.8599 - loss: 0.4587 - val_acc: 0.7977 - val_auc: 0.8737 - val_loss: 0.4380\n",
      "Epoch 5971/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7801 - auc: 0.8603 - loss: 0.4571 - val_acc: 0.7976 - val_auc: 0.8734 - val_loss: 0.4395\n",
      "Epoch 5972/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7824 - auc: 0.8607 - loss: 0.4565 - val_acc: 0.7978 - val_auc: 0.8735 - val_loss: 0.4379\n",
      "Epoch 5973/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7825 - auc: 0.8604 - loss: 0.4573 - val_acc: 0.7943 - val_auc: 0.8716 - val_loss: 0.4407\n",
      "Epoch 5974/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7816 - auc: 0.8595 - loss: 0.4602 - val_acc: 0.7965 - val_auc: 0.8730 - val_loss: 0.4389\n",
      "Epoch 5975/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7834 - auc: 0.8616 - loss: 0.4573 - val_acc: 0.7942 - val_auc: 0.8724 - val_loss: 0.4414\n",
      "Epoch 5976/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7801 - auc: 0.8607 - loss: 0.4573 - val_acc: 0.7944 - val_auc: 0.8719 - val_loss: 0.4413\n",
      "Epoch 5977/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7832 - auc: 0.8619 - loss: 0.4555 - val_acc: 0.7951 - val_auc: 0.8740 - val_loss: 0.4381\n",
      "Epoch 5978/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7814 - auc: 0.8605 - loss: 0.4581 - val_acc: 0.7977 - val_auc: 0.8735 - val_loss: 0.4386\n",
      "Epoch 5979/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7803 - auc: 0.8602 - loss: 0.4575 - val_acc: 0.7974 - val_auc: 0.8735 - val_loss: 0.4381\n",
      "Epoch 5980/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7793 - auc: 0.8597 - loss: 0.4589 - val_acc: 0.7964 - val_auc: 0.8743 - val_loss: 0.4384\n",
      "Epoch 5981/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8598 - loss: 0.4595 - val_acc: 0.7964 - val_auc: 0.8734 - val_loss: 0.4374\n",
      "Epoch 5982/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7805 - auc: 0.8603 - loss: 0.4579 - val_acc: 0.7956 - val_auc: 0.8720 - val_loss: 0.4395\n",
      "Epoch 5983/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7820 - auc: 0.8599 - loss: 0.4593 - val_acc: 0.7968 - val_auc: 0.8730 - val_loss: 0.4383\n",
      "Epoch 5984/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7814 - auc: 0.8618 - loss: 0.4571 - val_acc: 0.7976 - val_auc: 0.8728 - val_loss: 0.4390\n",
      "Epoch 5985/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7794 - auc: 0.8582 - loss: 0.4607 - val_acc: 0.7958 - val_auc: 0.8730 - val_loss: 0.4400\n",
      "Epoch 5986/7000\n",
      "106/106 - 2s - 15ms/step - acc: 0.7836 - auc: 0.8617 - loss: 0.4557 - val_acc: 0.7979 - val_auc: 0.8726 - val_loss: 0.4392\n",
      "Epoch 5987/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7819 - auc: 0.8606 - loss: 0.4580 - val_acc: 0.7985 - val_auc: 0.8743 - val_loss: 0.4375\n",
      "Epoch 5988/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7823 - auc: 0.8615 - loss: 0.4557 - val_acc: 0.7974 - val_auc: 0.8738 - val_loss: 0.4384\n",
      "Epoch 5989/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7817 - auc: 0.8614 - loss: 0.4561 - val_acc: 0.7908 - val_auc: 0.8710 - val_loss: 0.4420\n",
      "Epoch 5990/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7799 - auc: 0.8608 - loss: 0.4566 - val_acc: 0.7967 - val_auc: 0.8733 - val_loss: 0.4384\n",
      "Epoch 5991/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7810 - auc: 0.8607 - loss: 0.4582 - val_acc: 0.7951 - val_auc: 0.8728 - val_loss: 0.4398\n",
      "Epoch 5992/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7824 - auc: 0.8607 - loss: 0.4579 - val_acc: 0.7969 - val_auc: 0.8733 - val_loss: 0.4391\n",
      "Epoch 5993/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7816 - auc: 0.8614 - loss: 0.4565 - val_acc: 0.7938 - val_auc: 0.8727 - val_loss: 0.4403\n",
      "Epoch 5994/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7804 - auc: 0.8603 - loss: 0.4576 - val_acc: 0.7951 - val_auc: 0.8730 - val_loss: 0.4402\n",
      "Epoch 5995/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7796 - auc: 0.8598 - loss: 0.4588 - val_acc: 0.7960 - val_auc: 0.8729 - val_loss: 0.4407\n",
      "Epoch 5996/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7810 - auc: 0.8612 - loss: 0.4568 - val_acc: 0.7970 - val_auc: 0.8718 - val_loss: 0.4393\n",
      "Epoch 5997/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7796 - auc: 0.8584 - loss: 0.4608 - val_acc: 0.7924 - val_auc: 0.8720 - val_loss: 0.4414\n",
      "Epoch 5998/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7781 - auc: 0.8595 - loss: 0.4585 - val_acc: 0.7969 - val_auc: 0.8735 - val_loss: 0.4384\n",
      "Epoch 5999/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8593 - loss: 0.4589 - val_acc: 0.7955 - val_auc: 0.8729 - val_loss: 0.4398\n",
      "Epoch 6000/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7801 - auc: 0.8596 - loss: 0.4591 - val_acc: 0.7945 - val_auc: 0.8724 - val_loss: 0.4390\n",
      "Epoch 6001/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7809 - auc: 0.8607 - loss: 0.4572 - val_acc: 0.7944 - val_auc: 0.8729 - val_loss: 0.4402\n",
      "Epoch 6002/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7816 - auc: 0.8613 - loss: 0.4557 - val_acc: 0.7976 - val_auc: 0.8743 - val_loss: 0.4377\n",
      "Epoch 6003/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7790 - auc: 0.8593 - loss: 0.4602 - val_acc: 0.7964 - val_auc: 0.8739 - val_loss: 0.4389\n",
      "Epoch 6004/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7794 - auc: 0.8585 - loss: 0.4600 - val_acc: 0.7966 - val_auc: 0.8734 - val_loss: 0.4361\n",
      "Epoch 6005/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8600 - loss: 0.4579 - val_acc: 0.7940 - val_auc: 0.8730 - val_loss: 0.4397\n",
      "Epoch 6006/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7799 - auc: 0.8602 - loss: 0.4587 - val_acc: 0.7954 - val_auc: 0.8737 - val_loss: 0.4388\n",
      "Epoch 6007/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7830 - auc: 0.8618 - loss: 0.4561 - val_acc: 0.7964 - val_auc: 0.8723 - val_loss: 0.4391\n",
      "Epoch 6008/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7805 - auc: 0.8605 - loss: 0.4584 - val_acc: 0.7960 - val_auc: 0.8726 - val_loss: 0.4392\n",
      "Epoch 6009/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7814 - auc: 0.8606 - loss: 0.4570 - val_acc: 0.7966 - val_auc: 0.8727 - val_loss: 0.4389\n",
      "Epoch 6010/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7815 - auc: 0.8601 - loss: 0.4588 - val_acc: 0.7943 - val_auc: 0.8728 - val_loss: 0.4387\n",
      "Epoch 6011/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7805 - auc: 0.8604 - loss: 0.4582 - val_acc: 0.8001 - val_auc: 0.8735 - val_loss: 0.4363\n",
      "Epoch 6012/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7826 - auc: 0.8605 - loss: 0.4575 - val_acc: 0.7938 - val_auc: 0.8732 - val_loss: 0.4400\n",
      "Epoch 6013/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7810 - auc: 0.8608 - loss: 0.4574 - val_acc: 0.7957 - val_auc: 0.8731 - val_loss: 0.4384\n",
      "Epoch 6014/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7833 - auc: 0.8619 - loss: 0.4557 - val_acc: 0.7940 - val_auc: 0.8727 - val_loss: 0.4389\n",
      "Epoch 6015/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7804 - auc: 0.8607 - loss: 0.4575 - val_acc: 0.7969 - val_auc: 0.8727 - val_loss: 0.4385\n",
      "Epoch 6016/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7809 - auc: 0.8605 - loss: 0.4590 - val_acc: 0.7982 - val_auc: 0.8733 - val_loss: 0.4391\n",
      "Epoch 6017/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7821 - auc: 0.8603 - loss: 0.4582 - val_acc: 0.7955 - val_auc: 0.8732 - val_loss: 0.4385\n",
      "Epoch 6018/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7791 - auc: 0.8604 - loss: 0.4575 - val_acc: 0.7958 - val_auc: 0.8736 - val_loss: 0.4387\n",
      "Epoch 6019/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7806 - auc: 0.8606 - loss: 0.4577 - val_acc: 0.7980 - val_auc: 0.8739 - val_loss: 0.4369\n",
      "Epoch 6020/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7815 - auc: 0.8607 - loss: 0.4580 - val_acc: 0.7957 - val_auc: 0.8727 - val_loss: 0.4388\n",
      "Epoch 6021/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7807 - auc: 0.8572 - loss: 0.4621 - val_acc: 0.7959 - val_auc: 0.8728 - val_loss: 0.4399\n",
      "Epoch 6022/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7809 - auc: 0.8602 - loss: 0.4579 - val_acc: 0.7957 - val_auc: 0.8734 - val_loss: 0.4392\n",
      "Epoch 6023/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7806 - auc: 0.8611 - loss: 0.4574 - val_acc: 0.7963 - val_auc: 0.8720 - val_loss: 0.4398\n",
      "Epoch 6024/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7798 - auc: 0.8594 - loss: 0.4584 - val_acc: 0.7976 - val_auc: 0.8737 - val_loss: 0.4374\n",
      "Epoch 6025/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7820 - auc: 0.8605 - loss: 0.4576 - val_acc: 0.7964 - val_auc: 0.8726 - val_loss: 0.4394\n",
      "Epoch 6026/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7827 - auc: 0.8623 - loss: 0.4553 - val_acc: 0.7976 - val_auc: 0.8735 - val_loss: 0.4362\n",
      "Epoch 6027/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7824 - auc: 0.8609 - loss: 0.4570 - val_acc: 0.7951 - val_auc: 0.8727 - val_loss: 0.4400\n",
      "Epoch 6028/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7816 - auc: 0.8615 - loss: 0.4554 - val_acc: 0.7948 - val_auc: 0.8731 - val_loss: 0.4402\n",
      "Epoch 6029/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8604 - loss: 0.4569 - val_acc: 0.7962 - val_auc: 0.8730 - val_loss: 0.4374\n",
      "Epoch 6030/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7799 - auc: 0.8605 - loss: 0.4570 - val_acc: 0.7964 - val_auc: 0.8746 - val_loss: 0.4391\n",
      "Epoch 6031/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7802 - auc: 0.8603 - loss: 0.4580 - val_acc: 0.7930 - val_auc: 0.8715 - val_loss: 0.4417\n",
      "Epoch 6032/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7820 - auc: 0.8612 - loss: 0.4567 - val_acc: 0.7978 - val_auc: 0.8730 - val_loss: 0.4371\n",
      "Epoch 6033/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7816 - auc: 0.8600 - loss: 0.4584 - val_acc: 0.7974 - val_auc: 0.8742 - val_loss: 0.4379\n",
      "Epoch 6034/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7815 - auc: 0.8608 - loss: 0.4570 - val_acc: 0.7964 - val_auc: 0.8730 - val_loss: 0.4387\n",
      "Epoch 6035/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7817 - auc: 0.8612 - loss: 0.4567 - val_acc: 0.7953 - val_auc: 0.8732 - val_loss: 0.4393\n",
      "Epoch 6036/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7809 - auc: 0.8604 - loss: 0.4586 - val_acc: 0.7979 - val_auc: 0.8738 - val_loss: 0.4372\n",
      "Epoch 6037/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7812 - auc: 0.8619 - loss: 0.4562 - val_acc: 0.7989 - val_auc: 0.8758 - val_loss: 0.4363\n",
      "Epoch 6038/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7821 - auc: 0.8601 - loss: 0.4581 - val_acc: 0.7956 - val_auc: 0.8734 - val_loss: 0.4393\n",
      "Epoch 6039/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7840 - auc: 0.8613 - loss: 0.4565 - val_acc: 0.7963 - val_auc: 0.8740 - val_loss: 0.4372\n",
      "Epoch 6040/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7798 - auc: 0.8603 - loss: 0.4581 - val_acc: 0.7967 - val_auc: 0.8742 - val_loss: 0.4376\n",
      "Epoch 6041/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7801 - auc: 0.8598 - loss: 0.4583 - val_acc: 0.7956 - val_auc: 0.8727 - val_loss: 0.4381\n",
      "Epoch 6042/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7811 - auc: 0.8624 - loss: 0.4551 - val_acc: 0.7934 - val_auc: 0.8719 - val_loss: 0.4409\n",
      "Epoch 6043/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7816 - auc: 0.8615 - loss: 0.4565 - val_acc: 0.7969 - val_auc: 0.8730 - val_loss: 0.4400\n",
      "Epoch 6044/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7826 - auc: 0.8614 - loss: 0.4561 - val_acc: 0.7966 - val_auc: 0.8732 - val_loss: 0.4387\n",
      "Epoch 6045/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7809 - auc: 0.8607 - loss: 0.4587 - val_acc: 0.7975 - val_auc: 0.8738 - val_loss: 0.4391\n",
      "Epoch 6046/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7820 - auc: 0.8596 - loss: 0.4588 - val_acc: 0.7971 - val_auc: 0.8734 - val_loss: 0.4378\n",
      "Epoch 6047/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7803 - auc: 0.8609 - loss: 0.4562 - val_acc: 0.7963 - val_auc: 0.8733 - val_loss: 0.4390\n",
      "Epoch 6048/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7798 - auc: 0.8592 - loss: 0.4594 - val_acc: 0.7952 - val_auc: 0.8724 - val_loss: 0.4398\n",
      "Epoch 6049/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7806 - auc: 0.8596 - loss: 0.4592 - val_acc: 0.7964 - val_auc: 0.8726 - val_loss: 0.4397\n",
      "Epoch 6050/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7804 - auc: 0.8603 - loss: 0.4579 - val_acc: 0.7977 - val_auc: 0.8745 - val_loss: 0.4392\n",
      "Epoch 6051/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7836 - auc: 0.8617 - loss: 0.4558 - val_acc: 0.7966 - val_auc: 0.8735 - val_loss: 0.4388\n",
      "Epoch 6052/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7830 - auc: 0.8612 - loss: 0.4570 - val_acc: 0.7954 - val_auc: 0.8738 - val_loss: 0.4389\n",
      "Epoch 6053/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7806 - auc: 0.8603 - loss: 0.4582 - val_acc: 0.7979 - val_auc: 0.8735 - val_loss: 0.4378\n",
      "Epoch 6054/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7830 - auc: 0.8619 - loss: 0.4550 - val_acc: 0.7953 - val_auc: 0.8734 - val_loss: 0.4378\n",
      "Epoch 6055/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7823 - auc: 0.8610 - loss: 0.4580 - val_acc: 0.7961 - val_auc: 0.8734 - val_loss: 0.4391\n",
      "Epoch 6056/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7808 - auc: 0.8607 - loss: 0.4574 - val_acc: 0.7964 - val_auc: 0.8734 - val_loss: 0.4383\n",
      "Epoch 6057/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7837 - auc: 0.8617 - loss: 0.4564 - val_acc: 0.7955 - val_auc: 0.8734 - val_loss: 0.4390\n",
      "Epoch 6058/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7804 - auc: 0.8600 - loss: 0.4602 - val_acc: 0.7976 - val_auc: 0.8736 - val_loss: 0.4382\n",
      "Epoch 6059/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7820 - auc: 0.8604 - loss: 0.4567 - val_acc: 0.7976 - val_auc: 0.8746 - val_loss: 0.4371\n",
      "Epoch 6060/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7816 - auc: 0.8615 - loss: 0.4561 - val_acc: 0.7952 - val_auc: 0.8725 - val_loss: 0.4389\n",
      "Epoch 6061/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7794 - auc: 0.8597 - loss: 0.4579 - val_acc: 0.7989 - val_auc: 0.8751 - val_loss: 0.4387\n",
      "Epoch 6062/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7802 - auc: 0.8602 - loss: 0.4586 - val_acc: 0.7973 - val_auc: 0.8734 - val_loss: 0.4367\n",
      "Epoch 6063/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7826 - auc: 0.8610 - loss: 0.4570 - val_acc: 0.7952 - val_auc: 0.8726 - val_loss: 0.4395\n",
      "Epoch 6064/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7833 - auc: 0.8614 - loss: 0.4565 - val_acc: 0.7951 - val_auc: 0.8732 - val_loss: 0.4389\n",
      "Epoch 6065/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7793 - auc: 0.8601 - loss: 0.4577 - val_acc: 0.7940 - val_auc: 0.8732 - val_loss: 0.4398\n",
      "Epoch 6066/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7806 - auc: 0.8592 - loss: 0.4599 - val_acc: 0.7960 - val_auc: 0.8730 - val_loss: 0.4398\n",
      "Epoch 6067/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7807 - auc: 0.8604 - loss: 0.4566 - val_acc: 0.7963 - val_auc: 0.8737 - val_loss: 0.4386\n",
      "Epoch 6068/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7823 - auc: 0.8610 - loss: 0.4574 - val_acc: 0.7934 - val_auc: 0.8728 - val_loss: 0.4394\n",
      "Epoch 6069/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7828 - auc: 0.8632 - loss: 0.4539 - val_acc: 0.7994 - val_auc: 0.8747 - val_loss: 0.4364\n",
      "Epoch 6070/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7820 - auc: 0.8605 - loss: 0.4573 - val_acc: 0.7954 - val_auc: 0.8742 - val_loss: 0.4381\n",
      "Epoch 6071/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7806 - auc: 0.8607 - loss: 0.4563 - val_acc: 0.7952 - val_auc: 0.8732 - val_loss: 0.4379\n",
      "Epoch 6072/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7801 - auc: 0.8589 - loss: 0.4597 - val_acc: 0.7971 - val_auc: 0.8744 - val_loss: 0.4371\n",
      "Epoch 6073/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7805 - auc: 0.8604 - loss: 0.4575 - val_acc: 0.7969 - val_auc: 0.8736 - val_loss: 0.4393\n",
      "Epoch 6074/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7794 - auc: 0.8589 - loss: 0.4602 - val_acc: 0.7957 - val_auc: 0.8739 - val_loss: 0.4391\n",
      "Epoch 6075/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7820 - auc: 0.8607 - loss: 0.4566 - val_acc: 0.7956 - val_auc: 0.8736 - val_loss: 0.4394\n",
      "Epoch 6076/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7801 - auc: 0.8607 - loss: 0.4574 - val_acc: 0.7981 - val_auc: 0.8738 - val_loss: 0.4382\n",
      "Epoch 6077/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7815 - auc: 0.8597 - loss: 0.4579 - val_acc: 0.7968 - val_auc: 0.8728 - val_loss: 0.4391\n",
      "Epoch 6078/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7815 - auc: 0.8608 - loss: 0.4577 - val_acc: 0.7991 - val_auc: 0.8742 - val_loss: 0.4377\n",
      "Epoch 6079/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7816 - auc: 0.8606 - loss: 0.4571 - val_acc: 0.7951 - val_auc: 0.8731 - val_loss: 0.4383\n",
      "Epoch 6080/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7826 - auc: 0.8611 - loss: 0.4561 - val_acc: 0.7935 - val_auc: 0.8725 - val_loss: 0.4392\n",
      "Epoch 6081/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7808 - auc: 0.8601 - loss: 0.4570 - val_acc: 0.7943 - val_auc: 0.8745 - val_loss: 0.4400\n",
      "Epoch 6082/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7806 - auc: 0.8608 - loss: 0.4567 - val_acc: 0.7974 - val_auc: 0.8728 - val_loss: 0.4384\n",
      "Epoch 6083/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7818 - auc: 0.8606 - loss: 0.4575 - val_acc: 0.7978 - val_auc: 0.8734 - val_loss: 0.4374\n",
      "Epoch 6084/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7799 - auc: 0.8593 - loss: 0.4582 - val_acc: 0.7959 - val_auc: 0.8743 - val_loss: 0.4385\n",
      "Epoch 6085/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7828 - auc: 0.8625 - loss: 0.4547 - val_acc: 0.8003 - val_auc: 0.8734 - val_loss: 0.4358\n",
      "Epoch 6086/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7815 - auc: 0.8617 - loss: 0.4567 - val_acc: 0.7972 - val_auc: 0.8743 - val_loss: 0.4380\n",
      "Epoch 6087/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7815 - auc: 0.8611 - loss: 0.4574 - val_acc: 0.7985 - val_auc: 0.8731 - val_loss: 0.4381\n",
      "Epoch 6088/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7806 - auc: 0.8612 - loss: 0.4570 - val_acc: 0.8007 - val_auc: 0.8737 - val_loss: 0.4370\n",
      "Epoch 6089/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7811 - auc: 0.8608 - loss: 0.4565 - val_acc: 0.7989 - val_auc: 0.8734 - val_loss: 0.4383\n",
      "Epoch 6090/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7817 - auc: 0.8612 - loss: 0.4570 - val_acc: 0.7969 - val_auc: 0.8728 - val_loss: 0.4379\n",
      "Epoch 6091/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7819 - auc: 0.8611 - loss: 0.4565 - val_acc: 0.7956 - val_auc: 0.8733 - val_loss: 0.4366\n",
      "Epoch 6092/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7799 - auc: 0.8605 - loss: 0.4582 - val_acc: 0.7944 - val_auc: 0.8722 - val_loss: 0.4399\n",
      "Epoch 6093/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7812 - auc: 0.8606 - loss: 0.4575 - val_acc: 0.7983 - val_auc: 0.8731 - val_loss: 0.4390\n",
      "Epoch 6094/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7825 - auc: 0.8611 - loss: 0.4563 - val_acc: 0.7958 - val_auc: 0.8739 - val_loss: 0.4391\n",
      "Epoch 6095/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7798 - auc: 0.8598 - loss: 0.4594 - val_acc: 0.7995 - val_auc: 0.8741 - val_loss: 0.4379\n",
      "Epoch 6096/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7788 - auc: 0.8598 - loss: 0.4584 - val_acc: 0.7975 - val_auc: 0.8736 - val_loss: 0.4388\n",
      "Epoch 6097/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7799 - auc: 0.8579 - loss: 0.4611 - val_acc: 0.7995 - val_auc: 0.8746 - val_loss: 0.4377\n",
      "Epoch 6098/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7808 - auc: 0.8611 - loss: 0.4569 - val_acc: 0.7938 - val_auc: 0.8729 - val_loss: 0.4397\n",
      "Epoch 6099/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7804 - auc: 0.8597 - loss: 0.4594 - val_acc: 0.7967 - val_auc: 0.8738 - val_loss: 0.4383\n",
      "Epoch 6100/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7812 - auc: 0.8613 - loss: 0.4564 - val_acc: 0.7938 - val_auc: 0.8729 - val_loss: 0.4404\n",
      "Epoch 6101/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7827 - auc: 0.8607 - loss: 0.4569 - val_acc: 0.7980 - val_auc: 0.8731 - val_loss: 0.4382\n",
      "Epoch 6102/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7812 - auc: 0.8597 - loss: 0.4583 - val_acc: 0.7940 - val_auc: 0.8727 - val_loss: 0.4394\n",
      "Epoch 6103/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7815 - auc: 0.8603 - loss: 0.4581 - val_acc: 0.7972 - val_auc: 0.8733 - val_loss: 0.4394\n",
      "Epoch 6104/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7809 - auc: 0.8605 - loss: 0.4573 - val_acc: 0.7982 - val_auc: 0.8754 - val_loss: 0.4367\n",
      "Epoch 6105/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7809 - auc: 0.8593 - loss: 0.4583 - val_acc: 0.7962 - val_auc: 0.8730 - val_loss: 0.4372\n",
      "Epoch 6106/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7800 - auc: 0.8602 - loss: 0.4582 - val_acc: 0.7967 - val_auc: 0.8730 - val_loss: 0.4387\n",
      "Epoch 6107/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7806 - auc: 0.8608 - loss: 0.4573 - val_acc: 0.7964 - val_auc: 0.8735 - val_loss: 0.4376\n",
      "Epoch 6108/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7826 - auc: 0.8613 - loss: 0.4562 - val_acc: 0.7964 - val_auc: 0.8740 - val_loss: 0.4382\n",
      "Epoch 6109/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7814 - auc: 0.8613 - loss: 0.4564 - val_acc: 0.7963 - val_auc: 0.8726 - val_loss: 0.4392\n",
      "Epoch 6110/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7834 - auc: 0.8618 - loss: 0.4560 - val_acc: 0.7961 - val_auc: 0.8732 - val_loss: 0.4388\n",
      "Epoch 6111/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7812 - auc: 0.8605 - loss: 0.4578 - val_acc: 0.7972 - val_auc: 0.8734 - val_loss: 0.4391\n",
      "Epoch 6112/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7799 - auc: 0.8608 - loss: 0.4572 - val_acc: 0.7969 - val_auc: 0.8729 - val_loss: 0.4379\n",
      "Epoch 6113/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7796 - auc: 0.8605 - loss: 0.4567 - val_acc: 0.7980 - val_auc: 0.8735 - val_loss: 0.4376\n",
      "Epoch 6114/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7804 - auc: 0.8604 - loss: 0.4581 - val_acc: 0.7998 - val_auc: 0.8739 - val_loss: 0.4372\n",
      "Epoch 6115/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7819 - auc: 0.8607 - loss: 0.4574 - val_acc: 0.7959 - val_auc: 0.8726 - val_loss: 0.4398\n",
      "Epoch 6116/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7789 - auc: 0.8602 - loss: 0.4573 - val_acc: 0.7963 - val_auc: 0.8722 - val_loss: 0.4384\n",
      "Epoch 6117/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7815 - auc: 0.8614 - loss: 0.4568 - val_acc: 0.7972 - val_auc: 0.8743 - val_loss: 0.4390\n",
      "Epoch 6118/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7804 - auc: 0.8603 - loss: 0.4576 - val_acc: 0.7961 - val_auc: 0.8730 - val_loss: 0.4391\n",
      "Epoch 6119/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7810 - auc: 0.8613 - loss: 0.4576 - val_acc: 0.7963 - val_auc: 0.8723 - val_loss: 0.4391\n",
      "Epoch 6120/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7828 - auc: 0.8613 - loss: 0.4567 - val_acc: 0.7957 - val_auc: 0.8735 - val_loss: 0.4381\n",
      "Epoch 6121/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7809 - auc: 0.8601 - loss: 0.4581 - val_acc: 0.7958 - val_auc: 0.8734 - val_loss: 0.4381\n",
      "Epoch 6122/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7814 - auc: 0.8600 - loss: 0.4584 - val_acc: 0.7984 - val_auc: 0.8740 - val_loss: 0.4390\n",
      "Epoch 6123/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7785 - auc: 0.8585 - loss: 0.4598 - val_acc: 0.7959 - val_auc: 0.8724 - val_loss: 0.4408\n",
      "Epoch 6124/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7820 - auc: 0.8610 - loss: 0.4575 - val_acc: 0.7950 - val_auc: 0.8718 - val_loss: 0.4400\n",
      "Epoch 6125/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7805 - auc: 0.8612 - loss: 0.4562 - val_acc: 0.7987 - val_auc: 0.8749 - val_loss: 0.4361\n",
      "Epoch 6126/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7828 - auc: 0.8625 - loss: 0.4544 - val_acc: 0.7952 - val_auc: 0.8736 - val_loss: 0.4397\n",
      "Epoch 6127/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7793 - auc: 0.8605 - loss: 0.4576 - val_acc: 0.7983 - val_auc: 0.8735 - val_loss: 0.4385\n",
      "Epoch 6128/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7818 - auc: 0.8610 - loss: 0.4571 - val_acc: 0.7976 - val_auc: 0.8737 - val_loss: 0.4374\n",
      "Epoch 6129/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7823 - auc: 0.8618 - loss: 0.4556 - val_acc: 0.7935 - val_auc: 0.8722 - val_loss: 0.4389\n",
      "Epoch 6130/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7801 - auc: 0.8601 - loss: 0.4581 - val_acc: 0.7974 - val_auc: 0.8737 - val_loss: 0.4384\n",
      "Epoch 6131/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7809 - auc: 0.8600 - loss: 0.4581 - val_acc: 0.7948 - val_auc: 0.8733 - val_loss: 0.4385\n",
      "Epoch 6132/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7813 - auc: 0.8601 - loss: 0.4594 - val_acc: 0.7975 - val_auc: 0.8741 - val_loss: 0.4398\n",
      "Epoch 6133/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7818 - auc: 0.8600 - loss: 0.4586 - val_acc: 0.7948 - val_auc: 0.8731 - val_loss: 0.4398\n",
      "Epoch 6134/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7820 - auc: 0.8610 - loss: 0.4577 - val_acc: 0.7995 - val_auc: 0.8753 - val_loss: 0.4353\n",
      "Epoch 6135/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7815 - auc: 0.8607 - loss: 0.4577 - val_acc: 0.7976 - val_auc: 0.8735 - val_loss: 0.4374\n",
      "Epoch 6136/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8599 - loss: 0.4583 - val_acc: 0.7950 - val_auc: 0.8743 - val_loss: 0.4403\n",
      "Epoch 6137/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7833 - auc: 0.8614 - loss: 0.4551 - val_acc: 0.7929 - val_auc: 0.8733 - val_loss: 0.4373\n",
      "Epoch 6138/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7825 - auc: 0.8610 - loss: 0.4566 - val_acc: 0.7959 - val_auc: 0.8740 - val_loss: 0.4382\n",
      "Epoch 6139/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7815 - auc: 0.8604 - loss: 0.4581 - val_acc: 0.7975 - val_auc: 0.8742 - val_loss: 0.4377\n",
      "Epoch 6140/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7803 - auc: 0.8615 - loss: 0.4558 - val_acc: 0.7962 - val_auc: 0.8729 - val_loss: 0.4379\n",
      "Epoch 6141/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7807 - auc: 0.8602 - loss: 0.4590 - val_acc: 0.7973 - val_auc: 0.8733 - val_loss: 0.4382\n",
      "Epoch 6142/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7809 - auc: 0.8594 - loss: 0.4593 - val_acc: 0.7989 - val_auc: 0.8754 - val_loss: 0.4366\n",
      "Epoch 6143/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7818 - auc: 0.8598 - loss: 0.4576 - val_acc: 0.7970 - val_auc: 0.8726 - val_loss: 0.4393\n",
      "Epoch 6144/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7833 - auc: 0.8617 - loss: 0.4554 - val_acc: 0.7972 - val_auc: 0.8736 - val_loss: 0.4383\n",
      "Epoch 6145/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7815 - auc: 0.8616 - loss: 0.4563 - val_acc: 0.7962 - val_auc: 0.8732 - val_loss: 0.4376\n",
      "Epoch 6146/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7796 - auc: 0.8604 - loss: 0.4569 - val_acc: 0.7951 - val_auc: 0.8731 - val_loss: 0.4407\n",
      "Epoch 6147/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8597 - loss: 0.4589 - val_acc: 0.7966 - val_auc: 0.8737 - val_loss: 0.4395\n",
      "Epoch 6148/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7816 - auc: 0.8616 - loss: 0.4571 - val_acc: 0.7946 - val_auc: 0.8732 - val_loss: 0.4389\n",
      "Epoch 6149/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7822 - auc: 0.8616 - loss: 0.4565 - val_acc: 0.7936 - val_auc: 0.8729 - val_loss: 0.4402\n",
      "Epoch 6150/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7798 - auc: 0.8604 - loss: 0.4580 - val_acc: 0.7951 - val_auc: 0.8733 - val_loss: 0.4391\n",
      "Epoch 6151/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7825 - auc: 0.8626 - loss: 0.4554 - val_acc: 0.7951 - val_auc: 0.8736 - val_loss: 0.4385\n",
      "Epoch 6152/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7817 - auc: 0.8619 - loss: 0.4553 - val_acc: 0.7916 - val_auc: 0.8710 - val_loss: 0.4402\n",
      "Epoch 6153/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7796 - auc: 0.8591 - loss: 0.4592 - val_acc: 0.7971 - val_auc: 0.8735 - val_loss: 0.4386\n",
      "Epoch 6154/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7811 - auc: 0.8611 - loss: 0.4577 - val_acc: 0.7959 - val_auc: 0.8733 - val_loss: 0.4380\n",
      "Epoch 6155/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7831 - auc: 0.8624 - loss: 0.4553 - val_acc: 0.7933 - val_auc: 0.8728 - val_loss: 0.4394\n",
      "Epoch 6156/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7822 - auc: 0.8616 - loss: 0.4574 - val_acc: 0.7969 - val_auc: 0.8743 - val_loss: 0.4372\n",
      "Epoch 6157/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7829 - auc: 0.8623 - loss: 0.4545 - val_acc: 0.7975 - val_auc: 0.8736 - val_loss: 0.4378\n",
      "Epoch 6158/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7827 - auc: 0.8624 - loss: 0.4545 - val_acc: 0.7978 - val_auc: 0.8737 - val_loss: 0.4378\n",
      "Epoch 6159/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7822 - auc: 0.8606 - loss: 0.4584 - val_acc: 0.7989 - val_auc: 0.8748 - val_loss: 0.4359\n",
      "Epoch 6160/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7818 - auc: 0.8605 - loss: 0.4573 - val_acc: 0.7984 - val_auc: 0.8733 - val_loss: 0.4374\n",
      "Epoch 6161/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7826 - auc: 0.8605 - loss: 0.4573 - val_acc: 0.7962 - val_auc: 0.8738 - val_loss: 0.4386\n",
      "Epoch 6162/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7824 - auc: 0.8612 - loss: 0.4575 - val_acc: 0.7996 - val_auc: 0.8739 - val_loss: 0.4370\n",
      "Epoch 6163/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7804 - auc: 0.8597 - loss: 0.4587 - val_acc: 0.7957 - val_auc: 0.8736 - val_loss: 0.4385\n",
      "Epoch 6164/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7796 - auc: 0.8600 - loss: 0.4573 - val_acc: 0.7961 - val_auc: 0.8735 - val_loss: 0.4405\n",
      "Epoch 6165/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7805 - auc: 0.8622 - loss: 0.4546 - val_acc: 0.7962 - val_auc: 0.8746 - val_loss: 0.4368\n",
      "Epoch 6166/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7797 - auc: 0.8595 - loss: 0.4587 - val_acc: 0.7923 - val_auc: 0.8715 - val_loss: 0.4415\n",
      "Epoch 6167/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7815 - auc: 0.8610 - loss: 0.4568 - val_acc: 0.7974 - val_auc: 0.8741 - val_loss: 0.4363\n",
      "Epoch 6168/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7819 - auc: 0.8611 - loss: 0.4570 - val_acc: 0.7976 - val_auc: 0.8743 - val_loss: 0.4375\n",
      "Epoch 6169/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7812 - auc: 0.8598 - loss: 0.4585 - val_acc: 0.7963 - val_auc: 0.8732 - val_loss: 0.4385\n",
      "Epoch 6170/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7825 - auc: 0.8609 - loss: 0.4557 - val_acc: 0.7974 - val_auc: 0.8743 - val_loss: 0.4375\n",
      "Epoch 6171/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7815 - auc: 0.8613 - loss: 0.4561 - val_acc: 0.7950 - val_auc: 0.8725 - val_loss: 0.4398\n",
      "Epoch 6172/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8595 - loss: 0.4604 - val_acc: 0.7941 - val_auc: 0.8735 - val_loss: 0.4394\n",
      "Epoch 6173/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7833 - auc: 0.8619 - loss: 0.4560 - val_acc: 0.7989 - val_auc: 0.8741 - val_loss: 0.4367\n",
      "Epoch 6174/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7818 - auc: 0.8607 - loss: 0.4574 - val_acc: 0.7949 - val_auc: 0.8736 - val_loss: 0.4395\n",
      "Epoch 6175/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7821 - auc: 0.8594 - loss: 0.4581 - val_acc: 0.7970 - val_auc: 0.8747 - val_loss: 0.4363\n",
      "Epoch 6176/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7810 - auc: 0.8611 - loss: 0.4579 - val_acc: 0.7943 - val_auc: 0.8729 - val_loss: 0.4399\n",
      "Epoch 6177/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7806 - auc: 0.8596 - loss: 0.4582 - val_acc: 0.7995 - val_auc: 0.8735 - val_loss: 0.4383\n",
      "Epoch 6178/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7815 - auc: 0.8610 - loss: 0.4568 - val_acc: 0.7968 - val_auc: 0.8746 - val_loss: 0.4381\n",
      "Epoch 6179/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7801 - auc: 0.8601 - loss: 0.4582 - val_acc: 0.7970 - val_auc: 0.8755 - val_loss: 0.4369\n",
      "Epoch 6180/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7818 - auc: 0.8606 - loss: 0.4559 - val_acc: 0.7951 - val_auc: 0.8730 - val_loss: 0.4401\n",
      "Epoch 6181/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7812 - auc: 0.8617 - loss: 0.4564 - val_acc: 0.7986 - val_auc: 0.8745 - val_loss: 0.4369\n",
      "Epoch 6182/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7804 - auc: 0.8601 - loss: 0.4588 - val_acc: 0.7966 - val_auc: 0.8736 - val_loss: 0.4379\n",
      "Epoch 6183/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7823 - auc: 0.8617 - loss: 0.4563 - val_acc: 0.7978 - val_auc: 0.8744 - val_loss: 0.4392\n",
      "Epoch 6184/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7821 - auc: 0.8620 - loss: 0.4550 - val_acc: 0.7963 - val_auc: 0.8733 - val_loss: 0.4372\n",
      "Epoch 6185/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7825 - auc: 0.8609 - loss: 0.4575 - val_acc: 0.7988 - val_auc: 0.8744 - val_loss: 0.4378\n",
      "Epoch 6186/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7801 - auc: 0.8601 - loss: 0.4571 - val_acc: 0.7972 - val_auc: 0.8737 - val_loss: 0.4383\n",
      "Epoch 6187/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7808 - auc: 0.8609 - loss: 0.4562 - val_acc: 0.7976 - val_auc: 0.8747 - val_loss: 0.4375\n",
      "Epoch 6188/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7840 - auc: 0.8622 - loss: 0.4550 - val_acc: 0.7963 - val_auc: 0.8737 - val_loss: 0.4377\n",
      "Epoch 6189/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7808 - auc: 0.8608 - loss: 0.4558 - val_acc: 0.7953 - val_auc: 0.8731 - val_loss: 0.4369\n",
      "Epoch 6190/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7838 - auc: 0.8616 - loss: 0.4563 - val_acc: 0.7980 - val_auc: 0.8729 - val_loss: 0.4381\n",
      "Epoch 6191/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7812 - auc: 0.8608 - loss: 0.4570 - val_acc: 0.7943 - val_auc: 0.8733 - val_loss: 0.4388\n",
      "Epoch 6192/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7801 - auc: 0.8602 - loss: 0.4575 - val_acc: 0.7957 - val_auc: 0.8739 - val_loss: 0.4396\n",
      "Epoch 6193/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7814 - auc: 0.8606 - loss: 0.4574 - val_acc: 0.7959 - val_auc: 0.8727 - val_loss: 0.4389\n",
      "Epoch 6194/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7793 - auc: 0.8599 - loss: 0.4574 - val_acc: 0.7967 - val_auc: 0.8735 - val_loss: 0.4381\n",
      "Epoch 6195/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7823 - auc: 0.8614 - loss: 0.4551 - val_acc: 0.7975 - val_auc: 0.8736 - val_loss: 0.4384\n",
      "Epoch 6196/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7810 - auc: 0.8609 - loss: 0.4580 - val_acc: 0.7983 - val_auc: 0.8746 - val_loss: 0.4364\n",
      "Epoch 6197/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7831 - auc: 0.8623 - loss: 0.4546 - val_acc: 0.7951 - val_auc: 0.8737 - val_loss: 0.4402\n",
      "Epoch 6198/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7827 - auc: 0.8613 - loss: 0.4569 - val_acc: 0.7959 - val_auc: 0.8730 - val_loss: 0.4383\n",
      "Epoch 6199/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7814 - auc: 0.8610 - loss: 0.4568 - val_acc: 0.7979 - val_auc: 0.8751 - val_loss: 0.4362\n",
      "Epoch 6200/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7815 - auc: 0.8618 - loss: 0.4553 - val_acc: 0.7990 - val_auc: 0.8749 - val_loss: 0.4348\n",
      "Epoch 6201/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7811 - auc: 0.8610 - loss: 0.4569 - val_acc: 0.7976 - val_auc: 0.8748 - val_loss: 0.4363\n",
      "Epoch 6202/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7834 - auc: 0.8616 - loss: 0.4551 - val_acc: 0.7939 - val_auc: 0.8732 - val_loss: 0.4395\n",
      "Epoch 6203/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7824 - auc: 0.8623 - loss: 0.4550 - val_acc: 0.7984 - val_auc: 0.8731 - val_loss: 0.4384\n",
      "Epoch 6204/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7807 - auc: 0.8606 - loss: 0.4571 - val_acc: 0.7963 - val_auc: 0.8733 - val_loss: 0.4384\n",
      "Epoch 6205/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7803 - auc: 0.8607 - loss: 0.4573 - val_acc: 0.7948 - val_auc: 0.8713 - val_loss: 0.4399\n",
      "Epoch 6206/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7816 - auc: 0.8610 - loss: 0.4569 - val_acc: 0.7943 - val_auc: 0.8725 - val_loss: 0.4408\n",
      "Epoch 6207/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7800 - auc: 0.8594 - loss: 0.4589 - val_acc: 0.7941 - val_auc: 0.8730 - val_loss: 0.4407\n",
      "Epoch 6208/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7812 - auc: 0.8602 - loss: 0.4581 - val_acc: 0.7968 - val_auc: 0.8734 - val_loss: 0.4391\n",
      "Epoch 6209/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7809 - auc: 0.8602 - loss: 0.4586 - val_acc: 0.7961 - val_auc: 0.8737 - val_loss: 0.4408\n",
      "Epoch 6210/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7793 - auc: 0.8604 - loss: 0.4580 - val_acc: 0.7959 - val_auc: 0.8742 - val_loss: 0.4392\n",
      "Epoch 6211/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7831 - auc: 0.8617 - loss: 0.4553 - val_acc: 0.7993 - val_auc: 0.8744 - val_loss: 0.4377\n",
      "Epoch 6212/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7807 - auc: 0.8596 - loss: 0.4586 - val_acc: 0.7959 - val_auc: 0.8744 - val_loss: 0.4398\n",
      "Epoch 6213/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7807 - auc: 0.8609 - loss: 0.4570 - val_acc: 0.7963 - val_auc: 0.8737 - val_loss: 0.4397\n",
      "Epoch 6214/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7821 - auc: 0.8618 - loss: 0.4556 - val_acc: 0.7986 - val_auc: 0.8737 - val_loss: 0.4391\n",
      "Epoch 6215/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7800 - auc: 0.8596 - loss: 0.4599 - val_acc: 0.7950 - val_auc: 0.8736 - val_loss: 0.4398\n",
      "Epoch 6216/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7800 - auc: 0.8620 - loss: 0.4560 - val_acc: 0.7978 - val_auc: 0.8749 - val_loss: 0.4381\n",
      "Epoch 6217/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7817 - auc: 0.8618 - loss: 0.4563 - val_acc: 0.7957 - val_auc: 0.8740 - val_loss: 0.4389\n",
      "Epoch 6218/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7788 - auc: 0.8592 - loss: 0.4586 - val_acc: 0.7971 - val_auc: 0.8740 - val_loss: 0.4389\n",
      "Epoch 6219/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7811 - auc: 0.8597 - loss: 0.4585 - val_acc: 0.7992 - val_auc: 0.8744 - val_loss: 0.4377\n",
      "Epoch 6220/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7829 - auc: 0.8614 - loss: 0.4558 - val_acc: 0.7945 - val_auc: 0.8731 - val_loss: 0.4415\n",
      "Epoch 6221/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7807 - auc: 0.8616 - loss: 0.4561 - val_acc: 0.7955 - val_auc: 0.8734 - val_loss: 0.4376\n",
      "Epoch 6222/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7803 - auc: 0.8610 - loss: 0.4566 - val_acc: 0.7953 - val_auc: 0.8728 - val_loss: 0.4401\n",
      "Epoch 6223/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7823 - auc: 0.8611 - loss: 0.4566 - val_acc: 0.7964 - val_auc: 0.8744 - val_loss: 0.4375\n",
      "Epoch 6224/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7828 - auc: 0.8621 - loss: 0.4548 - val_acc: 0.7975 - val_auc: 0.8744 - val_loss: 0.4377\n",
      "Epoch 6225/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7816 - auc: 0.8602 - loss: 0.4596 - val_acc: 0.7964 - val_auc: 0.8746 - val_loss: 0.4383\n",
      "Epoch 6226/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7790 - auc: 0.8603 - loss: 0.4587 - val_acc: 0.7989 - val_auc: 0.8748 - val_loss: 0.4366\n",
      "Epoch 6227/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7794 - auc: 0.8598 - loss: 0.4579 - val_acc: 0.7960 - val_auc: 0.8745 - val_loss: 0.4380\n",
      "Epoch 6228/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7826 - auc: 0.8608 - loss: 0.4572 - val_acc: 0.7977 - val_auc: 0.8734 - val_loss: 0.4382\n",
      "Epoch 6229/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7842 - auc: 0.8630 - loss: 0.4548 - val_acc: 0.7989 - val_auc: 0.8737 - val_loss: 0.4379\n",
      "Epoch 6230/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7813 - auc: 0.8604 - loss: 0.4588 - val_acc: 0.7949 - val_auc: 0.8730 - val_loss: 0.4390\n",
      "Epoch 6231/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7794 - auc: 0.8594 - loss: 0.4588 - val_acc: 0.7939 - val_auc: 0.8738 - val_loss: 0.4406\n",
      "Epoch 6232/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7825 - auc: 0.8624 - loss: 0.4547 - val_acc: 0.7967 - val_auc: 0.8750 - val_loss: 0.4366\n",
      "Epoch 6233/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7817 - auc: 0.8606 - loss: 0.4567 - val_acc: 0.7959 - val_auc: 0.8735 - val_loss: 0.4387\n",
      "Epoch 6234/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7814 - auc: 0.8615 - loss: 0.4560 - val_acc: 0.7983 - val_auc: 0.8749 - val_loss: 0.4357\n",
      "Epoch 6235/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7822 - auc: 0.8614 - loss: 0.4564 - val_acc: 0.7967 - val_auc: 0.8733 - val_loss: 0.4390\n",
      "Epoch 6236/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7834 - auc: 0.8610 - loss: 0.4567 - val_acc: 0.7973 - val_auc: 0.8739 - val_loss: 0.4384\n",
      "Epoch 6237/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7806 - auc: 0.8604 - loss: 0.4586 - val_acc: 0.7955 - val_auc: 0.8739 - val_loss: 0.4400\n",
      "Epoch 6238/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7826 - auc: 0.8614 - loss: 0.4563 - val_acc: 0.7978 - val_auc: 0.8743 - val_loss: 0.4366\n",
      "Epoch 6239/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7819 - auc: 0.8606 - loss: 0.4577 - val_acc: 0.7949 - val_auc: 0.8740 - val_loss: 0.4407\n",
      "Epoch 6240/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7806 - auc: 0.8609 - loss: 0.4565 - val_acc: 0.7921 - val_auc: 0.8724 - val_loss: 0.4418\n",
      "Epoch 6241/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7835 - auc: 0.8609 - loss: 0.4562 - val_acc: 0.7977 - val_auc: 0.8739 - val_loss: 0.4371\n",
      "Epoch 6242/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7826 - auc: 0.8615 - loss: 0.4557 - val_acc: 0.7978 - val_auc: 0.8741 - val_loss: 0.4395\n",
      "Epoch 6243/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7834 - auc: 0.8619 - loss: 0.4564 - val_acc: 0.7999 - val_auc: 0.8742 - val_loss: 0.4370\n",
      "Epoch 6244/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7816 - auc: 0.8609 - loss: 0.4564 - val_acc: 0.7959 - val_auc: 0.8728 - val_loss: 0.4398\n",
      "Epoch 6245/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7827 - auc: 0.8606 - loss: 0.4570 - val_acc: 0.7984 - val_auc: 0.8743 - val_loss: 0.4371\n",
      "Epoch 6246/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7840 - auc: 0.8612 - loss: 0.4564 - val_acc: 0.7955 - val_auc: 0.8752 - val_loss: 0.4382\n",
      "Epoch 6247/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7834 - auc: 0.8631 - loss: 0.4541 - val_acc: 0.7971 - val_auc: 0.8740 - val_loss: 0.4388\n",
      "Epoch 6248/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7810 - auc: 0.8603 - loss: 0.4579 - val_acc: 0.7993 - val_auc: 0.8728 - val_loss: 0.4381\n",
      "Epoch 6249/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7806 - auc: 0.8609 - loss: 0.4577 - val_acc: 0.7961 - val_auc: 0.8736 - val_loss: 0.4377\n",
      "Epoch 6250/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7829 - auc: 0.8621 - loss: 0.4553 - val_acc: 0.7966 - val_auc: 0.8740 - val_loss: 0.4381\n",
      "Epoch 6251/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7823 - auc: 0.8613 - loss: 0.4561 - val_acc: 0.7950 - val_auc: 0.8745 - val_loss: 0.4392\n",
      "Epoch 6252/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7791 - auc: 0.8612 - loss: 0.4558 - val_acc: 0.7989 - val_auc: 0.8740 - val_loss: 0.4373\n",
      "Epoch 6253/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7829 - auc: 0.8619 - loss: 0.4555 - val_acc: 0.7951 - val_auc: 0.8748 - val_loss: 0.4377\n",
      "Epoch 6254/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7804 - auc: 0.8602 - loss: 0.4575 - val_acc: 0.7986 - val_auc: 0.8752 - val_loss: 0.4369\n",
      "Epoch 6255/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7816 - auc: 0.8612 - loss: 0.4571 - val_acc: 0.7958 - val_auc: 0.8743 - val_loss: 0.4388\n",
      "Epoch 6256/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7812 - auc: 0.8603 - loss: 0.4577 - val_acc: 0.7950 - val_auc: 0.8729 - val_loss: 0.4385\n",
      "Epoch 6257/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7814 - auc: 0.8610 - loss: 0.4570 - val_acc: 0.7965 - val_auc: 0.8754 - val_loss: 0.4372\n",
      "Epoch 6258/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7815 - auc: 0.8616 - loss: 0.4559 - val_acc: 0.7975 - val_auc: 0.8747 - val_loss: 0.4360\n",
      "Epoch 6259/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7826 - auc: 0.8609 - loss: 0.4571 - val_acc: 0.7946 - val_auc: 0.8744 - val_loss: 0.4403\n",
      "Epoch 6260/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7812 - auc: 0.8616 - loss: 0.4555 - val_acc: 0.7964 - val_auc: 0.8749 - val_loss: 0.4376\n",
      "Epoch 6261/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7827 - auc: 0.8601 - loss: 0.4575 - val_acc: 0.7959 - val_auc: 0.8736 - val_loss: 0.4382\n",
      "Epoch 6262/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7813 - auc: 0.8612 - loss: 0.4570 - val_acc: 0.7978 - val_auc: 0.8752 - val_loss: 0.4356\n",
      "Epoch 6263/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7809 - auc: 0.8598 - loss: 0.4590 - val_acc: 0.7985 - val_auc: 0.8752 - val_loss: 0.4376\n",
      "Epoch 6264/7000\n",
      "106/106 - 2s - 17ms/step - acc: 0.7815 - auc: 0.8614 - loss: 0.4565 - val_acc: 0.7979 - val_auc: 0.8749 - val_loss: 0.4374\n",
      "Epoch 6265/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7826 - auc: 0.8622 - loss: 0.4548 - val_acc: 0.8001 - val_auc: 0.8746 - val_loss: 0.4370\n",
      "Epoch 6266/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7804 - auc: 0.8597 - loss: 0.4604 - val_acc: 0.7965 - val_auc: 0.8752 - val_loss: 0.4389\n",
      "Epoch 6267/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7840 - auc: 0.8624 - loss: 0.4546 - val_acc: 0.7985 - val_auc: 0.8741 - val_loss: 0.4373\n",
      "Epoch 6268/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7825 - auc: 0.8602 - loss: 0.4580 - val_acc: 0.7974 - val_auc: 0.8743 - val_loss: 0.4371\n",
      "Epoch 6269/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7826 - auc: 0.8612 - loss: 0.4568 - val_acc: 0.7965 - val_auc: 0.8733 - val_loss: 0.4383\n",
      "Epoch 6270/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7837 - auc: 0.8625 - loss: 0.4552 - val_acc: 0.8001 - val_auc: 0.8756 - val_loss: 0.4360\n",
      "Epoch 6271/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7807 - auc: 0.8604 - loss: 0.4562 - val_acc: 0.7976 - val_auc: 0.8743 - val_loss: 0.4377\n",
      "Epoch 6272/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7827 - auc: 0.8614 - loss: 0.4572 - val_acc: 0.7969 - val_auc: 0.8745 - val_loss: 0.4388\n",
      "Epoch 6273/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7801 - auc: 0.8606 - loss: 0.4577 - val_acc: 0.7981 - val_auc: 0.8746 - val_loss: 0.4382\n",
      "Epoch 6274/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7825 - auc: 0.8616 - loss: 0.4558 - val_acc: 0.7964 - val_auc: 0.8750 - val_loss: 0.4368\n",
      "Epoch 6275/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7816 - auc: 0.8615 - loss: 0.4564 - val_acc: 0.7973 - val_auc: 0.8729 - val_loss: 0.4389\n",
      "Epoch 6276/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7846 - auc: 0.8630 - loss: 0.4533 - val_acc: 0.7963 - val_auc: 0.8738 - val_loss: 0.4374\n",
      "Epoch 6277/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7805 - auc: 0.8598 - loss: 0.4582 - val_acc: 0.7992 - val_auc: 0.8744 - val_loss: 0.4372\n",
      "Epoch 6278/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7834 - auc: 0.8606 - loss: 0.4579 - val_acc: 0.7994 - val_auc: 0.8739 - val_loss: 0.4379\n",
      "Epoch 6279/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7825 - auc: 0.8611 - loss: 0.4580 - val_acc: 0.7976 - val_auc: 0.8744 - val_loss: 0.4380\n",
      "Epoch 6280/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7824 - auc: 0.8625 - loss: 0.4546 - val_acc: 0.7980 - val_auc: 0.8732 - val_loss: 0.4375\n",
      "Epoch 6281/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7808 - auc: 0.8598 - loss: 0.4578 - val_acc: 0.7969 - val_auc: 0.8741 - val_loss: 0.4396\n",
      "Epoch 6282/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7797 - auc: 0.8609 - loss: 0.4563 - val_acc: 0.7952 - val_auc: 0.8725 - val_loss: 0.4381\n",
      "Epoch 6283/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7821 - auc: 0.8598 - loss: 0.4584 - val_acc: 0.7961 - val_auc: 0.8736 - val_loss: 0.4379\n",
      "Epoch 6284/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7802 - auc: 0.8602 - loss: 0.4584 - val_acc: 0.7989 - val_auc: 0.8739 - val_loss: 0.4375\n",
      "Epoch 6285/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7818 - auc: 0.8601 - loss: 0.4589 - val_acc: 0.7981 - val_auc: 0.8742 - val_loss: 0.4376\n",
      "Epoch 6286/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7826 - auc: 0.8619 - loss: 0.4557 - val_acc: 0.7962 - val_auc: 0.8742 - val_loss: 0.4384\n",
      "Epoch 6287/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7820 - auc: 0.8606 - loss: 0.4570 - val_acc: 0.7974 - val_auc: 0.8736 - val_loss: 0.4376\n",
      "Epoch 6288/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7818 - auc: 0.8616 - loss: 0.4554 - val_acc: 0.7966 - val_auc: 0.8737 - val_loss: 0.4372\n",
      "Epoch 6289/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7833 - auc: 0.8618 - loss: 0.4555 - val_acc: 0.8001 - val_auc: 0.8752 - val_loss: 0.4363\n",
      "Epoch 6290/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7788 - auc: 0.8591 - loss: 0.4589 - val_acc: 0.7973 - val_auc: 0.8737 - val_loss: 0.4367\n",
      "Epoch 6291/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7832 - auc: 0.8624 - loss: 0.4545 - val_acc: 0.7964 - val_auc: 0.8735 - val_loss: 0.4389\n",
      "Epoch 6292/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7802 - auc: 0.8600 - loss: 0.4579 - val_acc: 0.7970 - val_auc: 0.8745 - val_loss: 0.4374\n",
      "Epoch 6293/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7814 - auc: 0.8614 - loss: 0.4562 - val_acc: 0.7963 - val_auc: 0.8739 - val_loss: 0.4378\n",
      "Epoch 6294/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7822 - auc: 0.8604 - loss: 0.4584 - val_acc: 0.7970 - val_auc: 0.8755 - val_loss: 0.4364\n",
      "Epoch 6295/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7829 - auc: 0.8615 - loss: 0.4563 - val_acc: 0.7973 - val_auc: 0.8735 - val_loss: 0.4383\n",
      "Epoch 6296/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7827 - auc: 0.8611 - loss: 0.4575 - val_acc: 0.7955 - val_auc: 0.8739 - val_loss: 0.4382\n",
      "Epoch 6297/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7816 - auc: 0.8601 - loss: 0.4581 - val_acc: 0.7953 - val_auc: 0.8731 - val_loss: 0.4390\n",
      "Epoch 6298/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7830 - auc: 0.8616 - loss: 0.4563 - val_acc: 0.7963 - val_auc: 0.8735 - val_loss: 0.4373\n",
      "Epoch 6299/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7819 - auc: 0.8614 - loss: 0.4562 - val_acc: 0.7980 - val_auc: 0.8748 - val_loss: 0.4373\n",
      "Epoch 6300/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7811 - auc: 0.8596 - loss: 0.4587 - val_acc: 0.7928 - val_auc: 0.8721 - val_loss: 0.4398\n",
      "Epoch 6301/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7796 - auc: 0.8604 - loss: 0.4572 - val_acc: 0.7969 - val_auc: 0.8744 - val_loss: 0.4374\n",
      "Epoch 6302/7000\n",
      "106/106 - 2s - 18ms/step - acc: 0.7820 - auc: 0.8604 - loss: 0.4575 - val_acc: 0.7983 - val_auc: 0.8748 - val_loss: 0.4358\n",
      "Epoch 6303/7000\n",
      "106/106 - 2s - 21ms/step - acc: 0.7805 - auc: 0.8599 - loss: 0.4592 - val_acc: 0.7957 - val_auc: 0.8729 - val_loss: 0.4377\n",
      "Epoch 6304/7000\n",
      "106/106 - 2s - 16ms/step - acc: 0.7820 - auc: 0.8606 - loss: 0.4567 - val_acc: 0.7951 - val_auc: 0.8732 - val_loss: 0.4401\n",
      "Epoch 6305/7000\n",
      "106/106 - 2s - 14ms/step - acc: 0.7795 - auc: 0.8604 - loss: 0.4575 - val_acc: 0.7948 - val_auc: 0.8732 - val_loss: 0.4384\n",
      "Epoch 6306/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7783 - auc: 0.8596 - loss: 0.4590 - val_acc: 0.7968 - val_auc: 0.8742 - val_loss: 0.4380\n",
      "Epoch 6307/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7821 - auc: 0.8618 - loss: 0.4561 - val_acc: 0.7953 - val_auc: 0.8732 - val_loss: 0.4397\n",
      "Epoch 6308/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7829 - auc: 0.8619 - loss: 0.4551 - val_acc: 0.7991 - val_auc: 0.8744 - val_loss: 0.4380\n",
      "Epoch 6309/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7816 - auc: 0.8603 - loss: 0.4568 - val_acc: 0.7962 - val_auc: 0.8734 - val_loss: 0.4396\n",
      "Epoch 6310/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7812 - auc: 0.8606 - loss: 0.4569 - val_acc: 0.7942 - val_auc: 0.8734 - val_loss: 0.4397\n",
      "Epoch 6311/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7842 - auc: 0.8630 - loss: 0.4542 - val_acc: 0.7979 - val_auc: 0.8750 - val_loss: 0.4357\n",
      "Epoch 6312/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7834 - auc: 0.8617 - loss: 0.4560 - val_acc: 0.7967 - val_auc: 0.8732 - val_loss: 0.4387\n",
      "Epoch 6313/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7801 - auc: 0.8608 - loss: 0.4570 - val_acc: 0.7957 - val_auc: 0.8732 - val_loss: 0.4385\n",
      "Epoch 6314/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7839 - auc: 0.8619 - loss: 0.4570 - val_acc: 0.7955 - val_auc: 0.8731 - val_loss: 0.4379\n",
      "Epoch 6315/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7830 - auc: 0.8627 - loss: 0.4545 - val_acc: 0.7964 - val_auc: 0.8731 - val_loss: 0.4385\n",
      "Epoch 6316/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7814 - auc: 0.8605 - loss: 0.4573 - val_acc: 0.7964 - val_auc: 0.8743 - val_loss: 0.4364\n",
      "Epoch 6317/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7821 - auc: 0.8622 - loss: 0.4545 - val_acc: 0.7967 - val_auc: 0.8742 - val_loss: 0.4381\n",
      "Epoch 6318/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7809 - auc: 0.8613 - loss: 0.4568 - val_acc: 0.7980 - val_auc: 0.8736 - val_loss: 0.4387\n",
      "Epoch 6319/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7818 - auc: 0.8626 - loss: 0.4545 - val_acc: 0.7939 - val_auc: 0.8735 - val_loss: 0.4389\n",
      "Epoch 6320/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7818 - auc: 0.8611 - loss: 0.4566 - val_acc: 0.7932 - val_auc: 0.8723 - val_loss: 0.4387\n",
      "Epoch 6321/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7797 - auc: 0.8592 - loss: 0.4597 - val_acc: 0.7944 - val_auc: 0.8735 - val_loss: 0.4400\n",
      "Epoch 6322/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7819 - auc: 0.8618 - loss: 0.4560 - val_acc: 0.7939 - val_auc: 0.8719 - val_loss: 0.4403\n",
      "Epoch 6323/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7808 - auc: 0.8609 - loss: 0.4570 - val_acc: 0.7948 - val_auc: 0.8727 - val_loss: 0.4407\n",
      "Epoch 6324/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7827 - auc: 0.8607 - loss: 0.4576 - val_acc: 0.7971 - val_auc: 0.8734 - val_loss: 0.4377\n",
      "Epoch 6325/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7812 - auc: 0.8608 - loss: 0.4566 - val_acc: 0.7970 - val_auc: 0.8746 - val_loss: 0.4372\n",
      "Epoch 6326/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7802 - auc: 0.8592 - loss: 0.4590 - val_acc: 0.7934 - val_auc: 0.8737 - val_loss: 0.4401\n",
      "Epoch 6327/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7817 - auc: 0.8610 - loss: 0.4569 - val_acc: 0.7944 - val_auc: 0.8746 - val_loss: 0.4390\n",
      "Epoch 6328/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7818 - auc: 0.8599 - loss: 0.4585 - val_acc: 0.7926 - val_auc: 0.8731 - val_loss: 0.4406\n",
      "Epoch 6329/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7816 - auc: 0.8617 - loss: 0.4557 - val_acc: 0.7986 - val_auc: 0.8732 - val_loss: 0.4376\n",
      "Epoch 6330/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7812 - auc: 0.8618 - loss: 0.4559 - val_acc: 0.7989 - val_auc: 0.8747 - val_loss: 0.4366\n",
      "Epoch 6331/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7806 - auc: 0.8608 - loss: 0.4570 - val_acc: 0.7969 - val_auc: 0.8735 - val_loss: 0.4370\n",
      "Epoch 6332/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7798 - auc: 0.8600 - loss: 0.4582 - val_acc: 0.7972 - val_auc: 0.8727 - val_loss: 0.4400\n",
      "Epoch 6333/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7800 - auc: 0.8595 - loss: 0.4590 - val_acc: 0.7980 - val_auc: 0.8739 - val_loss: 0.4379\n",
      "Epoch 6334/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7831 - auc: 0.8617 - loss: 0.4563 - val_acc: 0.7936 - val_auc: 0.8734 - val_loss: 0.4399\n",
      "Epoch 6335/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7813 - auc: 0.8605 - loss: 0.4585 - val_acc: 0.7961 - val_auc: 0.8729 - val_loss: 0.4388\n",
      "Epoch 6336/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7806 - auc: 0.8606 - loss: 0.4576 - val_acc: 0.7957 - val_auc: 0.8739 - val_loss: 0.4381\n",
      "Epoch 6337/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7811 - auc: 0.8611 - loss: 0.4568 - val_acc: 0.7954 - val_auc: 0.8745 - val_loss: 0.4376\n",
      "Epoch 6338/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7841 - auc: 0.8620 - loss: 0.4552 - val_acc: 0.7944 - val_auc: 0.8733 - val_loss: 0.4395\n",
      "Epoch 6339/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7804 - auc: 0.8609 - loss: 0.4562 - val_acc: 0.8005 - val_auc: 0.8751 - val_loss: 0.4358\n",
      "Epoch 6340/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7812 - auc: 0.8608 - loss: 0.4579 - val_acc: 0.7961 - val_auc: 0.8727 - val_loss: 0.4397\n",
      "Epoch 6341/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7808 - auc: 0.8605 - loss: 0.4577 - val_acc: 0.7992 - val_auc: 0.8750 - val_loss: 0.4378\n",
      "Epoch 6342/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7819 - auc: 0.8618 - loss: 0.4559 - val_acc: 0.7970 - val_auc: 0.8742 - val_loss: 0.4388\n",
      "Epoch 6343/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7808 - auc: 0.8609 - loss: 0.4571 - val_acc: 0.7950 - val_auc: 0.8739 - val_loss: 0.4401\n",
      "Epoch 6344/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7813 - auc: 0.8612 - loss: 0.4567 - val_acc: 0.7955 - val_auc: 0.8727 - val_loss: 0.4380\n",
      "Epoch 6345/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7813 - auc: 0.8605 - loss: 0.4582 - val_acc: 0.8002 - val_auc: 0.8749 - val_loss: 0.4372\n",
      "Epoch 6346/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7837 - auc: 0.8626 - loss: 0.4551 - val_acc: 0.7981 - val_auc: 0.8746 - val_loss: 0.4375\n",
      "Epoch 6347/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7835 - auc: 0.8628 - loss: 0.4539 - val_acc: 0.7958 - val_auc: 0.8748 - val_loss: 0.4379\n",
      "Epoch 6348/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7811 - auc: 0.8602 - loss: 0.4574 - val_acc: 0.7976 - val_auc: 0.8734 - val_loss: 0.4394\n",
      "Epoch 6349/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7802 - auc: 0.8605 - loss: 0.4570 - val_acc: 0.7983 - val_auc: 0.8744 - val_loss: 0.4360\n",
      "Epoch 6350/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7818 - auc: 0.8603 - loss: 0.4587 - val_acc: 0.7938 - val_auc: 0.8716 - val_loss: 0.4419\n",
      "Epoch 6351/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7801 - auc: 0.8610 - loss: 0.4559 - val_acc: 0.7953 - val_auc: 0.8746 - val_loss: 0.4388\n",
      "Epoch 6352/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7834 - auc: 0.8636 - loss: 0.4533 - val_acc: 0.7977 - val_auc: 0.8745 - val_loss: 0.4368\n",
      "Epoch 6353/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7808 - auc: 0.8609 - loss: 0.4571 - val_acc: 0.7965 - val_auc: 0.8739 - val_loss: 0.4377\n",
      "Epoch 6354/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7798 - auc: 0.8607 - loss: 0.4567 - val_acc: 0.7973 - val_auc: 0.8742 - val_loss: 0.4380\n",
      "Epoch 6355/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7817 - auc: 0.8625 - loss: 0.4547 - val_acc: 0.7984 - val_auc: 0.8748 - val_loss: 0.4364\n",
      "Epoch 6356/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7817 - auc: 0.8601 - loss: 0.4589 - val_acc: 0.7952 - val_auc: 0.8740 - val_loss: 0.4399\n",
      "Epoch 6357/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7830 - auc: 0.8616 - loss: 0.4565 - val_acc: 0.7939 - val_auc: 0.8722 - val_loss: 0.4406\n",
      "Epoch 6358/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7822 - auc: 0.8612 - loss: 0.4581 - val_acc: 0.7934 - val_auc: 0.8729 - val_loss: 0.4408\n",
      "Epoch 6359/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7798 - auc: 0.8609 - loss: 0.4562 - val_acc: 0.7988 - val_auc: 0.8744 - val_loss: 0.4375\n",
      "Epoch 6360/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7806 - auc: 0.8609 - loss: 0.4574 - val_acc: 0.7978 - val_auc: 0.8731 - val_loss: 0.4374\n",
      "Epoch 6361/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7829 - auc: 0.8621 - loss: 0.4549 - val_acc: 0.7968 - val_auc: 0.8737 - val_loss: 0.4387\n",
      "Epoch 6362/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7797 - auc: 0.8598 - loss: 0.4582 - val_acc: 0.7969 - val_auc: 0.8742 - val_loss: 0.4379\n",
      "Epoch 6363/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7829 - auc: 0.8623 - loss: 0.4553 - val_acc: 0.7964 - val_auc: 0.8739 - val_loss: 0.4381\n",
      "Epoch 6364/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7803 - auc: 0.8604 - loss: 0.4592 - val_acc: 0.7949 - val_auc: 0.8740 - val_loss: 0.4395\n",
      "Epoch 6365/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7815 - auc: 0.8600 - loss: 0.4572 - val_acc: 0.7974 - val_auc: 0.8735 - val_loss: 0.4384\n",
      "Epoch 6366/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7810 - auc: 0.8604 - loss: 0.4563 - val_acc: 0.7963 - val_auc: 0.8746 - val_loss: 0.4388\n",
      "Epoch 6367/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7836 - auc: 0.8626 - loss: 0.4547 - val_acc: 0.7974 - val_auc: 0.8750 - val_loss: 0.4380\n",
      "Epoch 6368/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7839 - auc: 0.8614 - loss: 0.4564 - val_acc: 0.7977 - val_auc: 0.8737 - val_loss: 0.4385\n",
      "Epoch 6369/7000\n",
      "106/106 - 2s - 14ms/step - acc: 0.7823 - auc: 0.8618 - loss: 0.4555 - val_acc: 0.7941 - val_auc: 0.8729 - val_loss: 0.4389\n",
      "Epoch 6370/7000\n",
      "106/106 - 2s - 18ms/step - acc: 0.7816 - auc: 0.8611 - loss: 0.4567 - val_acc: 0.7943 - val_auc: 0.8730 - val_loss: 0.4394\n",
      "Epoch 6371/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7816 - auc: 0.8600 - loss: 0.4587 - val_acc: 0.7957 - val_auc: 0.8729 - val_loss: 0.4398\n",
      "Epoch 6372/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7816 - auc: 0.8598 - loss: 0.4580 - val_acc: 0.7980 - val_auc: 0.8746 - val_loss: 0.4363\n",
      "Epoch 6373/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7834 - auc: 0.8623 - loss: 0.4555 - val_acc: 0.7969 - val_auc: 0.8729 - val_loss: 0.4385\n",
      "Epoch 6374/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7827 - auc: 0.8618 - loss: 0.4559 - val_acc: 0.7975 - val_auc: 0.8746 - val_loss: 0.4372\n",
      "Epoch 6375/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7819 - auc: 0.8615 - loss: 0.4555 - val_acc: 0.7956 - val_auc: 0.8726 - val_loss: 0.4403\n",
      "Epoch 6376/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7806 - auc: 0.8600 - loss: 0.4576 - val_acc: 0.8000 - val_auc: 0.8743 - val_loss: 0.4368\n",
      "Epoch 6377/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7816 - auc: 0.8612 - loss: 0.4563 - val_acc: 0.7953 - val_auc: 0.8733 - val_loss: 0.4389\n",
      "Epoch 6378/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7823 - auc: 0.8614 - loss: 0.4556 - val_acc: 0.7936 - val_auc: 0.8735 - val_loss: 0.4403\n",
      "Epoch 6379/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7810 - auc: 0.8610 - loss: 0.4564 - val_acc: 0.7983 - val_auc: 0.8733 - val_loss: 0.4384\n",
      "Epoch 6380/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7840 - auc: 0.8627 - loss: 0.4542 - val_acc: 0.7951 - val_auc: 0.8747 - val_loss: 0.4383\n",
      "Epoch 6381/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7823 - auc: 0.8622 - loss: 0.4556 - val_acc: 0.7976 - val_auc: 0.8744 - val_loss: 0.4357\n",
      "Epoch 6382/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7795 - auc: 0.8597 - loss: 0.4587 - val_acc: 0.7976 - val_auc: 0.8743 - val_loss: 0.4383\n",
      "Epoch 6383/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7815 - auc: 0.8614 - loss: 0.4550 - val_acc: 0.7973 - val_auc: 0.8739 - val_loss: 0.4382\n",
      "Epoch 6384/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7806 - auc: 0.8610 - loss: 0.4566 - val_acc: 0.7957 - val_auc: 0.8728 - val_loss: 0.4395\n",
      "Epoch 6385/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7817 - auc: 0.8605 - loss: 0.4576 - val_acc: 0.7962 - val_auc: 0.8741 - val_loss: 0.4402\n",
      "Epoch 6386/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7808 - auc: 0.8606 - loss: 0.4572 - val_acc: 0.7983 - val_auc: 0.8734 - val_loss: 0.4387\n",
      "Epoch 6387/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7844 - auc: 0.8635 - loss: 0.4537 - val_acc: 0.7937 - val_auc: 0.8733 - val_loss: 0.4395\n",
      "Epoch 6388/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7843 - auc: 0.8627 - loss: 0.4540 - val_acc: 0.7962 - val_auc: 0.8733 - val_loss: 0.4386\n",
      "Epoch 6389/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7818 - auc: 0.8609 - loss: 0.4573 - val_acc: 0.7968 - val_auc: 0.8731 - val_loss: 0.4382\n",
      "Epoch 6390/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7812 - auc: 0.8617 - loss: 0.4564 - val_acc: 0.7983 - val_auc: 0.8733 - val_loss: 0.4393\n",
      "Epoch 6391/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7838 - auc: 0.8621 - loss: 0.4557 - val_acc: 0.7982 - val_auc: 0.8747 - val_loss: 0.4371\n",
      "Epoch 6392/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7809 - auc: 0.8618 - loss: 0.4558 - val_acc: 0.7981 - val_auc: 0.8739 - val_loss: 0.4375\n",
      "Epoch 6393/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7807 - auc: 0.8608 - loss: 0.4580 - val_acc: 0.7979 - val_auc: 0.8745 - val_loss: 0.4383\n",
      "Epoch 6394/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7822 - auc: 0.8607 - loss: 0.4583 - val_acc: 0.7963 - val_auc: 0.8732 - val_loss: 0.4387\n",
      "Epoch 6395/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7827 - auc: 0.8620 - loss: 0.4561 - val_acc: 0.7984 - val_auc: 0.8742 - val_loss: 0.4368\n",
      "Epoch 6396/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7826 - auc: 0.8620 - loss: 0.4553 - val_acc: 0.7953 - val_auc: 0.8726 - val_loss: 0.4382\n",
      "Epoch 6397/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7796 - auc: 0.8588 - loss: 0.4609 - val_acc: 0.7991 - val_auc: 0.8741 - val_loss: 0.4370\n",
      "Epoch 6398/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7801 - auc: 0.8613 - loss: 0.4565 - val_acc: 0.8002 - val_auc: 0.8755 - val_loss: 0.4390\n",
      "Epoch 6399/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7828 - auc: 0.8631 - loss: 0.4546 - val_acc: 0.7990 - val_auc: 0.8744 - val_loss: 0.4372\n",
      "Epoch 6400/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7808 - auc: 0.8609 - loss: 0.4554 - val_acc: 0.7951 - val_auc: 0.8735 - val_loss: 0.4394\n",
      "Epoch 6401/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7805 - auc: 0.8603 - loss: 0.4578 - val_acc: 0.7979 - val_auc: 0.8746 - val_loss: 0.4371\n",
      "Epoch 6402/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7834 - auc: 0.8617 - loss: 0.4554 - val_acc: 0.7977 - val_auc: 0.8739 - val_loss: 0.4376\n",
      "Epoch 6403/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7829 - auc: 0.8607 - loss: 0.4572 - val_acc: 0.8001 - val_auc: 0.8744 - val_loss: 0.4384\n",
      "Epoch 6404/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7814 - auc: 0.8616 - loss: 0.4566 - val_acc: 0.7953 - val_auc: 0.8731 - val_loss: 0.4404\n",
      "Epoch 6405/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7817 - auc: 0.8625 - loss: 0.4553 - val_acc: 0.7985 - val_auc: 0.8755 - val_loss: 0.4363\n",
      "Epoch 6406/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7824 - auc: 0.8620 - loss: 0.4550 - val_acc: 0.7972 - val_auc: 0.8740 - val_loss: 0.4386\n",
      "Epoch 6407/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7821 - auc: 0.8610 - loss: 0.4567 - val_acc: 0.7963 - val_auc: 0.8740 - val_loss: 0.4387\n",
      "Epoch 6408/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7820 - auc: 0.8613 - loss: 0.4564 - val_acc: 0.7955 - val_auc: 0.8730 - val_loss: 0.4390\n",
      "Epoch 6409/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7804 - auc: 0.8608 - loss: 0.4558 - val_acc: 0.8001 - val_auc: 0.8746 - val_loss: 0.4349\n",
      "Epoch 6410/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7816 - auc: 0.8616 - loss: 0.4560 - val_acc: 0.7978 - val_auc: 0.8743 - val_loss: 0.4385\n",
      "Epoch 6411/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7849 - auc: 0.8633 - loss: 0.4537 - val_acc: 0.7966 - val_auc: 0.8737 - val_loss: 0.4378\n",
      "Epoch 6412/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7827 - auc: 0.8605 - loss: 0.4578 - val_acc: 0.7972 - val_auc: 0.8744 - val_loss: 0.4370\n",
      "Epoch 6413/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7826 - auc: 0.8610 - loss: 0.4568 - val_acc: 0.7976 - val_auc: 0.8738 - val_loss: 0.4384\n",
      "Epoch 6414/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7810 - auc: 0.8610 - loss: 0.4575 - val_acc: 0.7991 - val_auc: 0.8753 - val_loss: 0.4378\n",
      "Epoch 6415/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7830 - auc: 0.8617 - loss: 0.4560 - val_acc: 0.7974 - val_auc: 0.8748 - val_loss: 0.4376\n",
      "Epoch 6416/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7800 - auc: 0.8606 - loss: 0.4561 - val_acc: 0.7980 - val_auc: 0.8740 - val_loss: 0.4368\n",
      "Epoch 6417/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7815 - auc: 0.8606 - loss: 0.4578 - val_acc: 0.7989 - val_auc: 0.8744 - val_loss: 0.4375\n",
      "Epoch 6418/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7803 - auc: 0.8603 - loss: 0.4576 - val_acc: 0.7979 - val_auc: 0.8736 - val_loss: 0.4380\n",
      "Epoch 6419/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7823 - auc: 0.8612 - loss: 0.4574 - val_acc: 0.7973 - val_auc: 0.8741 - val_loss: 0.4376\n",
      "Epoch 6420/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7818 - auc: 0.8616 - loss: 0.4562 - val_acc: 0.7951 - val_auc: 0.8729 - val_loss: 0.4390\n",
      "Epoch 6421/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7824 - auc: 0.8616 - loss: 0.4553 - val_acc: 0.7989 - val_auc: 0.8737 - val_loss: 0.4371\n",
      "Epoch 6422/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7831 - auc: 0.8621 - loss: 0.4555 - val_acc: 0.7960 - val_auc: 0.8735 - val_loss: 0.4366\n",
      "Epoch 6423/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7826 - auc: 0.8614 - loss: 0.4563 - val_acc: 0.7989 - val_auc: 0.8746 - val_loss: 0.4362\n",
      "Epoch 6424/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7809 - auc: 0.8598 - loss: 0.4593 - val_acc: 0.7976 - val_auc: 0.8744 - val_loss: 0.4383\n",
      "Epoch 6425/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7827 - auc: 0.8612 - loss: 0.4556 - val_acc: 0.7974 - val_auc: 0.8736 - val_loss: 0.4369\n",
      "Epoch 6426/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7806 - auc: 0.8592 - loss: 0.4593 - val_acc: 0.7932 - val_auc: 0.8716 - val_loss: 0.4401\n",
      "Epoch 6427/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7815 - auc: 0.8624 - loss: 0.4552 - val_acc: 0.7955 - val_auc: 0.8735 - val_loss: 0.4375\n",
      "Epoch 6428/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7825 - auc: 0.8623 - loss: 0.4541 - val_acc: 0.7964 - val_auc: 0.8742 - val_loss: 0.4366\n",
      "Epoch 6429/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7813 - auc: 0.8612 - loss: 0.4562 - val_acc: 0.7986 - val_auc: 0.8734 - val_loss: 0.4395\n",
      "Epoch 6430/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7824 - auc: 0.8596 - loss: 0.4584 - val_acc: 0.7973 - val_auc: 0.8741 - val_loss: 0.4390\n",
      "Epoch 6431/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7802 - auc: 0.8602 - loss: 0.4582 - val_acc: 0.7965 - val_auc: 0.8726 - val_loss: 0.4400\n",
      "Epoch 6432/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7817 - auc: 0.8613 - loss: 0.4561 - val_acc: 0.7974 - val_auc: 0.8747 - val_loss: 0.4377\n",
      "Epoch 6433/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7798 - auc: 0.8609 - loss: 0.4564 - val_acc: 0.7982 - val_auc: 0.8735 - val_loss: 0.4367\n",
      "Epoch 6434/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7811 - auc: 0.8601 - loss: 0.4575 - val_acc: 0.7984 - val_auc: 0.8738 - val_loss: 0.4368\n",
      "Epoch 6435/7000\n",
      "106/106 - 2s - 14ms/step - acc: 0.7828 - auc: 0.8617 - loss: 0.4556 - val_acc: 0.7943 - val_auc: 0.8729 - val_loss: 0.4411\n",
      "Epoch 6436/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7844 - auc: 0.8628 - loss: 0.4550 - val_acc: 0.7984 - val_auc: 0.8750 - val_loss: 0.4375\n",
      "Epoch 6437/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7828 - auc: 0.8611 - loss: 0.4562 - val_acc: 0.7990 - val_auc: 0.8743 - val_loss: 0.4359\n",
      "Epoch 6438/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7815 - auc: 0.8623 - loss: 0.4554 - val_acc: 0.7977 - val_auc: 0.8745 - val_loss: 0.4369\n",
      "Epoch 6439/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8613 - loss: 0.4569 - val_acc: 0.7986 - val_auc: 0.8746 - val_loss: 0.4379\n",
      "Epoch 6440/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7810 - auc: 0.8611 - loss: 0.4561 - val_acc: 0.7972 - val_auc: 0.8749 - val_loss: 0.4376\n",
      "Epoch 6441/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7822 - auc: 0.8601 - loss: 0.4589 - val_acc: 0.7982 - val_auc: 0.8747 - val_loss: 0.4375\n",
      "Epoch 6442/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7817 - auc: 0.8602 - loss: 0.4575 - val_acc: 0.7973 - val_auc: 0.8740 - val_loss: 0.4374\n",
      "Epoch 6443/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7819 - auc: 0.8612 - loss: 0.4557 - val_acc: 0.7960 - val_auc: 0.8751 - val_loss: 0.4380\n",
      "Epoch 6444/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7819 - auc: 0.8609 - loss: 0.4571 - val_acc: 0.7975 - val_auc: 0.8750 - val_loss: 0.4373\n",
      "Epoch 6445/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7817 - auc: 0.8625 - loss: 0.4550 - val_acc: 0.7987 - val_auc: 0.8763 - val_loss: 0.4347\n",
      "Epoch 6446/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7842 - auc: 0.8634 - loss: 0.4527 - val_acc: 0.7967 - val_auc: 0.8748 - val_loss: 0.4369\n",
      "Epoch 6447/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7842 - auc: 0.8617 - loss: 0.4559 - val_acc: 0.7993 - val_auc: 0.8754 - val_loss: 0.4374\n",
      "Epoch 6448/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7800 - auc: 0.8594 - loss: 0.4581 - val_acc: 0.7964 - val_auc: 0.8740 - val_loss: 0.4398\n",
      "Epoch 6449/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7798 - auc: 0.8589 - loss: 0.4593 - val_acc: 0.8002 - val_auc: 0.8743 - val_loss: 0.4378\n",
      "Epoch 6450/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7800 - auc: 0.8612 - loss: 0.4570 - val_acc: 0.7987 - val_auc: 0.8743 - val_loss: 0.4391\n",
      "Epoch 6451/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7817 - auc: 0.8610 - loss: 0.4571 - val_acc: 0.7981 - val_auc: 0.8737 - val_loss: 0.4384\n",
      "Epoch 6452/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7807 - auc: 0.8608 - loss: 0.4572 - val_acc: 0.7968 - val_auc: 0.8742 - val_loss: 0.4389\n",
      "Epoch 6453/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7825 - auc: 0.8633 - loss: 0.4544 - val_acc: 0.7996 - val_auc: 0.8753 - val_loss: 0.4376\n",
      "Epoch 6454/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7809 - auc: 0.8598 - loss: 0.4585 - val_acc: 0.7983 - val_auc: 0.8744 - val_loss: 0.4366\n",
      "Epoch 6455/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7819 - auc: 0.8619 - loss: 0.4555 - val_acc: 0.7952 - val_auc: 0.8736 - val_loss: 0.4378\n",
      "Epoch 6456/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7820 - auc: 0.8614 - loss: 0.4558 - val_acc: 0.7952 - val_auc: 0.8739 - val_loss: 0.4391\n",
      "Epoch 6457/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7808 - auc: 0.8614 - loss: 0.4549 - val_acc: 0.7977 - val_auc: 0.8747 - val_loss: 0.4365\n",
      "Epoch 6458/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7793 - auc: 0.8611 - loss: 0.4563 - val_acc: 0.7976 - val_auc: 0.8741 - val_loss: 0.4388\n",
      "Epoch 6459/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7815 - auc: 0.8604 - loss: 0.4570 - val_acc: 0.7983 - val_auc: 0.8746 - val_loss: 0.4357\n",
      "Epoch 6460/7000\n",
      "106/106 - 2s - 15ms/step - acc: 0.7824 - auc: 0.8620 - loss: 0.4558 - val_acc: 0.7952 - val_auc: 0.8746 - val_loss: 0.4379\n",
      "Epoch 6461/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7818 - auc: 0.8614 - loss: 0.4558 - val_acc: 0.8004 - val_auc: 0.8755 - val_loss: 0.4367\n",
      "Epoch 6462/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7825 - auc: 0.8617 - loss: 0.4554 - val_acc: 0.7964 - val_auc: 0.8742 - val_loss: 0.4378\n",
      "Epoch 6463/7000\n",
      "106/106 - 2s - 23ms/step - acc: 0.7828 - auc: 0.8626 - loss: 0.4553 - val_acc: 0.7957 - val_auc: 0.8736 - val_loss: 0.4365\n",
      "Epoch 6464/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7815 - auc: 0.8611 - loss: 0.4571 - val_acc: 0.7969 - val_auc: 0.8747 - val_loss: 0.4378\n",
      "Epoch 6465/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7799 - auc: 0.8597 - loss: 0.4584 - val_acc: 0.7962 - val_auc: 0.8747 - val_loss: 0.4383\n",
      "Epoch 6466/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7791 - auc: 0.8603 - loss: 0.4583 - val_acc: 0.7968 - val_auc: 0.8749 - val_loss: 0.4387\n",
      "Epoch 6467/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7808 - auc: 0.8605 - loss: 0.4573 - val_acc: 0.7975 - val_auc: 0.8738 - val_loss: 0.4388\n",
      "Epoch 6468/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7824 - auc: 0.8607 - loss: 0.4572 - val_acc: 0.7989 - val_auc: 0.8746 - val_loss: 0.4376\n",
      "Epoch 6469/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7824 - auc: 0.8616 - loss: 0.4565 - val_acc: 0.7968 - val_auc: 0.8747 - val_loss: 0.4383\n",
      "Epoch 6470/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7804 - auc: 0.8615 - loss: 0.4557 - val_acc: 0.7983 - val_auc: 0.8751 - val_loss: 0.4384\n",
      "Epoch 6471/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7827 - auc: 0.8606 - loss: 0.4571 - val_acc: 0.7980 - val_auc: 0.8753 - val_loss: 0.4362\n",
      "Epoch 6472/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7815 - auc: 0.8610 - loss: 0.4565 - val_acc: 0.7964 - val_auc: 0.8737 - val_loss: 0.4385\n",
      "Epoch 6473/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7814 - auc: 0.8602 - loss: 0.4581 - val_acc: 0.7952 - val_auc: 0.8744 - val_loss: 0.4402\n",
      "Epoch 6474/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7808 - auc: 0.8614 - loss: 0.4554 - val_acc: 0.7948 - val_auc: 0.8731 - val_loss: 0.4394\n",
      "Epoch 6475/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7829 - auc: 0.8616 - loss: 0.4559 - val_acc: 0.7961 - val_auc: 0.8730 - val_loss: 0.4387\n",
      "Epoch 6476/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7815 - auc: 0.8619 - loss: 0.4559 - val_acc: 0.8004 - val_auc: 0.8737 - val_loss: 0.4362\n",
      "Epoch 6477/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7832 - auc: 0.8623 - loss: 0.4561 - val_acc: 0.7976 - val_auc: 0.8739 - val_loss: 0.4371\n",
      "Epoch 6478/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7830 - auc: 0.8608 - loss: 0.4581 - val_acc: 0.7974 - val_auc: 0.8743 - val_loss: 0.4395\n",
      "Epoch 6479/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7819 - auc: 0.8613 - loss: 0.4557 - val_acc: 0.7963 - val_auc: 0.8736 - val_loss: 0.4395\n",
      "Epoch 6480/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7811 - auc: 0.8607 - loss: 0.4567 - val_acc: 0.7986 - val_auc: 0.8749 - val_loss: 0.4359\n",
      "Epoch 6481/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7819 - auc: 0.8612 - loss: 0.4559 - val_acc: 0.7974 - val_auc: 0.8745 - val_loss: 0.4379\n",
      "Epoch 6482/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7807 - auc: 0.8615 - loss: 0.4562 - val_acc: 0.7993 - val_auc: 0.8753 - val_loss: 0.4362\n",
      "Epoch 6483/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7830 - auc: 0.8623 - loss: 0.4550 - val_acc: 0.7985 - val_auc: 0.8742 - val_loss: 0.4366\n",
      "Epoch 6484/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7828 - auc: 0.8621 - loss: 0.4553 - val_acc: 0.7987 - val_auc: 0.8752 - val_loss: 0.4372\n",
      "Epoch 6485/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7850 - auc: 0.8637 - loss: 0.4533 - val_acc: 0.7967 - val_auc: 0.8756 - val_loss: 0.4361\n",
      "Epoch 6486/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7813 - auc: 0.8624 - loss: 0.4545 - val_acc: 0.7974 - val_auc: 0.8746 - val_loss: 0.4367\n",
      "Epoch 6487/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7833 - auc: 0.8615 - loss: 0.4560 - val_acc: 0.7987 - val_auc: 0.8738 - val_loss: 0.4370\n",
      "Epoch 6488/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7830 - auc: 0.8623 - loss: 0.4550 - val_acc: 0.7961 - val_auc: 0.8735 - val_loss: 0.4388\n",
      "Epoch 6489/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7812 - auc: 0.8608 - loss: 0.4570 - val_acc: 0.7986 - val_auc: 0.8751 - val_loss: 0.4373\n",
      "Epoch 6490/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7809 - auc: 0.8609 - loss: 0.4569 - val_acc: 0.7974 - val_auc: 0.8748 - val_loss: 0.4385\n",
      "Epoch 6491/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7798 - auc: 0.8602 - loss: 0.4584 - val_acc: 0.7980 - val_auc: 0.8751 - val_loss: 0.4376\n",
      "Epoch 6492/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7806 - auc: 0.8596 - loss: 0.4585 - val_acc: 0.7983 - val_auc: 0.8753 - val_loss: 0.4387\n",
      "Epoch 6493/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7817 - auc: 0.8609 - loss: 0.4568 - val_acc: 0.7979 - val_auc: 0.8750 - val_loss: 0.4376\n",
      "Epoch 6494/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7812 - auc: 0.8619 - loss: 0.4551 - val_acc: 0.7973 - val_auc: 0.8741 - val_loss: 0.4381\n",
      "Epoch 6495/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7823 - auc: 0.8616 - loss: 0.4556 - val_acc: 0.7989 - val_auc: 0.8740 - val_loss: 0.4387\n",
      "Epoch 6496/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7812 - auc: 0.8608 - loss: 0.4570 - val_acc: 0.7991 - val_auc: 0.8752 - val_loss: 0.4374\n",
      "Epoch 6497/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7823 - auc: 0.8617 - loss: 0.4559 - val_acc: 0.7974 - val_auc: 0.8736 - val_loss: 0.4378\n",
      "Epoch 6498/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7834 - auc: 0.8610 - loss: 0.4566 - val_acc: 0.7972 - val_auc: 0.8742 - val_loss: 0.4381\n",
      "Epoch 6499/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7817 - auc: 0.8612 - loss: 0.4560 - val_acc: 0.7984 - val_auc: 0.8736 - val_loss: 0.4375\n",
      "Epoch 6500/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7811 - auc: 0.8597 - loss: 0.4578 - val_acc: 0.7931 - val_auc: 0.8728 - val_loss: 0.4397\n",
      "Epoch 6501/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7820 - auc: 0.8625 - loss: 0.4555 - val_acc: 0.7985 - val_auc: 0.8754 - val_loss: 0.4367\n",
      "Epoch 6502/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7832 - auc: 0.8599 - loss: 0.4588 - val_acc: 0.7971 - val_auc: 0.8750 - val_loss: 0.4369\n",
      "Epoch 6503/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7844 - auc: 0.8637 - loss: 0.4541 - val_acc: 0.7979 - val_auc: 0.8741 - val_loss: 0.4383\n",
      "Epoch 6504/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7853 - auc: 0.8630 - loss: 0.4538 - val_acc: 0.7988 - val_auc: 0.8747 - val_loss: 0.4371\n",
      "Epoch 6505/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7804 - auc: 0.8597 - loss: 0.4583 - val_acc: 0.7949 - val_auc: 0.8736 - val_loss: 0.4399\n",
      "Epoch 6506/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7839 - auc: 0.8632 - loss: 0.4542 - val_acc: 0.8008 - val_auc: 0.8758 - val_loss: 0.4356\n",
      "Epoch 6507/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7827 - auc: 0.8632 - loss: 0.4536 - val_acc: 0.7959 - val_auc: 0.8734 - val_loss: 0.4385\n",
      "Epoch 6508/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7802 - auc: 0.8606 - loss: 0.4573 - val_acc: 0.7956 - val_auc: 0.8748 - val_loss: 0.4373\n",
      "Epoch 6509/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7804 - auc: 0.8604 - loss: 0.4587 - val_acc: 0.7993 - val_auc: 0.8745 - val_loss: 0.4380\n",
      "Epoch 6510/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7811 - auc: 0.8604 - loss: 0.4580 - val_acc: 0.7975 - val_auc: 0.8745 - val_loss: 0.4387\n",
      "Epoch 6511/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7823 - auc: 0.8628 - loss: 0.4541 - val_acc: 0.7973 - val_auc: 0.8743 - val_loss: 0.4382\n",
      "Epoch 6512/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7835 - auc: 0.8635 - loss: 0.4527 - val_acc: 0.7995 - val_auc: 0.8748 - val_loss: 0.4357\n",
      "Epoch 6513/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7821 - auc: 0.8620 - loss: 0.4557 - val_acc: 0.7995 - val_auc: 0.8744 - val_loss: 0.4387\n",
      "Epoch 6514/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7824 - auc: 0.8619 - loss: 0.4560 - val_acc: 0.7984 - val_auc: 0.8742 - val_loss: 0.4378\n",
      "Epoch 6515/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7807 - auc: 0.8600 - loss: 0.4577 - val_acc: 0.7993 - val_auc: 0.8750 - val_loss: 0.4363\n",
      "Epoch 6516/7000\n",
      "106/106 - 2s - 17ms/step - acc: 0.7819 - auc: 0.8607 - loss: 0.4576 - val_acc: 0.7969 - val_auc: 0.8744 - val_loss: 0.4392\n",
      "Epoch 6517/7000\n",
      "106/106 - 2s - 21ms/step - acc: 0.7823 - auc: 0.8611 - loss: 0.4558 - val_acc: 0.7976 - val_auc: 0.8750 - val_loss: 0.4365\n",
      "Epoch 6518/7000\n",
      "106/106 - 2s - 19ms/step - acc: 0.7819 - auc: 0.8621 - loss: 0.4555 - val_acc: 0.7970 - val_auc: 0.8741 - val_loss: 0.4375\n",
      "Epoch 6519/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7804 - auc: 0.8589 - loss: 0.4597 - val_acc: 0.7993 - val_auc: 0.8753 - val_loss: 0.4376\n",
      "Epoch 6520/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7836 - auc: 0.8619 - loss: 0.4549 - val_acc: 0.7964 - val_auc: 0.8735 - val_loss: 0.4377\n",
      "Epoch 6521/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7829 - auc: 0.8610 - loss: 0.4571 - val_acc: 0.7966 - val_auc: 0.8750 - val_loss: 0.4380\n",
      "Epoch 6522/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7834 - auc: 0.8616 - loss: 0.4560 - val_acc: 0.7989 - val_auc: 0.8751 - val_loss: 0.4360\n",
      "Epoch 6523/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7830 - auc: 0.8616 - loss: 0.4573 - val_acc: 0.7960 - val_auc: 0.8753 - val_loss: 0.4374\n",
      "Epoch 6524/7000\n",
      "106/106 - 2s - 14ms/step - acc: 0.7831 - auc: 0.8620 - loss: 0.4551 - val_acc: 0.8001 - val_auc: 0.8749 - val_loss: 0.4376\n",
      "Epoch 6525/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7807 - auc: 0.8606 - loss: 0.4574 - val_acc: 0.8001 - val_auc: 0.8753 - val_loss: 0.4374\n",
      "Epoch 6526/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7817 - auc: 0.8620 - loss: 0.4556 - val_acc: 0.8000 - val_auc: 0.8746 - val_loss: 0.4363\n",
      "Epoch 6527/7000\n",
      "106/106 - 2s - 16ms/step - acc: 0.7820 - auc: 0.8618 - loss: 0.4561 - val_acc: 0.7974 - val_auc: 0.8753 - val_loss: 0.4367\n",
      "Epoch 6528/7000\n",
      "106/106 - 2s - 16ms/step - acc: 0.7844 - auc: 0.8618 - loss: 0.4554 - val_acc: 0.7989 - val_auc: 0.8750 - val_loss: 0.4360\n",
      "Epoch 6529/7000\n",
      "106/106 - 2s - 15ms/step - acc: 0.7798 - auc: 0.8604 - loss: 0.4584 - val_acc: 0.7961 - val_auc: 0.8732 - val_loss: 0.4395\n",
      "Epoch 6530/7000\n",
      "106/106 - 2s - 15ms/step - acc: 0.7813 - auc: 0.8626 - loss: 0.4548 - val_acc: 0.7982 - val_auc: 0.8752 - val_loss: 0.4379\n",
      "Epoch 6531/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7818 - auc: 0.8621 - loss: 0.4560 - val_acc: 0.7974 - val_auc: 0.8743 - val_loss: 0.4392\n",
      "Epoch 6532/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7824 - auc: 0.8616 - loss: 0.4567 - val_acc: 0.7992 - val_auc: 0.8749 - val_loss: 0.4360\n",
      "Epoch 6533/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7830 - auc: 0.8632 - loss: 0.4533 - val_acc: 0.7974 - val_auc: 0.8743 - val_loss: 0.4377\n",
      "Epoch 6534/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7834 - auc: 0.8619 - loss: 0.4560 - val_acc: 0.7990 - val_auc: 0.8747 - val_loss: 0.4373\n",
      "Epoch 6535/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7831 - auc: 0.8607 - loss: 0.4575 - val_acc: 0.7954 - val_auc: 0.8744 - val_loss: 0.4386\n",
      "Epoch 6536/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7821 - auc: 0.8614 - loss: 0.4564 - val_acc: 0.8001 - val_auc: 0.8750 - val_loss: 0.4371\n",
      "Epoch 6537/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7818 - auc: 0.8608 - loss: 0.4572 - val_acc: 0.7960 - val_auc: 0.8749 - val_loss: 0.4380\n",
      "Epoch 6538/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7811 - auc: 0.8626 - loss: 0.4542 - val_acc: 0.7983 - val_auc: 0.8751 - val_loss: 0.4381\n",
      "Epoch 6539/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7798 - auc: 0.8610 - loss: 0.4571 - val_acc: 0.7974 - val_auc: 0.8736 - val_loss: 0.4368\n",
      "Epoch 6540/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7831 - auc: 0.8623 - loss: 0.4538 - val_acc: 0.7968 - val_auc: 0.8744 - val_loss: 0.4368\n",
      "Epoch 6541/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7857 - auc: 0.8626 - loss: 0.4543 - val_acc: 0.7982 - val_auc: 0.8746 - val_loss: 0.4372\n",
      "Epoch 6542/7000\n",
      "106/106 - 2s - 15ms/step - acc: 0.7800 - auc: 0.8603 - loss: 0.4583 - val_acc: 0.7949 - val_auc: 0.8727 - val_loss: 0.4390\n",
      "Epoch 6543/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7829 - auc: 0.8614 - loss: 0.4565 - val_acc: 0.7965 - val_auc: 0.8742 - val_loss: 0.4393\n",
      "Epoch 6544/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7812 - auc: 0.8615 - loss: 0.4568 - val_acc: 0.7973 - val_auc: 0.8732 - val_loss: 0.4379\n",
      "Epoch 6545/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7831 - auc: 0.8615 - loss: 0.4557 - val_acc: 0.7979 - val_auc: 0.8748 - val_loss: 0.4375\n",
      "Epoch 6546/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7835 - auc: 0.8613 - loss: 0.4557 - val_acc: 0.7967 - val_auc: 0.8752 - val_loss: 0.4393\n",
      "Epoch 6547/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7814 - auc: 0.8608 - loss: 0.4573 - val_acc: 0.7952 - val_auc: 0.8747 - val_loss: 0.4391\n",
      "Epoch 6548/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7805 - auc: 0.8605 - loss: 0.4575 - val_acc: 0.7969 - val_auc: 0.8740 - val_loss: 0.4392\n",
      "Epoch 6549/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7840 - auc: 0.8617 - loss: 0.4559 - val_acc: 0.7968 - val_auc: 0.8743 - val_loss: 0.4394\n",
      "Epoch 6550/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7833 - auc: 0.8609 - loss: 0.4584 - val_acc: 0.7990 - val_auc: 0.8752 - val_loss: 0.4374\n",
      "Epoch 6551/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7811 - auc: 0.8615 - loss: 0.4570 - val_acc: 0.7969 - val_auc: 0.8746 - val_loss: 0.4388\n",
      "Epoch 6552/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7822 - auc: 0.8604 - loss: 0.4577 - val_acc: 0.8001 - val_auc: 0.8752 - val_loss: 0.4363\n",
      "Epoch 6553/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7823 - auc: 0.8613 - loss: 0.4572 - val_acc: 0.7994 - val_auc: 0.8736 - val_loss: 0.4391\n",
      "Epoch 6554/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7836 - auc: 0.8624 - loss: 0.4558 - val_acc: 0.7992 - val_auc: 0.8753 - val_loss: 0.4364\n",
      "Epoch 6555/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7808 - auc: 0.8603 - loss: 0.4579 - val_acc: 0.7948 - val_auc: 0.8724 - val_loss: 0.4391\n",
      "Epoch 6556/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7834 - auc: 0.8626 - loss: 0.4564 - val_acc: 0.7966 - val_auc: 0.8739 - val_loss: 0.4389\n",
      "Epoch 6557/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7826 - auc: 0.8609 - loss: 0.4571 - val_acc: 0.7997 - val_auc: 0.8748 - val_loss: 0.4376\n",
      "Epoch 6558/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7819 - auc: 0.8610 - loss: 0.4563 - val_acc: 0.7970 - val_auc: 0.8747 - val_loss: 0.4380\n",
      "Epoch 6559/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7818 - auc: 0.8614 - loss: 0.4558 - val_acc: 0.7987 - val_auc: 0.8748 - val_loss: 0.4378\n",
      "Epoch 6560/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7819 - auc: 0.8627 - loss: 0.4545 - val_acc: 0.7975 - val_auc: 0.8749 - val_loss: 0.4379\n",
      "Epoch 6561/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7821 - auc: 0.8612 - loss: 0.4573 - val_acc: 0.7981 - val_auc: 0.8739 - val_loss: 0.4366\n",
      "Epoch 6562/7000\n",
      "106/106 - 1s - 14ms/step - acc: 0.7808 - auc: 0.8595 - loss: 0.4591 - val_acc: 0.7977 - val_auc: 0.8744 - val_loss: 0.4383\n",
      "Epoch 6563/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7824 - auc: 0.8625 - loss: 0.4552 - val_acc: 0.7994 - val_auc: 0.8756 - val_loss: 0.4366\n",
      "Epoch 6564/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7852 - auc: 0.8640 - loss: 0.4524 - val_acc: 0.7986 - val_auc: 0.8750 - val_loss: 0.4370\n",
      "Epoch 6565/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7792 - auc: 0.8600 - loss: 0.4586 - val_acc: 0.7975 - val_auc: 0.8740 - val_loss: 0.4385\n",
      "Epoch 6566/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7839 - auc: 0.8627 - loss: 0.4541 - val_acc: 0.7993 - val_auc: 0.8750 - val_loss: 0.4377\n",
      "Epoch 6567/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7807 - auc: 0.8606 - loss: 0.4567 - val_acc: 0.7927 - val_auc: 0.8716 - val_loss: 0.4415\n",
      "Epoch 6568/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7799 - auc: 0.8607 - loss: 0.4571 - val_acc: 0.7943 - val_auc: 0.8736 - val_loss: 0.4391\n",
      "Epoch 6569/7000\n",
      "106/106 - 1s - 13ms/step - acc: 0.7817 - auc: 0.8618 - loss: 0.4553 - val_acc: 0.7951 - val_auc: 0.8736 - val_loss: 0.4398\n",
      "Epoch 6570/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7806 - auc: 0.8601 - loss: 0.4580 - val_acc: 0.7980 - val_auc: 0.8749 - val_loss: 0.4381\n",
      "Epoch 6571/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7817 - auc: 0.8622 - loss: 0.4561 - val_acc: 0.7972 - val_auc: 0.8742 - val_loss: 0.4382\n",
      "Epoch 6572/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7828 - auc: 0.8611 - loss: 0.4573 - val_acc: 0.7993 - val_auc: 0.8754 - val_loss: 0.4363\n",
      "Epoch 6573/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7818 - auc: 0.8608 - loss: 0.4566 - val_acc: 0.7965 - val_auc: 0.8748 - val_loss: 0.4393\n",
      "Epoch 6574/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7796 - auc: 0.8618 - loss: 0.4553 - val_acc: 0.7986 - val_auc: 0.8758 - val_loss: 0.4368\n",
      "Epoch 6575/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7844 - auc: 0.8634 - loss: 0.4536 - val_acc: 0.8009 - val_auc: 0.8753 - val_loss: 0.4347\n",
      "Epoch 6576/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7815 - auc: 0.8615 - loss: 0.4559 - val_acc: 0.7971 - val_auc: 0.8745 - val_loss: 0.4363\n",
      "Epoch 6577/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7826 - auc: 0.8620 - loss: 0.4555 - val_acc: 0.7973 - val_auc: 0.8739 - val_loss: 0.4378\n",
      "Epoch 6578/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7818 - auc: 0.8631 - loss: 0.4539 - val_acc: 0.7972 - val_auc: 0.8737 - val_loss: 0.4388\n",
      "Epoch 6579/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7830 - auc: 0.8614 - loss: 0.4570 - val_acc: 0.7981 - val_auc: 0.8752 - val_loss: 0.4363\n",
      "Epoch 6580/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7815 - auc: 0.8597 - loss: 0.4583 - val_acc: 0.7986 - val_auc: 0.8745 - val_loss: 0.4383\n",
      "Epoch 6581/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7830 - auc: 0.8620 - loss: 0.4564 - val_acc: 0.7982 - val_auc: 0.8752 - val_loss: 0.4370\n",
      "Epoch 6582/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7832 - auc: 0.8613 - loss: 0.4568 - val_acc: 0.7967 - val_auc: 0.8737 - val_loss: 0.4387\n",
      "Epoch 6583/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7815 - auc: 0.8609 - loss: 0.4569 - val_acc: 0.7980 - val_auc: 0.8748 - val_loss: 0.4374\n",
      "Epoch 6584/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7811 - auc: 0.8615 - loss: 0.4554 - val_acc: 0.8008 - val_auc: 0.8751 - val_loss: 0.4357\n",
      "Epoch 6585/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7834 - auc: 0.8619 - loss: 0.4564 - val_acc: 0.7976 - val_auc: 0.8745 - val_loss: 0.4355\n",
      "Epoch 6586/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7807 - auc: 0.8608 - loss: 0.4584 - val_acc: 0.7987 - val_auc: 0.8748 - val_loss: 0.4366\n",
      "Epoch 6587/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7816 - auc: 0.8612 - loss: 0.4565 - val_acc: 0.7993 - val_auc: 0.8742 - val_loss: 0.4381\n",
      "Epoch 6588/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7822 - auc: 0.8611 - loss: 0.4572 - val_acc: 0.7982 - val_auc: 0.8744 - val_loss: 0.4372\n",
      "Epoch 6589/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7810 - auc: 0.8603 - loss: 0.4576 - val_acc: 0.7954 - val_auc: 0.8743 - val_loss: 0.4389\n",
      "Epoch 6590/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7837 - auc: 0.8615 - loss: 0.4555 - val_acc: 0.7962 - val_auc: 0.8745 - val_loss: 0.4384\n",
      "Epoch 6591/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7825 - auc: 0.8632 - loss: 0.4543 - val_acc: 0.7990 - val_auc: 0.8746 - val_loss: 0.4373\n",
      "Epoch 6592/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8612 - loss: 0.4563 - val_acc: 0.7952 - val_auc: 0.8745 - val_loss: 0.4388\n",
      "Epoch 6593/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7802 - auc: 0.8610 - loss: 0.4571 - val_acc: 0.7971 - val_auc: 0.8742 - val_loss: 0.4391\n",
      "Epoch 6594/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7810 - auc: 0.8608 - loss: 0.4566 - val_acc: 0.7980 - val_auc: 0.8737 - val_loss: 0.4390\n",
      "Epoch 6595/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7819 - auc: 0.8610 - loss: 0.4571 - val_acc: 0.7967 - val_auc: 0.8752 - val_loss: 0.4362\n",
      "Epoch 6596/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7818 - auc: 0.8607 - loss: 0.4569 - val_acc: 0.7989 - val_auc: 0.8747 - val_loss: 0.4381\n",
      "Epoch 6597/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7824 - auc: 0.8620 - loss: 0.4552 - val_acc: 0.7963 - val_auc: 0.8744 - val_loss: 0.4385\n",
      "Epoch 6598/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7823 - auc: 0.8626 - loss: 0.4543 - val_acc: 0.7962 - val_auc: 0.8740 - val_loss: 0.4380\n",
      "Epoch 6599/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7837 - auc: 0.8616 - loss: 0.4557 - val_acc: 0.7980 - val_auc: 0.8749 - val_loss: 0.4378\n",
      "Epoch 6600/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7817 - auc: 0.8615 - loss: 0.4559 - val_acc: 0.7985 - val_auc: 0.8753 - val_loss: 0.4372\n",
      "Epoch 6601/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7826 - auc: 0.8617 - loss: 0.4565 - val_acc: 0.7968 - val_auc: 0.8744 - val_loss: 0.4382\n",
      "Epoch 6602/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7823 - auc: 0.8622 - loss: 0.4556 - val_acc: 0.7964 - val_auc: 0.8741 - val_loss: 0.4391\n",
      "Epoch 6603/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7818 - auc: 0.8606 - loss: 0.4585 - val_acc: 0.7998 - val_auc: 0.8754 - val_loss: 0.4358\n",
      "Epoch 6604/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7797 - auc: 0.8598 - loss: 0.4587 - val_acc: 0.8001 - val_auc: 0.8765 - val_loss: 0.4362\n",
      "Epoch 6605/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7823 - auc: 0.8628 - loss: 0.4543 - val_acc: 0.8013 - val_auc: 0.8752 - val_loss: 0.4365\n",
      "Epoch 6606/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7827 - auc: 0.8636 - loss: 0.4528 - val_acc: 0.8003 - val_auc: 0.8744 - val_loss: 0.4364\n",
      "Epoch 6607/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7809 - auc: 0.8610 - loss: 0.4571 - val_acc: 0.8001 - val_auc: 0.8735 - val_loss: 0.4372\n",
      "Epoch 6608/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7802 - auc: 0.8605 - loss: 0.4574 - val_acc: 0.7997 - val_auc: 0.8753 - val_loss: 0.4373\n",
      "Epoch 6609/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7813 - auc: 0.8616 - loss: 0.4564 - val_acc: 0.7999 - val_auc: 0.8745 - val_loss: 0.4369\n",
      "Epoch 6610/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7829 - auc: 0.8616 - loss: 0.4556 - val_acc: 0.7999 - val_auc: 0.8753 - val_loss: 0.4361\n",
      "Epoch 6611/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7807 - auc: 0.8605 - loss: 0.4570 - val_acc: 0.7976 - val_auc: 0.8752 - val_loss: 0.4379\n",
      "Epoch 6612/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7796 - auc: 0.8619 - loss: 0.4551 - val_acc: 0.7973 - val_auc: 0.8746 - val_loss: 0.4369\n",
      "Epoch 6613/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7828 - auc: 0.8619 - loss: 0.4565 - val_acc: 0.7960 - val_auc: 0.8745 - val_loss: 0.4376\n",
      "Epoch 6614/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7821 - auc: 0.8623 - loss: 0.4553 - val_acc: 0.7984 - val_auc: 0.8741 - val_loss: 0.4373\n",
      "Epoch 6615/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7823 - auc: 0.8620 - loss: 0.4545 - val_acc: 0.7961 - val_auc: 0.8742 - val_loss: 0.4391\n",
      "Epoch 6616/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7829 - auc: 0.8618 - loss: 0.4560 - val_acc: 0.7976 - val_auc: 0.8746 - val_loss: 0.4364\n",
      "Epoch 6617/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7815 - auc: 0.8613 - loss: 0.4561 - val_acc: 0.8009 - val_auc: 0.8758 - val_loss: 0.4369\n",
      "Epoch 6618/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7816 - auc: 0.8615 - loss: 0.4563 - val_acc: 0.8004 - val_auc: 0.8755 - val_loss: 0.4360\n",
      "Epoch 6619/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7825 - auc: 0.8636 - loss: 0.4539 - val_acc: 0.7991 - val_auc: 0.8754 - val_loss: 0.4360\n",
      "Epoch 6620/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7810 - auc: 0.8603 - loss: 0.4572 - val_acc: 0.7962 - val_auc: 0.8745 - val_loss: 0.4363\n",
      "Epoch 6621/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7848 - auc: 0.8635 - loss: 0.4546 - val_acc: 0.7994 - val_auc: 0.8758 - val_loss: 0.4352\n",
      "Epoch 6622/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8611 - loss: 0.4562 - val_acc: 0.7973 - val_auc: 0.8753 - val_loss: 0.4365\n",
      "Epoch 6623/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7800 - auc: 0.8601 - loss: 0.4590 - val_acc: 0.8022 - val_auc: 0.8766 - val_loss: 0.4359\n",
      "Epoch 6624/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7840 - auc: 0.8634 - loss: 0.4532 - val_acc: 0.7958 - val_auc: 0.8742 - val_loss: 0.4381\n",
      "Epoch 6625/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7814 - auc: 0.8611 - loss: 0.4561 - val_acc: 0.7999 - val_auc: 0.8752 - val_loss: 0.4354\n",
      "Epoch 6626/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7802 - auc: 0.8609 - loss: 0.4572 - val_acc: 0.7975 - val_auc: 0.8749 - val_loss: 0.4376\n",
      "Epoch 6627/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7828 - auc: 0.8617 - loss: 0.4561 - val_acc: 0.7992 - val_auc: 0.8752 - val_loss: 0.4370\n",
      "Epoch 6628/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7827 - auc: 0.8614 - loss: 0.4567 - val_acc: 0.7967 - val_auc: 0.8748 - val_loss: 0.4374\n",
      "Epoch 6629/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7829 - auc: 0.8622 - loss: 0.4549 - val_acc: 0.7955 - val_auc: 0.8747 - val_loss: 0.4383\n",
      "Epoch 6630/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7835 - auc: 0.8620 - loss: 0.4554 - val_acc: 0.7978 - val_auc: 0.8738 - val_loss: 0.4380\n",
      "Epoch 6631/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7864 - auc: 0.8642 - loss: 0.4523 - val_acc: 0.7980 - val_auc: 0.8750 - val_loss: 0.4357\n",
      "Epoch 6632/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7807 - auc: 0.8615 - loss: 0.4561 - val_acc: 0.7957 - val_auc: 0.8749 - val_loss: 0.4365\n",
      "Epoch 6633/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7819 - auc: 0.8628 - loss: 0.4541 - val_acc: 0.7989 - val_auc: 0.8757 - val_loss: 0.4356\n",
      "Epoch 6634/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7830 - auc: 0.8620 - loss: 0.4559 - val_acc: 0.7996 - val_auc: 0.8752 - val_loss: 0.4360\n",
      "Epoch 6635/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7812 - auc: 0.8612 - loss: 0.4566 - val_acc: 0.8008 - val_auc: 0.8756 - val_loss: 0.4365\n",
      "Epoch 6636/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7820 - auc: 0.8623 - loss: 0.4558 - val_acc: 0.7977 - val_auc: 0.8737 - val_loss: 0.4382\n",
      "Epoch 6637/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7823 - auc: 0.8622 - loss: 0.4552 - val_acc: 0.7968 - val_auc: 0.8755 - val_loss: 0.4348\n",
      "Epoch 6638/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7803 - auc: 0.8593 - loss: 0.4592 - val_acc: 0.8007 - val_auc: 0.8732 - val_loss: 0.4389\n",
      "Epoch 6639/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7835 - auc: 0.8618 - loss: 0.4561 - val_acc: 0.7967 - val_auc: 0.8736 - val_loss: 0.4373\n",
      "Epoch 6640/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7834 - auc: 0.8614 - loss: 0.4555 - val_acc: 0.7985 - val_auc: 0.8742 - val_loss: 0.4364\n",
      "Epoch 6641/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7832 - auc: 0.8611 - loss: 0.4565 - val_acc: 0.8004 - val_auc: 0.8759 - val_loss: 0.4353\n",
      "Epoch 6642/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7834 - auc: 0.8622 - loss: 0.4551 - val_acc: 0.7983 - val_auc: 0.8747 - val_loss: 0.4374\n",
      "Epoch 6643/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8607 - loss: 0.4568 - val_acc: 0.7967 - val_auc: 0.8752 - val_loss: 0.4371\n",
      "Epoch 6644/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7822 - auc: 0.8603 - loss: 0.4579 - val_acc: 0.7983 - val_auc: 0.8754 - val_loss: 0.4353\n",
      "Epoch 6645/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7832 - auc: 0.8614 - loss: 0.4554 - val_acc: 0.7975 - val_auc: 0.8754 - val_loss: 0.4379\n",
      "Epoch 6646/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7808 - auc: 0.8597 - loss: 0.4587 - val_acc: 0.7962 - val_auc: 0.8739 - val_loss: 0.4381\n",
      "Epoch 6647/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7802 - auc: 0.8609 - loss: 0.4570 - val_acc: 0.7994 - val_auc: 0.8744 - val_loss: 0.4371\n",
      "Epoch 6648/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7822 - auc: 0.8626 - loss: 0.4546 - val_acc: 0.7977 - val_auc: 0.8744 - val_loss: 0.4374\n",
      "Epoch 6649/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7841 - auc: 0.8633 - loss: 0.4541 - val_acc: 0.7995 - val_auc: 0.8748 - val_loss: 0.4364\n",
      "Epoch 6650/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7814 - auc: 0.8622 - loss: 0.4560 - val_acc: 0.7978 - val_auc: 0.8751 - val_loss: 0.4370\n",
      "Epoch 6651/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7789 - auc: 0.8597 - loss: 0.4587 - val_acc: 0.7979 - val_auc: 0.8742 - val_loss: 0.4373\n",
      "Epoch 6652/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7812 - auc: 0.8623 - loss: 0.4548 - val_acc: 0.7954 - val_auc: 0.8742 - val_loss: 0.4375\n",
      "Epoch 6653/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7819 - auc: 0.8609 - loss: 0.4575 - val_acc: 0.7979 - val_auc: 0.8751 - val_loss: 0.4369\n",
      "Epoch 6654/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7820 - auc: 0.8617 - loss: 0.4551 - val_acc: 0.7947 - val_auc: 0.8744 - val_loss: 0.4396\n",
      "Epoch 6655/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7825 - auc: 0.8611 - loss: 0.4573 - val_acc: 0.7950 - val_auc: 0.8737 - val_loss: 0.4394\n",
      "Epoch 6656/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7833 - auc: 0.8619 - loss: 0.4554 - val_acc: 0.7965 - val_auc: 0.8735 - val_loss: 0.4383\n",
      "Epoch 6657/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7829 - auc: 0.8628 - loss: 0.4544 - val_acc: 0.7988 - val_auc: 0.8753 - val_loss: 0.4355\n",
      "Epoch 6658/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7826 - auc: 0.8617 - loss: 0.4570 - val_acc: 0.7987 - val_auc: 0.8751 - val_loss: 0.4371\n",
      "Epoch 6659/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7828 - auc: 0.8607 - loss: 0.4569 - val_acc: 0.7985 - val_auc: 0.8755 - val_loss: 0.4355\n",
      "Epoch 6660/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7811 - auc: 0.8609 - loss: 0.4568 - val_acc: 0.7997 - val_auc: 0.8756 - val_loss: 0.4389\n",
      "Epoch 6661/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7839 - auc: 0.8631 - loss: 0.4544 - val_acc: 0.7973 - val_auc: 0.8741 - val_loss: 0.4379\n",
      "Epoch 6662/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7824 - auc: 0.8621 - loss: 0.4544 - val_acc: 0.7960 - val_auc: 0.8742 - val_loss: 0.4374\n",
      "Epoch 6663/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7843 - auc: 0.8618 - loss: 0.4562 - val_acc: 0.7974 - val_auc: 0.8743 - val_loss: 0.4367\n",
      "Epoch 6664/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7810 - auc: 0.8609 - loss: 0.4573 - val_acc: 0.7982 - val_auc: 0.8751 - val_loss: 0.4378\n",
      "Epoch 6665/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7825 - auc: 0.8620 - loss: 0.4554 - val_acc: 0.7968 - val_auc: 0.8743 - val_loss: 0.4377\n",
      "Epoch 6666/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7828 - auc: 0.8628 - loss: 0.4548 - val_acc: 0.7988 - val_auc: 0.8745 - val_loss: 0.4367\n",
      "Epoch 6667/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7812 - auc: 0.8626 - loss: 0.4544 - val_acc: 0.7957 - val_auc: 0.8734 - val_loss: 0.4370\n",
      "Epoch 6668/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7837 - auc: 0.8620 - loss: 0.4562 - val_acc: 0.7992 - val_auc: 0.8750 - val_loss: 0.4363\n",
      "Epoch 6669/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7831 - auc: 0.8604 - loss: 0.4567 - val_acc: 0.7973 - val_auc: 0.8743 - val_loss: 0.4373\n",
      "Epoch 6670/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7806 - auc: 0.8599 - loss: 0.4578 - val_acc: 0.7989 - val_auc: 0.8747 - val_loss: 0.4366\n",
      "Epoch 6671/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7830 - auc: 0.8618 - loss: 0.4558 - val_acc: 0.7972 - val_auc: 0.8737 - val_loss: 0.4381\n",
      "Epoch 6672/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7837 - auc: 0.8629 - loss: 0.4534 - val_acc: 0.7979 - val_auc: 0.8749 - val_loss: 0.4372\n",
      "Epoch 6673/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7825 - auc: 0.8621 - loss: 0.4548 - val_acc: 0.7985 - val_auc: 0.8743 - val_loss: 0.4371\n",
      "Epoch 6674/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7817 - auc: 0.8617 - loss: 0.4568 - val_acc: 0.7990 - val_auc: 0.8757 - val_loss: 0.4366\n",
      "Epoch 6675/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7827 - auc: 0.8615 - loss: 0.4563 - val_acc: 0.7964 - val_auc: 0.8745 - val_loss: 0.4372\n",
      "Epoch 6676/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7810 - auc: 0.8614 - loss: 0.4570 - val_acc: 0.7976 - val_auc: 0.8749 - val_loss: 0.4374\n",
      "Epoch 6677/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7814 - auc: 0.8620 - loss: 0.4559 - val_acc: 0.7989 - val_auc: 0.8749 - val_loss: 0.4372\n",
      "Epoch 6678/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7818 - auc: 0.8612 - loss: 0.4572 - val_acc: 0.7997 - val_auc: 0.8751 - val_loss: 0.4375\n",
      "Epoch 6679/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7812 - auc: 0.8622 - loss: 0.4546 - val_acc: 0.7984 - val_auc: 0.8752 - val_loss: 0.4364\n",
      "Epoch 6680/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7830 - auc: 0.8624 - loss: 0.4555 - val_acc: 0.8011 - val_auc: 0.8753 - val_loss: 0.4360\n",
      "Epoch 6681/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7817 - auc: 0.8610 - loss: 0.4564 - val_acc: 0.7996 - val_auc: 0.8748 - val_loss: 0.4375\n",
      "Epoch 6682/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7832 - auc: 0.8610 - loss: 0.4567 - val_acc: 0.8000 - val_auc: 0.8755 - val_loss: 0.4359\n",
      "Epoch 6683/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7844 - auc: 0.8625 - loss: 0.4553 - val_acc: 0.8007 - val_auc: 0.8754 - val_loss: 0.4357\n",
      "Epoch 6684/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7812 - auc: 0.8610 - loss: 0.4570 - val_acc: 0.7966 - val_auc: 0.8739 - val_loss: 0.4388\n",
      "Epoch 6685/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7809 - auc: 0.8605 - loss: 0.4574 - val_acc: 0.8008 - val_auc: 0.8742 - val_loss: 0.4379\n",
      "Epoch 6686/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7826 - auc: 0.8620 - loss: 0.4555 - val_acc: 0.7975 - val_auc: 0.8747 - val_loss: 0.4385\n",
      "Epoch 6687/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7826 - auc: 0.8613 - loss: 0.4569 - val_acc: 0.7996 - val_auc: 0.8752 - val_loss: 0.4366\n",
      "Epoch 6688/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7807 - auc: 0.8615 - loss: 0.4560 - val_acc: 0.7978 - val_auc: 0.8743 - val_loss: 0.4368\n",
      "Epoch 6689/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7848 - auc: 0.8625 - loss: 0.4555 - val_acc: 0.7978 - val_auc: 0.8756 - val_loss: 0.4370\n",
      "Epoch 6690/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7831 - auc: 0.8621 - loss: 0.4546 - val_acc: 0.7972 - val_auc: 0.8749 - val_loss: 0.4383\n",
      "Epoch 6691/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7827 - auc: 0.8614 - loss: 0.4567 - val_acc: 0.7991 - val_auc: 0.8753 - val_loss: 0.4383\n",
      "Epoch 6692/7000\n",
      "106/106 - 2s - 14ms/step - acc: 0.7834 - auc: 0.8633 - loss: 0.4530 - val_acc: 0.8008 - val_auc: 0.8764 - val_loss: 0.4346\n",
      "Epoch 6693/7000\n",
      "106/106 - 2s - 15ms/step - acc: 0.7804 - auc: 0.8611 - loss: 0.4568 - val_acc: 0.7986 - val_auc: 0.8758 - val_loss: 0.4362\n",
      "Epoch 6694/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7837 - auc: 0.8629 - loss: 0.4536 - val_acc: 0.7986 - val_auc: 0.8756 - val_loss: 0.4360\n",
      "Epoch 6695/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7826 - auc: 0.8613 - loss: 0.4565 - val_acc: 0.7987 - val_auc: 0.8752 - val_loss: 0.4377\n",
      "Epoch 6696/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7821 - auc: 0.8629 - loss: 0.4543 - val_acc: 0.7984 - val_auc: 0.8753 - val_loss: 0.4366\n",
      "Epoch 6697/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7832 - auc: 0.8616 - loss: 0.4560 - val_acc: 0.7957 - val_auc: 0.8752 - val_loss: 0.4386\n",
      "Epoch 6698/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7831 - auc: 0.8633 - loss: 0.4541 - val_acc: 0.7977 - val_auc: 0.8756 - val_loss: 0.4364\n",
      "Epoch 6699/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7837 - auc: 0.8620 - loss: 0.4557 - val_acc: 0.7996 - val_auc: 0.8760 - val_loss: 0.4364\n",
      "Epoch 6700/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7813 - auc: 0.8621 - loss: 0.4543 - val_acc: 0.8001 - val_auc: 0.8760 - val_loss: 0.4343\n",
      "Epoch 6701/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7828 - auc: 0.8625 - loss: 0.4534 - val_acc: 0.7991 - val_auc: 0.8761 - val_loss: 0.4365\n",
      "Epoch 6702/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7829 - auc: 0.8619 - loss: 0.4554 - val_acc: 0.7973 - val_auc: 0.8749 - val_loss: 0.4372\n",
      "Epoch 6703/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7836 - auc: 0.8634 - loss: 0.4539 - val_acc: 0.7974 - val_auc: 0.8741 - val_loss: 0.4369\n",
      "Epoch 6704/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7813 - auc: 0.8611 - loss: 0.4573 - val_acc: 0.7971 - val_auc: 0.8743 - val_loss: 0.4382\n",
      "Epoch 6705/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7829 - auc: 0.8616 - loss: 0.4570 - val_acc: 0.8001 - val_auc: 0.8753 - val_loss: 0.4373\n",
      "Epoch 6706/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7829 - auc: 0.8625 - loss: 0.4538 - val_acc: 0.7954 - val_auc: 0.8735 - val_loss: 0.4403\n",
      "Epoch 6707/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7832 - auc: 0.8632 - loss: 0.4530 - val_acc: 0.7967 - val_auc: 0.8757 - val_loss: 0.4361\n",
      "Epoch 6708/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7838 - auc: 0.8629 - loss: 0.4544 - val_acc: 0.7955 - val_auc: 0.8752 - val_loss: 0.4366\n",
      "Epoch 6709/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7818 - auc: 0.8619 - loss: 0.4556 - val_acc: 0.7983 - val_auc: 0.8760 - val_loss: 0.4357\n",
      "Epoch 6710/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7834 - auc: 0.8621 - loss: 0.4551 - val_acc: 0.7980 - val_auc: 0.8749 - val_loss: 0.4363\n",
      "Epoch 6711/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7812 - auc: 0.8607 - loss: 0.4565 - val_acc: 0.7978 - val_auc: 0.8746 - val_loss: 0.4370\n",
      "Epoch 6712/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7836 - auc: 0.8636 - loss: 0.4524 - val_acc: 0.7969 - val_auc: 0.8738 - val_loss: 0.4373\n",
      "Epoch 6713/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7834 - auc: 0.8623 - loss: 0.4553 - val_acc: 0.7982 - val_auc: 0.8756 - val_loss: 0.4362\n",
      "Epoch 6714/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7825 - auc: 0.8629 - loss: 0.4530 - val_acc: 0.7985 - val_auc: 0.8753 - val_loss: 0.4344\n",
      "Epoch 6715/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7855 - auc: 0.8648 - loss: 0.4511 - val_acc: 0.7985 - val_auc: 0.8756 - val_loss: 0.4359\n",
      "Epoch 6716/7000\n",
      "106/106 - 1s - 11ms/step - acc: 0.7819 - auc: 0.8610 - loss: 0.4564 - val_acc: 0.7964 - val_auc: 0.8746 - val_loss: 0.4374\n",
      "Epoch 6717/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7833 - auc: 0.8623 - loss: 0.4548 - val_acc: 0.7978 - val_auc: 0.8759 - val_loss: 0.4360\n",
      "Epoch 6718/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7827 - auc: 0.8622 - loss: 0.4546 - val_acc: 0.7976 - val_auc: 0.8752 - val_loss: 0.4377\n",
      "Epoch 6719/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7833 - auc: 0.8630 - loss: 0.4547 - val_acc: 0.7987 - val_auc: 0.8760 - val_loss: 0.4351\n",
      "Epoch 6720/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7816 - auc: 0.8613 - loss: 0.4571 - val_acc: 0.7961 - val_auc: 0.8744 - val_loss: 0.4397\n",
      "Epoch 6721/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7818 - auc: 0.8611 - loss: 0.4574 - val_acc: 0.7976 - val_auc: 0.8756 - val_loss: 0.4377\n",
      "Epoch 6722/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7824 - auc: 0.8621 - loss: 0.4550 - val_acc: 0.7992 - val_auc: 0.8760 - val_loss: 0.4361\n",
      "Epoch 6723/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7813 - auc: 0.8618 - loss: 0.4551 - val_acc: 0.8006 - val_auc: 0.8765 - val_loss: 0.4357\n",
      "Epoch 6724/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7839 - auc: 0.8645 - loss: 0.4511 - val_acc: 0.7972 - val_auc: 0.8739 - val_loss: 0.4367\n",
      "Epoch 6725/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7822 - auc: 0.8617 - loss: 0.4555 - val_acc: 0.7965 - val_auc: 0.8752 - val_loss: 0.4355\n",
      "Epoch 6726/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7831 - auc: 0.8623 - loss: 0.4552 - val_acc: 0.7963 - val_auc: 0.8751 - val_loss: 0.4368\n",
      "Epoch 6727/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7832 - auc: 0.8616 - loss: 0.4568 - val_acc: 0.7988 - val_auc: 0.8757 - val_loss: 0.4362\n",
      "Epoch 6728/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7849 - auc: 0.8632 - loss: 0.4539 - val_acc: 0.7977 - val_auc: 0.8748 - val_loss: 0.4357\n",
      "Epoch 6729/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7820 - auc: 0.8603 - loss: 0.4583 - val_acc: 0.7961 - val_auc: 0.8745 - val_loss: 0.4375\n",
      "Epoch 6730/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7817 - auc: 0.8615 - loss: 0.4563 - val_acc: 0.7992 - val_auc: 0.8759 - val_loss: 0.4361\n",
      "Epoch 6731/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7820 - auc: 0.8621 - loss: 0.4554 - val_acc: 0.7964 - val_auc: 0.8749 - val_loss: 0.4373\n",
      "Epoch 6732/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7821 - auc: 0.8616 - loss: 0.4560 - val_acc: 0.7978 - val_auc: 0.8743 - val_loss: 0.4373\n",
      "Epoch 6733/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7835 - auc: 0.8629 - loss: 0.4562 - val_acc: 0.7980 - val_auc: 0.8753 - val_loss: 0.4365\n",
      "Epoch 6734/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7833 - auc: 0.8617 - loss: 0.4557 - val_acc: 0.7941 - val_auc: 0.8739 - val_loss: 0.4398\n",
      "Epoch 6735/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7836 - auc: 0.8626 - loss: 0.4544 - val_acc: 0.7937 - val_auc: 0.8740 - val_loss: 0.4402\n",
      "Epoch 6736/7000\n",
      "106/106 - 1s - 6ms/step - acc: 0.7838 - auc: 0.8634 - loss: 0.4536 - val_acc: 0.7990 - val_auc: 0.8747 - val_loss: 0.4364\n",
      "Epoch 6737/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7831 - auc: 0.8633 - loss: 0.4543 - val_acc: 0.7948 - val_auc: 0.8750 - val_loss: 0.4392\n",
      "Epoch 6738/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7842 - auc: 0.8635 - loss: 0.4542 - val_acc: 0.7958 - val_auc: 0.8739 - val_loss: 0.4382\n",
      "Epoch 6739/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7846 - auc: 0.8631 - loss: 0.4539 - val_acc: 0.7998 - val_auc: 0.8740 - val_loss: 0.4371\n",
      "Epoch 6740/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7828 - auc: 0.8620 - loss: 0.4552 - val_acc: 0.8011 - val_auc: 0.8757 - val_loss: 0.4357\n",
      "Epoch 6741/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7830 - auc: 0.8630 - loss: 0.4535 - val_acc: 0.7995 - val_auc: 0.8748 - val_loss: 0.4377\n",
      "Epoch 6742/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7838 - auc: 0.8643 - loss: 0.4527 - val_acc: 0.7973 - val_auc: 0.8744 - val_loss: 0.4374\n",
      "Epoch 6743/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7821 - auc: 0.8611 - loss: 0.4570 - val_acc: 0.7988 - val_auc: 0.8746 - val_loss: 0.4364\n",
      "Epoch 6744/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7840 - auc: 0.8634 - loss: 0.4533 - val_acc: 0.7987 - val_auc: 0.8735 - val_loss: 0.4374\n",
      "Epoch 6745/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7817 - auc: 0.8618 - loss: 0.4558 - val_acc: 0.8009 - val_auc: 0.8746 - val_loss: 0.4368\n",
      "Epoch 6746/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7830 - auc: 0.8629 - loss: 0.4531 - val_acc: 0.7990 - val_auc: 0.8737 - val_loss: 0.4388\n",
      "Epoch 6747/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7827 - auc: 0.8631 - loss: 0.4532 - val_acc: 0.8012 - val_auc: 0.8757 - val_loss: 0.4359\n",
      "Epoch 6748/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7817 - auc: 0.8617 - loss: 0.4553 - val_acc: 0.7979 - val_auc: 0.8744 - val_loss: 0.4366\n",
      "Epoch 6749/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7821 - auc: 0.8622 - loss: 0.4546 - val_acc: 0.7989 - val_auc: 0.8743 - val_loss: 0.4372\n",
      "Epoch 6750/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7824 - auc: 0.8617 - loss: 0.4559 - val_acc: 0.8025 - val_auc: 0.8759 - val_loss: 0.4353\n",
      "Epoch 6751/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7829 - auc: 0.8622 - loss: 0.4549 - val_acc: 0.7979 - val_auc: 0.8745 - val_loss: 0.4382\n",
      "Epoch 6752/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7806 - auc: 0.8609 - loss: 0.4563 - val_acc: 0.7983 - val_auc: 0.8754 - val_loss: 0.4354\n",
      "Epoch 6753/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7847 - auc: 0.8634 - loss: 0.4531 - val_acc: 0.7977 - val_auc: 0.8750 - val_loss: 0.4360\n",
      "Epoch 6754/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7804 - auc: 0.8610 - loss: 0.4574 - val_acc: 0.7971 - val_auc: 0.8734 - val_loss: 0.4391\n",
      "Epoch 6755/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7811 - auc: 0.8618 - loss: 0.4562 - val_acc: 0.7985 - val_auc: 0.8750 - val_loss: 0.4364\n",
      "Epoch 6756/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7842 - auc: 0.8619 - loss: 0.4555 - val_acc: 0.7984 - val_auc: 0.8754 - val_loss: 0.4382\n",
      "Epoch 6757/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7832 - auc: 0.8636 - loss: 0.4538 - val_acc: 0.8000 - val_auc: 0.8752 - val_loss: 0.4351\n",
      "Epoch 6758/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7809 - auc: 0.8618 - loss: 0.4557 - val_acc: 0.7989 - val_auc: 0.8753 - val_loss: 0.4365\n",
      "Epoch 6759/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7809 - auc: 0.8611 - loss: 0.4571 - val_acc: 0.7984 - val_auc: 0.8750 - val_loss: 0.4359\n",
      "Epoch 6760/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7808 - auc: 0.8601 - loss: 0.4585 - val_acc: 0.7987 - val_auc: 0.8754 - val_loss: 0.4371\n",
      "Epoch 6761/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7804 - auc: 0.8605 - loss: 0.4576 - val_acc: 0.7949 - val_auc: 0.8738 - val_loss: 0.4410\n",
      "Epoch 6762/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7825 - auc: 0.8614 - loss: 0.4560 - val_acc: 0.7959 - val_auc: 0.8744 - val_loss: 0.4392\n",
      "Epoch 6763/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7823 - auc: 0.8634 - loss: 0.4526 - val_acc: 0.7986 - val_auc: 0.8746 - val_loss: 0.4377\n",
      "Epoch 6764/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7834 - auc: 0.8624 - loss: 0.4544 - val_acc: 0.7990 - val_auc: 0.8749 - val_loss: 0.4362\n",
      "Epoch 6765/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7810 - auc: 0.8611 - loss: 0.4561 - val_acc: 0.7989 - val_auc: 0.8749 - val_loss: 0.4377\n",
      "Epoch 6766/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7825 - auc: 0.8617 - loss: 0.4560 - val_acc: 0.7985 - val_auc: 0.8755 - val_loss: 0.4382\n",
      "Epoch 6767/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7823 - auc: 0.8622 - loss: 0.4549 - val_acc: 0.8008 - val_auc: 0.8753 - val_loss: 0.4382\n",
      "Epoch 6768/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7839 - auc: 0.8621 - loss: 0.4557 - val_acc: 0.7990 - val_auc: 0.8750 - val_loss: 0.4376\n",
      "Epoch 6769/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7827 - auc: 0.8620 - loss: 0.4548 - val_acc: 0.8001 - val_auc: 0.8748 - val_loss: 0.4371\n",
      "Epoch 6770/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7829 - auc: 0.8620 - loss: 0.4562 - val_acc: 0.7989 - val_auc: 0.8753 - val_loss: 0.4367\n",
      "Epoch 6771/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7833 - auc: 0.8630 - loss: 0.4537 - val_acc: 0.8009 - val_auc: 0.8751 - val_loss: 0.4352\n",
      "Epoch 6772/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7827 - auc: 0.8631 - loss: 0.4531 - val_acc: 0.7976 - val_auc: 0.8747 - val_loss: 0.4375\n",
      "Epoch 6773/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7823 - auc: 0.8608 - loss: 0.4569 - val_acc: 0.8012 - val_auc: 0.8766 - val_loss: 0.4362\n",
      "Epoch 6774/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7824 - auc: 0.8618 - loss: 0.4560 - val_acc: 0.7999 - val_auc: 0.8748 - val_loss: 0.4380\n",
      "Epoch 6775/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7814 - auc: 0.8595 - loss: 0.4591 - val_acc: 0.7982 - val_auc: 0.8747 - val_loss: 0.4383\n",
      "Epoch 6776/7000\n",
      "106/106 - 1s - 10ms/step - acc: 0.7841 - auc: 0.8632 - loss: 0.4537 - val_acc: 0.7960 - val_auc: 0.8741 - val_loss: 0.4367\n",
      "Epoch 6777/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7811 - auc: 0.8613 - loss: 0.4561 - val_acc: 0.7973 - val_auc: 0.8736 - val_loss: 0.4382\n",
      "Epoch 6778/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7824 - auc: 0.8619 - loss: 0.4556 - val_acc: 0.7980 - val_auc: 0.8737 - val_loss: 0.4379\n",
      "Epoch 6779/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7807 - auc: 0.8623 - loss: 0.4564 - val_acc: 0.7965 - val_auc: 0.8736 - val_loss: 0.4363\n",
      "Epoch 6780/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7826 - auc: 0.8623 - loss: 0.4557 - val_acc: 0.7999 - val_auc: 0.8751 - val_loss: 0.4364\n",
      "Epoch 6781/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7842 - auc: 0.8621 - loss: 0.4550 - val_acc: 0.7988 - val_auc: 0.8751 - val_loss: 0.4357\n",
      "Epoch 6782/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7830 - auc: 0.8624 - loss: 0.4551 - val_acc: 0.7990 - val_auc: 0.8757 - val_loss: 0.4360\n",
      "Epoch 6783/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7839 - auc: 0.8625 - loss: 0.4543 - val_acc: 0.7989 - val_auc: 0.8749 - val_loss: 0.4380\n",
      "Epoch 6784/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7809 - auc: 0.8609 - loss: 0.4575 - val_acc: 0.7972 - val_auc: 0.8741 - val_loss: 0.4380\n",
      "Epoch 6785/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7830 - auc: 0.8617 - loss: 0.4568 - val_acc: 0.7998 - val_auc: 0.8762 - val_loss: 0.4373\n",
      "Epoch 6786/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7830 - auc: 0.8628 - loss: 0.4546 - val_acc: 0.7975 - val_auc: 0.8745 - val_loss: 0.4381\n",
      "Epoch 6787/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7840 - auc: 0.8620 - loss: 0.4556 - val_acc: 0.7986 - val_auc: 0.8747 - val_loss: 0.4375\n",
      "Epoch 6788/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7814 - auc: 0.8608 - loss: 0.4575 - val_acc: 0.7999 - val_auc: 0.8745 - val_loss: 0.4366\n",
      "Epoch 6789/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7809 - auc: 0.8597 - loss: 0.4582 - val_acc: 0.7981 - val_auc: 0.8735 - val_loss: 0.4380\n",
      "Epoch 6790/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7844 - auc: 0.8629 - loss: 0.4553 - val_acc: 0.7990 - val_auc: 0.8739 - val_loss: 0.4383\n",
      "Epoch 6791/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7826 - auc: 0.8614 - loss: 0.4563 - val_acc: 0.7993 - val_auc: 0.8757 - val_loss: 0.4358\n",
      "Epoch 6792/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7830 - auc: 0.8631 - loss: 0.4535 - val_acc: 0.7983 - val_auc: 0.8739 - val_loss: 0.4369\n",
      "Epoch 6793/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7823 - auc: 0.8616 - loss: 0.4561 - val_acc: 0.7970 - val_auc: 0.8744 - val_loss: 0.4366\n",
      "Epoch 6794/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7846 - auc: 0.8626 - loss: 0.4545 - val_acc: 0.7995 - val_auc: 0.8749 - val_loss: 0.4353\n",
      "Epoch 6795/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7837 - auc: 0.8626 - loss: 0.4543 - val_acc: 0.7986 - val_auc: 0.8753 - val_loss: 0.4353\n",
      "Epoch 6796/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7829 - auc: 0.8617 - loss: 0.4564 - val_acc: 0.7980 - val_auc: 0.8743 - val_loss: 0.4377\n",
      "Epoch 6797/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7830 - auc: 0.8621 - loss: 0.4555 - val_acc: 0.7975 - val_auc: 0.8742 - val_loss: 0.4382\n",
      "Epoch 6798/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7824 - auc: 0.8613 - loss: 0.4567 - val_acc: 0.7953 - val_auc: 0.8750 - val_loss: 0.4375\n",
      "Epoch 6799/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7833 - auc: 0.8621 - loss: 0.4553 - val_acc: 0.7966 - val_auc: 0.8738 - val_loss: 0.4373\n",
      "Epoch 6800/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7824 - auc: 0.8608 - loss: 0.4570 - val_acc: 0.7997 - val_auc: 0.8751 - val_loss: 0.4373\n",
      "Epoch 6801/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7849 - auc: 0.8641 - loss: 0.4529 - val_acc: 0.7991 - val_auc: 0.8747 - val_loss: 0.4368\n",
      "Epoch 6802/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7821 - auc: 0.8613 - loss: 0.4569 - val_acc: 0.7998 - val_auc: 0.8747 - val_loss: 0.4371\n",
      "Epoch 6803/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7818 - auc: 0.8612 - loss: 0.4555 - val_acc: 0.7987 - val_auc: 0.8748 - val_loss: 0.4361\n",
      "Epoch 6804/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7833 - auc: 0.8624 - loss: 0.4545 - val_acc: 0.7981 - val_auc: 0.8751 - val_loss: 0.4381\n",
      "Epoch 6805/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7824 - auc: 0.8624 - loss: 0.4551 - val_acc: 0.7992 - val_auc: 0.8759 - val_loss: 0.4364\n",
      "Epoch 6806/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7827 - auc: 0.8628 - loss: 0.4546 - val_acc: 0.7995 - val_auc: 0.8750 - val_loss: 0.4364\n",
      "Epoch 6807/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7833 - auc: 0.8618 - loss: 0.4551 - val_acc: 0.7977 - val_auc: 0.8746 - val_loss: 0.4376\n",
      "Epoch 6808/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7819 - auc: 0.8625 - loss: 0.4548 - val_acc: 0.8005 - val_auc: 0.8759 - val_loss: 0.4358\n",
      "Epoch 6809/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7842 - auc: 0.8618 - loss: 0.4568 - val_acc: 0.7985 - val_auc: 0.8756 - val_loss: 0.4379\n",
      "Epoch 6810/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7843 - auc: 0.8636 - loss: 0.4542 - val_acc: 0.8005 - val_auc: 0.8765 - val_loss: 0.4343\n",
      "Epoch 6811/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7829 - auc: 0.8620 - loss: 0.4551 - val_acc: 0.7979 - val_auc: 0.8756 - val_loss: 0.4378\n",
      "Epoch 6812/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7828 - auc: 0.8622 - loss: 0.4548 - val_acc: 0.7978 - val_auc: 0.8748 - val_loss: 0.4367\n",
      "Epoch 6813/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7847 - auc: 0.8628 - loss: 0.4536 - val_acc: 0.7963 - val_auc: 0.8754 - val_loss: 0.4365\n",
      "Epoch 6814/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7823 - auc: 0.8612 - loss: 0.4566 - val_acc: 0.7987 - val_auc: 0.8753 - val_loss: 0.4368\n",
      "Epoch 6815/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7818 - auc: 0.8619 - loss: 0.4560 - val_acc: 0.7979 - val_auc: 0.8744 - val_loss: 0.4375\n",
      "Epoch 6816/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7832 - auc: 0.8625 - loss: 0.4537 - val_acc: 0.7999 - val_auc: 0.8765 - val_loss: 0.4349\n",
      "Epoch 6817/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7832 - auc: 0.8615 - loss: 0.4562 - val_acc: 0.7985 - val_auc: 0.8752 - val_loss: 0.4375\n",
      "Epoch 6818/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7843 - auc: 0.8634 - loss: 0.4529 - val_acc: 0.8002 - val_auc: 0.8752 - val_loss: 0.4368\n",
      "Epoch 6819/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7819 - auc: 0.8620 - loss: 0.4552 - val_acc: 0.8003 - val_auc: 0.8757 - val_loss: 0.4363\n",
      "Epoch 6820/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7822 - auc: 0.8619 - loss: 0.4564 - val_acc: 0.7982 - val_auc: 0.8762 - val_loss: 0.4376\n",
      "Epoch 6821/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7850 - auc: 0.8634 - loss: 0.4538 - val_acc: 0.7983 - val_auc: 0.8744 - val_loss: 0.4378\n",
      "Epoch 6822/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7825 - auc: 0.8620 - loss: 0.4558 - val_acc: 0.7995 - val_auc: 0.8752 - val_loss: 0.4380\n",
      "Epoch 6823/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7848 - auc: 0.8625 - loss: 0.4552 - val_acc: 0.7989 - val_auc: 0.8752 - val_loss: 0.4371\n",
      "Epoch 6824/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7813 - auc: 0.8606 - loss: 0.4567 - val_acc: 0.7985 - val_auc: 0.8745 - val_loss: 0.4379\n",
      "Epoch 6825/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7829 - auc: 0.8620 - loss: 0.4556 - val_acc: 0.7989 - val_auc: 0.8750 - val_loss: 0.4364\n",
      "Epoch 6826/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7828 - auc: 0.8611 - loss: 0.4575 - val_acc: 0.7987 - val_auc: 0.8751 - val_loss: 0.4362\n",
      "Epoch 6827/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7833 - auc: 0.8624 - loss: 0.4553 - val_acc: 0.8001 - val_auc: 0.8742 - val_loss: 0.4365\n",
      "Epoch 6828/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7800 - auc: 0.8618 - loss: 0.4556 - val_acc: 0.7973 - val_auc: 0.8750 - val_loss: 0.4372\n",
      "Epoch 6829/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7839 - auc: 0.8631 - loss: 0.4544 - val_acc: 0.7982 - val_auc: 0.8743 - val_loss: 0.4374\n",
      "Epoch 6830/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7835 - auc: 0.8618 - loss: 0.4554 - val_acc: 0.8003 - val_auc: 0.8748 - val_loss: 0.4365\n",
      "Epoch 6831/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7856 - auc: 0.8623 - loss: 0.4552 - val_acc: 0.7967 - val_auc: 0.8743 - val_loss: 0.4392\n",
      "Epoch 6832/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7811 - auc: 0.8617 - loss: 0.4564 - val_acc: 0.7982 - val_auc: 0.8743 - val_loss: 0.4377\n",
      "Epoch 6833/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7818 - auc: 0.8606 - loss: 0.4570 - val_acc: 0.7976 - val_auc: 0.8753 - val_loss: 0.4362\n",
      "Epoch 6834/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7824 - auc: 0.8609 - loss: 0.4579 - val_acc: 0.7990 - val_auc: 0.8746 - val_loss: 0.4385\n",
      "Epoch 6835/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7831 - auc: 0.8624 - loss: 0.4551 - val_acc: 0.7974 - val_auc: 0.8754 - val_loss: 0.4369\n",
      "Epoch 6836/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7834 - auc: 0.8636 - loss: 0.4530 - val_acc: 0.7976 - val_auc: 0.8739 - val_loss: 0.4380\n",
      "Epoch 6837/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7828 - auc: 0.8624 - loss: 0.4546 - val_acc: 0.7972 - val_auc: 0.8746 - val_loss: 0.4369\n",
      "Epoch 6838/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7852 - auc: 0.8632 - loss: 0.4531 - val_acc: 0.7977 - val_auc: 0.8744 - val_loss: 0.4369\n",
      "Epoch 6839/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7818 - auc: 0.8609 - loss: 0.4563 - val_acc: 0.7972 - val_auc: 0.8746 - val_loss: 0.4377\n",
      "Epoch 6840/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7816 - auc: 0.8602 - loss: 0.4573 - val_acc: 0.7978 - val_auc: 0.8750 - val_loss: 0.4384\n",
      "Epoch 6841/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7828 - auc: 0.8632 - loss: 0.4532 - val_acc: 0.7966 - val_auc: 0.8743 - val_loss: 0.4382\n",
      "Epoch 6842/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7827 - auc: 0.8622 - loss: 0.4543 - val_acc: 0.8001 - val_auc: 0.8746 - val_loss: 0.4356\n",
      "Epoch 6843/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7839 - auc: 0.8628 - loss: 0.4542 - val_acc: 0.8009 - val_auc: 0.8760 - val_loss: 0.4374\n",
      "Epoch 6844/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7827 - auc: 0.8630 - loss: 0.4552 - val_acc: 0.8010 - val_auc: 0.8764 - val_loss: 0.4347\n",
      "Epoch 6845/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7826 - auc: 0.8617 - loss: 0.4554 - val_acc: 0.7987 - val_auc: 0.8744 - val_loss: 0.4368\n",
      "Epoch 6846/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7835 - auc: 0.8627 - loss: 0.4551 - val_acc: 0.7998 - val_auc: 0.8750 - val_loss: 0.4359\n",
      "Epoch 6847/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7829 - auc: 0.8619 - loss: 0.4561 - val_acc: 0.7964 - val_auc: 0.8746 - val_loss: 0.4377\n",
      "Epoch 6848/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7826 - auc: 0.8617 - loss: 0.4556 - val_acc: 0.8014 - val_auc: 0.8757 - val_loss: 0.4359\n",
      "Epoch 6849/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7847 - auc: 0.8636 - loss: 0.4532 - val_acc: 0.7980 - val_auc: 0.8740 - val_loss: 0.4387\n",
      "Epoch 6850/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7802 - auc: 0.8597 - loss: 0.4586 - val_acc: 0.7974 - val_auc: 0.8741 - val_loss: 0.4384\n",
      "Epoch 6851/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7817 - auc: 0.8610 - loss: 0.4573 - val_acc: 0.8000 - val_auc: 0.8748 - val_loss: 0.4357\n",
      "Epoch 6852/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7833 - auc: 0.8633 - loss: 0.4531 - val_acc: 0.7976 - val_auc: 0.8735 - val_loss: 0.4382\n",
      "Epoch 6853/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7829 - auc: 0.8621 - loss: 0.4550 - val_acc: 0.7975 - val_auc: 0.8741 - val_loss: 0.4385\n",
      "Epoch 6854/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7824 - auc: 0.8614 - loss: 0.4568 - val_acc: 0.8003 - val_auc: 0.8753 - val_loss: 0.4360\n",
      "Epoch 6855/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7827 - auc: 0.8604 - loss: 0.4582 - val_acc: 0.7950 - val_auc: 0.8729 - val_loss: 0.4416\n",
      "Epoch 6856/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7810 - auc: 0.8607 - loss: 0.4581 - val_acc: 0.7963 - val_auc: 0.8741 - val_loss: 0.4397\n",
      "Epoch 6857/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7832 - auc: 0.8621 - loss: 0.4550 - val_acc: 0.7973 - val_auc: 0.8727 - val_loss: 0.4382\n",
      "Epoch 6858/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7840 - auc: 0.8631 - loss: 0.4544 - val_acc: 0.7998 - val_auc: 0.8763 - val_loss: 0.4368\n",
      "Epoch 6859/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7855 - auc: 0.8631 - loss: 0.4534 - val_acc: 0.8014 - val_auc: 0.8761 - val_loss: 0.4352\n",
      "Epoch 6860/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7809 - auc: 0.8615 - loss: 0.4561 - val_acc: 0.7969 - val_auc: 0.8741 - val_loss: 0.4367\n",
      "Epoch 6861/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7799 - auc: 0.8601 - loss: 0.4577 - val_acc: 0.7966 - val_auc: 0.8750 - val_loss: 0.4384\n",
      "Epoch 6862/7000\n",
      "106/106 - 1s - 12ms/step - acc: 0.7827 - auc: 0.8617 - loss: 0.4568 - val_acc: 0.7984 - val_auc: 0.8736 - val_loss: 0.4387\n",
      "Epoch 6863/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7819 - auc: 0.8619 - loss: 0.4566 - val_acc: 0.8000 - val_auc: 0.8753 - val_loss: 0.4376\n",
      "Epoch 6864/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7823 - auc: 0.8601 - loss: 0.4584 - val_acc: 0.7962 - val_auc: 0.8739 - val_loss: 0.4408\n",
      "Epoch 6865/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7846 - auc: 0.8629 - loss: 0.4526 - val_acc: 0.7983 - val_auc: 0.8744 - val_loss: 0.4373\n",
      "Epoch 6866/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7818 - auc: 0.8610 - loss: 0.4553 - val_acc: 0.7995 - val_auc: 0.8753 - val_loss: 0.4365\n",
      "Epoch 6867/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7829 - auc: 0.8633 - loss: 0.4535 - val_acc: 0.7968 - val_auc: 0.8740 - val_loss: 0.4395\n",
      "Epoch 6868/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7827 - auc: 0.8612 - loss: 0.4563 - val_acc: 0.7964 - val_auc: 0.8758 - val_loss: 0.4374\n",
      "Epoch 6869/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7839 - auc: 0.8617 - loss: 0.4550 - val_acc: 0.7985 - val_auc: 0.8749 - val_loss: 0.4368\n",
      "Epoch 6870/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7817 - auc: 0.8609 - loss: 0.4562 - val_acc: 0.7982 - val_auc: 0.8750 - val_loss: 0.4368\n",
      "Epoch 6871/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7842 - auc: 0.8619 - loss: 0.4542 - val_acc: 0.7992 - val_auc: 0.8752 - val_loss: 0.4359\n",
      "Epoch 6872/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7824 - auc: 0.8626 - loss: 0.4538 - val_acc: 0.8009 - val_auc: 0.8749 - val_loss: 0.4352\n",
      "Epoch 6873/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7828 - auc: 0.8613 - loss: 0.4561 - val_acc: 0.7989 - val_auc: 0.8750 - val_loss: 0.4358\n",
      "Epoch 6874/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7825 - auc: 0.8619 - loss: 0.4558 - val_acc: 0.7968 - val_auc: 0.8753 - val_loss: 0.4387\n",
      "Epoch 6875/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7828 - auc: 0.8627 - loss: 0.4543 - val_acc: 0.8010 - val_auc: 0.8765 - val_loss: 0.4353\n",
      "Epoch 6876/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7839 - auc: 0.8636 - loss: 0.4537 - val_acc: 0.7991 - val_auc: 0.8750 - val_loss: 0.4366\n",
      "Epoch 6877/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7839 - auc: 0.8628 - loss: 0.4532 - val_acc: 0.7976 - val_auc: 0.8756 - val_loss: 0.4372\n",
      "Epoch 6878/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7849 - auc: 0.8624 - loss: 0.4548 - val_acc: 0.8002 - val_auc: 0.8750 - val_loss: 0.4376\n",
      "Epoch 6879/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7832 - auc: 0.8636 - loss: 0.4531 - val_acc: 0.7987 - val_auc: 0.8751 - val_loss: 0.4355\n",
      "Epoch 6880/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7806 - auc: 0.8609 - loss: 0.4569 - val_acc: 0.7972 - val_auc: 0.8737 - val_loss: 0.4382\n",
      "Epoch 6881/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7831 - auc: 0.8622 - loss: 0.4544 - val_acc: 0.8005 - val_auc: 0.8746 - val_loss: 0.4356\n",
      "Epoch 6882/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7820 - auc: 0.8617 - loss: 0.4566 - val_acc: 0.7976 - val_auc: 0.8755 - val_loss: 0.4381\n",
      "Epoch 6883/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7838 - auc: 0.8618 - loss: 0.4552 - val_acc: 0.8002 - val_auc: 0.8750 - val_loss: 0.4348\n",
      "Epoch 6884/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7824 - auc: 0.8607 - loss: 0.4575 - val_acc: 0.8004 - val_auc: 0.8761 - val_loss: 0.4358\n",
      "Epoch 6885/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7819 - auc: 0.8622 - loss: 0.4558 - val_acc: 0.7984 - val_auc: 0.8758 - val_loss: 0.4371\n",
      "Epoch 6886/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7838 - auc: 0.8631 - loss: 0.4543 - val_acc: 0.7968 - val_auc: 0.8748 - val_loss: 0.4388\n",
      "Epoch 6887/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7822 - auc: 0.8620 - loss: 0.4551 - val_acc: 0.7993 - val_auc: 0.8752 - val_loss: 0.4357\n",
      "Epoch 6888/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7827 - auc: 0.8624 - loss: 0.4545 - val_acc: 0.7976 - val_auc: 0.8739 - val_loss: 0.4366\n",
      "Epoch 6889/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7830 - auc: 0.8634 - loss: 0.4536 - val_acc: 0.7969 - val_auc: 0.8752 - val_loss: 0.4375\n",
      "Epoch 6890/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7807 - auc: 0.8614 - loss: 0.4568 - val_acc: 0.7990 - val_auc: 0.8759 - val_loss: 0.4366\n",
      "Epoch 6891/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7835 - auc: 0.8625 - loss: 0.4550 - val_acc: 0.7989 - val_auc: 0.8761 - val_loss: 0.4372\n",
      "Epoch 6892/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7824 - auc: 0.8615 - loss: 0.4560 - val_acc: 0.7986 - val_auc: 0.8738 - val_loss: 0.4377\n",
      "Epoch 6893/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7834 - auc: 0.8631 - loss: 0.4542 - val_acc: 0.7986 - val_auc: 0.8745 - val_loss: 0.4362\n",
      "Epoch 6894/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7822 - auc: 0.8622 - loss: 0.4553 - val_acc: 0.8005 - val_auc: 0.8757 - val_loss: 0.4355\n",
      "Epoch 6895/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7838 - auc: 0.8625 - loss: 0.4546 - val_acc: 0.7988 - val_auc: 0.8748 - val_loss: 0.4380\n",
      "Epoch 6896/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7840 - auc: 0.8640 - loss: 0.4532 - val_acc: 0.7967 - val_auc: 0.8748 - val_loss: 0.4390\n",
      "Epoch 6897/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7797 - auc: 0.8608 - loss: 0.4574 - val_acc: 0.7982 - val_auc: 0.8751 - val_loss: 0.4368\n",
      "Epoch 6898/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7816 - auc: 0.8615 - loss: 0.4556 - val_acc: 0.8002 - val_auc: 0.8752 - val_loss: 0.4376\n",
      "Epoch 6899/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7838 - auc: 0.8631 - loss: 0.4544 - val_acc: 0.8000 - val_auc: 0.8752 - val_loss: 0.4366\n",
      "Epoch 6900/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7834 - auc: 0.8623 - loss: 0.4552 - val_acc: 0.8004 - val_auc: 0.8750 - val_loss: 0.4359\n",
      "Epoch 6901/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7845 - auc: 0.8626 - loss: 0.4543 - val_acc: 0.7986 - val_auc: 0.8755 - val_loss: 0.4372\n",
      "Epoch 6902/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7828 - auc: 0.8631 - loss: 0.4539 - val_acc: 0.8014 - val_auc: 0.8759 - val_loss: 0.4366\n",
      "Epoch 6903/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7839 - auc: 0.8631 - loss: 0.4536 - val_acc: 0.7979 - val_auc: 0.8750 - val_loss: 0.4378\n",
      "Epoch 6904/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7830 - auc: 0.8629 - loss: 0.4539 - val_acc: 0.7988 - val_auc: 0.8744 - val_loss: 0.4374\n",
      "Epoch 6905/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7815 - auc: 0.8594 - loss: 0.4593 - val_acc: 0.7986 - val_auc: 0.8744 - val_loss: 0.4382\n",
      "Epoch 6906/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7831 - auc: 0.8617 - loss: 0.4549 - val_acc: 0.7980 - val_auc: 0.8740 - val_loss: 0.4392\n",
      "Epoch 6907/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7834 - auc: 0.8627 - loss: 0.4547 - val_acc: 0.8015 - val_auc: 0.8755 - val_loss: 0.4361\n",
      "Epoch 6908/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7823 - auc: 0.8623 - loss: 0.4547 - val_acc: 0.7988 - val_auc: 0.8742 - val_loss: 0.4380\n",
      "Epoch 6909/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7839 - auc: 0.8626 - loss: 0.4555 - val_acc: 0.7996 - val_auc: 0.8751 - val_loss: 0.4367\n",
      "Epoch 6910/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7823 - auc: 0.8625 - loss: 0.4548 - val_acc: 0.8021 - val_auc: 0.8749 - val_loss: 0.4362\n",
      "Epoch 6911/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7841 - auc: 0.8636 - loss: 0.4534 - val_acc: 0.7996 - val_auc: 0.8758 - val_loss: 0.4353\n",
      "Epoch 6912/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7846 - auc: 0.8633 - loss: 0.4527 - val_acc: 0.7995 - val_auc: 0.8753 - val_loss: 0.4347\n",
      "Epoch 6913/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7818 - auc: 0.8621 - loss: 0.4557 - val_acc: 0.7964 - val_auc: 0.8753 - val_loss: 0.4376\n",
      "Epoch 6914/7000\n",
      "106/106 - 1s - 9ms/step - acc: 0.7828 - auc: 0.8615 - loss: 0.4571 - val_acc: 0.8001 - val_auc: 0.8759 - val_loss: 0.4362\n",
      "Epoch 6915/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7816 - auc: 0.8616 - loss: 0.4562 - val_acc: 0.8002 - val_auc: 0.8749 - val_loss: 0.4375\n",
      "Epoch 6916/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7831 - auc: 0.8630 - loss: 0.4539 - val_acc: 0.7974 - val_auc: 0.8737 - val_loss: 0.4387\n",
      "Epoch 6917/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7820 - auc: 0.8608 - loss: 0.4572 - val_acc: 0.8003 - val_auc: 0.8750 - val_loss: 0.4365\n",
      "Epoch 6918/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7846 - auc: 0.8638 - loss: 0.4540 - val_acc: 0.8010 - val_auc: 0.8755 - val_loss: 0.4347\n",
      "Epoch 6919/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7837 - auc: 0.8622 - loss: 0.4547 - val_acc: 0.8010 - val_auc: 0.8753 - val_loss: 0.4361\n",
      "Epoch 6920/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7822 - auc: 0.8629 - loss: 0.4538 - val_acc: 0.8001 - val_auc: 0.8758 - val_loss: 0.4353\n",
      "Epoch 6921/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7805 - auc: 0.8609 - loss: 0.4575 - val_acc: 0.7967 - val_auc: 0.8744 - val_loss: 0.4381\n",
      "Epoch 6922/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7819 - auc: 0.8622 - loss: 0.4548 - val_acc: 0.8001 - val_auc: 0.8759 - val_loss: 0.4350\n",
      "Epoch 6923/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7839 - auc: 0.8636 - loss: 0.4529 - val_acc: 0.8015 - val_auc: 0.8769 - val_loss: 0.4351\n",
      "Epoch 6924/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7841 - auc: 0.8624 - loss: 0.4554 - val_acc: 0.7985 - val_auc: 0.8757 - val_loss: 0.4366\n",
      "Epoch 6925/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7842 - auc: 0.8635 - loss: 0.4532 - val_acc: 0.7968 - val_auc: 0.8739 - val_loss: 0.4381\n",
      "Epoch 6926/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7802 - auc: 0.8618 - loss: 0.4554 - val_acc: 0.7998 - val_auc: 0.8766 - val_loss: 0.4349\n",
      "Epoch 6927/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7816 - auc: 0.8613 - loss: 0.4574 - val_acc: 0.7983 - val_auc: 0.8756 - val_loss: 0.4372\n",
      "Epoch 6928/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7825 - auc: 0.8616 - loss: 0.4565 - val_acc: 0.8011 - val_auc: 0.8755 - val_loss: 0.4352\n",
      "Epoch 6929/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7805 - auc: 0.8600 - loss: 0.4578 - val_acc: 0.8008 - val_auc: 0.8768 - val_loss: 0.4357\n",
      "Epoch 6930/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7824 - auc: 0.8621 - loss: 0.4558 - val_acc: 0.7989 - val_auc: 0.8762 - val_loss: 0.4357\n",
      "Epoch 6931/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7812 - auc: 0.8615 - loss: 0.4568 - val_acc: 0.7979 - val_auc: 0.8756 - val_loss: 0.4376\n",
      "Epoch 6932/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7817 - auc: 0.8631 - loss: 0.4549 - val_acc: 0.8010 - val_auc: 0.8758 - val_loss: 0.4360\n",
      "Epoch 6933/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7826 - auc: 0.8604 - loss: 0.4579 - val_acc: 0.7991 - val_auc: 0.8755 - val_loss: 0.4370\n",
      "Epoch 6934/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7831 - auc: 0.8615 - loss: 0.4551 - val_acc: 0.8016 - val_auc: 0.8753 - val_loss: 0.4359\n",
      "Epoch 6935/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7834 - auc: 0.8623 - loss: 0.4546 - val_acc: 0.7979 - val_auc: 0.8745 - val_loss: 0.4368\n",
      "Epoch 6936/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7852 - auc: 0.8641 - loss: 0.4514 - val_acc: 0.7993 - val_auc: 0.8754 - val_loss: 0.4363\n",
      "Epoch 6937/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7842 - auc: 0.8636 - loss: 0.4532 - val_acc: 0.7980 - val_auc: 0.8761 - val_loss: 0.4367\n",
      "Epoch 6938/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7829 - auc: 0.8623 - loss: 0.4544 - val_acc: 0.7987 - val_auc: 0.8751 - val_loss: 0.4356\n",
      "Epoch 6939/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7825 - auc: 0.8628 - loss: 0.4534 - val_acc: 0.7956 - val_auc: 0.8743 - val_loss: 0.4360\n",
      "Epoch 6940/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7831 - auc: 0.8632 - loss: 0.4543 - val_acc: 0.8007 - val_auc: 0.8740 - val_loss: 0.4364\n",
      "Epoch 6941/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7822 - auc: 0.8610 - loss: 0.4564 - val_acc: 0.7976 - val_auc: 0.8743 - val_loss: 0.4378\n",
      "Epoch 6942/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7838 - auc: 0.8629 - loss: 0.4537 - val_acc: 0.8011 - val_auc: 0.8746 - val_loss: 0.4349\n",
      "Epoch 6943/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7839 - auc: 0.8631 - loss: 0.4543 - val_acc: 0.7979 - val_auc: 0.8743 - val_loss: 0.4379\n",
      "Epoch 6944/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7825 - auc: 0.8631 - loss: 0.4545 - val_acc: 0.7996 - val_auc: 0.8758 - val_loss: 0.4359\n",
      "Epoch 6945/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7820 - auc: 0.8613 - loss: 0.4560 - val_acc: 0.8001 - val_auc: 0.8748 - val_loss: 0.4375\n",
      "Epoch 6946/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7830 - auc: 0.8637 - loss: 0.4525 - val_acc: 0.7990 - val_auc: 0.8751 - val_loss: 0.4356\n",
      "Epoch 6947/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7830 - auc: 0.8630 - loss: 0.4529 - val_acc: 0.8031 - val_auc: 0.8769 - val_loss: 0.4344\n",
      "Epoch 6948/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7827 - auc: 0.8613 - loss: 0.4558 - val_acc: 0.7989 - val_auc: 0.8760 - val_loss: 0.4356\n",
      "Epoch 6949/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7822 - auc: 0.8615 - loss: 0.4573 - val_acc: 0.7986 - val_auc: 0.8745 - val_loss: 0.4390\n",
      "Epoch 6950/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7812 - auc: 0.8622 - loss: 0.4554 - val_acc: 0.8001 - val_auc: 0.8754 - val_loss: 0.4367\n",
      "Epoch 6951/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7815 - auc: 0.8605 - loss: 0.4567 - val_acc: 0.8000 - val_auc: 0.8755 - val_loss: 0.4365\n",
      "Epoch 6952/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7827 - auc: 0.8617 - loss: 0.4554 - val_acc: 0.8010 - val_auc: 0.8763 - val_loss: 0.4352\n",
      "Epoch 6953/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7834 - auc: 0.8642 - loss: 0.4536 - val_acc: 0.7999 - val_auc: 0.8763 - val_loss: 0.4358\n",
      "Epoch 6954/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7838 - auc: 0.8631 - loss: 0.4531 - val_acc: 0.8015 - val_auc: 0.8758 - val_loss: 0.4347\n",
      "Epoch 6955/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7828 - auc: 0.8633 - loss: 0.4532 - val_acc: 0.7983 - val_auc: 0.8752 - val_loss: 0.4349\n",
      "Epoch 6956/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7818 - auc: 0.8621 - loss: 0.4552 - val_acc: 0.7983 - val_auc: 0.8758 - val_loss: 0.4364\n",
      "Epoch 6957/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7839 - auc: 0.8631 - loss: 0.4525 - val_acc: 0.7974 - val_auc: 0.8753 - val_loss: 0.4357\n",
      "Epoch 6958/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7833 - auc: 0.8623 - loss: 0.4545 - val_acc: 0.8011 - val_auc: 0.8751 - val_loss: 0.4366\n",
      "Epoch 6959/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7844 - auc: 0.8635 - loss: 0.4533 - val_acc: 0.7979 - val_auc: 0.8747 - val_loss: 0.4375\n",
      "Epoch 6960/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7815 - auc: 0.8614 - loss: 0.4563 - val_acc: 0.8000 - val_auc: 0.8753 - val_loss: 0.4358\n",
      "Epoch 6961/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7813 - auc: 0.8610 - loss: 0.4572 - val_acc: 0.7982 - val_auc: 0.8742 - val_loss: 0.4392\n",
      "Epoch 6962/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7807 - auc: 0.8605 - loss: 0.4575 - val_acc: 0.7979 - val_auc: 0.8749 - val_loss: 0.4378\n",
      "Epoch 6963/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7837 - auc: 0.8632 - loss: 0.4537 - val_acc: 0.7993 - val_auc: 0.8749 - val_loss: 0.4362\n",
      "Epoch 6964/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7835 - auc: 0.8629 - loss: 0.4550 - val_acc: 0.7970 - val_auc: 0.8741 - val_loss: 0.4385\n",
      "Epoch 6965/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7845 - auc: 0.8627 - loss: 0.4542 - val_acc: 0.7990 - val_auc: 0.8747 - val_loss: 0.4368\n",
      "Epoch 6966/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7817 - auc: 0.8620 - loss: 0.4560 - val_acc: 0.7976 - val_auc: 0.8754 - val_loss: 0.4374\n",
      "Epoch 6967/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7812 - auc: 0.8622 - loss: 0.4558 - val_acc: 0.7983 - val_auc: 0.8746 - val_loss: 0.4380\n",
      "Epoch 6968/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7834 - auc: 0.8627 - loss: 0.4537 - val_acc: 0.7971 - val_auc: 0.8743 - val_loss: 0.4363\n",
      "Epoch 6969/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7839 - auc: 0.8638 - loss: 0.4535 - val_acc: 0.7997 - val_auc: 0.8756 - val_loss: 0.4366\n",
      "Epoch 6970/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7836 - auc: 0.8620 - loss: 0.4540 - val_acc: 0.8036 - val_auc: 0.8771 - val_loss: 0.4344\n",
      "Epoch 6971/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7843 - auc: 0.8636 - loss: 0.4531 - val_acc: 0.7989 - val_auc: 0.8748 - val_loss: 0.4364\n",
      "Epoch 6972/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7813 - auc: 0.8615 - loss: 0.4557 - val_acc: 0.8014 - val_auc: 0.8746 - val_loss: 0.4370\n",
      "Epoch 6973/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7841 - auc: 0.8633 - loss: 0.4537 - val_acc: 0.7998 - val_auc: 0.8752 - val_loss: 0.4360\n",
      "Epoch 6974/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7831 - auc: 0.8628 - loss: 0.4549 - val_acc: 0.7996 - val_auc: 0.8739 - val_loss: 0.4368\n",
      "Epoch 6975/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7840 - auc: 0.8626 - loss: 0.4540 - val_acc: 0.7989 - val_auc: 0.8758 - val_loss: 0.4362\n",
      "Epoch 6976/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7841 - auc: 0.8619 - loss: 0.4562 - val_acc: 0.7977 - val_auc: 0.8751 - val_loss: 0.4368\n",
      "Epoch 6977/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7844 - auc: 0.8629 - loss: 0.4544 - val_acc: 0.8001 - val_auc: 0.8752 - val_loss: 0.4360\n",
      "Epoch 6978/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7847 - auc: 0.8631 - loss: 0.4534 - val_acc: 0.7973 - val_auc: 0.8743 - val_loss: 0.4370\n",
      "Epoch 6979/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7833 - auc: 0.8606 - loss: 0.4578 - val_acc: 0.7958 - val_auc: 0.8740 - val_loss: 0.4379\n",
      "Epoch 6980/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7831 - auc: 0.8610 - loss: 0.4566 - val_acc: 0.7989 - val_auc: 0.8751 - val_loss: 0.4365\n",
      "Epoch 6981/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7841 - auc: 0.8632 - loss: 0.4537 - val_acc: 0.7982 - val_auc: 0.8764 - val_loss: 0.4358\n",
      "Epoch 6982/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7849 - auc: 0.8635 - loss: 0.4531 - val_acc: 0.7987 - val_auc: 0.8749 - val_loss: 0.4363\n",
      "Epoch 6983/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7819 - auc: 0.8627 - loss: 0.4541 - val_acc: 0.7991 - val_auc: 0.8749 - val_loss: 0.4380\n",
      "Epoch 6984/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7826 - auc: 0.8607 - loss: 0.4572 - val_acc: 0.7966 - val_auc: 0.8754 - val_loss: 0.4377\n",
      "Epoch 6985/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7854 - auc: 0.8639 - loss: 0.4531 - val_acc: 0.8012 - val_auc: 0.8757 - val_loss: 0.4344\n",
      "Epoch 6986/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7843 - auc: 0.8623 - loss: 0.4559 - val_acc: 0.8005 - val_auc: 0.8757 - val_loss: 0.4347\n",
      "Epoch 6987/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7840 - auc: 0.8622 - loss: 0.4552 - val_acc: 0.8013 - val_auc: 0.8760 - val_loss: 0.4347\n",
      "Epoch 6988/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7851 - auc: 0.8644 - loss: 0.4519 - val_acc: 0.8011 - val_auc: 0.8766 - val_loss: 0.4352\n",
      "Epoch 6989/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7810 - auc: 0.8615 - loss: 0.4562 - val_acc: 0.7991 - val_auc: 0.8755 - val_loss: 0.4344\n",
      "Epoch 6990/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7843 - auc: 0.8632 - loss: 0.4542 - val_acc: 0.7991 - val_auc: 0.8746 - val_loss: 0.4377\n",
      "Epoch 6991/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7838 - auc: 0.8628 - loss: 0.4538 - val_acc: 0.7994 - val_auc: 0.8738 - val_loss: 0.4365\n",
      "Epoch 6992/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7846 - auc: 0.8647 - loss: 0.4503 - val_acc: 0.8030 - val_auc: 0.8765 - val_loss: 0.4330\n",
      "Epoch 6993/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7836 - auc: 0.8637 - loss: 0.4535 - val_acc: 0.8009 - val_auc: 0.8770 - val_loss: 0.4351\n",
      "Epoch 6994/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7836 - auc: 0.8620 - loss: 0.4547 - val_acc: 0.7974 - val_auc: 0.8757 - val_loss: 0.4363\n",
      "Epoch 6995/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7820 - auc: 0.8622 - loss: 0.4548 - val_acc: 0.8002 - val_auc: 0.8763 - val_loss: 0.4344\n",
      "Epoch 6996/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7820 - auc: 0.8618 - loss: 0.4551 - val_acc: 0.8010 - val_auc: 0.8747 - val_loss: 0.4377\n",
      "Epoch 6997/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7821 - auc: 0.8610 - loss: 0.4561 - val_acc: 0.7991 - val_auc: 0.8750 - val_loss: 0.4368\n",
      "Epoch 6998/7000\n",
      "106/106 - 1s - 8ms/step - acc: 0.7824 - auc: 0.8632 - loss: 0.4531 - val_acc: 0.7972 - val_auc: 0.8750 - val_loss: 0.4361\n",
      "Epoch 6999/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7844 - auc: 0.8654 - loss: 0.4511 - val_acc: 0.8015 - val_auc: 0.8743 - val_loss: 0.4346\n",
      "Epoch 7000/7000\n",
      "106/106 - 1s - 7ms/step - acc: 0.7829 - auc: 0.8624 - loss: 0.4551 - val_acc: 0.7976 - val_auc: 0.8759 - val_loss: 0.4370\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hist = model.fit([X_tr_f, X_tr_lab], y_tr_over,\n",
    "                 validation_data=([X_v_f, X_v_lab], y_val),\n",
    "                 epochs=7000, batch_size=512,\n",
    "                #  callbacks=[es],\n",
    "                 verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e9c4677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.733     0.922     0.817      1351\n",
      "           1      0.894     0.665     0.763      1351\n",
      "\n",
      "    accuracy                          0.793      2702\n",
      "   macro avg      0.814     0.793     0.790      2702\n",
      "weighted avg      0.814     0.793     0.790      2702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prob = model.predict([X_te_f, X_te_lab]).ravel()\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c6a3d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict probabilities on the test set\n",
    "y_prob = model.predict([X_te_f, X_te_lab]).ravel()  # Flatten to 1D\n",
    "\n",
    "# Predict class labels if needed\n",
    "y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "\n",
    "# Compute ROC and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:0.3f})', color='orange', lw=2)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "# plt.grid()\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(here() / config.plots / 'cibmtr' / 'cibmtr_roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(here() / config.plots / 'cibmtr' / 'cibmtr_roc_curve.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c76bc3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True, xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.savefig(here() / config.plots / 'cibmtr' / 'cibmtr_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(here() / config.plots / 'cibmtr' / 'cibmtr_confusion_matrix.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16792e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation Coefficient: 0.607\n",
      "Accuracy: 0.793\n"
     ]
    }
   ],
   "source": [
    "# print mathews correlation coefficient\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(f'Matthews Correlation Coefficient: {mcc:.3f}')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred):.3f}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3f8a456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(hist.history['loss'], label='Training Loss')\n",
    "plt.plot(hist.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Curves')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(here() / config.plots / 'cibmtr' / 'cibmtr_loss_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(here() / config.plots / 'cibmtr' / 'cibmtr_loss_curves.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67296b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "att_test = att_extractor.predict([X_te_f, X_te_lab])\n",
    "att_df   = pd.DataFrame(att_test, columns=X_train.drop(columns=['labtype']).columns)\n",
    "att_df['labtype'] = X_test['labtype'].values\n",
    "\n",
    "\n",
    "for lt in (0,1):\n",
    "    mean_w = att_df[att_df.labtype==lt].drop(columns=['labtype']).mean()\n",
    "    ax = plt.figure(figsize=(10,4))\n",
    "    # sort the mean weights for better visualization\n",
    "    mean_w = mean_w.sort_values(ascending=False)\n",
    "    mean_w.plot(kind='bar')\n",
    "    plt.title(f'Mean per-feature attention  labtype {lt} '\n",
    "              f\"({'post' if lt==1 else 'pre'}-G-CSF)\")\n",
    "    plt.ylabel('attention weight')\n",
    "    # make the axes size thicker for better visibility\n",
    "    plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "    # use gradiend color for bars\n",
    "    plt.bar(mean_w.index, mean_w.values, color=plt.cm.Blues(mean_w.values / mean_w.max()))\n",
    "    \n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(here() / config.plots / 'cibmtr' / f'cibmtr_attn_weights_labtype_{lt}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(here() / config.plots / 'cibmtr' / f'cibmtr_attn_weights_labtype_{lt}.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa243132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 0.899\n",
      "F1 Score: 0.763\n",
      "Precision: 0.894\n",
      "Recall: 0.665\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score, f1_score, precision_score, recall_score\n",
    "# Calculate precision-recall curve\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_prob)\n",
    "# Calculate average precision score\n",
    "average_precision = average_precision_score(y_test, y_prob)\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "# Calculate precision and recall\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Average Precision: {average_precision:.3f}')\n",
    "print(f'F1 Score: {f1:.3f}')\n",
    "print(f'Precision: {precision:.3f}')\n",
    "print(f'Recall: {recall:.3f}')\n",
    "# Plot Precision-Recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_curve, precision_curve, label=f'Precision-Recall curve (AP = {average_precision:0.3f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='lower left')\n",
    "plt.grid()\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(here() / config.plots / 'cibmtr' / 'cibmtr_precision_recall_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(here() / config.plots / 'cibmtr' / 'cibmtr_precision_recall_curve.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e37bbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model \n",
    "model.save(here() / config.model_dl / 'cibmtr_attn_model_hsu.keras')\n",
    "# save the history\n",
    "hist_df = pd.DataFrame(hist.history)\n",
    "hist_df.to_csv(here() / config.model_dl / 'cibmtr_attn_history_hsu.csv', index=False)\n",
    "\n",
    "# save the attention weights\n",
    "att_df.to_csv(here() / config.model_dl / 'cibmtr_attn_weights_hsu.csv', index=False)\n",
    "# save the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "968aa3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAGGCAYAAABmGOKbAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAeR5JREFUeJzt3Qd8VFXax/EnoYdeBEEpIiogIKKCq4gFEUXsWHERQbBhe1GsWFcREBTbCooIdsSyihVBsCGoCzYQUUCkKL13Mu/nf9gz3kwmIRMymZnk9/1sNnin5N459945zznPOSctFAqFDAAAAAAAFLj0gn9LAAAAAAAgBN0AAAAAAMQJQTcAAAAAAHFC0A0AAAAAQJwQdAMAAAAAECcE3QAAAAAAxAlBNwAAAAAAcULQDQAAAABAnBB0AwAAAAAQJwTdAICovv76azvqqKOsfPnylpaWZjNnzkz0LiGfjjvuOPeTKrp3724NGjTI12t1rvbp06fA9ynVTZ8+3UqXLm2///57onel2Jo1a5aVLFnSfvzxx0TvCoBCRtANoMh47rnnXIVbP59//nm2x0OhkNWtW9c93rlz54TsY6rYvn27nXvuubZq1Sp7+OGH7fnnn7f69esX+N9ZsmSJ3X333Skd0G/atMkdw+TJk7M99t5777nHCqtCr7+1YMGCQvl7qe7LL790n9eaNWss2b366qt28cUX2wEHHODuX/lpQLn99tvtwgsvjMt1XFif+/z5812DyoEHHmgZGRnup2nTpnb11Vfb999/H9N76Xo9++yzbe+993aNETVr1rTTTjvN3njjjSzPW758uV133XXWuHFjK1eunHte69at7eabb7YNGzZkaSjy3z+RPx988IF7jvb11FNPtTvvvDPmYweQ2komegcAoKCVLVvWXnrpJWvbtm2W7VOmTLFFixZZmTJlErZvqeK3335zPWJPP/20XXbZZXH7Owq677nnHter2bJlS0vVoFvHIJHBkILuJ554olACbwXd2g/tQ2Qv8UcffRT3v59qFPzp81KwVKVKFUtm//73v+3bb7+1I444wlauXBnz69Wo9fHHH7tjTtXPffz48Xb++ee7nuKuXbvaIYccYunp6fbzzz+7QFmfkYLyvDQq3HXXXXbvvfe6RozLL7/cvUafq67Xc845x1588UW76KKLXKPj4YcfbuvWrbMePXq4wFvPU4Cvv3fllVdahQoVwu+r75Znnnkm29/TvnpXXHGFderUyd1j999//zwfP4DURtANoMhRhea1116zRx991FXQPAXihx12mK1YsSKh+5cstmzZ4np4VHGNtGzZMvc72YOR/BxbcaTPAqlLmSb77LOPO5+bNWsW8+tHjRpl9erVsyOPPNJSkQLUCy64wAXHEydOtNq1a2d5fODAgfbkk0/m6XofN26cC7i7dOnivhNKlSoVfuymm26yDz/80GX6yMiRI23hwoX2xRdfuKE2QQrEI68rfd8oIyE3J554olWtWtVGjx7t9gNAMRECgCJi1KhRId3WXnvttVBaWlrovffeCz+2devWUNWqVUNDhgwJ1a9fP3Tqqadmee3OnTtDDz/8cKhp06ahMmXKhGrWrBnq3bt3aNWqVVme99Zbb4U6deoUql27dqh06dKhhg0bhu69997Qjh07sjzv2GOPDR188MGhn376KXTccceFypUrF6pTp05o4MCBeToWHcfVV18deuGFF0IHHnig26dWrVqFpkyZku25ixYtCl166aVun7VPOoaRI0dmec4nn3zi3vPll18O3X777W5f9BmtXr062/tdcskl7rnBHx2PN3v27NA555zjPk/t12GHHRb6z3/+k+U9Vq5cGerbt2+oWbNmofLly4cqVqwYOvnkk0MzZ87Mtk+RPypHUTlpXyJpX4L7s7tj++qrr0IdO3YMVapUyZVDu3btQp9//vluy0DnTP/+/d3nrtdmZGSE2rZtG5o0aVL4OfPnz496DHfddVfUzzH4tZvXc86fr5999lnoiCOOcM/db7/9QqNHj8527kf+6LOJ9pnJX3/9FerRo4f7u3rPFi1ahJ577rksz/HHN3jw4NDw4cPd+a5z7PDDDw9Nnz49FC/67HTcQdqHf/zjH6Fq1aqFypYt68pF13p+rh2VT7TPS8er80OfRTR6v5NOOinbZzN06NBQvXr13H7p9T/88EO21+bluskL3Vciy3J3tG/du3fPtt2fWx9++GHokEMOcfvVpEmT0Ouvv57tub/99luoS5cubv91HbVp0yY0fvz4bM979NFH3Tmt51SpUsUd54svvrjbzz03ui70PF3Le6px48buHFq3bt1un3v55ZeHSpQo4a7VvJyzutflxVlnnZXjOQagaKKnG0CRo9Taf/zjH/byyy/bKaec4ra9//77tnbtWtdboh7wSEox1JjwSy+91K699lqXpvj444/bjBkzXC+H7w3Rc5RO+H//93/u96RJk9z4PPV6DB48OMt7rl692k4++WQ3bvC8885zPSwaB9i8efPwfuVG6fAay6n9UdqienL0fpoQyfd2/fXXX673yk8etddee7lj7dmzp9un66+/Pst73nfffa535sYbb7StW7dG7QHVZ6FetQceeMD9baW01qpVyz32008/2dFHH+0ev+WWW9wka2PHjrUzzzzTXn/9dTvrrLPc8+bNm2dvvfWWGxe+3377uf0cPny4HXvssS4Nuk6dOtakSRPX06PPr3fv3nbMMce410b2KOVVtGNT+eizVoaDUkrVE6ZevxNOOME+++wzNzYzJ/r8lCqqcbC9evWy9evXu56vjh07ujJQOrw+b59mqmNXWUuLFi1s48aNLn1+woQJrqcyv+ec/Prrr65nTuV6ySWX2LPPPuvSc3VcBx98sLVr1869h87t2267zX224n9H2rx5s0tD1/vqvFEZKTtE76mxthrDGqQeQR2/9lnn2qBBg9yxqpyD+xlPw4YNs9NPP92lFm/bts1eeeUVd34p7VjjZGO5drTvv/zyi7tHaM6CGjVquNepPP/5z3+68tZkV8FeZU0sqNfccccdWf7WmDFj3GejccXKsNB+6vz64YcfYr5u4mHx4sWut7ZVq1ZRH587d65L21bas84tXR/6XDUOuUOHDu45un51XWoohT7T6tWru55alYfua37/NRxFj+tc1Tmkz0Op2NOmTXPp2rl97rlRGTdq1MjatGmzR5+FjlXp6EoVr1ix4m6fr571nTt3uutXn01eRGZS6fqoXLlylm26bv/zn/+4e0ylSpViPAoAKSnRUT8AFBTf2/f111+HHn/8cde7umnTJvfYueeeGzr++OPdvyN7utWDqNf53hjvgw8+yLbdv19kb4h6Qbds2RLepp4ovXbMmDFZek733ntv19u1O74H6Jtvvglv+/33311PmnpJvJ49e7pe9xUrVmR5/QUXXBCqXLlyeH99b7B6KqMdQyT//MiexPbt24eaN2+e5VgzMzNDRx11VOiAAw4Ib9Pjkb1D6s1ST5oyAzyVVbB3OyjWnu7IY9N+aZ/Uy61/e3qOeoo7dOiQ62eg7AWVWZB6z2vVquV6iL3ly5eHe7cjqcc12ldtLOecPgdt+/TTT8Pbli1b5j5LZRN4Kqtg73Zun9kjjzzinqveYG/btm2uJ7lChQrhXkDfm1u9evUsPfDqodX2d955J1RYPd2R5632V5kUJ5xwQr6uHfVQR+tlXbNmjXvuzTffnGX7tdde63oyN2zYkOWzUY+usk28adOmue033HBDzNdNPHq6P/744xzLyp9bwZ7ttWvXunvKoYceGt52/fXXu+fpvPXWr1/vrqMGDRqEr/UzzjjD7V9ucvrcc6L90fPPPPPMbI/petT15392d2/z560yTPLizz//DO21117uNeohv+KKK0IvvfSSO0ci5ZTZEq2s9B56TOcKgOKBwW4AiiT1LKs3Tz0k6oXSb/W0RKMePvVEqFdHvRT+R70R6s3+5JNPws/V7LWe3lfPUw+teoDUgxKk1wbH96nnVT2r6h3MC/XWax88jck844wz3JhD9b4ovlAvmWbc1b+D+67eWPXs//e//83ynuqtCR5DLDSpkHqO9dn6Y9ePJhbS31MvknrVRL2Lfnyl9lXP0edx0EEHZdunghJ5bJo8Svukctff9/urHuj27dvbp59+apmZmTm+X4kSJcKZAHqejn/Hjh1uYqU9PYZYzjk/67HPBPA9g/os83ouRdKEUZq1Wb34wR459VJqRmb1FAepJ1TjUD2/L/n9+/kRLFtlkej81n5EK4vdXTu5UbnoueqN3RXD7zqH1XOunmn1Ugdpm3qwPV3j6pHVZxzrdRMPfuK1YPkFKesk2NOuntdu3bq5jIs///zTbdOx6LiCk1PqPFWGimbLV/aKnwNCk1UqK6CgqDfY/71IytbQteB/NGlhXt4rL73cokyF7777zmUB6Jx76qmn3P1EM5grs8afH8FJPJXZEvwZMmRItvf1ZcH8IkDxQXo5gCJJFTBNWKO0WAXEqjQr5TEaVXpVgVdFKho/qZhPE1V6qSrRvgLn6T2C9t13X5eKG1nZyuvSNppZN5KWytHxaBkbBbVKBR4xYoT72d2+i9KIPX0mep+gatWq5TjpllKRVcns37+/+8np7ykAUZCqNFul9SptOhjoKDU1HoLH5stVcksLVZnlFIyIUmhVaVaDip9cKdrfilUs55wPGiNpvxUI5Idmptf5FTnxlE9Hj1zLOfLv+88st78f7fwKBtCRKbe7o4azf/3rX64xRcMHvMhrLC/XjhoccqOgU0G2hiAodV8zfyvFWqnnef1bSh+P9bqJp8gA0VPaduRnqP0XBdT6rHQ+REvtDp4vSsXX8Bl9VgrQ9b4nnXSSC1KVWr87apzQsIHIc8QHyMHluTwNWVFDhsom2MCpBtfI+7GOw6dy6zV5pUnbNIRE9zJdt2q40cRtGhajx4KrO6ihTt87eS2LaOcugKKJoBtAkaXKnsZmqrdG43pzmolbAaKCHy0TE40fb6gAV2OSVXHTWGQt96KeDfW0qbIZ2WuqClgsld9Y+b+nymZOgaXGFufUW/jHH39kCx7Vw5rTGsD+72nMtHroolFFWzQeXAGGxk6qR0jBvAI8jTHPrXc5KKcKqYK5aJ9tZA++/zsaa5/TcmTRes+8F154wY1xVk+mZjXWOaK/O2DAADeb8p7I6zlXWOfS7uTn70c7vzydrxrPnlcKfjV+WAGwgh8FO+qZ1/hjNawVNJ3f6uXUOaC/qd8K2vISUO3JdRMPvpErvw00sVAQPmfOHNdAojHhysRReSlA9cvq5UTjvYMZFv4cUeCt8tYY+0i+ISBybXo1mGiuhMhzVUt+icbbx0r3IzVG6EdzCKixRddvfpZU9GXhx7QDKPoIugEUWUqZ1MRPX331lauE5UTBs3pn1BuTW+r15MmTXaqm1oRVRdxTT248+J7aIE1ClJGREQ7K1AukIDQ/wYCCCKU/5rSebKSGDRu63wp2dvf3NLnS8ccf7yYeC1LDRbCimVtPj3pT9fxI6lXz+5IbvwauGkny8/noGPR3VN7B/dSEbEG5HUNOj+X1nItFLL1mmiBKGRcKCIO93X6IRF7WOs7P+RVMaY6Fgjc1cKmXUUMXPAXd+b12cvu81MigRjsFferV1KSAasCL1viQ09/ya6XHct3Egw80c7pP+Z744Oeh/Rd/DDofFExHina+KP1ewxH0o55rBdP333+/3Xrrra4Mc/rclVESbBgIniMKcjWpoSbCy23yQ0+NG9HOPQXMGpahScyUiZNbo1tuVKa6Py1dujRfr1dZ6LrzGQUAij7GdAMoslShUlrg3Xff7cY950RjLRW4qkc2ksbw+sDPV7iDvXuqVKonJx6mTp2aZbyqeg5VWVTKpvZFP+ecc44LSKL1AuWU2uupAqwgIPiTW6q1embVC66UzmiVzeDf075F9oJqHHPk2FU/PjZacK3AVA0mwZRT9aDpc8gLjenVezz00ENRU1N39/lEK2/NwqxyCVIgl9Mx5HR8eT3nYpHbZxltLXtlgAQbo/R3H3vsMXfdKKNjT0U7v/yPxqjHQmWhYC04TEG9mwqG83Pt5OXzUiq5gkA13On8yWn9Ze1D8LxWYKjzxK9QEMt1Ew9KW69bt6598803UR/XDPtvvvlm+L81bEYzsis7xKfh63zRcQXPfc2NoGEtCsx9efrx456GqugxXUN+eEZOn7uu15zOkX79+rnrTJkzSiWPFHmvUc945Dnnqcdd+6keap3zkT766CN3nxGVo44zkj4LvYcC+Pz49ttv3aoDsQ6xAJC66OkGUKTlZZkXBRiqWCttWONFVTFXr5R6sBQoqkdE48G1ZI6CUr2nJpxSEKClZOKV4qsxkuqxCS57JME0zQcffNClhCvNUj1xqqhqbKQCDvWk6t8FSRMVaTIlLXumv6ceH1WCVRnXBEqadEg6d+7sUvCV4qnPTemcSsWM7KFWUKy0f01QpF57Vch1LEpLVqVYvc1a6klBqlK6lebre7B3Rz1J6h1T8KMKrvZFAYgCJH1m6gF/5513cny9jkG93MqYUE+beqe0n/qMg0G8eqq1TQGseq6USq+y04+fzEtlqLJUwKdl6/J6zsVCQZLeXz2zGs+qc0ZLV0UbN64JsBQEKn1eAYACJ33WWqrskUceyfNEU4VFn//QoUPduaAeaI2B1rmotOxocyTk5drxZXP77be7MtHnr8Y5HxQeeuih7n1UHkqbzmnJLe2DrgktG6ex5vr8lNKtQDHW6yYnmvRPPz5IVyCo8e2irJtg5k00mhhOgXVkj7bonNVSdJr8TCn1Wo5O+xbMItAyZ34JRn2mOsc134GuCTX6+WwJnccK1JXBofeaPXu2WwZP5efPqd197tEolVvDCDTxnwJdLRunrBwdj/ZBj2kfNI/G7qgHXvcj9b5rsji9p3rqFUQrJX7ixInhIQu6v+u+pXuA9luNCDomfUZqVNLyfLFS44PS6K+66qqYXwsghSV6+nQAiMeSYbmJXDLMGzFiROiwww5zSwBpuTEt8dOvX7/QkiVLws/54osvQkceeaR7Tp06ddzjH374YbalmrRMTLSlc6IthRSN3k/LTWlJJy0ppOWhtIRPtOWg/vrrL/fcunXrhkqVKuWWJdMSRTqe3S0BlpPcnv/bb7+FunXr5v6O/t4+++wT6ty5c2jcuHHh52hpJC1npaWH9FkdffTRoalTp2Zbusov49O0adNQyZIlsy0fNmTIEPf+On69h5aBymnJsJyObcaMGaGzzz7bLXul99Hnf95554UmTpyY62egJZ0eeOAB93z/+Y8fPz5qGX755Zfu3CldunSW5cO07Ng111zjlh1KS0vLtnxYXs65nM7XaJ/l008/7ZZOK1GiRJZzMtpzdd5ceumloRo1arj91t+OXLrNL4ulZZ4i5bRMWkGI9hmPHDkyfC1o+Sbtq/5+5Gcay7Vz3333ufMrPT096jJWgwYNctt1HkQKfjY6T3X96W8dc8wxoe+++y5f101O/HFG+8lLGfz3v//NtuRX8NzSPaxFixbhzzan675Lly6hKlWquCXVWrdu7a6HoOHDh4fatWsXvtb233//0E033eSW/Yrlc8/Jr7/+GrryyitDjRo1cvug68Yv5TVz5sxQLHT9a4mzmjVrunuPrtHTTjvN3Y+877//3u1/q1atQtWqVXPP0z1NS1DqM408Z7Wk3O68//777pjnzp0b0/4CSG1p+r9EB/4AgKzUG3X11Ve7XiIAiaGMgxtuuMGlskfO4K5tysjQRH2aJC3ZaZk8jZNW762nDAf15vt0asSfJmbU/T2Y0g+g6GNMNwAAQAT1SWgiQA0FiLZkW6rRigIaAhG5HBwKj1LT1cARbS4HAEUbY7oBAAD+R+Ol3377bTfuX2N/NQFbUaC5EoKTEqLwaW6AaJO3ASj6CLoBAAD+RxOVabI2TfCnibK0PjgAAHuCMd0AAAAAAMQJY7oBAAAAAIgTgm4AAAAAAOKEoPt/M5SuW7fO/QYAAAAAoKAQdJvZ+vXrrXLlyu43AAAAAAAFhaAbAAAAAIA4IegGAAAAACBOCLoBAAAAAIgTgm4AAAAAAOKEoBsAAAAAgDgh6AYAAAAAIE4IugEAAAAAiBOCbgAAAAAA4oSgGwAAAACAOCHoBgAAAAAgTgi6AQAAAACIE4JuAAAAAADipGS83rgoK3don0TvQrGyecbjid4FAAAAAMgXeroBAAAAAIgTgm4AAAAAAOKEoBsAAAAAgDgh6AYAAAAAIE4IugEAAAAAiBOCbgAAAAAA4oSgGwAAAACAOCHoBgAAAAAgTgi6AQAAAACIE4JuAAAAAADihKAbAAAAAIA4IegGAAAAACBOCLoBAAAAAIgTgm4AAAAAAOKEoBsAAAAAgDgh6AYAAAAAIE4IugEAAAAAiBOCbgAAAAAA4oSgGwAAAACAOCHoBgAAAAAgTgi6AQAAAACIE4JuAAAAAADihKAbAAAAAIA4IegGAAAAACBOCLoBAAAAAIgTgm4AAAAAAOKEoBsAAAAAgDgh6AYAAAAAIE4IugEAAAAAiBOCbgAAAAAA4oSgGwAAAACAohp0b9261W6++WarU6eOlStXztq0aWMTJkyI+X06dOhgaWlp1qdPn7jsJwAAAAAAKRd0d+/e3YYOHWpdu3a1YcOGWYkSJaxTp072+eef5/k93njjDZs6dWpc9xMAAAAAgJQKuqdPn26vvPKKDRgwwAYPHmy9e/e2SZMmWf369a1fv355eo8tW7ZY3759XW85AAAAAADJJKFB97hx41zPtoJtr2zZstazZ0/Xc/3HH3/s9j0GDRpkmZmZduONN8Z5bwEAAAAASKGge8aMGXbggQdapUqVsmxv3bq1+z1z5sxcX79w4UJ78MEHbeDAgW48OAAAAAAAyaRkIv/40qVLrXbt2tm2+21LlizJ9fVKKz/00EPtggsuiHnyNv1469atc7/VY64f0aRs+gmFQu7H07Zdv//+t+x6nll6+t/bdr3nrtfGc3tO+1JQ2xN9TCqT3MojP9t9Oed3e3p6erb3jnU7x8QxcUwcE8fEMXFMHBPHxDFxTJkpfUz6ndRB9+bNm61MmTLZtivF3D+ek08++cRef/11mzZtWsx/V2PI77nnnmzbly9f7saIi3rOK1eu7ALy4H6UL1/e/d5/n8pWKaNUePvvf22wlWu3WON6Vaxs6RLh7XMXrbX1m7Zbi4bVsgSXsxastm07Mq1lo+pZ9mHmryutdMl0a9qgapYgVNsrZpSyA/atHN6+ZdtO9z7VKpW1+rUqhLev27Tdfl201vaulmG1q2eEt69Yu8UW/rXB6tasYDUq7/qMZenKTe4nWY9p2bJlVrp0aatWrZpt2LDBNm7cGH5+buVUsWJFW716tW3bti28XVkVGRkZtmrVKtuxY0d4e9WqVd25qHMgeEFVr17dDYHQPgTVrFnTdu7caStXrgxv0wVXq1Yt9/f0d72SJUtajRo13P75Bh7hmDgmjolj4pg4Jo6JY+KYOCaOaVVKH5NetztpocjQvxA1a9bMfRgTJ07Msn3WrFl28MEH21NPPWWXX355ttepUNTD3apVKxs9enSWD/fqq6+2xx9/POae7rp167oPzae659aqkdHqmqTtFS6KPd3rvx5GixrHxDFxTBwTx8QxcUwcE8fEMXFMlmzHpN9J3dOtNPLFixdHTTsXrd0dzZgxY2zOnDk2fPhwW7BgQZbH1q9f77apxUMtJ9Go5SRaD7sKQD9B/gONpM88sgCDgWRhbs9pXwpqe6KPKVgmOZVHrNsjyzk/2wtqXzgmjinW7RwTx5Sf7RwTx8QxcUy5beeYOCaOyfK1PeknUmvZsqX98ssvWbr2xaeM6/GcJlDbvn27HX300bbffvuFf3xArn9/9NFHhXAEAAAAAAAkaU93ly5d7KGHHrIRI0aEl/xS2veoUaOsTZs2LuXbB9mbNm2yxo0bu//WxGnRAvKzzjrLOnXqZL169XKvBwAAAACg2AbdCozPPfdcu/XWW92A+EaNGrkx2koPHzlyZPh53bp1sylTpoTTjRV8+wA8knq5zzzzzEI7BgAAAAAAkjLo9ung/fv3t+eff95NZNaiRQsbP368tWvXLtG7BgAAAADAHkno7OXJQmPKNRX82rVrw7OX56bcoX0KZb+wy+YZuc9GDwAAAADJKqETqQEAAAAAUJQRdAMAAAAAECcE3QAAAAAAxAlBNwAAAAAAcULQDQAAAABAnBB0AwAAAAAQJwTdAAAAAADECUE3AAAAAABxQtANAAAAAECcEHQDAAAAABAnBN0AAAAAAMQJQTcAAAAAAHFC0A0AAAAAQJwQdAMAAAAAECcE3QAAAAAAxAlBNwAAAAAAyRJ0jxkzxrZu3Zpt+7Zt29xjAAAAAAAgn0H3pZdeamvXrs22ff369e4xAAAAAACQz6A7FApZWlpatu2LFi2yypUrx/p2AAAAAAAUWSXz+sRDDz3UBdv6ad++vZUs+fdLd+7cafPnz7eTTz45XvsJAAAAAEDRDbrPPPNM93vmzJnWsWNHq1ChQvix0qVLW4MGDeycc86Jz14CAAAAAFCUg+677rrL/VZwff7551vZsmXjuV8AAAAAABSfoNu75JJLwrOVL1u2zDIzM7M8Xq9evYLbOwAAAAAAilPQPXfuXOvRo4d9+eWXUSdY0/huAAAAAACQj6C7e/fubhK18ePHW+3ataPOZA4AAAAAAPIRdGsitW+//dYaN24cnz0CAAAAAKC4rtPdtGlTW7FiRXz2BgAAAACA4hZ0r1u3LvwzcOBA69evn02ePNlWrlyZ5TH9AAAAAACAGNLLq1SpkmXstiZNa9++fZbnMJEaAAAAAAD5CLo/+eSTvDwNAAAAAADEGnQfe+yxeXkaAAAAAADYk9nLv//++6jblVpetmxZq1evnpUpUybWtwUAAAAAoMiJOehu2bJlrmtzlypVys4//3wbPny4C8IBAAAAACiuYl4y7M0337QDDjjARowY4dbs1o/+fdBBB9lLL71kI0eOtEmTJtkdd9wRnz0GAAAAAKCo9nTff//9NmzYMOvYsWN4W/PmzW3fffe1/v372/Tp0618+fLWt29fe+ihhwp6fwEAAAAAKLo93T/88IPVr18/23Zt02M+BX3p0qUFs4cAAAAAABSXoLtx48b24IMP2rZt28Lbtm/f7rbpMVm8eLHVqlWrYPcUAAAAAICinl7+xBNP2Omnn+7SyVu0aOG2qYd7586dNn78ePff8+bNs6uuuqrg9xYAAAAAgBSSFgqFQrG+aP369fbiiy/aL7/84v5bk6hddNFFVrFiRUtF69ats8qVK9vatWutUqVKu31+uUP7FMp+YZfNMx5P9C4AAAAAQOGkl4uC6yuuuMKGDh3qfi6//PJ8B9xbt261m2++2erUqWPlypWzNm3a2IQJE/I0i7omc9PrtC64et67dOliP/74Y772AwAAAACAhKSXv/3223bKKae4Nbj179wo9TwW3bt3t3Hjxtn111/vliJ77rnnrFOnTvbJJ59Y27Ztc3ydUtqrVq1q1113ndWoUcP+/PNPe/bZZ61169Y2depUO+SQQ2LaDwAAAAAAEpJenp6e7oLamjVrun/n+GZpaW5sd15peTH1bA8ePNhuvPFGt23Lli3WrFkz97e+/PJLi8Vff/3lerx79uxpTz31VJ5fR3p5ciO9HAAAAECRTi/PzMx0QbD/d04/sQTcoh7uEiVKWO/evcPbypYt64Jm9Vb/8ccfMb2f9jEjI8PWrFkT0+sAAAAAAEiaMd2eeqX3xIwZM+zAAw/M1rusFHGZOXPmbt9DAfby5ctduvlll13meq3bt2+/R/sFAAAAAEBClgxTb/YDDzzg0reVzq0ZzBs2bGj9+/e3Bg0auF7qvFq6dKnVrl0723a/bcmSJbt9jyOPPNLmzJnj/l2hQgW74447drsPmrxNP54CdfE99j5VXj/Kvg9m4Gvbrt9//1t2PU+p+H9v2/Weu14bz+057UtBbU/0MalMciuP/Gz35Zzf7RpmEfnesW7nmDgmjolj4pg4Jo6JY+KYOCaOKTOlj0m/Czzovv/++2306NE2aNAg69WrV3i7xmE/8sgjMQXdmzdvdjOPR1KKuX98d0aNGuWCZq0Nrn/rNWoYyG3s+YABA+yee+7Jtl095r73XjOpa5y33ju4H+XLl3e/99+nslXKKBXe/vtfG2zl2i3WuF4VK1u6RHj73EVrbf2m7daiYbUsweWsBatt245Ma9moepZ9mPnrSitdMt2aNqiaJQjV9ooZpeyAfSuHt2/ZttO9T7VKZa1+rQrh7es2bbdfF621vatlWO3qGeHtK9ZusYV/bbC6NStYjcq7PmNZunKT+0nWY1q2bJmVLl3aqlWrZhs2bLCNGzeGn59bOWlG/dWrV9u2bdvC25VVoSEIq1atsh07doS3a1I+nYs6B4IXVPXq1d0QCO1D5FAGnWcrV64Mb9MFV6tWLff39He9kiVLusn+tH++gUc4Jo6JY+KYOCaOiWPimDgmjoljWpXSx6TXFfg63Y0aNbLhw4e7FG79oe+++871dP/888/2j3/8I8tB7Y4CdX0YEydOzLJ91qxZdvDBB7vedC1Hllf6202aNLGLL77YHnrooZh6uuvWrete71Pdc2vVyGh1TdL2ChfFnu71Xw+jRY1j4pg4Jo6JY+KYOCaOiWPimDgmS7Zj0u8C7+levHixC7wj6eC3b98e03spjVzvFy3tXLQGdyzUKnLCCSfYiy++mGvQrZaTaD3sKoDIHnL/gUbSZx5ZgMFAsjC357QvBbU90ccULJOcyiPW7TllQsSyvaD2hWPimGLdzjFxTPnZzjFxTBwTx5Tbdo6JY+KYLF/b4zKRWtOmTe2zzz6LOhP5oYceGtN7tWzZ0o0JD3bty7Rp08KPx0rd/lr6CwAAAACARIs56L7zzjutT58+NnDgQNe7/cYbb7ix3Rrrrcdi0aVLF5d/P2LEiPA2pX1rbLbW71bKtyxcuNClrwdF5vLLggULXKr64YcfHuthAQAAAABQ4GJOLz/jjDPsnXfesXvvvdcNIFeg3apVK7etQ4cOMb2XAutzzz3Xbr31VhdEK21dk7QpeB45cmT4ed26dbMpU6ZkSX1u3ry5G1eu3nCllc+dO9e9RinuDz74YKyHBQAAAABA4oNuOeaYY2zChAkFsgNjxoxxy409//zzbiKzFi1a2Pjx461du3a5vu7KK6+0d9991z744ANbv369m7XupJNOsttuu80F5AAAAAAAJFrMs5erZ/v44493M5X7pb1SncaUayp4jQX3s5fnptyhfQplv7DL5hmPJ3oXAAAAAKBwxnRPnTrVTjvtNKtSpYrr8b7jjjvs448/ztOa2gAAAAAAFCcxB91KK1+zZo2bsKxTp072zTff2Nlnn+2C8LZt28ZnLwEAAAAAKC5jukuWLGlHH3207bXXXlatWjWrWLGivfXWW9lmGAcAAAAAoDiLuadby3tddNFFts8++9hRRx3lJjJTD7d6vJcvXx6fvQQAAAAAoDj0dF9xxRWuh7tv37521VVXWYUKFeKzZwAAAAAApLiYe7rfeOMN69q1q73yyisu+FZvt5bp+uijj2zTpk3x2UsAAAAAAIpDT/eZZ57pfkRLbH322Wf22muvWefOnS09Pd22bNkSj/0EAAAAAKB4TKS2cuVKmzJlik2ePNn9/PTTT1a1alW3hBgAAAAAAMhn0N28eXObPXu2C7LbtWtnvXr1smOPPdZatGgR61sBAAAAAFCk5WsiNQXZzZo1i88eAQAAAABQXIPuq6++Oj57AgAAAABAcZ+9HAAAAAAA5A1BNwAAAAAAcULQDQAAAABAnBB0AwAAAACQTOt0r1mzxqZPn27Lli2zzMzMLI9169atoPYNAAAAAIDiFXS/88471rVrV9uwYYNVqlTJ0tLSwo/p3wTdAAAAAADkM728b9++1qNHDxd0q8d79erV4Z9Vq1bF+nYAAAAAABRZMQfdixcvtmuvvdYyMjLis0cAAAAAABTXoLtjx472zTffxGdvAAAAAAAozmO6Tz31VLvpppts1qxZ1rx5cytVqlSWx08//fSC3D8AAAAAAFJWWigUCsXygvT0nDvHNZHazp07LdWsW7fOKleubGvXrnWTw+1OuUP7FMp+YZfNMx5P9C4AAAAAQOH0dEcuEQYAAAAAAApoTDcAAAAAAIhj0D1lyhQ77bTTrFGjRu5H47g/++yz/LwVAAAAAABFVsxB9wsvvGAnnniiWzJMS4fpp1y5cta+fXt76aWX4rOXAAAAAAAUh4nUmjRpYr1797Ybbrghy/ahQ4fa008/bbNnz7ZUw0RqyY2J1AAAAAAUm57uefPmudTySEoxnz9/fkHtFwAAAAAAxS/orlu3rk2cODHb9o8//tg9BgAAAAAA8rlkWN++fd047pkzZ9pRRx3ltn3xxRf23HPP2bBhw2J9OwAAAAAAiqyYg+4rr7zS9t57bxsyZIiNHTs2PM771VdftTPOOCMe+wgAAAAAQPEIuuWss85yPwAAAAAAoIDX6QYAAAAAAAXU012tWjX75ZdfrEaNGla1alVLS0vL8bmrVq3Ky1sCAAAAAFDk5Snofvjhh61ixYrhf+cWdAMAAAAAgF3SQqFQyIq5devWWeXKlW3t2rVWqVKl3T6/3KF9CmW/sMvmGY8nehcAAAAAoHDGdJcoUcKWLVuWbfvKlSvdYwAAAAAAIJ9Bd04d41u3brXSpUvH+nYAAAAAABRZeV4y7NFHH3W/NZ77mWeesQoVKoQf27lzp3366afWuHHj+OwlAAAAAABFOejWBGq+p/upp57KkkquHu4GDRq47bFSD/mdd95pzz//vK1evdpatGhh//rXv6xDhw65vu6NN96wV1991b7++mv7888/rW7duta5c2fr37+/ValSJeb9AAAAAAAg4ROpHX/88S7g1dJhBeHCCy+0cePG2fXXX28HHHCAPffccy6Q/uSTT6xt27Y5vk7Ll9WpU8fOPPNMq1evnv3www8u6G/YsKH997//tXLlyuV5H5hILbkxkRoAAACAVJXQ2cunT59ubdq0scGDB9uNN97otm3ZssWaNWtmNWvWtC+//DLH106ePNmOO+64LNvGjBljl1xyiT399NN22WWX5Xk/CLqTG0E3AAAAgCKfXh4cv63e6IkTJ7pZzDMzM7M8PmnSpDy/l3q4labeu3fv8LayZctaz5497bbbbrM//vjDpY1HExlwy1lnneWC7tmzZ8d0TAAAAAAAJEXQfd1117mg+9RTT3U90ppYLb9mzJhhBx54YLbe5datW7vfM2fOzDHojkZju33qOQAAAAAAKRd0v/LKKzZ27Fjr1KnTHv/xpUuXWu3atbNt99uWLFkS0/sNHDjQ9Zx36dJlt5O36SeYXi7qtfc992pM0I+y74MZ+L6RQb+CDQ67nmeWnp61ESIzc9dr47k9p30pqO2JPiaVSW7lkZ/tkRkasW5PT0/P9t6xbueYOCaOiWPimDgmjolj4pg4Jo4pM6WPSb8LPOjWTOWNGjWygrB582YrU6ZMtu1KMfeP59VLL71kI0eOtH79+rkJ2XIzYMAAu+eee7JtX758uRtTLpqITeO8FZAH96N8+fLu9/77VLZKGaXC23//a4OtXLvFGterYmVL/z2z+9xFa239pu3WomG1LMHlrAWrbduOTGvZqHqWfZj560orXTLdmjaomiUI1faKGaXsgH0rh7dv2bbTvU+1SmWtfq2/l3Bbt2m7/bpore1dLcNqV88Ib1+xdost/GuD1a1ZwWpU3vUZy9KVm9xPsh6ThjHovKtWrZpt2LDBNm7cGH5+buVUsWJFNyP+tm3bwtuVVZGRkWGrVq2yHTt2hLdrYkCdizoHghdU9erVXUOO9iFIcw5oqMXKlSvD23TB1apVy/09/V2vZMmSLvtC++cbeIRj4pg4Jo6JY+KYOCaOiWPimDimVSl9THpdgU+kNmTIEJs3b549/vjjeYrqc6P0dH0YGh8eNGvWLDv44IPdbOSXX375bt/ns88+s5NOOsmOPfZYGz9+vPswY+3pVhq7PjSf6p5bq0ZGq2uStle4KPZ0r/96GC1qHBPHxDFxTBwTx8QxcUwcE8fEMVmyHZN+F3hP9+eff+6W83r//fddYFyq1N89o6LlxPJKaeSLFy+OmnYuWhJsd7777js7/fTTXQCvidl2F3CLWk6i9bCrAPQT5D/QSPrMIwswGEgW5vac9qWgtif6mIJlklN5xLo9spzzs72g9oVj4phi3c4xcUz52c4xcUwcE8eU23aOiWPimCxf2/Mi5qC7SpUqbpbwgtCyZUsXwKunOTiZ2rRp08KP5+a3336zk08+2aUUvPfee1ahwt8p1gAAAAAAFOt1uhVcH3nkkVnW6Vbat3qtlbP/1VdfuW0LFy60TZs2WePGjbPMVH700Ue7MdhffPGFNWjQIN/7wTrdyY11ugEAAACkqph7ukUD3SdPnux6mi+66CI3iFwzjStgjaW3uU2bNnbuuefarbfe6gbEa4K20aNH24IFC9ykaF63bt1sypQpWVKf1cOtseWaOE0p7/rxNE68Q4cO+Tk0AAAAAAASF3T//vvvLuBV77N6pRXcKujWcl36b01+FosxY8ZY//797fnnn3cTmbVo0cJNhtauXbvdjuWWQYMGZXtME6oRdAMAAAAAUi69/Mwzz3RBtnqilQKu4Ldhw4au57tXr142d+5cSzWklyc30ssBAAAAFJuebi3P9eWXX7q1zII0pjraTOQAAAAAABRX0edhz4XWRdPi45EWLVrkesABAAAAAEA+g+6TTjrJHnnkkSxrk23YsMHuuusu69SpU6xvBwAAAABAkRVzevmQIUOsY8eO1rRpU7dcl2Yv1zjuGjVq2MsvvxyfvQQAAAAAoDgE3fvuu6+bPO3VV191v9XL3bNnT+vatauVK1cuPnsJAAAAAEBxmL38008/taOOOspKliyZbe1uTbC2u6W+khGzlyc3Zi8HAAAAUGzGdB9//PG2atWqbNsVsOoxAAAAAACQz6BbHeOaPC3SypUrrXz58rG+HQAAAAAARVaex3SfffbZ7rcC7u7du1uZMmXCj2kJse+//96lnQMAAAAAgBiDbo159j3dWo87OGla6dKl7cgjj7RevXrl9e0AAAAAACjy8hx0jxo1yv1u0KCB3XTTTZaRkRHP/QIAAAAAoPiN6Z4yZYpt27Yt6gzgJ5xwQkHtFwAAAAAAKa/Agu4tW7bYZ599VlD7BQAAAABA8Ukv10Rpfkz3rFmz7M8//8wykdoHH3xg++yzT3z2EgAAAACAohx0t2zZ0s1crp9oaeSaWO2xxx4r6P0DAAAAAKDoB93z5893vdwNGza06dOn21577ZVl9vKaNWtaiRIl4rWfAAAAAAAU3aC7fv367ndmZmY89wcAAAAAgOIXdEfSuO6FCxdmm1Tt9NNPL4j9AgAAAACg+AXd8+bNs7POOst++OEHN75bKeeif/tJ1QAAAAAAQD6WDLvuuutsv/32s2XLlllGRob99NNP9umnn9rhhx9ukydPjs9eAgAAAABQHHq6p06dapMmTbIaNWpYenq6+2nbtq0NGDDArr32WpsxY0Z89hQAAAAAgKLe06308YoVK7p/K/BesmRJeKK1OXPmFPweAgAAAABQXHq6mzVrZt99951LMW/Tpo0NGjTILRk2YsQIt5wYAAAAAADIZ9B9xx132MaNG92/7733XuvcubMdc8wxVr16dXv11VdjfTsgYT74aXmid6FYOfngvRK9CwAAAEDyB90dO3YM/7tRo0b2888/26pVq6xq1arhGcwBoDB9OIsGlMLSsSmNJwAAAIWyTndQtWrVCuJtAAAAAAAo3hOpAQAAAACAvCHoBgAAAAAgTgi6AQAAAACIE4JuAAAAAADihKAbAAAAAIA4IegGAAAAACBOCLoBAAAAAIgTgm4AAAAAAOKEoBsAAAAAgDgh6AYAAAAAIE4IugEAAAAAiBOCbgAAAAAA4oSgGwAAAACAohp0b9261W6++WarU6eOlStXztq0aWMTJkzY7evmzJljN9xwgx111FFWtmxZS0tLswULFhTKPgMAAAAAkBJBd/fu3W3o0KHWtWtXGzZsmJUoUcI6depkn3/+ea6vmzp1qj366KO2fv16a9KkSaHtLwAAAAAAKRF0T58+3V555RUbMGCADR482Hr37m2TJk2y+vXrW79+/XJ97emnn25r1qyxH374wQXsAAAAAAAkm4QG3ePGjXM92wq2PaWK9+zZ0/Vk//HHHzm+tlq1alaxYsVC2lMAAAAAAFIs6J4xY4YdeOCBVqlSpSzbW7du7X7PnDkzQXsGAAAAAMCeK2kJtHTpUqtdu3a27X7bkiVL4jZ5m368devWud+ZmZnuRzQxm35CoZD78bRt1++//y27nmeWnv73tl3vueu18dye074U1PZEH5PKJLfyyM92vWdwu38scltO22N5bqpsj/fflPyUU+R7R9uu11JOhbM9+NnHWk45bU9PT892DsS6PR73CI6JY+KYOCaOiWPimDimtN1s1++kDro3b95sZcqUybZdKeb+8XjQGPJ77rkn2/bly5fbli1b3L81k3rlypVdQB7cj/Lly7vf++9T2SpllApv//2vDbZy7RZrXK+KlS1dIrx97qK1tn7TdmvRsFqW4HLWgtW2bUemtWxUPcs+zPx1pZUumW5NG1TNEoRqe8WMUnbAvpXD27ds2+nep1qlsla/VoXw9nWbttuvi9ba3tUyrHb1jPD2FWu32MK/NljdmhWsRuVdn7EsXbnJ/STrMS1btsxKly7thhRs2LDBNm7cGH5+buWk4QerV6+2bdu2hbcrqyIjI8NWrVplmZtWh7enl61oVqKUZW5aoxDu7+3lKlvI0rM8123PqGoWyrTMzWsDW9OsRPmqZpk7LHPL+r+3ppWwtIzKZju2Wea2v/c9rUQpSytb0ULbt1ho+9/7nlayjKWVKW+hbZsstOPvxqG0UuUsrXQ5C23dYKGd2//el9LlzUqVsdDmdRYK7UzaY5L8lNOOHTvC26tWreruGbpWs9xAQ/pfumVujDim8v87pk2BY0r73zHtzHpMll7CSvhj2hpxTOX+d0zbAsdUKlBO2wPlVPp/5bQlopzK7CqnzM3rzDIjyqnk/8opcEzpGZWT8piWLcvMdzlVr17dDSnSNR1Us2ZN27lzp61cuTJwSGlWq1Ytd17o/PBKlixpNWrUcOeRbzCVeNwjOCaOiWPimDgmjolj4pgq7+aY9LrdSQtFhv6FqFmzZu7DmDhxYpbts2bNsoMPPtieeuopu/zyy3f7Pg899JDddNNNNn/+fGvQoEG+errr1q3rPjSf6p5bq0ZGq2uStle4KPZ0r/96WFxa1D6ctSLL3/XPjxRteyzPTZXt8f6bpzSrGbeWz49mr6CcCmn7SU1qFLkW6qLY6s4xcUwcE8fEMXFMHFN6oRyTfid1T7fSyBcvXhw17Vy0dnc8qOUkWg+7CkA/Qf4DjaTPPLIAg4FkYW7PaV8KanuijylYJjmVR6zb9Z45PT+aPX1uqmwvjL8ZazlFE+06zenvJtPnW1DbE7kv0cokr+WU2/aCurYL8h6R133PaTvHxDHlZzvHxDFxTBxTbts5Jku6Y0r6idRatmxpv/zyS5aufZk2bVr4cQAAAAAAUlVCg+4uXbq4/PsRI0aEtynte9SoUdamTRuX8i0LFy60n3/+OYF7CgAAAABA7BKaXq7A+txzz7Vbb73VDYhv1KiRjR492hYsWGAjR44MP69bt242ZcqULKnPa9eutccee8z9+4svvnC/H3/8catSpYr76dOnTwKOCAAAAACAJAm6ZcyYMda/f397/vnn3URmLVq0sPHjx1u7du1yfZ2eq9cFDRkyxP2uX78+QTcAAAAAIOESHnRrebDBgwe7n5xMnjw52zbNUh5t0i8AAAAAAJJFQsd0AwAAAABQlBF0AwAAAABQVNPLAQCQ2Us2JnoXio0mdconehcAACg2CLoBAECBmb2UxpPC1KQ2DSgAkOxILwcAAAAAIE4IugEAAAAAiBOCbgAAAAAA4oSgGwAAAACAOCHoBgAAAAAgTgi6AQAAAACIE4JuAAAAAADihKAbAAAAAIA4IegGAAAAACBOCLoBAAAAAIgTgm4AAAAAAOKEoBsAAAAAgDgh6AYAAAAAIE5KxuuNAQAAkLoWrtqa6F0oNupVK5PoXQAQR/R0AwAAAAAQJwTdAAAAAADECUE3AAAAAABxQtANAAAAAECcEHQDAAAAABAnBN0AAAAAAMQJQTcAAAAAAHFC0A0AAAAAQJwQdAMAAAAAECcE3QAAAAAAxAlBNwAAAAAAcULQDQAAAABAnBB0AwAAAAAQJyXj9cYAAAAAEmvVxp2J3oVio1r5EoneBSQperoBAAAAAIgTgm4AAAAAAOKEoBsAAAAAgDgh6AYAAAAAIE4IugEAAAAAiBOCbgAAAAAA4oQlwwAAAAAgia3fkpnoXShWKpZNL1o93Vu3brWbb77Z6tSpY+XKlbM2bdrYhAkT8vTaxYsX23nnnWdVqlSxSpUq2RlnnGHz5s2L+z4DAAAAAJASQXf37t1t6NCh1rVrVxs2bJiVKFHCOnXqZJ9//nmur9uwYYMdf/zxNmXKFLvtttvsnnvusRkzZtixxx5rK1euLLT9BwAAAAAgKdPLp0+fbq+88ooNHjzYbrzxRretW7du1qxZM+vXr599+eWXOb72ySeftLlz57r3OOKII9y2U045xb12yJAh9sADDxTacQAAAAAAkHQ93ePGjXM927179w5vK1u2rPXs2dOmTp1qf/zxR66vVbDtA25p3LixtW/f3saOHRv3fQcAAAAAIKmDbqWDH3jggW48dlDr1q3d75kzZ0Z9XWZmpn3//fd2+OGHZ3tMr/3tt99s/fr1cdprAAAAAABSIL186dKlVrt27Wzb/bYlS5ZEfd2qVavcBGy7e+1BBx0U9fV6rX68tWvXut9r1qxxAb2kpaW5n1Ao5H48t23nNktL2/Vvb9fzzNLT/94mmZm7XhvP7TntS0FtT/QxqVxyK4/8bFc5b1y/LsvfdX808Nxct8fy3FTZHue/uW5dmXyVU9a3jr59w/p14feJfH7ktlTfnuh9WbOmVL7LKaft6enp7r3Xr9sQ8fxd281Cedj+97lUMNsjZ4mNbXts+174x7QmY3u+yyny/Ijcvn7dxoQcU1Esp7xsX1Nue77KKbft/hxYt25L9n20NAu5bbFsj7LvMWxPs/Qo7x3r9vzue+Ec05r0Mvkup91tX7dxp3/g7+/o4Pv77RHXfMzb09Ozv3es23e3j7FuL+RjKrmzVIHVVSO3b9gaKtDv3IK4RxRkvTzZjmnn/2Yvz8sx6XfFihWzxFFJFXRv3rzZypTZdZMJUoq5fzyn10l+XisDBgxwE69Fql+/fgx7j8JSteqIRO8CAAAAAESlTtzI7O2kCbq1RFiwx9nbsmVL+PGcXif5ea3ceuut9n//93/h/1ZriXrPq1evnmsLRSpbt26d1a1b142Tz+2EQHKjHIsGyrHooCyLBsqxaKAciw7KsmgoTuVYsWLFXB9PaNCtVHCttR0t7Vy0dnc01apVc73c/nmxvFb02shecq31XRzohC/qJ31xQDkWDZRj0UFZFg2UY9FAORYdlGXRUIlyTOxEai1btrRffvnFtYIETZs2Lfx4NMrDb968uX3zzTfZHtNrGzZsuNvWBgAAAAAAinTQ3aVLF9u5c6eNGPH3mF2ljI8aNcratGnj0hFk4cKF9vPPP2d77ddff50l8J4zZ45NmjTJzj333EI8CgAAAAAAkjC9XIG1AmSNsV62bJk1atTIRo8ebQsWLLCRI0eGn9etWzebMmVKlhnjrrrqKnv66aft1FNPtRtvvNFKlSplQ4cOtVq1alnfvn0TdETJS+n0d911V9TJ55A6KMeigXIsOijLooFyLBoox6KDsiwaKMe/pYWirQ1TiDTxWf/+/e2FF16w1atXW4sWLey+++6zjh07hp9z3HHHZQu6ZdGiRXbDDTfYRx995CZD0/MefvhhF7wDAAAAAGDFPegGAAAAAKCoSuiYbgAAAAAAijKCbgAAAAAA4oSgGwAAAACAOCHoBgAAAACgKC4ZhsTTUm1//PGHlShRwpo0acKU/kAK2Llzp7tmFy9ebFWrVrWMjIxE7xIAAHGluZ/T0tISvRtIEqEUOx/o6S7G3nrrLTv//POtdevWdtttt9ncuXMTvUsA8kAB9+zZs23//fe30aNHu6UXkbq2b9+e5b9ZVARIDlqOVrZt28Z1mQQ2bNhg69atcx1GwfJB8ZD5v/LevHmz+62AO5WuS4LuYur555+3Cy+80Pbaay/376efftr1dKN4C968+DJLzh5u2bp1qw0fPtyOPPJIa968uZUtWzbRu4YYLV26NNzQWapUKZszZ449++yz7r9TqeUeeb9uo+E+m9zllp6ebr/99ptdffXVNnLkSBfwITHeffdd++c//2ktW7a0tm3b2oQJE1z5pFLQhT2/Hn/99Vfr06eP9evXL+W+Lwm6i6GPP/7YrrnmGuvVq5cNHDjQLrroIttnn31c7xmKrx07dmS5eSmwC+KLLfF0jc6bN8/Gjh1r06ZNs1NPPdVVPpBaNm3aZI8++qiryP/3v/91lfpWrVrZ9OnTbc2aNYnePcRhKIg89dRTrqI4YMAAe/PNN902VSKRfNQYonL76aef7LjjjrOpU6faggULrFKlSonetWJJGV3nnXeerV271t0rVR/p1KmTff/99ykVdGHPrsdZs2a56/Hnn39OyTopY7qLEZ2gSpF66aWXbL/99nNBt377x7hxFe+KYcmSu24HN954o82YMcOlb5155pl2yimn2FFHHRVO4+E8SewXz5VXXula+OvUqRMOuIMVeyQ/jcE//PDDXaNnjx49XNCtisR1111nlStXTvTuoQD567Jz5872/vvvW8WKFW39+vXuXtq1a1cbNGiQ1a5dO9G7iQhqDFm4cKGddtpp1rRpU7v33nutTZs2id6tYmnUqFHWs2dPd39UD6eGVanz6IwzzrDvvvvOWrRokehdRCFdj507d3aZDhoSq3ppqqGJtRhRsKQeFlXYNY5baanBx1B8+YqhgmylLWvcVLVq1eyBBx5wFcNhw4al5PiZovjF89xzz9nJJ59sS5Yssccee8xWrVpFwJ2CzjnnHHd9qSetdOnSdtZZZ7khPrrGcktHRmoIluE777xjP/74o0tP/v333+2HH36wW265xV5//XW77LLLbMWKFe55pJonl3Hjxrn5Fm699dZwwK37rcpSDSgqR8TXmDFj3DXSt29fu/32261hw4ZuuxpCGjRoYH/99Zern7z33ntuYlEUXR9++KGrm1577bXhgPvPP/90nUTPPPOMC8qVsZnMCLqL4ThCpefsu+++7r/V850bBen6QdGvGCp9TpNzKQXyk08+sSlTpthXX33lAgIFB0888YR7Hg00hSdaA4d6xdTyr55RTYaozBV9ESF1+OBKAbfKUz2fqjRMmjTJbVcjCo1bqS2YUq5eOQUJSo9VJoP+fdNNN9mQIUNs4sSJLqgTUs2Ti4I4XYd169Z1//3GG2+4DEH1rGpojxrK1HCCgqfPffXq1da9e3f3b3US1ahRI1z/eO2111x9ZejQoXb33Xe7HlAF5x999FGidx1xsnDhQvddeeKJJ7r/1hCdq666ygXgvXv3dnUi1Vslab8/QyhWli9fHqpXr17o5JNPzvV5O3bscL9feuml0Mcff1xIe4dE+b//+7/QoEGDQkcddVRo/fr1btu2bdvc7x9++CG03377hQ466KDQzJkzE7ynxYe/BleuXOk+9ylTpoQWLVoUfnzZsmWhf/zjH6GqVauGRowYES43JK/MzMxs2zZv3hx69dVXQ6VKlQq1adMmNGHChJhej+T18MMPh9LS0kKNGjUKXXnllW7b1q1bw4+vWLEidNVVV7nn6PpGcnnllVdc2Zx44omhDh06hMqVK+eu0UcffTT0/vvvh2rUqBHq2rVraMuWLYne1SLr888/D1WoUCF08MEHh/7zn/+4bc8991yoRIkSoeuuuy70zTffhH755ZfQfffd58qqXbt2oVmzZiV6t1EAMv/3fbdz5073+9NPPw2VL1/e1Xs6deoUKlOmTKh169ahIUOGhD766CN3jhx33HGhZEbQXcxOYAVS+vLQTeyDDz7Y7WuaNGkSuvjiiwtl/5AY//3vf0PVqlVzX1j777+/C/L8+eJvdp988ol7/JFHHknw3hYP/nP/6aefQocffnioevXqrsKncho2bFjo119/dY//9ddfrqFEgffw4cNDGzZsSPCeY3eNKCqjjRs3hsvQe/HFF8OBtyoQ3vz5810FH6lTxkH//Oc/3b1zn332CS1evDj8PF+h/Oqrr9zjY8aMKfT9RdZyi9aopQq9KvPNmzcPPfnkk6Eff/wx/Jg6L44++ugsDSmIT+CtAKtFixYu0Nb1cuedd7pGq+B35u233x5KT093jSVIPZn/u/789bh9+/Ys9aF169a5a1DfkYpN/v3vf7s6knfOOeeEDjvssHCHUTIi6C7C9OXw9ttvhwYPHuwq596XX37pKukKvtVCGDzhg1867777buiAAw4IvfDCC4W+7yi8iqF62saPHx9q27at+8J6+eWXw8/RzU4/6kVVb7daF/12FJxolT0FZTVr1nQt9/qiUSt/r169XIWjf//+obVr12YJvPVcBeQE3snHX0+zZ88OnXLKKaH69eu7XrILLrjAZRL5yoUqi6VLlw4deeSR7t6te3jnzp1dw0uwgonk9vPPP2f578suu8xdt2effXZoyZIlbpsv86+//trdd59++umE7GtxpDrNwoULs1ybqgv17t071LFjR/d71KhR4cfUWBJ5X502bZoLxJXBkMyV/FSjRv+5c+eGJk+eHDXw1nV04YUXunqLr4v4cvrss8/c4zfeeGNC9h3589RTT4X/7a8lXY/du3d335enn366+z5cvXp1+HmR1+O3334bOuKII0KXXnpp+N6ajAi6iygFTgqYK1as6G5CDRs2DLcI6cS99957QyVLlnQVOqXnRH5pKJ1VJ3uzZs2ypLSiaN3o1IsWDLybNm3qAgKlOgbPiXnz5oXq1q3rgj4UrGADR7Dx69prrw0deuihrnLn9evXz6XVqVc02LuiwFtlp4aR4BcTkqdBRYGYAm0F1H369An961//Cu29996uB/SZZ54JP++1114LValSxWU21K5dO1S5cuXQjBkzEnwUyKvbbrvNfed+8cUXWbZ369YtVLZsWfed6++7v//+u7um9V2sbCLEn3rHVD4qJ1+3mTNnjssiqlWrlguklVmkslIdyFfgg43VaihTcK7rU69FwVBGz1lnnRXKyMgInXbaaeHvPv/dqKwQBd4a6vbOO+9ke72GQ+p++fzzzxf6viN/Ro0a5a5HP/zGf1fqGtx3333d9aghsXrOeeedl6U+5ClrV9ejrt9kvx4JuovoSayW8x49eoRef/1113uiyvgJJ5wQfo6+9G+++WZXsdNJrVQd9cIouNJ4pWOPPdZV/L7//vuEHgviQ70q/kbnW/w1Lu29995zX2i6yalyokqJ0s+VtqXn60sNBUeNGHfccUe4gSOYQaDMg/PPPz/83zfddJOrnKvslGYlwRZdjfH2lXkkl02bNrlezmOOOSY0ffr08Hb1qGmoj1rxg41cqtSrvNXwkuyVCGSl3jaV81577ZUt8L7kkkvcfVSNL+3bt3cZKgr2Bg4cmLD9LW4UPF9++eWu8VINHmr4uOuuu9y4bQV1snTpUjfWXsM9lD7uA24NCznjjDNcJ4Z+qB8VnNGjR7uAWY1SytjSZx38fvPfjcrUVOCtRuY333wz/LjK4vjjjw8deOCBoT/++CMhx4DYzZ8/P9S3b193X/SdOopNdG/016PqNuoo1HPUEKZ5hkTZfrpO1SGkeTNS4Xok6C5iNC5MJ6YmxlqwYEF4u8Zl64YkvkdFKcO60Skg12uU1qgvGVUIlNIaHCuBoke9bSrrK664IlvgrQwHnRN16tRxqa36bw1TQMFRpcK34qrS7YMuX9HQ2CSlSvkvIV2bmjBNAZy/jpV2xeR2yUPlFG3iSZWZ7rN63FNFw5fpmjVrws8LYuK05BYsn2BPqHpjFKyptyYy8Pap5hqfOnLkyCxDvBi2Uzj0OavBS50T99xzjxtqpzpTkBo2NYxH9aKrr746fM9+4IEH3LWrDgoUjDfeeMN9zmpkDA7N8NdDZCqxrikfeKvBUteQesbVgJkKgReyUiOJrj/dFzVmX3XTW2+9Ndt9dujQoeEsFdFQHTWY3X333SnT4UDQXYQoLVEnZJcuXdyXQ7AioBYk9WBqzEPLli1dz7afyEetReoN10yrmsFaLYl+Mi0UvTHcwbRkVSY0vj8y8FaquVoaFRS89dZbWW5oVAz3nP8MlQquHi+lUT344INZejv1paNW+3PPPdf1cCsF2fdwy7hx41xvmq57JJ7Sg9VTo/Rx9XZ6akRRBb1SpUruWhJV2lWmkY0ouv8yPCA1RLsPBnvmcgu8NeO1MskUgGtFEWFccOGXn28A0bWpzC5/HfrvTN1vFZCrYVS9bR5lVXDUOaSJsZRWHmzI8NeShk5pIjtlbkYLvDWMslWrVm5Wa4bhpK6FCxe6wFvZt7omlYUSnFcoODGl7p2+Tqr6bCpdjwTdRYROOh906wYW/JLXrMbarjEPmphAaVT6b02tr9RhFA/BZTSCNykF3kpxVODtx7j5Md4K+tSaHG0cDfaMr1QEA2/1ovhGEQVuqrDrWr3hhhuyvFbzMOg1CvD+/PPPhOw/omcaNW7c2N2DtbxJkIbsqMxUsVBjluZUCPZsa1iPgnbuyalF6ca+JzTy3qr0SF2jmuTQp0oGA2+NXVU2i5/olAbN+In22Sq41r1V99hDDjnEDbHz/DJgGjusx1k6NT4mTpzoAubgOGzfs6k0f5WLGihVBsHrTKZOneq264ce7tS/JhcsWOCGVel7UJ0+q1atylZf0nmi8vbLx6Uagu4iQGu8qjKnE1jp4po8TevYaTY/TaimE1S9ZsEZzK+55hq3Xek8wdkfhZTGoke9pQoGgj1wwcqhUu10PkRLNVfgrfEyCvRQcILXnGZr1XJtauBQj7cPvDVmTeWiMtDSNRrf6+dcUEDOEJDkqzzoHqzyCgbeuqdqeIYqE6pAKqsoSAGZGkO1BFGwooHkpt5PvySY5r3wgnM06PvZT2Ya2eOtYV/qtVF2mu/xRsFSg7Ffqi3a9arKvF+GSvWiyDRVjS/W+G/Vp1Dw33+a00R1Vl9GvmzUIKkhVhra9uGHH7oOI5WRxvAGqVyCjSVIbjNnzszWsBy8HhV4+zHeKnNdn8GYRI3VmuRw0qRJoVRE0F0E9OzZ052gmtFYnnjiCVe5UyVeY5Y0S65fXshTpV6BuSoCkeMIUfToS0tjphSsBXvggoG3vuA0G6vOJ1/x0A1PM4oqGFRvOOlbBb8OtyoVJ510kksVV8+XUh01xtv3tKhFV+Pq1Tuq61yVdLUC+8lEkNyBt1/6RvdcTYynlEiNP1QqpYbxaLJLTXKpmVepPKYe3SvVeO0bt6MN49GwLl23eo7GIQbT0NVTrhns/VJiKDhqNNZnrmvrsccey5Zt4AM//VaDs56rye40xM4PGdG1qfkYyCiKD5WL6qlaEixIGWCauNU3LP/222/hJTP9+PvIoXNIbm+99ZYrP9V5dL3pnueXfguWpU8198vDqc6q++lHH33k5qbS9Ziq90uC7hTmW3900ipg0mLxfiz3448/7irw+jJX0OT5L3u9VievxsMEKwcoepP7+P9WBUK9bJpZN1rgrd4WBX56TrAVUeeMD/zUI4uCoZZ9jRXUdahUflUqVC4av6ZyGDBgQPjaVMVeLcSqhHz33Xes2ZykghWH5557Lhx4++tJDSlq1FL5auya5lNQQKAsFNIjk1tuFXzNj+Kzx/wkP54aKvU9q4aY4DJHwfeL7InFntPnq4wSXWOaGFaTgup+q8q8Grd8I5n/reerF9WnK6uhRJPd6drUPRcFQ9lbwayQYDamD8BySj/WTPNqvNLSUUg9AwcOdGWt1QMUr2hInXqzo2XsqazV461GamVCaNx+69atU/67kqA7xfkgWjcuBUtKdfM0MYh6zdQrFkwr1o1My9ZoYjW1IhF0Fx3BipzK2aeq+sBb46d84O174PwNTr1vOk80Tsrzr9N5FjmDKPaM0k4VeOnaDVKZ6ctF2Sr6kuL6TG65jcN99tlnswXeupbUuKKZWBWg6Twg6Eqd++qTTz7perY1JEdl6DNSlBapWXd9mrJmpNesyvfdd58L4KJNRklPXXwpuFb2lupC+vzVkKmMLV2TyjpRtonvqPDX5o033ujKUEP21FNOA2fBUF1CGZeaXFBZW5o13lMGnsrJZxjkRPdKDXXTb/+eSB1bt251c1wo7lADyy233OLujUoX1z1VnQ9B6ojQGG81TCtzV9+TwQkNUxFBdwrSuM7I8V/6YlBPpVqEgmspq4KgwFup5D59RxNqderUyY0JDS7PgNQWrMCp1Vit+w0aNHCtwkrr8csSaUIY3eR0s9PsyRoTpZkidT4E0++Y1Ce+XnjhBVe5mzJlSrgC4RvR9MWiSoh+gmO8kZzXnJY8Uc+2lhjSShDBtbWDgbeyTZBaghV7fW/qO1YZZPpe9amSvufFr/msxjRNnqbn6Tmsw524clOgrTLzdR3NbaOl+9RzpgBcjSeR40MVFCgbhVVcCp6uFQ2nUo+1VtERZdIpI0EBdXAIW3AYhjK91BCiuqwmWENq8asC3H333e77UAG1/+7U/fHQQw91vdrKNlFGkP9u1T1VPeNaDq4ozHtB0J2C6xnqS1wTsKhyF6QxnjoxNRlP8KYU7PHWzH9nn322my2S9X2LJt+goomZ1Hutyp+GGmiWVt9qrx5tjdNW8K1WZ/V+UzEsXBMmTHDXsuZcCPI9Z2r51fWsVt5HHnkkQXuJnPhGqR9//DFUv359t+a9KvEan6iKoSZ8iTbGO5h1JPTWpAalJauM1Vim8abr1693k2yp7NUL44M63WPVwH3RRRe5yqJmtPco68KnIE5ZfepZDTZe+tVe6tat665ZjeUOzoicqmNGk5k//1VX1Vh5n80l+o5TY5WuJ11jwc9fQZjqtQrUdb9F6lq0aJGrn/px+Z46gHQ9qq6qoSDKxlTWpTL/lGVZVOZUIOhO0TERzZs3dz2Z+qJQJd23CinA1uOqDARpu19+SAE4E2IVTUp31BeZKnp+rLZ6uNWyrFZEper4tZ6VbqfxVRr//8EHH4Tfgx7ugpVbCuk555zjAjU/xj742WuiEU2ydPrpp2fpOUXyUCu9JnVRA5euIV1bmqHaL90YnBhNgbfG6yv43l0aJZKL7qVKizzllFOyTEqqIE73UPVoa16VYM9cJO6riaPebJWRLztleymAO/XUU11Ap+9N3Yd13WqlD8SPvw40WZbG9arhXytzyKhRo1wDiV+x44ILLnBDrdQwou2pPJYXf9eFBg0a5DqD/FBGZZoo00H1ITVKa0iOYhydB1q/vShl+hF0pyCdmOr9GjlypOut1MmpcaFqEdJM5B06dHDpVJHLkygQVwsSLYVFR2RFTo0w6nVRL0zk0jUKDNTgkluKKxXD+HzJaOzgvffe61Idgw0cGlevQEwNYho/6CuFWuZGmSnPPPNMwvYdu++xUeq4VoDQXAmehgMoe0Tp5hovGrncSeT4XiQfHzzrfqhebV2XCsp69OiRJVVS1OitbBVVEMeOHRt+HInnv890vWnSJs2hoGtVAbfqSRpq56lhU2NMWYax4GgCuuBcMLou/LXhl9LTEDhldCkQE/VwK/1f33+qy6hH/KGHHgovZYrU99VXX7mhc2rsUsCt61EdQ8EJC5UxpKE6RS1eIehOIT6AUq+YZpLWCakxRwrCDznkENcipBuTWnGVptO1a9dsY19UgUDREFzuxK97qJ4YBQEqZ/+4r0BqEgoF3VdeeWUC97r4UcVOaaka0qEfP8Oxn6n13Xffda35SnHUb6XRqQw1ppA5F5JLsNIoqhyqrPy9WZkkCriVKucbvhR4+/Fr4udWQPLr3LmzCwY0x4LurepxC1YM/b1VFURd1/fff38C9xY5UWeEhuTtvffeLn1VFfzgkovBRhYUDF0nuiY0TCo4WZ2oMdlfLwrANFZbdRM1THv6fmQ526Lr+uuvd9mXynTQkMjisgRquiGpffvtt/brr7+6f5cqVcr9btWqlR111FH24Ycf2tq1a23cuHHWp08fW79+vbVo0cI2bNhgHTp0sA8++MCmT5/uXrNt2zb3u0qVKgk8GhSkEiVKuN+nn3669ejRw50Lp556qs2fP9+++OIL9/jOnTvdbzWw1a5d2/bbbz/76aef3Ou0DfGRmZnpfm/dutXuuusud82+++67NmXKFLvlllts8ODBds0117hrtlOnTjZ27Fjr37+/7dixw/78809r1qyZTZ482Q466KBEH0qxt2nTJvd7+/btlpaWZitWrAg/Vq5cOduyZYu7N9955532yCOP2BNPPGEXX3yxVahQwT3n0ksvtZdeesm9XipXrpygI8Hu6H7pqRx1H91nn31sr732snPOOccWLVpk//73v23BggXuOSVLlnS/Fy5c6M6FGjVqJGzfEZ2+51Q2t99+u7sG9R04atQod4/1fDmmp1MlLigNGjRw9dKnnnrKfQdu3LjRbX/22WetV69edtttt9lVV11lbdq0sUcffdQOP/xwGzJkiHuulC1bNlwu1FWKXt3okksucedIkyZN7P77789yPRZpiY76kTNNdKbWQPVia0x25GQEGqMUXCJMPZnqeVEaXNu2bd1rtT4orYVFS3Dc4Ouvv+4mHtEEeRpPqmVrlL6q4QXffPNNltcpC0LDEYIpkogfpTRqZnhNZqeeT0/lpHH0mrzusssuCy/rJspc0filyJ4BJIZSHbVWqGb/D96TNT5bNMZQQwM0NrFEiRJuLoVgNpFSWTUWUT06LA+VOpQtpqE6mgjNZyyIeu1U/lpr/euvv3bblMWgdYeVIhs5CzbiL7dx9J56sJWNoqXclGbuyw7xpWEZfgk2rezg5xy64447ssyNIEojViq5Mry0mgpSy9y5c91EhMOHD3f10N3ZsWOHW7ZPaeZ6bV6v5VRH0J3ENBZGszjWq1fPpSxqQiWdzL5CrjGgpUuXzlKhl7ffftstH6abm3405T6KHgVuKntNthWcaELjCjW5kwLvF1980Z0z+kLTeDWdL36NS8SPGro0g7Ufs+ZXCvANHUqde+yxx1zgrUl+tIwNks+vv/7qUlFVjg8//LBr0NRYUD8RpRpQNFxDqZFafzZIk8R07Ngx1Lhx4zxVQpBYvsLXq1ev8EROfuZxPxRENOuuHteElZphVw2ZSpNk9YfCo2FzmsTQl5nWQ9cav36YR05UN9I9V8sWCenk8afgWg2X+tx13age4idzjRyyo/H0mpBQ35lFYXmo4kJ1Ti3Bp6EbGpKjyQlz69TZ+b/rTg2Wuo+qMay4IOhOAZqESTMZ6+TUzUhjzHwgrQqfJpxQj1qQKnlar9u3IKFo8ZOQ6IvMz7Ya7ElTD7hmt/eVQ/XGqSeGimHhUFmoEqiWe5XB4MGDs7Xi+sBbX1RaXog1YZOT5kto2bKlK0dVLIKZCT7rSC326ulWlskDDzzgMhhatGjhrjtm3E1OaqhUJoMaryPLUxM4qby1vGZw7gxP360KznU+XHrppe6/PQK5+FKngzIL1AmhbCJdXyorVdyDWQk56d69u2t8VjmjcGgeC/Vuq/NI5RRsxPJ8kKYVH+goSh3KslS5KjNIdZ68yszMdNer7p+6fotLlhBBd4pQy6BS3o499lh3gmoiNQXaml6/WbNmbvZUtfKSwlj0KhjTp093S2qot9pX6FRZ1Lqjmo1eQwj8l1QwsNPkP+rp7tOnj5s1+8MPPww/RsWwYEVr1dX1qM9cLfcaCuKXBQvSzMeamVUpdawLm5xlqgpjo0aNXOaI7r1vvPGG2657rb/elKmgdWYVdCvQ1jWphpTgkmFIHupFU9CsRmzdQ322mO8p1b1TPd1++U3/vRrZk6rrN4j7auHQMm2q6CubSI3JmnwyOBN5btezVhXQ/TY4uSHiT/dRn2quCSeDs5p7DHlLLYo/tJLSVVddle+Gkrfeest1DBWXbDCC7hSkFkONS1Jr7aOPPup6OjU7sp9an8C7aFDF78wzz3RjttUbqhbFYEv+n3/+6QJvpTaq1T9ytvKcUDEsWP5z92PqVZlT2flKuhrL1DCmmY8///zzbK9XxT2y9xTJQ9ecrj39+CED48aNC1cS/dAO/VvXlgJtvYa5NJI3NVmNIuqlVqq47qPBcfj+/qntCsrViKKg3N83+X5NDmqs1LWo9X6DQ6Z29/2m8lPZIrFjvPWbuUtSk28cUcaJ6qda4jTysVisKkb1H4LuFBI8mbW+r9KkdPNSGqN+KwWS5WiKBl/h0xJSGkuqVuFo49XUO6rxaUoz19Jx/hwJniu0HsePr4Crl0VjerUkjXpE1Uvm1+xVJXB3gTeSR26Vdt13IwNvj3H5yU9Le2liuzZt2riy9PfGYENlsLFEAboqlWrUDgbeNFwmRvD7Tb1rmi9BDdIaxqNhING+/4Iot+QKvDXxb7QebyQ/dRYceuihbo4T5B1Bd4qJ/DJ57bXXXCVCNzBN8hO5LjdSj3pd1AujiuEXX3wRNbVRFUbf660yV+CtMaU5Bd6IH03io0q55lZ48MEHXfaJJtDSNan1SEVl6ANvrev8ySefJHq3EYW/1tSYpXkRVH7BVnw/I7nKWuWrNFfReurHHXecG+aD5C1b9WxrvPZHH30U3h4MuBXIqRFbwXlk4K1ZdjX7MoFbYvjP3ZeNGkeU0qrrVA2dCryZlTx1Am8F3H5Wc6RmPfXggw92q7NIcDLfnHqzFzGPAkF3UaCJRBR0zZkzJ9G7ggKg8duq5KknzQfOwZRGVRyrVq3qJkXz6Vk+8C5btqxLNSfgjj99xqqwawIRNZIEl2jTkkLp6elu9mP/ZeQDb43vVvBN+nFy8ZV6zaCrhkxV5DV0Q+V42223uZnMPU36oswGVRq1UsSRRx7prj0q/clL90r1zKhh0gveJzX3hcpaZaoGz+DEhso8UhaLGjb9MC4UPi2L2rx5c9dTGrxu1fngA2/NgeJporWvvvoq29h7JJ6yMhVw724sPpKXOhe0upKvh0ard/rvVTVW33rrrS6zoTjXTwm6iwjGmRWtG5kmyvNlGrxBafIfVe7V66LJJxSgBwNvfYmp0vjuu+8mbP+LssgUfwXdhxxySOjqq68Ob1MLvtL9R44cGV6L1Afe+q0sBSbxSU4KrDVfxvHHHx96+eWXXcqqshcUbF1//fVZGjY1TEAzrypzQUE3wVhyU4OIGlE0XCeyZ0ZzY+i+qUm2nnjiCdeoqXtwsMdbAd+zzz6bkH3HLuopU0aJlsQM9pDqPqxGagXeJ554orvHalk/fZdqWbfINaGRHMgaSR1aBkwTpwXdeeed7r6p375ulFNA3alTJzcRdHFH0A0kEfV+qhKvmY8jb2CjRo1ys67q5qdKhIK98uXLuwllfOCtHpnIdFjsOfWeaAZ4pZ6qt9o3iKjirnGFmo1V+vXr52bV1fhP35OtMlR5+rW6kXiaVT5y2RpdQ5onQ2O2tca2p15uVSzUC6oMhmDgrddoLHdxmggmVanXU+up6xqNdn3rviq6bpVGrll5lcGi/45s1CZYKHy+DBYuXBg644wz3PwYkYG3VhaoUqWKa1xRRpH+HcxAAhA7fcdpWI4mlfzyyy/D2/3KHrpXjh49Ohx46/4YOQeV5py6//77s6zLXhwRdANJRJV43cSUuhp541Irv4IBH8wpaFAapJZM+c9//pPtvagYFgytwasy0eRoSt1/++23w2WjL5nOnTu7nk5lIaiHW+OAg5PDqHdMX1gTJkxI6HFgl8cff9wF0cOHD8+SdqoGK63LrF5PT7OzqkzV4KXhHAq8lYasMdxILbp/anLKpk2b5qn8tCqIsoq0vBgKX+RcJrrf7i7w9sPt1Hh2ww03cJ0CBUDX3QcffOACZ6WTa64hX7/UUqjKvNSQSM1nE9mYraWN1cutzqT58+eHijuCbiDJqCdGQYFfVztY2Yic/Ofpp58OlStXzlU0UPC0zrmCriuuuCLHWceVWaDl+1Rm9957b5a0VfWyaJyh0pWpvCcHTZLWo0cPF1A99dRTWQJvDcvw15qCcpW9KhJqRPnjjz9cxUK9aF27dqUCkYLUcKLrVD0uweUXI82dO9elJffu3dv9Nw2YiaFyUBkEh24EA281gir7S/fdID2HIXfAngsulaiOA02e5gNvXz99//33XQOY7q2nnHKKm2BUk8VqeWN1SKiH/LvvvkvwkSQHgm4gybz33nsubVw9qxpTKj4lJ9jzrXHBqnSceuqpWSb9QcHQl0qdOnVcwK0KnueDaqVcKbVfs5drDWc1frRv396tGauMBfVwa3yhVhVgspjkoiBa47E1FECpxJGT2mn4hsryvPPOy5I6rgYUbVeZaowvUoO/b2q265NPPtk1uDz55JNZltj0z1m2bJmb8Ee9Nz7lHIkxaNAgV5H/5z//GZo9e3a2Rmg1hKkHTeUZzFABsGeizUbuA2+//KkPvEV1JPVoa64hXbP6UYOY6qj+2gVBN5CU/IRoWpoo2pg0TZqmySs04Y/Sn1FwfOVbrbTq2QyOYfKVPQXcTZo0cWWkSdSUaaCla1Qe/gtHk/potmSyEJKDykGzHGuWf7W6q7FEZafe7MgebwVeqjCowcXzS76p183PoYDUo3JU74syFjTpYfD+qvPilltucRPnDR48OKH7iV3uu+8+NzZb82IEA29/vT722GOugUS9acpgALBn1NioVXI0lC5yEkIN9/A93gq8lQHo60x6bMGCBW5JRnUeaUgP67BnRdANJJFgGuM111zjgreaNWu6mZTnzZsXXnpB68mql04zK3vFeXKKeLTyamkatdxGUkCmydOOOOKI0OWXX+7KSCmQyjZQ6rK+bNSLplZgBedIvFdeeSV0wAEHhDIyMlx5qZKuCroCaJWdhgdEBt7q0dZY/Lfeeiv0wgsvuIwSlbvKGKkneH+cMmWKG7/vG8dOOukkV96auV5LgymDxSO1vHDk9jnfddddrkHzwgsvzNZrpjkWlFF08cUXu4Y0AHvWKOk7DvTTunVrN5xKY7d9xp/upfpvdTxowsJg4I3cEXQDCeDHZO/usQceeMBVBH3lUDc4pdIpgFALv0fFsGBpvKfWatZkPZFLhWkpsHbt2oXHGapHXOWjma0JyJKPJkHTBGiqlCsrRLOsagJCVeI127Fa8rXWug+8fcu8hgQcdthhrmw1dEBZD4xLS12RlUJlK+hcOO2009wEQcpK0cR5qnR63FcLh88gUvq/lmxTg7PmVAimr/rMLg358NehJmlSwK1GMQB7TkOtlNGl7z3Na6HrS0Md9R2qxuq+ffu6Mduqp6qDQcuAqY4avFaRszT9nwGIu+XLl9ugQYNs8ODB7r937txpJUqUyPIcXY5paWm2bds2K126tNv2zTff2I8//miff/65e80JJ5xgTZs2tcMOO8w9npmZaenp6Qk4oqLt2GOPtRUrVrjPXmUS/JxXrlxp1atXDz/3nnvucT/vvvuunXLKKQncawSNGTPGLr30Urv++uvthhtusH333ddtnzp1qp144ol29NFH24cffujK+eabb7YXX3zRHn30UevRo4eVKlXKXYdjx451Zd28efPw65Fa/H1169at9u9//9vOP/98q127tntMZVyyZEnbsWNH+J4r3FcLh/+cf/rpJzv55JNdGena0zV5wAEH2AUXXGB33HGHe+7AgQPtiSeesC1btljLli1t3rx5tmbNGvviiy/soIMOSvShACl/j5TNmzfbkUceaatWrbJrrrnGunXrZhMmTLCPP/7Yxo8fb6tXr7YWLVq478T99tvPHnnkEWvYsKH77mzXrl2iDyW55RKQAyjAXhY/TlvLmXjBGVZ9T4xSXDV+Tb0weXlfFCz/mWosocoruCRNsMc7SONA1RNKT3fyUCaCyk8ZC7/++muWx7Q8mFLHNTGaL1MNG9Dkaurx1uRqjNtOHTn1SOv+6q9nDRk57rjj3PhgpSH77cHX0rOdGLpvalnGDh06uOFTMmPGDJfdpWXeZs6cGX6u5mW47LLLXHaChnwEZzYHEDstOasx3MHJ0/T9p3HbGpKl7BN/b9QyfMoQ01KpqvP4LEz9btu2bbYlw5AVQTdQSJQ6p4mblKaj2VijBd4KuJXOozTyr776KkF7CtGEIJooRJV0pZQHyytYOVc5KQ1LKcqRs2AjcVavXu0qEpowS8vwqWz8taZJ1ZQyru1BPvDW6gGPPPJIljHeSE7B4Thff/21mwRIqY7Byp/K8eijj3YzXWspGxorE8tfh74cVIlXBV5LD3lq9NS1+9xzz7khH8Ey0/1XQ4CYpAnY84BbAbNW5FDnQWTgrbltFHgPHTo0W0O0Vg/Q9akx30pJV0MZckfQDcSRKgbBAE2zOWpGZL8MiqcKhSqPHTt2DNWqVSs0efJkKoZJQJX3ChUquLFMw4YNy/b49OnT3bqUaiRhEp/ko/HaN954o7veFICLJrdT77dWBvBrNQcbvhR4d+nSxU1gqMAdyStYbioz3TtV1mo0UWXRz0yusYd6TL2o3FcTRw0easyU4PeilgarUaNGOIi+6aab3EShI0aMCG/Tb43hBlBwNM+J7pm6/pT9pYboYEafD7xVD1LgHa0nW8+nhztvCLqBOFHlXTcqVQbzEnirx1STxGhmXSqGyUPLX/i1J8855xy3NNjUqVPdWr6akEvBGRNspUbgfeWVV7oZV1u1apXr2unLly9nqEAKOffcc13DmJb5Um/L888/765LbfONYVpmkftq4vzwww8uu0SzIftZkH2jiVZ7UEaRKviazE7L+CngDmYOKQPl+uuvp3IPFCBdYxrOqKFWWpFFkxWqxzunwPvhhx8OX4O5TQiM6Ai6gThQZcIv+aWf888/P0uFL6fAW4E6ko8CNI0fDK7DrZZhLTukMU5IjcBbM/9XqlTJpSF7BGKpTQ1gderUCT3++OOhNWvWhBvKFOBpyMfixYsTvYv4H/VgK+NAMx77wNt/76mRROO31cM9ZsyYLOsDK/NL40u1UkRO82oAyB8tn6mVOqZNm+Yy9xRc5xZ4K+uPxq/8IegG4kTLD6nF/qyzznI9pQrQgoKBt8bEeEzmk5zWrVvnKvAad6gf9ZwxpjB1KFVcvWiaU0EBOOO1i4YXX3zRjf3VsAGZMGGCC7i1RJzusZ4vbxpZEjsMQIFz9erVXeCteU58hV5juLVGusaGBseOaoiPhl1pmcz58+cnZP+BoijYU605FZRJojHdmtBQddZogbeyxFRnVXYKYkfQDcTR8ccf725SqlCol02p5sFKn4I4Bd5+HWGPtB0gvqnmWm+UGcpTS7QGyXfffdfNnquxwhqa4wNuNYp56gVXoyf31cQJTtAUDLz9GG81kPiJDzUEpE+fPqELLrgg1LhxY5dVpMkPAeTfuHHj3LhsZQd5vj6qFTu0Hvfs2bNDq1atCq/0EBl4q6NBk1LqeYgdQTdQwHQT85XDZ5991gXdr7zySuiuu+5ylX2NP4wWeGupIlUyABRO4H3zzTeTrZCCgj2eSolU0K35MJT6qOE6wYBbQ0PUU6pUcz9xHuLvrbfecvNf5DSj8W233eYC73bt2oXLU9kKWhJMjdX77befS2fV8mBz5swp5L0HipaPP/44PDROjVq9e/d215WfN+Gnn35yE8L6FT1WrFiRY+CN/CPoBgqAKu6RawH7SoTSdjSWTSl2uQXeqlzosQ8//LCQ9x4ofoG3Au7IddiR/D3c6sXWZFzBcfnqOVVZatxvMMhT76ke0zhiBYAo/Aq+KvIaYjV8+HD3PResvN95550ujTUYeHuayFABAZV9YM/vn2PHjnX3R82Z0KtXr1C9evVCTZs2dZOo+UYtLY2qOU98T/jKlStdA9hee+3l5ijiWtxzBN3AHlKvimZ91Bqw6tnW2oVBo0aNcq2F6pFRT4sC7xIlSmQLvPW6SZMmJeAIgOJHk24p4M5tFnMkXjAlfO7cuS5QUzB34YUXhgNv3Vc1M722K1tIFUwthaMAXfNqaFZzFG4FX2OzVR4nnXSSG4+ttH+t96sVIBSAK4VVHnjgATfL/DHHHBNONWfcPVCw1ID15ptvuhRyTZqmwFrDHpUqrkD86quvDg0YMMCN577nnnvCPeC6TpWtqUkOmeh3z6Xp/wxAvp188sn20UcfWfXq1W3lypV20kknWYsWLez++++3UqVK2ZIlS6xz587Wvn17Gzx4sPvvESNG2L/+9S8799xz7aWXXrK0tLQs75mZmWnp6ekJOyagOOA6S53y6dKli/30009Wo0YNmzt3ri1btszdewcMGGCHHHKIbdu2zf370UcftdWrV7vX6D58xRVXuJ/I90P8bN682T788EO77bbbrGzZsu77TmXy8ccf23/+8x/75Zdf3PflscceaxdeeKE9//zzNmPGDDvggAPs2WeftXr16iX6EIAiZ8uWLfbBBx/Y1VdfbfXr17fhw4db06ZN7YknnrC3337b3V//+usvO+aYY+z999+3cuXKubrpmjVrbO3ate412DME3cAeWr58uas8bNiwwU499VRXsfvkk0/cDa53796uwjdu3Djr16+fzZ492/bZZx/7888/XUXk7rvvdhXH9957L9GHAQBJSffQV155xR555BE788wz3T134sSJ1rdvX2vbtq0NHDjQWrZs6Z7766+/2qZNm6xkyZJWtWpVq127tttOwJ24Cr7KYPTo0XbwwQe7xpIFCxa44Hry5Mnuu3Dnzp22ceNG97rTTjvN3njjDStRokSiDwEocrZu3eoC6muuucbdH3VfVeCta/Lnn392HUOtWrWym2++2TVw6trkWiw4BN3AHtixY4er3Kl18IgjjrDSpUtbnz59XOv9gw8+6ILvP/74w7p162aPP/64XXnllTZkyBDXA67XDB061Pbdd193AwQAZKUAunXr1taoUSMbO3asu8d6b775pl188cV2/PHH21133eXuwdGomhOZTYTCq+Bfe+21VrFiRVd+CryDjSCvvfaazZkzxzVCq2zVE+6fAyB+1+V1113nrstXX301fM3pfqt6baVKlRK9m0USQTcQI6XaqGKgXuuGDRu6Xu6DDjrIBdFt2rSxdevWuRRHVQbnz5/v0scVcGt79+7dXQqkv6EpDU8pPELFEEBxF7wPKjBTr3aTJk1cD7d6R1VhLFOmTPi5gwYNsltvvdXOP/98u+mmm1wvDZKzgl+5cmX3fdisWbNsz1u0aJEr17322ish+wkUJ3m9LlGwCLqBGCiw1vjsefPmuTEuqhQqHe6xxx5z49BUQVTgvWrVKnvooYdckK2e8O+//95+++0316udU28MABRHGu+r8YRKFfeCaY1nn322TZ8+3aU/VqhQIZxhJN9++62bL0ONmhreowZOjT2kETN1KviUFZD46/Lll18myyTOGOAE5JHGnmncoFLgnnrqKddL3b9/f3vnnXfceBhRK/1XX33lxspoDPfTTz/tKoia0Of0008n4AaAAAXLmgitXbt2bpjN+PHj3fbgOEJNOKnAXL3Zfry2gnLR/VX35WeeecYN5xk2bJjbThCXPNSDfcopp7iyUWP1RRdd5BpZPMoKSOx1qTkVNL+QMjgRPwTdQB4Dbo0rbNCggUsdP+uss9y4bE3wU61aNTdpzIoVK1xPeM2aNW3atGku8L799ttdZdD32qhnHACwi2Yi173xH//4h+t10cRbxx13nH3xxRfufipqsOzRo4cLqv1EanqNVoLQuG5VGLVqRK9evdxka+oVR3Khgg8k53XZqVMne+CBB1yd1Q/dQXwQdAO7oZ6VDh062NKlS93Mjocddlg4tXHWrFku4NZMj5ro5+ijj3a92z7wVsqOZijX0gzqkWH2XAD4m+6nhx9+uEsbV7Cse6yW/9IwHvVsv/7661a+fHm3XRNyKRjXGG/1jKuyqDHdmrhSQ3dOPPFE9566VyP5UMEHko+yN9WR9OWXX7p5ihA/RADAbihY1uy4CrQ1gZrSykXjunv27Gn77befnXHGGa5CqOeo91trcGu5BaWaq0dGaZMajwgA2MVn/mhyyc8++8xeeOEFO++881zlT4GZ7qEKvDVWW0vb3H///W62awXZ6u3W8oua9fr//u//3Pto4sqMjIzw5JRIPlTwgeS8LtXwifhiIjUgj+MO77vvPrfcl2bK7dq1q0uPU8Ct8d3qeRGtO3rLLbe4HptPP/3UTQykFEmlTWpSNQBAVhs2bLDevXu7HuoxY8ZY3bp13XYtt6h7qBo6NTmlUtAvueQSF4hrqZvt27e7YT7yzTffuAmBNGZYa3jXqlUrwUcFAMDf6OkG8kBLfGnSNPWoaP1tTfyj8d0jR44MB9yisYhai1u+/vprNyurKn8+4GZMNwBkpR4W3SM///xz9yOaI6Nbt24u02jo0KGuh1tBtoLzOnXquIBcAbfmy9A47uuvv95++eUXNwMvATcAINnsGpgKIE+B95133mlly5Z1y4FpDHft2rXDjyug1phtjS1USrnGdUfOysqYbgDIThOhKbV84MCB1rx5c7vhhhvcRFvKJNJEarp3Ki1ZAbgmr/S94UpT/vjjj924b2UXBRtBAQBIFgTdQIyB90033eQm+lHgrTGH6gFXqqMqhUolV4+MKoUHHHBAoncXAFKGZrfWUJyOHTu6++mTTz7ptunfPpXcj9/2jjnmGLcutyat1A8AAMmIoBuIkSp2d9xxh0sdV+Ct35r0Z/369fbss8+6iX009ltLjAEA8ubiiy+2sWPHurW633nnHTeBmufHbgfp3qtsonr16hXyngIAEBuCbmAPxniLAuytW7e6Xm8tD6YJ15QaGawUAgBy5ofnaGy3Vn3QcozBoDsa7q0AgFTB7OXAHs5qrl5urRUr+rdmLw9WIgEAebNs2TJr3769a9h888033dwYAACkOoJuYA9piZp7773X9t9/f7vqqqvcNgJuAMgfpZdr8rRhw4bZNddck+jdAQBgj5FeDhTAGG/1cJcpU8b9NwE3AOTf0Ucf7ZZkpE8AAFBU0NMNAACSysqVK6169eqJ3g0AAAoEQTcAAEhKTEYJACgKyIEFAABJiYAbAFAUEHQDAAAAABAnBN0AAAAAAMQJQTcAAAAAAHFC0A0AAAAAQJwQdAMAAAAAECcE3QAAAAAAxAlBNwAAAAAAcULQDQAAAABAnBB0AwAAAAAQJwTdAAAAAABYfPw/+tfaVHl2uTEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "att_test = att_extractor.predict([X_te_f, X_te_lab])\n",
    "att_df   = pd.DataFrame(att_test, columns=X_train.drop(columns=['labtype']).columns)\n",
    "att_df['labtype'] = X_test['labtype'].values\n",
    "\n",
    "\n",
    "for lt in (0,1):\n",
    "    mean_w = att_df[att_df.labtype==lt].drop(columns=['labtype']).mean()\n",
    "    ax = plt.figure(figsize=(10,4))\n",
    "    # sort the mean weights for better visualization\n",
    "    mean_w = mean_w.sort_values(ascending=False)\n",
    "    mean_w.plot(kind='bar')\n",
    "    plt.title(f'Mean per-feature attention  labtype {lt} '\n",
    "              f\"({'post' if lt==1 else 'pre'}-G-CSF)\")\n",
    "    plt.ylabel('attention weight')\n",
    "    # make the axes size thicker for better visibility\n",
    "    plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "    # use gradiend color for bars\n",
    "    plt.bar(mean_w.index, mean_w.values, color=plt.cm.Blues(mean_w.values / mean_w.max()))\n",
    "    \n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_hspc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
